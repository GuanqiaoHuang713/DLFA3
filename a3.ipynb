{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Pre-Processing Data ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I load the Google Stock Price dataset to preprocess the data for further analysis and model training. First, I handle the formatting inconsistencies by replacing any ',' symbols present in the data, which are often used as thousand separators. Next, I convert the relevant columns to float format. Following this, I apply normalization to scale the values between 0 and 1. Normalization is an essential step to ensure that all features contribute equally during model training, preventing features with larger numerical ranges from dominating the optimization process. This step also improves the numerical stability and convergence speed of machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Read dataset\n",
    "train_path = \"/home/hgq/Projects/DLFA3/dataset/Google_Stock_Price_Train.csv\"\n",
    "test_path = \"/home/hgq/Projects/DLFA3/dataset/Google_Stock_Price_Test.csv\"\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "train_data = train_data[features]\n",
    "test_data = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train=(873, 30, 5), y_train=(873, 5)\n",
      "X_val=(187, 30, 5), y_val=(187, 5)\n",
      "X_test=(188, 30, 5), y_test=(188, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Preprocessing\n",
    "# Transform to float\n",
    "for column in features:\n",
    "    if train_data[column].dtype == 'object':\n",
    "        train_data[column] = train_data[column].str.replace(',', '').astype(float)\n",
    "    if test_data[column].dtype == 'object':\n",
    "        test_data[column] = test_data[column].str.replace(',', '').astype(float)\n",
    "\n",
    "# Combine train and test datasets\n",
    "combined_data = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "combined_scaled = scaler.fit_transform(combined_data)\n",
    "\n",
    "# Look-back window size\n",
    "look_back = 30\n",
    "\n",
    "# Create input-output pairs\n",
    "X, y = [], []\n",
    "for i in range(look_back, len(combined_scaled)):\n",
    "    X.append(combined_scaled[i - look_back:i])  # Input: Previous `look_back` days\n",
    "    y.append(combined_scaled[i])               # Output: the data of the current day\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "train_end = int(len(X) * train_ratio)\n",
    "val_end = train_end + int(len(X) * val_ratio)\n",
    "\n",
    "X_train, y_train = X[:train_end], y[:train_end]\n",
    "X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "X_test, y_test = X[val_end:], y[val_end:]\n",
    "\n",
    "# Output shapes\n",
    "print(f\"X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"X_val={X_val.shape}, y_val={y_val.shape}\")\n",
    "print(f\"X_test={X_test.shape}, y_test={y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step that I deployed LSTM for stock prediction, I applied grid search to optimize hyperparameters such as learning rate, optimizer type, hidden layer size, number of LSTM layers, and dropout rate. Furthermore, I also utilized early stopping to prevent overfitting. Grid search evaluates all combinations of hyperparameters on the validation set, saving the best model based on the lowest validation loss. The best model is reloaded for further evaluation or testing. This approach ensures systematic exploration of hyperparameters for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1448, Val Loss: 0.2135\n",
      "Epoch [2/50], Train Loss: 0.0639, Val Loss: 0.0429\n",
      "Epoch [3/50], Train Loss: 0.0418, Val Loss: 0.0474\n",
      "Epoch [4/50], Train Loss: 0.0314, Val Loss: 0.0433\n",
      "Epoch [5/50], Train Loss: 0.0275, Val Loss: 0.0353\n",
      "Epoch [6/50], Train Loss: 0.0243, Val Loss: 0.0283\n",
      "Epoch [7/50], Train Loss: 0.0212, Val Loss: 0.0229\n",
      "Epoch [8/50], Train Loss: 0.0184, Val Loss: 0.0190\n",
      "Epoch [9/50], Train Loss: 0.0158, Val Loss: 0.0162\n",
      "Epoch [10/50], Train Loss: 0.0129, Val Loss: 0.0151\n",
      "Epoch [11/50], Train Loss: 0.0098, Val Loss: 0.0113\n",
      "Epoch [12/50], Train Loss: 0.0074, Val Loss: 0.0064\n",
      "Epoch [13/50], Train Loss: 0.0065, Val Loss: 0.0047\n",
      "Epoch [14/50], Train Loss: 0.0049, Val Loss: 0.0049\n",
      "Epoch [15/50], Train Loss: 0.0045, Val Loss: 0.0028\n",
      "Epoch [16/50], Train Loss: 0.0105, Val Loss: 0.0058\n",
      "Epoch [17/50], Train Loss: 0.0035, Val Loss: 0.0024\n",
      "Epoch [18/50], Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [19/50], Train Loss: 0.0042, Val Loss: 0.0023\n",
      "Epoch [20/50], Train Loss: 0.0044, Val Loss: 0.0020\n",
      "Epoch [21/50], Train Loss: 0.0029, Val Loss: 0.0034\n",
      "Epoch [22/50], Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [23/50], Train Loss: 0.0031, Val Loss: 0.0022\n",
      "Epoch [24/50], Train Loss: 0.0026, Val Loss: 0.0024\n",
      "Epoch [25/50], Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1377, Val Loss: 0.3200\n",
      "Epoch [2/50], Train Loss: 0.0785, Val Loss: 0.1721\n",
      "Epoch [3/50], Train Loss: 0.0362, Val Loss: 0.0600\n",
      "Epoch [4/50], Train Loss: 0.0368, Val Loss: 0.0562\n",
      "Epoch [5/50], Train Loss: 0.0298, Val Loss: 0.0370\n",
      "Epoch [6/50], Train Loss: 0.0232, Val Loss: 0.0199\n",
      "Epoch [7/50], Train Loss: 0.0164, Val Loss: 0.0167\n",
      "Epoch [8/50], Train Loss: 0.0126, Val Loss: 0.0150\n",
      "Epoch [9/50], Train Loss: 0.0111, Val Loss: 0.0123\n",
      "Epoch [10/50], Train Loss: 0.0110, Val Loss: 0.0125\n",
      "Epoch [11/50], Train Loss: 0.0102, Val Loss: 0.0123\n",
      "Epoch [12/50], Train Loss: 0.0106, Val Loss: 0.0189\n",
      "Epoch [13/50], Train Loss: 0.0102, Val Loss: 0.0137\n",
      "Epoch [14/50], Train Loss: 0.0088, Val Loss: 0.0113\n",
      "Epoch [15/50], Train Loss: 0.0095, Val Loss: 0.0149\n",
      "Epoch [16/50], Train Loss: 0.0086, Val Loss: 0.0111\n",
      "Epoch [17/50], Train Loss: 0.0084, Val Loss: 0.0103\n",
      "Epoch [18/50], Train Loss: 0.0079, Val Loss: 0.0122\n",
      "Epoch [19/50], Train Loss: 0.0087, Val Loss: 0.0123\n",
      "Epoch [20/50], Train Loss: 0.0080, Val Loss: 0.0088\n",
      "Epoch [21/50], Train Loss: 0.0077, Val Loss: 0.0098\n",
      "Epoch [22/50], Train Loss: 0.0084, Val Loss: 0.0144\n",
      "Epoch [23/50], Train Loss: 0.0080, Val Loss: 0.0092\n",
      "Epoch [24/50], Train Loss: 0.0088, Val Loss: 0.0100\n",
      "Epoch [25/50], Train Loss: 0.0079, Val Loss: 0.0135\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0905, Val Loss: 0.2312\n",
      "Epoch [2/50], Train Loss: 0.0600, Val Loss: 0.1400\n",
      "Epoch [3/50], Train Loss: 0.0448, Val Loss: 0.0750\n",
      "Epoch [4/50], Train Loss: 0.0391, Val Loss: 0.0492\n",
      "Epoch [5/50], Train Loss: 0.0338, Val Loss: 0.0357\n",
      "Epoch [6/50], Train Loss: 0.0304, Val Loss: 0.0203\n",
      "Epoch [7/50], Train Loss: 0.0256, Val Loss: 0.0141\n",
      "Epoch [8/50], Train Loss: 0.0230, Val Loss: 0.0087\n",
      "Epoch [9/50], Train Loss: 0.0202, Val Loss: 0.0142\n",
      "Epoch [10/50], Train Loss: 0.0177, Val Loss: 0.0140\n",
      "Epoch [11/50], Train Loss: 0.0167, Val Loss: 0.0118\n",
      "Epoch [12/50], Train Loss: 0.0170, Val Loss: 0.0107\n",
      "Epoch [13/50], Train Loss: 0.0158, Val Loss: 0.0150\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1152, Val Loss: 0.1807\n",
      "Epoch [2/50], Train Loss: 0.0343, Val Loss: 0.0369\n",
      "Epoch [3/50], Train Loss: 0.0431, Val Loss: 0.0566\n",
      "Epoch [4/50], Train Loss: 0.0314, Val Loss: 0.0403\n",
      "Epoch [5/50], Train Loss: 0.0286, Val Loss: 0.0280\n",
      "Epoch [6/50], Train Loss: 0.0248, Val Loss: 0.0212\n",
      "Epoch [7/50], Train Loss: 0.0223, Val Loss: 0.0226\n",
      "Epoch [8/50], Train Loss: 0.0202, Val Loss: 0.0230\n",
      "Epoch [9/50], Train Loss: 0.0187, Val Loss: 0.0183\n",
      "Epoch [10/50], Train Loss: 0.0163, Val Loss: 0.0098\n",
      "Epoch [11/50], Train Loss: 0.0088, Val Loss: 0.0173\n",
      "Epoch [12/50], Train Loss: 0.0054, Val Loss: 0.0128\n",
      "Epoch [13/50], Train Loss: 0.0112, Val Loss: 0.0057\n",
      "Epoch [14/50], Train Loss: 0.0049, Val Loss: 0.0226\n",
      "Epoch [15/50], Train Loss: 0.0043, Val Loss: 0.0210\n",
      "Epoch [16/50], Train Loss: 0.0035, Val Loss: 0.0196\n",
      "Epoch [17/50], Train Loss: 0.0041, Val Loss: 0.0152\n",
      "Epoch [18/50], Train Loss: 0.0048, Val Loss: 0.0220\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0801, Val Loss: 0.2180\n",
      "Epoch [2/50], Train Loss: 0.0493, Val Loss: 0.1438\n",
      "Epoch [3/50], Train Loss: 0.0429, Val Loss: 0.1086\n",
      "Epoch [4/50], Train Loss: 0.0404, Val Loss: 0.0888\n",
      "Epoch [5/50], Train Loss: 0.0375, Val Loss: 0.0691\n",
      "Epoch [6/50], Train Loss: 0.0343, Val Loss: 0.0408\n",
      "Epoch [7/50], Train Loss: 0.0271, Val Loss: 0.0175\n",
      "Epoch [8/50], Train Loss: 0.0231, Val Loss: 0.0105\n",
      "Epoch [9/50], Train Loss: 0.0141, Val Loss: 0.0223\n",
      "Epoch [10/50], Train Loss: 0.0100, Val Loss: 0.0201\n",
      "Epoch [11/50], Train Loss: 0.0102, Val Loss: 0.0213\n",
      "Epoch [12/50], Train Loss: 0.0103, Val Loss: 0.0138\n",
      "Epoch [13/50], Train Loss: 0.0089, Val Loss: 0.0104\n",
      "Epoch [14/50], Train Loss: 0.0095, Val Loss: 0.0287\n",
      "Epoch [15/50], Train Loss: 0.0090, Val Loss: 0.0086\n",
      "Epoch [16/50], Train Loss: 0.0081, Val Loss: 0.0174\n",
      "Epoch [17/50], Train Loss: 0.0113, Val Loss: 0.0262\n",
      "Epoch [18/50], Train Loss: 0.0103, Val Loss: 0.0131\n",
      "Epoch [19/50], Train Loss: 0.0085, Val Loss: 0.0231\n",
      "Epoch [20/50], Train Loss: 0.0104, Val Loss: 0.0134\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1051, Val Loss: 0.2263\n",
      "Epoch [2/50], Train Loss: 0.0587, Val Loss: 0.1005\n",
      "Epoch [3/50], Train Loss: 0.0554, Val Loss: 0.0970\n",
      "Epoch [4/50], Train Loss: 0.0489, Val Loss: 0.0811\n",
      "Epoch [5/50], Train Loss: 0.0453, Val Loss: 0.0702\n",
      "Epoch [6/50], Train Loss: 0.0405, Val Loss: 0.0529\n",
      "Epoch [7/50], Train Loss: 0.0371, Val Loss: 0.0325\n",
      "Epoch [8/50], Train Loss: 0.0291, Val Loss: 0.0272\n",
      "Epoch [9/50], Train Loss: 0.0270, Val Loss: 0.0330\n",
      "Epoch [10/50], Train Loss: 0.0230, Val Loss: 0.0258\n",
      "Epoch [11/50], Train Loss: 0.0243, Val Loss: 0.0220\n",
      "Epoch [12/50], Train Loss: 0.0203, Val Loss: 0.0376\n",
      "Epoch [13/50], Train Loss: 0.0207, Val Loss: 0.0223\n",
      "Epoch [14/50], Train Loss: 0.0192, Val Loss: 0.0272\n",
      "Epoch [15/50], Train Loss: 0.0215, Val Loss: 0.0374\n",
      "Epoch [16/50], Train Loss: 0.0221, Val Loss: 0.0281\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1018, Val Loss: 0.1881\n",
      "Epoch [2/50], Train Loss: 0.0417, Val Loss: 0.1012\n",
      "Epoch [3/50], Train Loss: 0.0426, Val Loss: 0.1015\n",
      "Epoch [4/50], Train Loss: 0.0402, Val Loss: 0.0957\n",
      "Epoch [5/50], Train Loss: 0.0394, Val Loss: 0.0881\n",
      "Epoch [6/50], Train Loss: 0.0372, Val Loss: 0.0714\n",
      "Epoch [7/50], Train Loss: 0.0332, Val Loss: 0.0550\n",
      "Epoch [8/50], Train Loss: 0.0288, Val Loss: 0.0423\n",
      "Epoch [9/50], Train Loss: 0.0243, Val Loss: 0.0516\n",
      "Epoch [10/50], Train Loss: 0.0203, Val Loss: 0.0375\n",
      "Epoch [11/50], Train Loss: 0.0197, Val Loss: 0.0362\n",
      "Epoch [12/50], Train Loss: 0.0138, Val Loss: 0.0388\n",
      "Epoch [13/50], Train Loss: 0.0125, Val Loss: 0.0221\n",
      "Epoch [14/50], Train Loss: 0.0092, Val Loss: 0.0364\n",
      "Epoch [15/50], Train Loss: 0.0124, Val Loss: 0.0353\n",
      "Epoch [16/50], Train Loss: 0.0131, Val Loss: 0.0212\n",
      "Epoch [17/50], Train Loss: 0.0087, Val Loss: 0.0552\n",
      "Epoch [18/50], Train Loss: 0.0097, Val Loss: 0.0393\n",
      "Epoch [19/50], Train Loss: 0.0069, Val Loss: 0.0408\n",
      "Epoch [20/50], Train Loss: 0.0091, Val Loss: 0.0383\n",
      "Epoch [21/50], Train Loss: 0.0067, Val Loss: 0.0397\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1111, Val Loss: 0.2673\n",
      "Epoch [2/50], Train Loss: 0.0524, Val Loss: 0.1003\n",
      "Epoch [3/50], Train Loss: 0.0539, Val Loss: 0.1084\n",
      "Epoch [4/50], Train Loss: 0.0469, Val Loss: 0.0914\n",
      "Epoch [5/50], Train Loss: 0.0458, Val Loss: 0.0852\n",
      "Epoch [6/50], Train Loss: 0.0431, Val Loss: 0.0710\n",
      "Epoch [7/50], Train Loss: 0.0393, Val Loss: 0.0511\n",
      "Epoch [8/50], Train Loss: 0.0314, Val Loss: 0.0371\n",
      "Epoch [9/50], Train Loss: 0.0277, Val Loss: 0.0485\n",
      "Epoch [10/50], Train Loss: 0.0304, Val Loss: 0.0492\n",
      "Epoch [11/50], Train Loss: 0.0210, Val Loss: 0.0525\n",
      "Epoch [12/50], Train Loss: 0.0169, Val Loss: 0.0548\n",
      "Epoch [13/50], Train Loss: 0.0144, Val Loss: 0.0557\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1038, Val Loss: 0.2061\n",
      "Epoch [2/50], Train Loss: 0.0643, Val Loss: 0.1111\n",
      "Epoch [3/50], Train Loss: 0.0604, Val Loss: 0.1177\n",
      "Epoch [4/50], Train Loss: 0.0523, Val Loss: 0.1028\n",
      "Epoch [5/50], Train Loss: 0.0517, Val Loss: 0.1008\n",
      "Epoch [6/50], Train Loss: 0.0503, Val Loss: 0.0914\n",
      "Epoch [7/50], Train Loss: 0.0465, Val Loss: 0.0694\n",
      "Epoch [8/50], Train Loss: 0.0417, Val Loss: 0.0507\n",
      "Epoch [9/50], Train Loss: 0.0329, Val Loss: 0.0509\n",
      "Epoch [10/50], Train Loss: 0.0271, Val Loss: 0.0412\n",
      "Epoch [11/50], Train Loss: 0.0299, Val Loss: 0.0271\n",
      "Epoch [12/50], Train Loss: 0.0240, Val Loss: 0.0480\n",
      "Epoch [13/50], Train Loss: 0.0226, Val Loss: 0.0267\n",
      "Epoch [14/50], Train Loss: 0.0245, Val Loss: 0.0438\n",
      "Epoch [15/50], Train Loss: 0.0240, Val Loss: 0.0362\n",
      "Epoch [16/50], Train Loss: 0.0191, Val Loss: 0.0341\n",
      "Epoch [17/50], Train Loss: 0.0190, Val Loss: 0.0403\n",
      "Epoch [18/50], Train Loss: 0.0174, Val Loss: 0.0353\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0800, Val Loss: 0.0960\n",
      "Epoch [2/50], Train Loss: 0.0306, Val Loss: 0.0506\n",
      "Epoch [3/50], Train Loss: 0.0306, Val Loss: 0.0349\n",
      "Epoch [4/50], Train Loss: 0.0267, Val Loss: 0.0328\n",
      "Epoch [5/50], Train Loss: 0.0221, Val Loss: 0.0225\n",
      "Epoch [6/50], Train Loss: 0.0181, Val Loss: 0.0121\n",
      "Epoch [7/50], Train Loss: 0.0094, Val Loss: 0.0028\n",
      "Epoch [8/50], Train Loss: 0.0110, Val Loss: 0.0064\n",
      "Epoch [9/50], Train Loss: 0.0044, Val Loss: 0.0095\n",
      "Epoch [10/50], Train Loss: 0.0056, Val Loss: 0.0036\n",
      "Epoch [11/50], Train Loss: 0.0035, Val Loss: 0.0058\n",
      "Epoch [12/50], Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1023, Val Loss: 0.1910\n",
      "Epoch [2/50], Train Loss: 0.0320, Val Loss: 0.0314\n",
      "Epoch [3/50], Train Loss: 0.0372, Val Loss: 0.0285\n",
      "Epoch [4/50], Train Loss: 0.0316, Val Loss: 0.0229\n",
      "Epoch [5/50], Train Loss: 0.0240, Val Loss: 0.0095\n",
      "Epoch [6/50], Train Loss: 0.0206, Val Loss: 0.0042\n",
      "Epoch [7/50], Train Loss: 0.0158, Val Loss: 0.0062\n",
      "Epoch [8/50], Train Loss: 0.0106, Val Loss: 0.0131\n",
      "Epoch [9/50], Train Loss: 0.0085, Val Loss: 0.0078\n",
      "Epoch [10/50], Train Loss: 0.0076, Val Loss: 0.0081\n",
      "Epoch [11/50], Train Loss: 0.0071, Val Loss: 0.0092\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1157, Val Loss: 0.1715\n",
      "Epoch [2/50], Train Loss: 0.0454, Val Loss: 0.0542\n",
      "Epoch [3/50], Train Loss: 0.0445, Val Loss: 0.0344\n",
      "Epoch [4/50], Train Loss: 0.0383, Val Loss: 0.0267\n",
      "Epoch [5/50], Train Loss: 0.0314, Val Loss: 0.0105\n",
      "Epoch [6/50], Train Loss: 0.0279, Val Loss: 0.0063\n",
      "Epoch [7/50], Train Loss: 0.0231, Val Loss: 0.0070\n",
      "Epoch [8/50], Train Loss: 0.0207, Val Loss: 0.0090\n",
      "Epoch [9/50], Train Loss: 0.0161, Val Loss: 0.0128\n",
      "Epoch [10/50], Train Loss: 0.0153, Val Loss: 0.0123\n",
      "Epoch [11/50], Train Loss: 0.0137, Val Loss: 0.0194\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0469, Val Loss: 0.0325\n",
      "Epoch [2/50], Train Loss: 0.0530, Val Loss: 0.0771\n",
      "Epoch [3/50], Train Loss: 0.0298, Val Loss: 0.0160\n",
      "Epoch [4/50], Train Loss: 0.0276, Val Loss: 0.0072\n",
      "Epoch [5/50], Train Loss: 0.0198, Val Loss: 0.0067\n",
      "Epoch [6/50], Train Loss: 0.0177, Val Loss: 0.0074\n",
      "Epoch [7/50], Train Loss: 0.0128, Val Loss: 0.0474\n",
      "Epoch [8/50], Train Loss: 0.0075, Val Loss: 0.0284\n",
      "Epoch [9/50], Train Loss: 0.0104, Val Loss: 0.0160\n",
      "Epoch [10/50], Train Loss: 0.0062, Val Loss: 0.0332\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0681, Val Loss: 0.1362\n",
      "Epoch [2/50], Train Loss: 0.0357, Val Loss: 0.0503\n",
      "Epoch [3/50], Train Loss: 0.0404, Val Loss: 0.0383\n",
      "Epoch [4/50], Train Loss: 0.0318, Val Loss: 0.0194\n",
      "Epoch [5/50], Train Loss: 0.0278, Val Loss: 0.0227\n",
      "Epoch [6/50], Train Loss: 0.0232, Val Loss: 0.0132\n",
      "Epoch [7/50], Train Loss: 0.0179, Val Loss: 0.0084\n",
      "Epoch [8/50], Train Loss: 0.0142, Val Loss: 0.0316\n",
      "Epoch [9/50], Train Loss: 0.0129, Val Loss: 0.0301\n",
      "Epoch [10/50], Train Loss: 0.0139, Val Loss: 0.0277\n",
      "Epoch [11/50], Train Loss: 0.0086, Val Loss: 0.0177\n",
      "Epoch [12/50], Train Loss: 0.0097, Val Loss: 0.0203\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0701, Val Loss: 0.1658\n",
      "Epoch [2/50], Train Loss: 0.0429, Val Loss: 0.0718\n",
      "Epoch [3/50], Train Loss: 0.0459, Val Loss: 0.0666\n",
      "Epoch [4/50], Train Loss: 0.0365, Val Loss: 0.0238\n",
      "Epoch [5/50], Train Loss: 0.0285, Val Loss: 0.0206\n",
      "Epoch [6/50], Train Loss: 0.0227, Val Loss: 0.0400\n",
      "Epoch [7/50], Train Loss: 0.0196, Val Loss: 0.0356\n",
      "Epoch [8/50], Train Loss: 0.0188, Val Loss: 0.0187\n",
      "Epoch [9/50], Train Loss: 0.0149, Val Loss: 0.0401\n",
      "Epoch [10/50], Train Loss: 0.0193, Val Loss: 0.0348\n",
      "Epoch [11/50], Train Loss: 0.0177, Val Loss: 0.0236\n",
      "Epoch [12/50], Train Loss: 0.0127, Val Loss: 0.0260\n",
      "Epoch [13/50], Train Loss: 0.0194, Val Loss: 0.0295\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0983, Val Loss: 0.0998\n",
      "Epoch [2/50], Train Loss: 0.0458, Val Loss: 0.0558\n",
      "Epoch [3/50], Train Loss: 0.0472, Val Loss: 0.0553\n",
      "Epoch [4/50], Train Loss: 0.0373, Val Loss: 0.0395\n",
      "Epoch [5/50], Train Loss: 0.0297, Val Loss: 0.0325\n",
      "Epoch [6/50], Train Loss: 0.0264, Val Loss: 0.0245\n",
      "Epoch [7/50], Train Loss: 0.0222, Val Loss: 0.0261\n",
      "Epoch [8/50], Train Loss: 0.0217, Val Loss: 0.0354\n",
      "Epoch [9/50], Train Loss: 0.0204, Val Loss: 0.0533\n",
      "Epoch [10/50], Train Loss: 0.0204, Val Loss: 0.0361\n",
      "Epoch [11/50], Train Loss: 0.0203, Val Loss: 0.0310\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0738, Val Loss: 0.0783\n",
      "Epoch [2/50], Train Loss: 0.0546, Val Loss: 0.0888\n",
      "Epoch [3/50], Train Loss: 0.0449, Val Loss: 0.0659\n",
      "Epoch [4/50], Train Loss: 0.0437, Val Loss: 0.0397\n",
      "Epoch [5/50], Train Loss: 0.0357, Val Loss: 0.0311\n",
      "Epoch [6/50], Train Loss: 0.0287, Val Loss: 0.0280\n",
      "Epoch [7/50], Train Loss: 0.0274, Val Loss: 0.0315\n",
      "Epoch [8/50], Train Loss: 0.0247, Val Loss: 0.0358\n",
      "Epoch [9/50], Train Loss: 0.0237, Val Loss: 0.0385\n",
      "Epoch [10/50], Train Loss: 0.0218, Val Loss: 0.0426\n",
      "Epoch [11/50], Train Loss: 0.0185, Val Loss: 0.0416\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0931, Val Loss: 0.1085\n",
      "Epoch [2/50], Train Loss: 0.0642, Val Loss: 0.0899\n",
      "Epoch [3/50], Train Loss: 0.0538, Val Loss: 0.0806\n",
      "Epoch [4/50], Train Loss: 0.0500, Val Loss: 0.0622\n",
      "Epoch [5/50], Train Loss: 0.0461, Val Loss: 0.0372\n",
      "Epoch [6/50], Train Loss: 0.0361, Val Loss: 0.0195\n",
      "Epoch [7/50], Train Loss: 0.0311, Val Loss: 0.0267\n",
      "Epoch [8/50], Train Loss: 0.0282, Val Loss: 0.0340\n",
      "Epoch [9/50], Train Loss: 0.0232, Val Loss: 0.0468\n",
      "Epoch [10/50], Train Loss: 0.0221, Val Loss: 0.0655\n",
      "Epoch [11/50], Train Loss: 0.0162, Val Loss: 0.0347\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0586, Val Loss: 0.0274\n",
      "Epoch [2/50], Train Loss: 0.0479, Val Loss: 0.0293\n",
      "Epoch [3/50], Train Loss: 0.0309, Val Loss: 0.0144\n",
      "Epoch [4/50], Train Loss: 0.0223, Val Loss: 0.0059\n",
      "Epoch [5/50], Train Loss: 0.0174, Val Loss: 0.0150\n",
      "Epoch [6/50], Train Loss: 0.0130, Val Loss: 0.0220\n",
      "Epoch [7/50], Train Loss: 0.0106, Val Loss: 0.0401\n",
      "Epoch [8/50], Train Loss: 0.0072, Val Loss: 0.0085\n",
      "Epoch [9/50], Train Loss: 0.0038, Val Loss: 0.0128\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0816, Val Loss: 0.0539\n",
      "Epoch [2/50], Train Loss: 0.0335, Val Loss: 0.0204\n",
      "Epoch [3/50], Train Loss: 0.0282, Val Loss: 0.0097\n",
      "Epoch [4/50], Train Loss: 0.0238, Val Loss: 0.0096\n",
      "Epoch [5/50], Train Loss: 0.0160, Val Loss: 0.0168\n",
      "Epoch [6/50], Train Loss: 0.0105, Val Loss: 0.0139\n",
      "Epoch [7/50], Train Loss: 0.0102, Val Loss: 0.0265\n",
      "Epoch [8/50], Train Loss: 0.0060, Val Loss: 0.0093\n",
      "Epoch [9/50], Train Loss: 0.0065, Val Loss: 0.0098\n",
      "Epoch [10/50], Train Loss: 0.0058, Val Loss: 0.0075\n",
      "Epoch [11/50], Train Loss: 0.0059, Val Loss: 0.0231\n",
      "Epoch [12/50], Train Loss: 0.0062, Val Loss: 0.0073\n",
      "Epoch [13/50], Train Loss: 0.0059, Val Loss: 0.0050\n",
      "Epoch [14/50], Train Loss: 0.0056, Val Loss: 0.0112\n",
      "Epoch [15/50], Train Loss: 0.0062, Val Loss: 0.0126\n",
      "Epoch [16/50], Train Loss: 0.0097, Val Loss: 0.0034\n",
      "Epoch [17/50], Train Loss: 0.0053, Val Loss: 0.0075\n",
      "Epoch [18/50], Train Loss: 0.0122, Val Loss: 0.0130\n",
      "Epoch [19/50], Train Loss: 0.0045, Val Loss: 0.0090\n",
      "Epoch [20/50], Train Loss: 0.0054, Val Loss: 0.0027\n",
      "Epoch [21/50], Train Loss: 0.0044, Val Loss: 0.0141\n",
      "Epoch [22/50], Train Loss: 0.0057, Val Loss: 0.0058\n",
      "Epoch [23/50], Train Loss: 0.0070, Val Loss: 0.0031\n",
      "Epoch [24/50], Train Loss: 0.0056, Val Loss: 0.0127\n",
      "Epoch [25/50], Train Loss: 0.0092, Val Loss: 0.0043\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0775, Val Loss: 0.0711\n",
      "Epoch [2/50], Train Loss: 0.0407, Val Loss: 0.0266\n",
      "Epoch [3/50], Train Loss: 0.0346, Val Loss: 0.0067\n",
      "Epoch [4/50], Train Loss: 0.0274, Val Loss: 0.0036\n",
      "Epoch [5/50], Train Loss: 0.0213, Val Loss: 0.0191\n",
      "Epoch [6/50], Train Loss: 0.0140, Val Loss: 0.0253\n",
      "Epoch [7/50], Train Loss: 0.0140, Val Loss: 0.0209\n",
      "Epoch [8/50], Train Loss: 0.0119, Val Loss: 0.0157\n",
      "Epoch [9/50], Train Loss: 0.0131, Val Loss: 0.0100\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0453, Val Loss: 0.0975\n",
      "Epoch [2/50], Train Loss: 0.0565, Val Loss: 0.0740\n",
      "Epoch [3/50], Train Loss: 0.0436, Val Loss: 0.0505\n",
      "Epoch [4/50], Train Loss: 0.0367, Val Loss: 0.0204\n",
      "Epoch [5/50], Train Loss: 0.0259, Val Loss: 0.0053\n",
      "Epoch [6/50], Train Loss: 0.0234, Val Loss: 0.0076\n",
      "Epoch [7/50], Train Loss: 0.0111, Val Loss: 0.0775\n",
      "Epoch [8/50], Train Loss: 0.0097, Val Loss: 0.0255\n",
      "Epoch [9/50], Train Loss: 0.0128, Val Loss: 0.0158\n",
      "Epoch [10/50], Train Loss: 0.0064, Val Loss: 0.0360\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0491, Val Loss: 0.1014\n",
      "Epoch [2/50], Train Loss: 0.0635, Val Loss: 0.0623\n",
      "Epoch [3/50], Train Loss: 0.0452, Val Loss: 0.0308\n",
      "Epoch [4/50], Train Loss: 0.0332, Val Loss: 0.0125\n",
      "Epoch [5/50], Train Loss: 0.0242, Val Loss: 0.0143\n",
      "Epoch [6/50], Train Loss: 0.0223, Val Loss: 0.0143\n",
      "Epoch [7/50], Train Loss: 0.0165, Val Loss: 0.0166\n",
      "Epoch [8/50], Train Loss: 0.0111, Val Loss: 0.0261\n",
      "Epoch [9/50], Train Loss: 0.0208, Val Loss: 0.0097\n",
      "Epoch [10/50], Train Loss: 0.0129, Val Loss: 0.0095\n",
      "Epoch [11/50], Train Loss: 0.0081, Val Loss: 0.0333\n",
      "Epoch [12/50], Train Loss: 0.0077, Val Loss: 0.0114\n",
      "Epoch [13/50], Train Loss: 0.0089, Val Loss: 0.0071\n",
      "Epoch [14/50], Train Loss: 0.0058, Val Loss: 0.0256\n",
      "Epoch [15/50], Train Loss: 0.0058, Val Loss: 0.0175\n",
      "Epoch [16/50], Train Loss: 0.0061, Val Loss: 0.0048\n",
      "Epoch [17/50], Train Loss: 0.0060, Val Loss: 0.0183\n",
      "Epoch [18/50], Train Loss: 0.0071, Val Loss: 0.0176\n",
      "Epoch [19/50], Train Loss: 0.0075, Val Loss: 0.0025\n",
      "Epoch [20/50], Train Loss: 0.0052, Val Loss: 0.0108\n",
      "Epoch [21/50], Train Loss: 0.0082, Val Loss: 0.0305\n",
      "Epoch [22/50], Train Loss: 0.0062, Val Loss: 0.0030\n",
      "Epoch [23/50], Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [24/50], Train Loss: 0.0072, Val Loss: 0.0248\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0719, Val Loss: 0.0890\n",
      "Epoch [2/50], Train Loss: 0.0608, Val Loss: 0.0262\n",
      "Epoch [3/50], Train Loss: 0.0595, Val Loss: 0.0486\n",
      "Epoch [4/50], Train Loss: 0.0387, Val Loss: 0.0229\n",
      "Epoch [5/50], Train Loss: 0.0332, Val Loss: 0.0114\n",
      "Epoch [6/50], Train Loss: 0.0293, Val Loss: 0.0088\n",
      "Epoch [7/50], Train Loss: 0.0229, Val Loss: 0.0062\n",
      "Epoch [8/50], Train Loss: 0.0141, Val Loss: 0.0098\n",
      "Epoch [9/50], Train Loss: 0.0184, Val Loss: 0.0186\n",
      "Epoch [10/50], Train Loss: 0.0133, Val Loss: 0.0097\n",
      "Epoch [11/50], Train Loss: 0.0140, Val Loss: 0.0303\n",
      "Epoch [12/50], Train Loss: 0.0109, Val Loss: 0.0145\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0417, Val Loss: 0.0705\n",
      "Epoch [2/50], Train Loss: 0.0648, Val Loss: 0.1210\n",
      "Epoch [3/50], Train Loss: 0.0395, Val Loss: 0.0580\n",
      "Epoch [4/50], Train Loss: 0.0441, Val Loss: 0.0166\n",
      "Epoch [5/50], Train Loss: 0.0350, Val Loss: 0.0472\n",
      "Epoch [6/50], Train Loss: 0.0229, Val Loss: 0.0759\n",
      "Epoch [7/50], Train Loss: 0.0226, Val Loss: 0.0305\n",
      "Epoch [8/50], Train Loss: 0.0214, Val Loss: 0.0315\n",
      "Epoch [9/50], Train Loss: 0.0187, Val Loss: 0.0416\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0421, Val Loss: 0.0982\n",
      "Epoch [2/50], Train Loss: 0.0581, Val Loss: 0.0555\n",
      "Epoch [3/50], Train Loss: 0.0559, Val Loss: 0.0703\n",
      "Epoch [4/50], Train Loss: 0.0401, Val Loss: 0.0282\n",
      "Epoch [5/50], Train Loss: 0.0299, Val Loss: 0.0182\n",
      "Epoch [6/50], Train Loss: 0.0256, Val Loss: 0.0154\n",
      "Epoch [7/50], Train Loss: 0.0219, Val Loss: 0.0175\n",
      "Epoch [8/50], Train Loss: 0.0213, Val Loss: 0.0189\n",
      "Epoch [9/50], Train Loss: 0.0214, Val Loss: 0.0301\n",
      "Epoch [10/50], Train Loss: 0.0193, Val Loss: 0.0410\n",
      "Epoch [11/50], Train Loss: 0.0191, Val Loss: 0.0363\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0649, Val Loss: 0.1357\n",
      "Epoch [2/50], Train Loss: 0.0632, Val Loss: 0.0579\n",
      "Epoch [3/50], Train Loss: 0.0639, Val Loss: 0.0915\n",
      "Epoch [4/50], Train Loss: 0.0466, Val Loss: 0.0667\n",
      "Epoch [5/50], Train Loss: 0.0468, Val Loss: 0.0368\n",
      "Epoch [6/50], Train Loss: 0.0354, Val Loss: 0.0403\n",
      "Epoch [7/50], Train Loss: 0.0280, Val Loss: 0.0224\n",
      "Epoch [8/50], Train Loss: 0.0249, Val Loss: 0.0216\n",
      "Epoch [9/50], Train Loss: 0.0250, Val Loss: 0.0443\n",
      "Epoch [10/50], Train Loss: 0.0234, Val Loss: 0.0398\n",
      "Epoch [11/50], Train Loss: 0.0183, Val Loss: 0.0184\n",
      "Epoch [12/50], Train Loss: 0.0176, Val Loss: 0.0290\n",
      "Epoch [13/50], Train Loss: 0.0180, Val Loss: 0.0133\n",
      "Epoch [14/50], Train Loss: 0.0177, Val Loss: 0.0395\n",
      "Epoch [15/50], Train Loss: 0.0357, Val Loss: 0.0133\n",
      "Epoch [16/50], Train Loss: 0.0158, Val Loss: 0.0379\n",
      "Epoch [17/50], Train Loss: 0.0221, Val Loss: 0.0472\n",
      "Epoch [18/50], Train Loss: 0.0134, Val Loss: 0.0093\n",
      "Epoch [19/50], Train Loss: 0.0122, Val Loss: 0.0186\n",
      "Epoch [20/50], Train Loss: 0.0225, Val Loss: 0.0633\n",
      "Epoch [21/50], Train Loss: 0.0200, Val Loss: 0.0273\n",
      "Epoch [22/50], Train Loss: 0.0138, Val Loss: 0.0181\n",
      "Epoch [23/50], Train Loss: 0.0134, Val Loss: 0.0348\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1325, Val Loss: 0.3571\n",
      "Epoch [2/50], Train Loss: 0.1296, Val Loss: 0.3516\n",
      "Epoch [3/50], Train Loss: 0.1268, Val Loss: 0.3463\n",
      "Epoch [4/50], Train Loss: 0.1240, Val Loss: 0.3411\n",
      "Epoch [5/50], Train Loss: 0.1214, Val Loss: 0.3360\n",
      "Epoch [6/50], Train Loss: 0.1188, Val Loss: 0.3309\n",
      "Epoch [7/50], Train Loss: 0.1163, Val Loss: 0.3261\n",
      "Epoch [8/50], Train Loss: 0.1138, Val Loss: 0.3213\n",
      "Epoch [9/50], Train Loss: 0.1115, Val Loss: 0.3167\n",
      "Epoch [10/50], Train Loss: 0.1092, Val Loss: 0.3121\n",
      "Epoch [11/50], Train Loss: 0.1070, Val Loss: 0.3076\n",
      "Epoch [12/50], Train Loss: 0.1048, Val Loss: 0.3033\n",
      "Epoch [13/50], Train Loss: 0.1027, Val Loss: 0.2990\n",
      "Epoch [14/50], Train Loss: 0.1007, Val Loss: 0.2949\n",
      "Epoch [15/50], Train Loss: 0.0987, Val Loss: 0.2908\n",
      "Epoch [16/50], Train Loss: 0.0968, Val Loss: 0.2868\n",
      "Epoch [17/50], Train Loss: 0.0949, Val Loss: 0.2829\n",
      "Epoch [18/50], Train Loss: 0.0931, Val Loss: 0.2791\n",
      "Epoch [19/50], Train Loss: 0.0914, Val Loss: 0.2754\n",
      "Epoch [20/50], Train Loss: 0.0897, Val Loss: 0.2717\n",
      "Epoch [21/50], Train Loss: 0.0880, Val Loss: 0.2682\n",
      "Epoch [22/50], Train Loss: 0.0864, Val Loss: 0.2647\n",
      "Epoch [23/50], Train Loss: 0.0849, Val Loss: 0.2613\n",
      "Epoch [24/50], Train Loss: 0.0834, Val Loss: 0.2579\n",
      "Epoch [25/50], Train Loss: 0.0819, Val Loss: 0.2546\n",
      "Epoch [26/50], Train Loss: 0.0805, Val Loss: 0.2515\n",
      "Epoch [27/50], Train Loss: 0.0792, Val Loss: 0.2483\n",
      "Epoch [28/50], Train Loss: 0.0778, Val Loss: 0.2453\n",
      "Epoch [29/50], Train Loss: 0.0765, Val Loss: 0.2423\n",
      "Epoch [30/50], Train Loss: 0.0753, Val Loss: 0.2394\n",
      "Epoch [31/50], Train Loss: 0.0741, Val Loss: 0.2365\n",
      "Epoch [32/50], Train Loss: 0.0729, Val Loss: 0.2337\n",
      "Epoch [33/50], Train Loss: 0.0718, Val Loss: 0.2309\n",
      "Epoch [34/50], Train Loss: 0.0706, Val Loss: 0.2283\n",
      "Epoch [35/50], Train Loss: 0.0696, Val Loss: 0.2256\n",
      "Epoch [36/50], Train Loss: 0.0685, Val Loss: 0.2231\n",
      "Epoch [37/50], Train Loss: 0.0675, Val Loss: 0.2206\n",
      "Epoch [38/50], Train Loss: 0.0665, Val Loss: 0.2181\n",
      "Epoch [39/50], Train Loss: 0.0656, Val Loss: 0.2157\n",
      "Epoch [40/50], Train Loss: 0.0647, Val Loss: 0.2133\n",
      "Epoch [41/50], Train Loss: 0.0638, Val Loss: 0.2110\n",
      "Epoch [42/50], Train Loss: 0.0629, Val Loss: 0.2088\n",
      "Epoch [43/50], Train Loss: 0.0621, Val Loss: 0.2066\n",
      "Epoch [44/50], Train Loss: 0.0613, Val Loss: 0.2044\n",
      "Epoch [45/50], Train Loss: 0.0605, Val Loss: 0.2023\n",
      "Epoch [46/50], Train Loss: 0.0597, Val Loss: 0.2002\n",
      "Epoch [47/50], Train Loss: 0.0590, Val Loss: 0.1982\n",
      "Epoch [48/50], Train Loss: 0.0583, Val Loss: 0.1962\n",
      "Epoch [49/50], Train Loss: 0.0576, Val Loss: 0.1943\n",
      "Epoch [50/50], Train Loss: 0.0569, Val Loss: 0.1924\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1234, Val Loss: 0.3422\n",
      "Epoch [2/50], Train Loss: 0.1215, Val Loss: 0.3371\n",
      "Epoch [3/50], Train Loss: 0.1185, Val Loss: 0.3321\n",
      "Epoch [4/50], Train Loss: 0.1165, Val Loss: 0.3272\n",
      "Epoch [5/50], Train Loss: 0.1139, Val Loss: 0.3225\n",
      "Epoch [6/50], Train Loss: 0.1113, Val Loss: 0.3178\n",
      "Epoch [7/50], Train Loss: 0.1096, Val Loss: 0.3132\n",
      "Epoch [8/50], Train Loss: 0.1075, Val Loss: 0.3087\n",
      "Epoch [9/50], Train Loss: 0.1049, Val Loss: 0.3044\n",
      "Epoch [10/50], Train Loss: 0.1023, Val Loss: 0.3000\n",
      "Epoch [11/50], Train Loss: 0.1000, Val Loss: 0.2958\n",
      "Epoch [12/50], Train Loss: 0.0986, Val Loss: 0.2917\n",
      "Epoch [13/50], Train Loss: 0.0966, Val Loss: 0.2877\n",
      "Epoch [14/50], Train Loss: 0.0945, Val Loss: 0.2837\n",
      "Epoch [15/50], Train Loss: 0.0931, Val Loss: 0.2799\n",
      "Epoch [16/50], Train Loss: 0.0912, Val Loss: 0.2761\n",
      "Epoch [17/50], Train Loss: 0.0894, Val Loss: 0.2723\n",
      "Epoch [18/50], Train Loss: 0.0883, Val Loss: 0.2687\n",
      "Epoch [19/50], Train Loss: 0.0866, Val Loss: 0.2651\n",
      "Epoch [20/50], Train Loss: 0.0845, Val Loss: 0.2617\n",
      "Epoch [21/50], Train Loss: 0.0837, Val Loss: 0.2582\n",
      "Epoch [22/50], Train Loss: 0.0817, Val Loss: 0.2549\n",
      "Epoch [23/50], Train Loss: 0.0807, Val Loss: 0.2516\n",
      "Epoch [24/50], Train Loss: 0.0790, Val Loss: 0.2484\n",
      "Epoch [25/50], Train Loss: 0.0777, Val Loss: 0.2452\n",
      "Epoch [26/50], Train Loss: 0.0762, Val Loss: 0.2421\n",
      "Epoch [27/50], Train Loss: 0.0758, Val Loss: 0.2391\n",
      "Epoch [28/50], Train Loss: 0.0732, Val Loss: 0.2361\n",
      "Epoch [29/50], Train Loss: 0.0729, Val Loss: 0.2332\n",
      "Epoch [30/50], Train Loss: 0.0713, Val Loss: 0.2304\n",
      "Epoch [31/50], Train Loss: 0.0701, Val Loss: 0.2276\n",
      "Epoch [32/50], Train Loss: 0.0694, Val Loss: 0.2248\n",
      "Epoch [33/50], Train Loss: 0.0685, Val Loss: 0.2222\n",
      "Epoch [34/50], Train Loss: 0.0671, Val Loss: 0.2195\n",
      "Epoch [35/50], Train Loss: 0.0661, Val Loss: 0.2170\n",
      "Epoch [36/50], Train Loss: 0.0650, Val Loss: 0.2144\n",
      "Epoch [37/50], Train Loss: 0.0638, Val Loss: 0.2119\n",
      "Epoch [38/50], Train Loss: 0.0631, Val Loss: 0.2095\n",
      "Epoch [39/50], Train Loss: 0.0626, Val Loss: 0.2071\n",
      "Epoch [40/50], Train Loss: 0.0609, Val Loss: 0.2048\n",
      "Epoch [41/50], Train Loss: 0.0604, Val Loss: 0.2025\n",
      "Epoch [42/50], Train Loss: 0.0592, Val Loss: 0.2003\n",
      "Epoch [43/50], Train Loss: 0.0589, Val Loss: 0.1981\n",
      "Epoch [44/50], Train Loss: 0.0586, Val Loss: 0.1959\n",
      "Epoch [45/50], Train Loss: 0.0574, Val Loss: 0.1938\n",
      "Epoch [46/50], Train Loss: 0.0565, Val Loss: 0.1917\n",
      "Epoch [47/50], Train Loss: 0.0564, Val Loss: 0.1897\n",
      "Epoch [48/50], Train Loss: 0.0554, Val Loss: 0.1877\n",
      "Epoch [49/50], Train Loss: 0.0547, Val Loss: 0.1857\n",
      "Epoch [50/50], Train Loss: 0.0536, Val Loss: 0.1838\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1554, Val Loss: 0.3725\n",
      "Epoch [2/50], Train Loss: 0.1510, Val Loss: 0.3667\n",
      "Epoch [3/50], Train Loss: 0.1505, Val Loss: 0.3611\n",
      "Epoch [4/50], Train Loss: 0.1450, Val Loss: 0.3557\n",
      "Epoch [5/50], Train Loss: 0.1425, Val Loss: 0.3503\n",
      "Epoch [6/50], Train Loss: 0.1397, Val Loss: 0.3451\n",
      "Epoch [7/50], Train Loss: 0.1350, Val Loss: 0.3401\n",
      "Epoch [8/50], Train Loss: 0.1346, Val Loss: 0.3351\n",
      "Epoch [9/50], Train Loss: 0.1306, Val Loss: 0.3302\n",
      "Epoch [10/50], Train Loss: 0.1291, Val Loss: 0.3255\n",
      "Epoch [11/50], Train Loss: 0.1246, Val Loss: 0.3209\n",
      "Epoch [12/50], Train Loss: 0.1223, Val Loss: 0.3164\n",
      "Epoch [13/50], Train Loss: 0.1199, Val Loss: 0.3120\n",
      "Epoch [14/50], Train Loss: 0.1179, Val Loss: 0.3077\n",
      "Epoch [15/50], Train Loss: 0.1150, Val Loss: 0.3034\n",
      "Epoch [16/50], Train Loss: 0.1126, Val Loss: 0.2993\n",
      "Epoch [17/50], Train Loss: 0.1106, Val Loss: 0.2953\n",
      "Epoch [18/50], Train Loss: 0.1077, Val Loss: 0.2914\n",
      "Epoch [19/50], Train Loss: 0.1074, Val Loss: 0.2875\n",
      "Epoch [20/50], Train Loss: 0.1064, Val Loss: 0.2838\n",
      "Epoch [21/50], Train Loss: 0.1026, Val Loss: 0.2801\n",
      "Epoch [22/50], Train Loss: 0.1012, Val Loss: 0.2765\n",
      "Epoch [23/50], Train Loss: 0.0984, Val Loss: 0.2731\n",
      "Epoch [24/50], Train Loss: 0.0975, Val Loss: 0.2696\n",
      "Epoch [25/50], Train Loss: 0.0962, Val Loss: 0.2662\n",
      "Epoch [26/50], Train Loss: 0.0941, Val Loss: 0.2629\n",
      "Epoch [27/50], Train Loss: 0.0924, Val Loss: 0.2597\n",
      "Epoch [28/50], Train Loss: 0.0908, Val Loss: 0.2566\n",
      "Epoch [29/50], Train Loss: 0.0890, Val Loss: 0.2535\n",
      "Epoch [30/50], Train Loss: 0.0872, Val Loss: 0.2505\n",
      "Epoch [31/50], Train Loss: 0.0865, Val Loss: 0.2476\n",
      "Epoch [32/50], Train Loss: 0.0847, Val Loss: 0.2447\n",
      "Epoch [33/50], Train Loss: 0.0842, Val Loss: 0.2419\n",
      "Epoch [34/50], Train Loss: 0.0823, Val Loss: 0.2392\n",
      "Epoch [35/50], Train Loss: 0.0816, Val Loss: 0.2365\n",
      "Epoch [36/50], Train Loss: 0.0808, Val Loss: 0.2338\n",
      "Epoch [37/50], Train Loss: 0.0789, Val Loss: 0.2312\n",
      "Epoch [38/50], Train Loss: 0.0773, Val Loss: 0.2287\n",
      "Epoch [39/50], Train Loss: 0.0759, Val Loss: 0.2263\n",
      "Epoch [40/50], Train Loss: 0.0751, Val Loss: 0.2238\n",
      "Epoch [41/50], Train Loss: 0.0739, Val Loss: 0.2215\n",
      "Epoch [42/50], Train Loss: 0.0731, Val Loss: 0.2192\n",
      "Epoch [43/50], Train Loss: 0.0727, Val Loss: 0.2169\n",
      "Epoch [44/50], Train Loss: 0.0710, Val Loss: 0.2147\n",
      "Epoch [45/50], Train Loss: 0.0707, Val Loss: 0.2125\n",
      "Epoch [46/50], Train Loss: 0.0697, Val Loss: 0.2104\n",
      "Epoch [47/50], Train Loss: 0.0683, Val Loss: 0.2083\n",
      "Epoch [48/50], Train Loss: 0.0681, Val Loss: 0.2062\n",
      "Epoch [49/50], Train Loss: 0.0668, Val Loss: 0.2042\n",
      "Epoch [50/50], Train Loss: 0.0652, Val Loss: 0.2023\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0879, Val Loss: 0.2597\n",
      "Epoch [2/50], Train Loss: 0.0862, Val Loss: 0.2563\n",
      "Epoch [3/50], Train Loss: 0.0845, Val Loss: 0.2530\n",
      "Epoch [4/50], Train Loss: 0.0829, Val Loss: 0.2498\n",
      "Epoch [5/50], Train Loss: 0.0814, Val Loss: 0.2467\n",
      "Epoch [6/50], Train Loss: 0.0799, Val Loss: 0.2436\n",
      "Epoch [7/50], Train Loss: 0.0784, Val Loss: 0.2406\n",
      "Epoch [8/50], Train Loss: 0.0770, Val Loss: 0.2377\n",
      "Epoch [9/50], Train Loss: 0.0756, Val Loss: 0.2348\n",
      "Epoch [10/50], Train Loss: 0.0743, Val Loss: 0.2320\n",
      "Epoch [11/50], Train Loss: 0.0731, Val Loss: 0.2293\n",
      "Epoch [12/50], Train Loss: 0.0718, Val Loss: 0.2266\n",
      "Epoch [13/50], Train Loss: 0.0706, Val Loss: 0.2240\n",
      "Epoch [14/50], Train Loss: 0.0695, Val Loss: 0.2215\n",
      "Epoch [15/50], Train Loss: 0.0684, Val Loss: 0.2190\n",
      "Epoch [16/50], Train Loss: 0.0673, Val Loss: 0.2166\n",
      "Epoch [17/50], Train Loss: 0.0663, Val Loss: 0.2142\n",
      "Epoch [18/50], Train Loss: 0.0652, Val Loss: 0.2119\n",
      "Epoch [19/50], Train Loss: 0.0643, Val Loss: 0.2096\n",
      "Epoch [20/50], Train Loss: 0.0633, Val Loss: 0.2074\n",
      "Epoch [21/50], Train Loss: 0.0624, Val Loss: 0.2053\n",
      "Epoch [22/50], Train Loss: 0.0616, Val Loss: 0.2032\n",
      "Epoch [23/50], Train Loss: 0.0607, Val Loss: 0.2011\n",
      "Epoch [24/50], Train Loss: 0.0599, Val Loss: 0.1991\n",
      "Epoch [25/50], Train Loss: 0.0591, Val Loss: 0.1971\n",
      "Epoch [26/50], Train Loss: 0.0583, Val Loss: 0.1952\n",
      "Epoch [27/50], Train Loss: 0.0576, Val Loss: 0.1934\n",
      "Epoch [28/50], Train Loss: 0.0569, Val Loss: 0.1915\n",
      "Epoch [29/50], Train Loss: 0.0562, Val Loss: 0.1897\n",
      "Epoch [30/50], Train Loss: 0.0555, Val Loss: 0.1880\n",
      "Epoch [31/50], Train Loss: 0.0549, Val Loss: 0.1863\n",
      "Epoch [32/50], Train Loss: 0.0542, Val Loss: 0.1846\n",
      "Epoch [33/50], Train Loss: 0.0536, Val Loss: 0.1830\n",
      "Epoch [34/50], Train Loss: 0.0531, Val Loss: 0.1814\n",
      "Epoch [35/50], Train Loss: 0.0525, Val Loss: 0.1799\n",
      "Epoch [36/50], Train Loss: 0.0520, Val Loss: 0.1783\n",
      "Epoch [37/50], Train Loss: 0.0514, Val Loss: 0.1769\n",
      "Epoch [38/50], Train Loss: 0.0509, Val Loss: 0.1754\n",
      "Epoch [39/50], Train Loss: 0.0504, Val Loss: 0.1740\n",
      "Epoch [40/50], Train Loss: 0.0500, Val Loss: 0.1726\n",
      "Epoch [41/50], Train Loss: 0.0495, Val Loss: 0.1713\n",
      "Epoch [42/50], Train Loss: 0.0491, Val Loss: 0.1699\n",
      "Epoch [43/50], Train Loss: 0.0486, Val Loss: 0.1686\n",
      "Epoch [44/50], Train Loss: 0.0482, Val Loss: 0.1674\n",
      "Epoch [45/50], Train Loss: 0.0478, Val Loss: 0.1661\n",
      "Epoch [46/50], Train Loss: 0.0475, Val Loss: 0.1649\n",
      "Epoch [47/50], Train Loss: 0.0471, Val Loss: 0.1638\n",
      "Epoch [48/50], Train Loss: 0.0467, Val Loss: 0.1626\n",
      "Epoch [49/50], Train Loss: 0.0464, Val Loss: 0.1615\n",
      "Epoch [50/50], Train Loss: 0.0461, Val Loss: 0.1604\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.2069, Val Loss: 0.5181\n",
      "Epoch [2/50], Train Loss: 0.1997, Val Loss: 0.5069\n",
      "Epoch [3/50], Train Loss: 0.1937, Val Loss: 0.4961\n",
      "Epoch [4/50], Train Loss: 0.1883, Val Loss: 0.4857\n",
      "Epoch [5/50], Train Loss: 0.1818, Val Loss: 0.4757\n",
      "Epoch [6/50], Train Loss: 0.1773, Val Loss: 0.4658\n",
      "Epoch [7/50], Train Loss: 0.1706, Val Loss: 0.4564\n",
      "Epoch [8/50], Train Loss: 0.1651, Val Loss: 0.4473\n",
      "Epoch [9/50], Train Loss: 0.1622, Val Loss: 0.4384\n",
      "Epoch [10/50], Train Loss: 0.1579, Val Loss: 0.4298\n",
      "Epoch [11/50], Train Loss: 0.1523, Val Loss: 0.4215\n",
      "Epoch [12/50], Train Loss: 0.1481, Val Loss: 0.4134\n",
      "Epoch [13/50], Train Loss: 0.1436, Val Loss: 0.4056\n",
      "Epoch [14/50], Train Loss: 0.1395, Val Loss: 0.3981\n",
      "Epoch [15/50], Train Loss: 0.1360, Val Loss: 0.3908\n",
      "Epoch [16/50], Train Loss: 0.1333, Val Loss: 0.3836\n",
      "Epoch [17/50], Train Loss: 0.1303, Val Loss: 0.3767\n",
      "Epoch [18/50], Train Loss: 0.1264, Val Loss: 0.3700\n",
      "Epoch [19/50], Train Loss: 0.1235, Val Loss: 0.3635\n",
      "Epoch [20/50], Train Loss: 0.1195, Val Loss: 0.3571\n",
      "Epoch [21/50], Train Loss: 0.1170, Val Loss: 0.3510\n",
      "Epoch [22/50], Train Loss: 0.1135, Val Loss: 0.3450\n",
      "Epoch [23/50], Train Loss: 0.1124, Val Loss: 0.3392\n",
      "Epoch [24/50], Train Loss: 0.1081, Val Loss: 0.3335\n",
      "Epoch [25/50], Train Loss: 0.1052, Val Loss: 0.3281\n",
      "Epoch [26/50], Train Loss: 0.1031, Val Loss: 0.3227\n",
      "Epoch [27/50], Train Loss: 0.1008, Val Loss: 0.3175\n",
      "Epoch [28/50], Train Loss: 0.0994, Val Loss: 0.3125\n",
      "Epoch [29/50], Train Loss: 0.0970, Val Loss: 0.3076\n",
      "Epoch [30/50], Train Loss: 0.0941, Val Loss: 0.3028\n",
      "Epoch [31/50], Train Loss: 0.0925, Val Loss: 0.2981\n",
      "Epoch [32/50], Train Loss: 0.0900, Val Loss: 0.2936\n",
      "Epoch [33/50], Train Loss: 0.0884, Val Loss: 0.2893\n",
      "Epoch [34/50], Train Loss: 0.0866, Val Loss: 0.2850\n",
      "Epoch [35/50], Train Loss: 0.0851, Val Loss: 0.2808\n",
      "Epoch [36/50], Train Loss: 0.0832, Val Loss: 0.2767\n",
      "Epoch [37/50], Train Loss: 0.0819, Val Loss: 0.2727\n",
      "Epoch [38/50], Train Loss: 0.0805, Val Loss: 0.2689\n",
      "Epoch [39/50], Train Loss: 0.0790, Val Loss: 0.2651\n",
      "Epoch [40/50], Train Loss: 0.0756, Val Loss: 0.2615\n",
      "Epoch [41/50], Train Loss: 0.0759, Val Loss: 0.2579\n",
      "Epoch [42/50], Train Loss: 0.0740, Val Loss: 0.2545\n",
      "Epoch [43/50], Train Loss: 0.0732, Val Loss: 0.2511\n",
      "Epoch [44/50], Train Loss: 0.0723, Val Loss: 0.2478\n",
      "Epoch [45/50], Train Loss: 0.0713, Val Loss: 0.2446\n",
      "Epoch [46/50], Train Loss: 0.0701, Val Loss: 0.2415\n",
      "Epoch [47/50], Train Loss: 0.0686, Val Loss: 0.2384\n",
      "Epoch [48/50], Train Loss: 0.0676, Val Loss: 0.2354\n",
      "Epoch [49/50], Train Loss: 0.0671, Val Loss: 0.2325\n",
      "Epoch [50/50], Train Loss: 0.0647, Val Loss: 0.2297\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1275, Val Loss: 0.3187\n",
      "Epoch [2/50], Train Loss: 0.1237, Val Loss: 0.3137\n",
      "Epoch [3/50], Train Loss: 0.1216, Val Loss: 0.3090\n",
      "Epoch [4/50], Train Loss: 0.1207, Val Loss: 0.3042\n",
      "Epoch [5/50], Train Loss: 0.1164, Val Loss: 0.2996\n",
      "Epoch [6/50], Train Loss: 0.1154, Val Loss: 0.2951\n",
      "Epoch [7/50], Train Loss: 0.1102, Val Loss: 0.2909\n",
      "Epoch [8/50], Train Loss: 0.1103, Val Loss: 0.2866\n",
      "Epoch [9/50], Train Loss: 0.1065, Val Loss: 0.2825\n",
      "Epoch [10/50], Train Loss: 0.1065, Val Loss: 0.2785\n",
      "Epoch [11/50], Train Loss: 0.1017, Val Loss: 0.2746\n",
      "Epoch [12/50], Train Loss: 0.0997, Val Loss: 0.2708\n",
      "Epoch [13/50], Train Loss: 0.1005, Val Loss: 0.2671\n",
      "Epoch [14/50], Train Loss: 0.0982, Val Loss: 0.2634\n",
      "Epoch [15/50], Train Loss: 0.0946, Val Loss: 0.2599\n",
      "Epoch [16/50], Train Loss: 0.0933, Val Loss: 0.2565\n",
      "Epoch [17/50], Train Loss: 0.0913, Val Loss: 0.2532\n",
      "Epoch [18/50], Train Loss: 0.0904, Val Loss: 0.2499\n",
      "Epoch [19/50], Train Loss: 0.0896, Val Loss: 0.2467\n",
      "Epoch [20/50], Train Loss: 0.0884, Val Loss: 0.2436\n",
      "Epoch [21/50], Train Loss: 0.0867, Val Loss: 0.2406\n",
      "Epoch [22/50], Train Loss: 0.0835, Val Loss: 0.2376\n",
      "Epoch [23/50], Train Loss: 0.0833, Val Loss: 0.2348\n",
      "Epoch [24/50], Train Loss: 0.0813, Val Loss: 0.2320\n",
      "Epoch [25/50], Train Loss: 0.0804, Val Loss: 0.2293\n",
      "Epoch [26/50], Train Loss: 0.0777, Val Loss: 0.2267\n",
      "Epoch [27/50], Train Loss: 0.0779, Val Loss: 0.2241\n",
      "Epoch [28/50], Train Loss: 0.0768, Val Loss: 0.2216\n",
      "Epoch [29/50], Train Loss: 0.0765, Val Loss: 0.2191\n",
      "Epoch [30/50], Train Loss: 0.0746, Val Loss: 0.2168\n",
      "Epoch [31/50], Train Loss: 0.0735, Val Loss: 0.2144\n",
      "Epoch [32/50], Train Loss: 0.0726, Val Loss: 0.2121\n",
      "Epoch [33/50], Train Loss: 0.0715, Val Loss: 0.2098\n",
      "Epoch [34/50], Train Loss: 0.0714, Val Loss: 0.2076\n",
      "Epoch [35/50], Train Loss: 0.0686, Val Loss: 0.2055\n",
      "Epoch [36/50], Train Loss: 0.0685, Val Loss: 0.2034\n",
      "Epoch [37/50], Train Loss: 0.0680, Val Loss: 0.2013\n",
      "Epoch [38/50], Train Loss: 0.0680, Val Loss: 0.1993\n",
      "Epoch [39/50], Train Loss: 0.0651, Val Loss: 0.1975\n",
      "Epoch [40/50], Train Loss: 0.0669, Val Loss: 0.1955\n",
      "Epoch [41/50], Train Loss: 0.0646, Val Loss: 0.1937\n",
      "Epoch [42/50], Train Loss: 0.0645, Val Loss: 0.1919\n",
      "Epoch [43/50], Train Loss: 0.0637, Val Loss: 0.1901\n",
      "Epoch [44/50], Train Loss: 0.0627, Val Loss: 0.1884\n",
      "Epoch [45/50], Train Loss: 0.0619, Val Loss: 0.1868\n",
      "Epoch [46/50], Train Loss: 0.0636, Val Loss: 0.1851\n",
      "Epoch [47/50], Train Loss: 0.0614, Val Loss: 0.1836\n",
      "Epoch [48/50], Train Loss: 0.0627, Val Loss: 0.1820\n",
      "Epoch [49/50], Train Loss: 0.0602, Val Loss: 0.1804\n",
      "Epoch [50/50], Train Loss: 0.0607, Val Loss: 0.1790\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1473, Val Loss: 0.3760\n",
      "Epoch [2/50], Train Loss: 0.1441, Val Loss: 0.3706\n",
      "Epoch [3/50], Train Loss: 0.1411, Val Loss: 0.3654\n",
      "Epoch [4/50], Train Loss: 0.1381, Val Loss: 0.3602\n",
      "Epoch [5/50], Train Loss: 0.1352, Val Loss: 0.3552\n",
      "Epoch [6/50], Train Loss: 0.1324, Val Loss: 0.3503\n",
      "Epoch [7/50], Train Loss: 0.1296, Val Loss: 0.3455\n",
      "Epoch [8/50], Train Loss: 0.1270, Val Loss: 0.3408\n",
      "Epoch [9/50], Train Loss: 0.1244, Val Loss: 0.3362\n",
      "Epoch [10/50], Train Loss: 0.1219, Val Loss: 0.3317\n",
      "Epoch [11/50], Train Loss: 0.1194, Val Loss: 0.3273\n",
      "Epoch [12/50], Train Loss: 0.1171, Val Loss: 0.3230\n",
      "Epoch [13/50], Train Loss: 0.1148, Val Loss: 0.3188\n",
      "Epoch [14/50], Train Loss: 0.1125, Val Loss: 0.3147\n",
      "Epoch [15/50], Train Loss: 0.1104, Val Loss: 0.3107\n",
      "Epoch [16/50], Train Loss: 0.1083, Val Loss: 0.3067\n",
      "Epoch [17/50], Train Loss: 0.1062, Val Loss: 0.3029\n",
      "Epoch [18/50], Train Loss: 0.1042, Val Loss: 0.2991\n",
      "Epoch [19/50], Train Loss: 0.1023, Val Loss: 0.2954\n",
      "Epoch [20/50], Train Loss: 0.1004, Val Loss: 0.2918\n",
      "Epoch [21/50], Train Loss: 0.0986, Val Loss: 0.2883\n",
      "Epoch [22/50], Train Loss: 0.0968, Val Loss: 0.2848\n",
      "Epoch [23/50], Train Loss: 0.0951, Val Loss: 0.2815\n",
      "Epoch [24/50], Train Loss: 0.0934, Val Loss: 0.2781\n",
      "Epoch [25/50], Train Loss: 0.0918, Val Loss: 0.2749\n",
      "Epoch [26/50], Train Loss: 0.0902, Val Loss: 0.2717\n",
      "Epoch [27/50], Train Loss: 0.0886, Val Loss: 0.2686\n",
      "Epoch [28/50], Train Loss: 0.0871, Val Loss: 0.2656\n",
      "Epoch [29/50], Train Loss: 0.0857, Val Loss: 0.2626\n",
      "Epoch [30/50], Train Loss: 0.0843, Val Loss: 0.2597\n",
      "Epoch [31/50], Train Loss: 0.0829, Val Loss: 0.2568\n",
      "Epoch [32/50], Train Loss: 0.0816, Val Loss: 0.2540\n",
      "Epoch [33/50], Train Loss: 0.0803, Val Loss: 0.2513\n",
      "Epoch [34/50], Train Loss: 0.0790, Val Loss: 0.2486\n",
      "Epoch [35/50], Train Loss: 0.0778, Val Loss: 0.2460\n",
      "Epoch [36/50], Train Loss: 0.0766, Val Loss: 0.2434\n",
      "Epoch [37/50], Train Loss: 0.0754, Val Loss: 0.2409\n",
      "Epoch [38/50], Train Loss: 0.0743, Val Loss: 0.2385\n",
      "Epoch [39/50], Train Loss: 0.0732, Val Loss: 0.2360\n",
      "Epoch [40/50], Train Loss: 0.0722, Val Loss: 0.2337\n",
      "Epoch [41/50], Train Loss: 0.0711, Val Loss: 0.2314\n",
      "Epoch [42/50], Train Loss: 0.0701, Val Loss: 0.2291\n",
      "Epoch [43/50], Train Loss: 0.0692, Val Loss: 0.2269\n",
      "Epoch [44/50], Train Loss: 0.0682, Val Loss: 0.2247\n",
      "Epoch [45/50], Train Loss: 0.0673, Val Loss: 0.2225\n",
      "Epoch [46/50], Train Loss: 0.0664, Val Loss: 0.2204\n",
      "Epoch [47/50], Train Loss: 0.0656, Val Loss: 0.2184\n",
      "Epoch [48/50], Train Loss: 0.0647, Val Loss: 0.2164\n",
      "Epoch [49/50], Train Loss: 0.0639, Val Loss: 0.2144\n",
      "Epoch [50/50], Train Loss: 0.0631, Val Loss: 0.2125\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1541, Val Loss: 0.4122\n",
      "Epoch [2/50], Train Loss: 0.1500, Val Loss: 0.4055\n",
      "Epoch [3/50], Train Loss: 0.1466, Val Loss: 0.3990\n",
      "Epoch [4/50], Train Loss: 0.1427, Val Loss: 0.3926\n",
      "Epoch [5/50], Train Loss: 0.1393, Val Loss: 0.3864\n",
      "Epoch [6/50], Train Loss: 0.1364, Val Loss: 0.3803\n",
      "Epoch [7/50], Train Loss: 0.1329, Val Loss: 0.3744\n",
      "Epoch [8/50], Train Loss: 0.1299, Val Loss: 0.3686\n",
      "Epoch [9/50], Train Loss: 0.1267, Val Loss: 0.3629\n",
      "Epoch [10/50], Train Loss: 0.1237, Val Loss: 0.3574\n",
      "Epoch [11/50], Train Loss: 0.1217, Val Loss: 0.3520\n",
      "Epoch [12/50], Train Loss: 0.1184, Val Loss: 0.3468\n",
      "Epoch [13/50], Train Loss: 0.1156, Val Loss: 0.3416\n",
      "Epoch [14/50], Train Loss: 0.1137, Val Loss: 0.3366\n",
      "Epoch [15/50], Train Loss: 0.1117, Val Loss: 0.3317\n",
      "Epoch [16/50], Train Loss: 0.1089, Val Loss: 0.3269\n",
      "Epoch [17/50], Train Loss: 0.1067, Val Loss: 0.3223\n",
      "Epoch [18/50], Train Loss: 0.1042, Val Loss: 0.3177\n",
      "Epoch [19/50], Train Loss: 0.1020, Val Loss: 0.3133\n",
      "Epoch [20/50], Train Loss: 0.0993, Val Loss: 0.3089\n",
      "Epoch [21/50], Train Loss: 0.0980, Val Loss: 0.3047\n",
      "Epoch [22/50], Train Loss: 0.0963, Val Loss: 0.3005\n",
      "Epoch [23/50], Train Loss: 0.0941, Val Loss: 0.2965\n",
      "Epoch [24/50], Train Loss: 0.0920, Val Loss: 0.2925\n",
      "Epoch [25/50], Train Loss: 0.0907, Val Loss: 0.2887\n",
      "Epoch [26/50], Train Loss: 0.0887, Val Loss: 0.2849\n",
      "Epoch [27/50], Train Loss: 0.0869, Val Loss: 0.2812\n",
      "Epoch [28/50], Train Loss: 0.0850, Val Loss: 0.2776\n",
      "Epoch [29/50], Train Loss: 0.0837, Val Loss: 0.2741\n",
      "Epoch [30/50], Train Loss: 0.0820, Val Loss: 0.2707\n",
      "Epoch [31/50], Train Loss: 0.0808, Val Loss: 0.2673\n",
      "Epoch [32/50], Train Loss: 0.0795, Val Loss: 0.2640\n",
      "Epoch [33/50], Train Loss: 0.0788, Val Loss: 0.2608\n",
      "Epoch [34/50], Train Loss: 0.0768, Val Loss: 0.2577\n",
      "Epoch [35/50], Train Loss: 0.0756, Val Loss: 0.2546\n",
      "Epoch [36/50], Train Loss: 0.0740, Val Loss: 0.2516\n",
      "Epoch [37/50], Train Loss: 0.0728, Val Loss: 0.2487\n",
      "Epoch [38/50], Train Loss: 0.0717, Val Loss: 0.2458\n",
      "Epoch [39/50], Train Loss: 0.0709, Val Loss: 0.2430\n",
      "Epoch [40/50], Train Loss: 0.0703, Val Loss: 0.2402\n",
      "Epoch [41/50], Train Loss: 0.0690, Val Loss: 0.2376\n",
      "Epoch [42/50], Train Loss: 0.0677, Val Loss: 0.2350\n",
      "Epoch [43/50], Train Loss: 0.0667, Val Loss: 0.2324\n",
      "Epoch [44/50], Train Loss: 0.0657, Val Loss: 0.2299\n",
      "Epoch [45/50], Train Loss: 0.0654, Val Loss: 0.2274\n",
      "Epoch [46/50], Train Loss: 0.0647, Val Loss: 0.2250\n",
      "Epoch [47/50], Train Loss: 0.0632, Val Loss: 0.2227\n",
      "Epoch [48/50], Train Loss: 0.0623, Val Loss: 0.2204\n",
      "Epoch [49/50], Train Loss: 0.0617, Val Loss: 0.2181\n",
      "Epoch [50/50], Train Loss: 0.0605, Val Loss: 0.2160\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1483, Val Loss: 0.4006\n",
      "Epoch [2/50], Train Loss: 0.1435, Val Loss: 0.3943\n",
      "Epoch [3/50], Train Loss: 0.1408, Val Loss: 0.3880\n",
      "Epoch [4/50], Train Loss: 0.1382, Val Loss: 0.3819\n",
      "Epoch [5/50], Train Loss: 0.1344, Val Loss: 0.3760\n",
      "Epoch [6/50], Train Loss: 0.1311, Val Loss: 0.3703\n",
      "Epoch [7/50], Train Loss: 0.1286, Val Loss: 0.3646\n",
      "Epoch [8/50], Train Loss: 0.1263, Val Loss: 0.3592\n",
      "Epoch [9/50], Train Loss: 0.1238, Val Loss: 0.3538\n",
      "Epoch [10/50], Train Loss: 0.1210, Val Loss: 0.3486\n",
      "Epoch [11/50], Train Loss: 0.1182, Val Loss: 0.3435\n",
      "Epoch [12/50], Train Loss: 0.1159, Val Loss: 0.3386\n",
      "Epoch [13/50], Train Loss: 0.1129, Val Loss: 0.3337\n",
      "Epoch [14/50], Train Loss: 0.1106, Val Loss: 0.3290\n",
      "Epoch [15/50], Train Loss: 0.1084, Val Loss: 0.3244\n",
      "Epoch [16/50], Train Loss: 0.1069, Val Loss: 0.3199\n",
      "Epoch [17/50], Train Loss: 0.1043, Val Loss: 0.3155\n",
      "Epoch [18/50], Train Loss: 0.1021, Val Loss: 0.3112\n",
      "Epoch [19/50], Train Loss: 0.0990, Val Loss: 0.3070\n",
      "Epoch [20/50], Train Loss: 0.0974, Val Loss: 0.3029\n",
      "Epoch [21/50], Train Loss: 0.0968, Val Loss: 0.2990\n",
      "Epoch [22/50], Train Loss: 0.0959, Val Loss: 0.2951\n",
      "Epoch [23/50], Train Loss: 0.0925, Val Loss: 0.2913\n",
      "Epoch [24/50], Train Loss: 0.0912, Val Loss: 0.2876\n",
      "Epoch [25/50], Train Loss: 0.0889, Val Loss: 0.2839\n",
      "Epoch [26/50], Train Loss: 0.0882, Val Loss: 0.2804\n",
      "Epoch [27/50], Train Loss: 0.0869, Val Loss: 0.2769\n",
      "Epoch [28/50], Train Loss: 0.0853, Val Loss: 0.2735\n",
      "Epoch [29/50], Train Loss: 0.0836, Val Loss: 0.2702\n",
      "Epoch [30/50], Train Loss: 0.0818, Val Loss: 0.2670\n",
      "Epoch [31/50], Train Loss: 0.0813, Val Loss: 0.2638\n",
      "Epoch [32/50], Train Loss: 0.0807, Val Loss: 0.2608\n",
      "Epoch [33/50], Train Loss: 0.0790, Val Loss: 0.2578\n",
      "Epoch [34/50], Train Loss: 0.0777, Val Loss: 0.2548\n",
      "Epoch [35/50], Train Loss: 0.0765, Val Loss: 0.2519\n",
      "Epoch [36/50], Train Loss: 0.0758, Val Loss: 0.2491\n",
      "Epoch [37/50], Train Loss: 0.0741, Val Loss: 0.2464\n",
      "Epoch [38/50], Train Loss: 0.0743, Val Loss: 0.2437\n",
      "Epoch [39/50], Train Loss: 0.0722, Val Loss: 0.2411\n",
      "Epoch [40/50], Train Loss: 0.0706, Val Loss: 0.2385\n",
      "Epoch [41/50], Train Loss: 0.0707, Val Loss: 0.2360\n",
      "Epoch [42/50], Train Loss: 0.0707, Val Loss: 0.2336\n",
      "Epoch [43/50], Train Loss: 0.0684, Val Loss: 0.2311\n",
      "Epoch [44/50], Train Loss: 0.0675, Val Loss: 0.2288\n",
      "Epoch [45/50], Train Loss: 0.0665, Val Loss: 0.2265\n",
      "Epoch [46/50], Train Loss: 0.0675, Val Loss: 0.2242\n",
      "Epoch [47/50], Train Loss: 0.0657, Val Loss: 0.2220\n",
      "Epoch [48/50], Train Loss: 0.0641, Val Loss: 0.2199\n",
      "Epoch [49/50], Train Loss: 0.0635, Val Loss: 0.2178\n",
      "Epoch [50/50], Train Loss: 0.0633, Val Loss: 0.2158\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1261, Val Loss: 0.3689\n",
      "Epoch [2/50], Train Loss: 0.1232, Val Loss: 0.3631\n",
      "Epoch [3/50], Train Loss: 0.1204, Val Loss: 0.3573\n",
      "Epoch [4/50], Train Loss: 0.1176, Val Loss: 0.3518\n",
      "Epoch [5/50], Train Loss: 0.1150, Val Loss: 0.3463\n",
      "Epoch [6/50], Train Loss: 0.1125, Val Loss: 0.3410\n",
      "Epoch [7/50], Train Loss: 0.1100, Val Loss: 0.3358\n",
      "Epoch [8/50], Train Loss: 0.1076, Val Loss: 0.3307\n",
      "Epoch [9/50], Train Loss: 0.1053, Val Loss: 0.3257\n",
      "Epoch [10/50], Train Loss: 0.1030, Val Loss: 0.3209\n",
      "Epoch [11/50], Train Loss: 0.1008, Val Loss: 0.3162\n",
      "Epoch [12/50], Train Loss: 0.0987, Val Loss: 0.3116\n",
      "Epoch [13/50], Train Loss: 0.0967, Val Loss: 0.3070\n",
      "Epoch [14/50], Train Loss: 0.0947, Val Loss: 0.3026\n",
      "Epoch [15/50], Train Loss: 0.0927, Val Loss: 0.2983\n",
      "Epoch [16/50], Train Loss: 0.0909, Val Loss: 0.2941\n",
      "Epoch [17/50], Train Loss: 0.0891, Val Loss: 0.2900\n",
      "Epoch [18/50], Train Loss: 0.0873, Val Loss: 0.2859\n",
      "Epoch [19/50], Train Loss: 0.0856, Val Loss: 0.2820\n",
      "Epoch [20/50], Train Loss: 0.0840, Val Loss: 0.2781\n",
      "Epoch [21/50], Train Loss: 0.0824, Val Loss: 0.2744\n",
      "Epoch [22/50], Train Loss: 0.0808, Val Loss: 0.2707\n",
      "Epoch [23/50], Train Loss: 0.0794, Val Loss: 0.2671\n",
      "Epoch [24/50], Train Loss: 0.0779, Val Loss: 0.2636\n",
      "Epoch [25/50], Train Loss: 0.0765, Val Loss: 0.2601\n",
      "Epoch [26/50], Train Loss: 0.0751, Val Loss: 0.2568\n",
      "Epoch [27/50], Train Loss: 0.0738, Val Loss: 0.2535\n",
      "Epoch [28/50], Train Loss: 0.0725, Val Loss: 0.2502\n",
      "Epoch [29/50], Train Loss: 0.0713, Val Loss: 0.2471\n",
      "Epoch [30/50], Train Loss: 0.0701, Val Loss: 0.2440\n",
      "Epoch [31/50], Train Loss: 0.0689, Val Loss: 0.2410\n",
      "Epoch [32/50], Train Loss: 0.0678, Val Loss: 0.2380\n",
      "Epoch [33/50], Train Loss: 0.0667, Val Loss: 0.2351\n",
      "Epoch [34/50], Train Loss: 0.0656, Val Loss: 0.2323\n",
      "Epoch [35/50], Train Loss: 0.0646, Val Loss: 0.2295\n",
      "Epoch [36/50], Train Loss: 0.0636, Val Loss: 0.2268\n",
      "Epoch [37/50], Train Loss: 0.0626, Val Loss: 0.2242\n",
      "Epoch [38/50], Train Loss: 0.0617, Val Loss: 0.2215\n",
      "Epoch [39/50], Train Loss: 0.0608, Val Loss: 0.2190\n",
      "Epoch [40/50], Train Loss: 0.0599, Val Loss: 0.2165\n",
      "Epoch [41/50], Train Loss: 0.0591, Val Loss: 0.2141\n",
      "Epoch [42/50], Train Loss: 0.0582, Val Loss: 0.2117\n",
      "Epoch [43/50], Train Loss: 0.0574, Val Loss: 0.2093\n",
      "Epoch [44/50], Train Loss: 0.0567, Val Loss: 0.2071\n",
      "Epoch [45/50], Train Loss: 0.0559, Val Loss: 0.2048\n",
      "Epoch [46/50], Train Loss: 0.0552, Val Loss: 0.2026\n",
      "Epoch [47/50], Train Loss: 0.0545, Val Loss: 0.2005\n",
      "Epoch [48/50], Train Loss: 0.0538, Val Loss: 0.1984\n",
      "Epoch [49/50], Train Loss: 0.0531, Val Loss: 0.1963\n",
      "Epoch [50/50], Train Loss: 0.0525, Val Loss: 0.1943\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1354, Val Loss: 0.3622\n",
      "Epoch [2/50], Train Loss: 0.1321, Val Loss: 0.3564\n",
      "Epoch [3/50], Train Loss: 0.1292, Val Loss: 0.3508\n",
      "Epoch [4/50], Train Loss: 0.1262, Val Loss: 0.3452\n",
      "Epoch [5/50], Train Loss: 0.1231, Val Loss: 0.3399\n",
      "Epoch [6/50], Train Loss: 0.1204, Val Loss: 0.3346\n",
      "Epoch [7/50], Train Loss: 0.1175, Val Loss: 0.3295\n",
      "Epoch [8/50], Train Loss: 0.1153, Val Loss: 0.3244\n",
      "Epoch [9/50], Train Loss: 0.1124, Val Loss: 0.3195\n",
      "Epoch [10/50], Train Loss: 0.1100, Val Loss: 0.3147\n",
      "Epoch [11/50], Train Loss: 0.1077, Val Loss: 0.3100\n",
      "Epoch [12/50], Train Loss: 0.1054, Val Loss: 0.3054\n",
      "Epoch [13/50], Train Loss: 0.1033, Val Loss: 0.3010\n",
      "Epoch [14/50], Train Loss: 0.1011, Val Loss: 0.2966\n",
      "Epoch [15/50], Train Loss: 0.0988, Val Loss: 0.2923\n",
      "Epoch [16/50], Train Loss: 0.0969, Val Loss: 0.2881\n",
      "Epoch [17/50], Train Loss: 0.0953, Val Loss: 0.2840\n",
      "Epoch [18/50], Train Loss: 0.0934, Val Loss: 0.2800\n",
      "Epoch [19/50], Train Loss: 0.0912, Val Loss: 0.2762\n",
      "Epoch [20/50], Train Loss: 0.0896, Val Loss: 0.2723\n",
      "Epoch [21/50], Train Loss: 0.0877, Val Loss: 0.2686\n",
      "Epoch [22/50], Train Loss: 0.0866, Val Loss: 0.2650\n",
      "Epoch [23/50], Train Loss: 0.0848, Val Loss: 0.2614\n",
      "Epoch [24/50], Train Loss: 0.0830, Val Loss: 0.2579\n",
      "Epoch [25/50], Train Loss: 0.0815, Val Loss: 0.2545\n",
      "Epoch [26/50], Train Loss: 0.0800, Val Loss: 0.2511\n",
      "Epoch [27/50], Train Loss: 0.0788, Val Loss: 0.2479\n",
      "Epoch [28/50], Train Loss: 0.0770, Val Loss: 0.2447\n",
      "Epoch [29/50], Train Loss: 0.0761, Val Loss: 0.2416\n",
      "Epoch [30/50], Train Loss: 0.0744, Val Loss: 0.2385\n",
      "Epoch [31/50], Train Loss: 0.0729, Val Loss: 0.2355\n",
      "Epoch [32/50], Train Loss: 0.0717, Val Loss: 0.2326\n",
      "Epoch [33/50], Train Loss: 0.0709, Val Loss: 0.2297\n",
      "Epoch [34/50], Train Loss: 0.0697, Val Loss: 0.2269\n",
      "Epoch [35/50], Train Loss: 0.0693, Val Loss: 0.2242\n",
      "Epoch [36/50], Train Loss: 0.0673, Val Loss: 0.2215\n",
      "Epoch [37/50], Train Loss: 0.0665, Val Loss: 0.2189\n",
      "Epoch [38/50], Train Loss: 0.0658, Val Loss: 0.2163\n",
      "Epoch [39/50], Train Loss: 0.0646, Val Loss: 0.2138\n",
      "Epoch [40/50], Train Loss: 0.0640, Val Loss: 0.2113\n",
      "Epoch [41/50], Train Loss: 0.0625, Val Loss: 0.2089\n",
      "Epoch [42/50], Train Loss: 0.0613, Val Loss: 0.2066\n",
      "Epoch [43/50], Train Loss: 0.0611, Val Loss: 0.2043\n",
      "Epoch [44/50], Train Loss: 0.0600, Val Loss: 0.2020\n",
      "Epoch [45/50], Train Loss: 0.0600, Val Loss: 0.1998\n",
      "Epoch [46/50], Train Loss: 0.0583, Val Loss: 0.1977\n",
      "Epoch [47/50], Train Loss: 0.0578, Val Loss: 0.1956\n",
      "Epoch [48/50], Train Loss: 0.0568, Val Loss: 0.1935\n",
      "Epoch [49/50], Train Loss: 0.0560, Val Loss: 0.1915\n",
      "Epoch [50/50], Train Loss: 0.0559, Val Loss: 0.1895\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1279, Val Loss: 0.3039\n",
      "Epoch [2/50], Train Loss: 0.1251, Val Loss: 0.2986\n",
      "Epoch [3/50], Train Loss: 0.1220, Val Loss: 0.2933\n",
      "Epoch [4/50], Train Loss: 0.1184, Val Loss: 0.2882\n",
      "Epoch [5/50], Train Loss: 0.1167, Val Loss: 0.2832\n",
      "Epoch [6/50], Train Loss: 0.1144, Val Loss: 0.2784\n",
      "Epoch [7/50], Train Loss: 0.1108, Val Loss: 0.2737\n",
      "Epoch [8/50], Train Loss: 0.1088, Val Loss: 0.2691\n",
      "Epoch [9/50], Train Loss: 0.1062, Val Loss: 0.2646\n",
      "Epoch [10/50], Train Loss: 0.1044, Val Loss: 0.2603\n",
      "Epoch [11/50], Train Loss: 0.1012, Val Loss: 0.2560\n",
      "Epoch [12/50], Train Loss: 0.0993, Val Loss: 0.2519\n",
      "Epoch [13/50], Train Loss: 0.0978, Val Loss: 0.2478\n",
      "Epoch [14/50], Train Loss: 0.0954, Val Loss: 0.2439\n",
      "Epoch [15/50], Train Loss: 0.0931, Val Loss: 0.2401\n",
      "Epoch [16/50], Train Loss: 0.0920, Val Loss: 0.2363\n",
      "Epoch [17/50], Train Loss: 0.0906, Val Loss: 0.2326\n",
      "Epoch [18/50], Train Loss: 0.0879, Val Loss: 0.2291\n",
      "Epoch [19/50], Train Loss: 0.0853, Val Loss: 0.2256\n",
      "Epoch [20/50], Train Loss: 0.0849, Val Loss: 0.2222\n",
      "Epoch [21/50], Train Loss: 0.0830, Val Loss: 0.2189\n",
      "Epoch [22/50], Train Loss: 0.0820, Val Loss: 0.2157\n",
      "Epoch [23/50], Train Loss: 0.0800, Val Loss: 0.2125\n",
      "Epoch [24/50], Train Loss: 0.0782, Val Loss: 0.2094\n",
      "Epoch [25/50], Train Loss: 0.0776, Val Loss: 0.2064\n",
      "Epoch [26/50], Train Loss: 0.0768, Val Loss: 0.2035\n",
      "Epoch [27/50], Train Loss: 0.0758, Val Loss: 0.2006\n",
      "Epoch [28/50], Train Loss: 0.0729, Val Loss: 0.1978\n",
      "Epoch [29/50], Train Loss: 0.0714, Val Loss: 0.1951\n",
      "Epoch [30/50], Train Loss: 0.0710, Val Loss: 0.1924\n",
      "Epoch [31/50], Train Loss: 0.0698, Val Loss: 0.1898\n",
      "Epoch [32/50], Train Loss: 0.0687, Val Loss: 0.1873\n",
      "Epoch [33/50], Train Loss: 0.0679, Val Loss: 0.1848\n",
      "Epoch [34/50], Train Loss: 0.0662, Val Loss: 0.1824\n",
      "Epoch [35/50], Train Loss: 0.0645, Val Loss: 0.1800\n",
      "Epoch [36/50], Train Loss: 0.0651, Val Loss: 0.1778\n",
      "Epoch [37/50], Train Loss: 0.0630, Val Loss: 0.1755\n",
      "Epoch [38/50], Train Loss: 0.0624, Val Loss: 0.1733\n",
      "Epoch [39/50], Train Loss: 0.0606, Val Loss: 0.1712\n",
      "Epoch [40/50], Train Loss: 0.0610, Val Loss: 0.1691\n",
      "Epoch [41/50], Train Loss: 0.0599, Val Loss: 0.1670\n",
      "Epoch [42/50], Train Loss: 0.0589, Val Loss: 0.1651\n",
      "Epoch [43/50], Train Loss: 0.0580, Val Loss: 0.1631\n",
      "Epoch [44/50], Train Loss: 0.0569, Val Loss: 0.1612\n",
      "Epoch [45/50], Train Loss: 0.0566, Val Loss: 0.1593\n",
      "Epoch [46/50], Train Loss: 0.0559, Val Loss: 0.1575\n",
      "Epoch [47/50], Train Loss: 0.0549, Val Loss: 0.1558\n",
      "Epoch [48/50], Train Loss: 0.0545, Val Loss: 0.1540\n",
      "Epoch [49/50], Train Loss: 0.0536, Val Loss: 0.1523\n",
      "Epoch [50/50], Train Loss: 0.0536, Val Loss: 0.1506\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1011, Val Loss: 0.3257\n",
      "Epoch [2/50], Train Loss: 0.0989, Val Loss: 0.3209\n",
      "Epoch [3/50], Train Loss: 0.0968, Val Loss: 0.3162\n",
      "Epoch [4/50], Train Loss: 0.0948, Val Loss: 0.3116\n",
      "Epoch [5/50], Train Loss: 0.0928, Val Loss: 0.3071\n",
      "Epoch [6/50], Train Loss: 0.0909, Val Loss: 0.3027\n",
      "Epoch [7/50], Train Loss: 0.0890, Val Loss: 0.2985\n",
      "Epoch [8/50], Train Loss: 0.0873, Val Loss: 0.2943\n",
      "Epoch [9/50], Train Loss: 0.0855, Val Loss: 0.2903\n",
      "Epoch [10/50], Train Loss: 0.0839, Val Loss: 0.2863\n",
      "Epoch [11/50], Train Loss: 0.0823, Val Loss: 0.2825\n",
      "Epoch [12/50], Train Loss: 0.0807, Val Loss: 0.2788\n",
      "Epoch [13/50], Train Loss: 0.0793, Val Loss: 0.2751\n",
      "Epoch [14/50], Train Loss: 0.0778, Val Loss: 0.2715\n",
      "Epoch [15/50], Train Loss: 0.0764, Val Loss: 0.2681\n",
      "Epoch [16/50], Train Loss: 0.0751, Val Loss: 0.2647\n",
      "Epoch [17/50], Train Loss: 0.0738, Val Loss: 0.2614\n",
      "Epoch [18/50], Train Loss: 0.0726, Val Loss: 0.2582\n",
      "Epoch [19/50], Train Loss: 0.0714, Val Loss: 0.2550\n",
      "Epoch [20/50], Train Loss: 0.0702, Val Loss: 0.2519\n",
      "Epoch [21/50], Train Loss: 0.0691, Val Loss: 0.2489\n",
      "Epoch [22/50], Train Loss: 0.0680, Val Loss: 0.2460\n",
      "Epoch [23/50], Train Loss: 0.0670, Val Loss: 0.2431\n",
      "Epoch [24/50], Train Loss: 0.0659, Val Loss: 0.2403\n",
      "Epoch [25/50], Train Loss: 0.0650, Val Loss: 0.2376\n",
      "Epoch [26/50], Train Loss: 0.0640, Val Loss: 0.2350\n",
      "Epoch [27/50], Train Loss: 0.0631, Val Loss: 0.2324\n",
      "Epoch [28/50], Train Loss: 0.0622, Val Loss: 0.2298\n",
      "Epoch [29/50], Train Loss: 0.0614, Val Loss: 0.2273\n",
      "Epoch [30/50], Train Loss: 0.0606, Val Loss: 0.2249\n",
      "Epoch [31/50], Train Loss: 0.0598, Val Loss: 0.2225\n",
      "Epoch [32/50], Train Loss: 0.0590, Val Loss: 0.2202\n",
      "Epoch [33/50], Train Loss: 0.0583, Val Loss: 0.2180\n",
      "Epoch [34/50], Train Loss: 0.0576, Val Loss: 0.2158\n",
      "Epoch [35/50], Train Loss: 0.0569, Val Loss: 0.2136\n",
      "Epoch [36/50], Train Loss: 0.0562, Val Loss: 0.2115\n",
      "Epoch [37/50], Train Loss: 0.0556, Val Loss: 0.2094\n",
      "Epoch [38/50], Train Loss: 0.0550, Val Loss: 0.2074\n",
      "Epoch [39/50], Train Loss: 0.0543, Val Loss: 0.2054\n",
      "Epoch [40/50], Train Loss: 0.0538, Val Loss: 0.2035\n",
      "Epoch [41/50], Train Loss: 0.0532, Val Loss: 0.2016\n",
      "Epoch [42/50], Train Loss: 0.0527, Val Loss: 0.1998\n",
      "Epoch [43/50], Train Loss: 0.0521, Val Loss: 0.1980\n",
      "Epoch [44/50], Train Loss: 0.0516, Val Loss: 0.1962\n",
      "Epoch [45/50], Train Loss: 0.0512, Val Loss: 0.1945\n",
      "Epoch [46/50], Train Loss: 0.0507, Val Loss: 0.1928\n",
      "Epoch [47/50], Train Loss: 0.0502, Val Loss: 0.1911\n",
      "Epoch [48/50], Train Loss: 0.0498, Val Loss: 0.1895\n",
      "Epoch [49/50], Train Loss: 0.0494, Val Loss: 0.1879\n",
      "Epoch [50/50], Train Loss: 0.0489, Val Loss: 0.1864\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1165, Val Loss: 0.3267\n",
      "Epoch [2/50], Train Loss: 0.1144, Val Loss: 0.3223\n",
      "Epoch [3/50], Train Loss: 0.1116, Val Loss: 0.3180\n",
      "Epoch [4/50], Train Loss: 0.1098, Val Loss: 0.3138\n",
      "Epoch [5/50], Train Loss: 0.1078, Val Loss: 0.3098\n",
      "Epoch [6/50], Train Loss: 0.1055, Val Loss: 0.3058\n",
      "Epoch [7/50], Train Loss: 0.1035, Val Loss: 0.3019\n",
      "Epoch [8/50], Train Loss: 0.1018, Val Loss: 0.2981\n",
      "Epoch [9/50], Train Loss: 0.0997, Val Loss: 0.2943\n",
      "Epoch [10/50], Train Loss: 0.0982, Val Loss: 0.2907\n",
      "Epoch [11/50], Train Loss: 0.0963, Val Loss: 0.2871\n",
      "Epoch [12/50], Train Loss: 0.0945, Val Loss: 0.2836\n",
      "Epoch [13/50], Train Loss: 0.0928, Val Loss: 0.2802\n",
      "Epoch [14/50], Train Loss: 0.0910, Val Loss: 0.2769\n",
      "Epoch [15/50], Train Loss: 0.0894, Val Loss: 0.2736\n",
      "Epoch [16/50], Train Loss: 0.0882, Val Loss: 0.2705\n",
      "Epoch [17/50], Train Loss: 0.0869, Val Loss: 0.2673\n",
      "Epoch [18/50], Train Loss: 0.0852, Val Loss: 0.2643\n",
      "Epoch [19/50], Train Loss: 0.0836, Val Loss: 0.2613\n",
      "Epoch [20/50], Train Loss: 0.0828, Val Loss: 0.2584\n",
      "Epoch [21/50], Train Loss: 0.0812, Val Loss: 0.2555\n",
      "Epoch [22/50], Train Loss: 0.0803, Val Loss: 0.2527\n",
      "Epoch [23/50], Train Loss: 0.0788, Val Loss: 0.2499\n",
      "Epoch [24/50], Train Loss: 0.0774, Val Loss: 0.2472\n",
      "Epoch [25/50], Train Loss: 0.0763, Val Loss: 0.2446\n",
      "Epoch [26/50], Train Loss: 0.0756, Val Loss: 0.2421\n",
      "Epoch [27/50], Train Loss: 0.0740, Val Loss: 0.2395\n",
      "Epoch [28/50], Train Loss: 0.0731, Val Loss: 0.2371\n",
      "Epoch [29/50], Train Loss: 0.0720, Val Loss: 0.2347\n",
      "Epoch [30/50], Train Loss: 0.0711, Val Loss: 0.2323\n",
      "Epoch [31/50], Train Loss: 0.0697, Val Loss: 0.2300\n",
      "Epoch [32/50], Train Loss: 0.0694, Val Loss: 0.2277\n",
      "Epoch [33/50], Train Loss: 0.0683, Val Loss: 0.2255\n",
      "Epoch [34/50], Train Loss: 0.0675, Val Loss: 0.2233\n",
      "Epoch [35/50], Train Loss: 0.0665, Val Loss: 0.2212\n",
      "Epoch [36/50], Train Loss: 0.0658, Val Loss: 0.2191\n",
      "Epoch [37/50], Train Loss: 0.0646, Val Loss: 0.2171\n",
      "Epoch [38/50], Train Loss: 0.0639, Val Loss: 0.2151\n",
      "Epoch [39/50], Train Loss: 0.0633, Val Loss: 0.2131\n",
      "Epoch [40/50], Train Loss: 0.0629, Val Loss: 0.2112\n",
      "Epoch [41/50], Train Loss: 0.0617, Val Loss: 0.2093\n",
      "Epoch [42/50], Train Loss: 0.0611, Val Loss: 0.2075\n",
      "Epoch [43/50], Train Loss: 0.0604, Val Loss: 0.2057\n",
      "Epoch [44/50], Train Loss: 0.0600, Val Loss: 0.2039\n",
      "Epoch [45/50], Train Loss: 0.0591, Val Loss: 0.2022\n",
      "Epoch [46/50], Train Loss: 0.0584, Val Loss: 0.2005\n",
      "Epoch [47/50], Train Loss: 0.0581, Val Loss: 0.1989\n",
      "Epoch [48/50], Train Loss: 0.0572, Val Loss: 0.1972\n",
      "Epoch [49/50], Train Loss: 0.0567, Val Loss: 0.1956\n",
      "Epoch [50/50], Train Loss: 0.0560, Val Loss: 0.1941\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1792, Val Loss: 0.4633\n",
      "Epoch [2/50], Train Loss: 0.1750, Val Loss: 0.4550\n",
      "Epoch [3/50], Train Loss: 0.1688, Val Loss: 0.4471\n",
      "Epoch [4/50], Train Loss: 0.1650, Val Loss: 0.4393\n",
      "Epoch [5/50], Train Loss: 0.1611, Val Loss: 0.4317\n",
      "Epoch [6/50], Train Loss: 0.1590, Val Loss: 0.4244\n",
      "Epoch [7/50], Train Loss: 0.1532, Val Loss: 0.4172\n",
      "Epoch [8/50], Train Loss: 0.1494, Val Loss: 0.4103\n",
      "Epoch [9/50], Train Loss: 0.1448, Val Loss: 0.4035\n",
      "Epoch [10/50], Train Loss: 0.1422, Val Loss: 0.3969\n",
      "Epoch [11/50], Train Loss: 0.1388, Val Loss: 0.3905\n",
      "Epoch [12/50], Train Loss: 0.1361, Val Loss: 0.3843\n",
      "Epoch [13/50], Train Loss: 0.1324, Val Loss: 0.3782\n",
      "Epoch [14/50], Train Loss: 0.1295, Val Loss: 0.3722\n",
      "Epoch [15/50], Train Loss: 0.1262, Val Loss: 0.3664\n",
      "Epoch [16/50], Train Loss: 0.1228, Val Loss: 0.3608\n",
      "Epoch [17/50], Train Loss: 0.1222, Val Loss: 0.3553\n",
      "Epoch [18/50], Train Loss: 0.1178, Val Loss: 0.3499\n",
      "Epoch [19/50], Train Loss: 0.1159, Val Loss: 0.3446\n",
      "Epoch [20/50], Train Loss: 0.1124, Val Loss: 0.3396\n",
      "Epoch [21/50], Train Loss: 0.1102, Val Loss: 0.3346\n",
      "Epoch [22/50], Train Loss: 0.1089, Val Loss: 0.3298\n",
      "Epoch [23/50], Train Loss: 0.1069, Val Loss: 0.3250\n",
      "Epoch [24/50], Train Loss: 0.1045, Val Loss: 0.3204\n",
      "Epoch [25/50], Train Loss: 0.1024, Val Loss: 0.3159\n",
      "Epoch [26/50], Train Loss: 0.1004, Val Loss: 0.3115\n",
      "Epoch [27/50], Train Loss: 0.0983, Val Loss: 0.3072\n",
      "Epoch [28/50], Train Loss: 0.0973, Val Loss: 0.3030\n",
      "Epoch [29/50], Train Loss: 0.0951, Val Loss: 0.2989\n",
      "Epoch [30/50], Train Loss: 0.0926, Val Loss: 0.2949\n",
      "Epoch [31/50], Train Loss: 0.0909, Val Loss: 0.2910\n",
      "Epoch [32/50], Train Loss: 0.0898, Val Loss: 0.2873\n",
      "Epoch [33/50], Train Loss: 0.0882, Val Loss: 0.2835\n",
      "Epoch [34/50], Train Loss: 0.0864, Val Loss: 0.2799\n",
      "Epoch [35/50], Train Loss: 0.0850, Val Loss: 0.2764\n",
      "Epoch [36/50], Train Loss: 0.0823, Val Loss: 0.2730\n",
      "Epoch [37/50], Train Loss: 0.0819, Val Loss: 0.2696\n",
      "Epoch [38/50], Train Loss: 0.0810, Val Loss: 0.2663\n",
      "Epoch [39/50], Train Loss: 0.0785, Val Loss: 0.2630\n",
      "Epoch [40/50], Train Loss: 0.0778, Val Loss: 0.2599\n",
      "Epoch [41/50], Train Loss: 0.0763, Val Loss: 0.2568\n",
      "Epoch [42/50], Train Loss: 0.0759, Val Loss: 0.2538\n",
      "Epoch [43/50], Train Loss: 0.0747, Val Loss: 0.2509\n",
      "Epoch [44/50], Train Loss: 0.0727, Val Loss: 0.2480\n",
      "Epoch [45/50], Train Loss: 0.0721, Val Loss: 0.2452\n",
      "Epoch [46/50], Train Loss: 0.0709, Val Loss: 0.2425\n",
      "Epoch [47/50], Train Loss: 0.0708, Val Loss: 0.2398\n",
      "Epoch [48/50], Train Loss: 0.0688, Val Loss: 0.2372\n",
      "Epoch [49/50], Train Loss: 0.0682, Val Loss: 0.2346\n",
      "Epoch [50/50], Train Loss: 0.0671, Val Loss: 0.2322\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1046, Val Loss: 0.2924\n",
      "Epoch [2/50], Train Loss: 0.1024, Val Loss: 0.2883\n",
      "Epoch [3/50], Train Loss: 0.1003, Val Loss: 0.2843\n",
      "Epoch [4/50], Train Loss: 0.0982, Val Loss: 0.2804\n",
      "Epoch [5/50], Train Loss: 0.0962, Val Loss: 0.2766\n",
      "Epoch [6/50], Train Loss: 0.0942, Val Loss: 0.2729\n",
      "Epoch [7/50], Train Loss: 0.0924, Val Loss: 0.2693\n",
      "Epoch [8/50], Train Loss: 0.0905, Val Loss: 0.2658\n",
      "Epoch [9/50], Train Loss: 0.0888, Val Loss: 0.2623\n",
      "Epoch [10/50], Train Loss: 0.0871, Val Loss: 0.2590\n",
      "Epoch [11/50], Train Loss: 0.0854, Val Loss: 0.2557\n",
      "Epoch [12/50], Train Loss: 0.0838, Val Loss: 0.2525\n",
      "Epoch [13/50], Train Loss: 0.0823, Val Loss: 0.2494\n",
      "Epoch [14/50], Train Loss: 0.0808, Val Loss: 0.2463\n",
      "Epoch [15/50], Train Loss: 0.0794, Val Loss: 0.2434\n",
      "Epoch [16/50], Train Loss: 0.0780, Val Loss: 0.2405\n",
      "Epoch [17/50], Train Loss: 0.0766, Val Loss: 0.2376\n",
      "Epoch [18/50], Train Loss: 0.0753, Val Loss: 0.2349\n",
      "Epoch [19/50], Train Loss: 0.0741, Val Loss: 0.2322\n",
      "Epoch [20/50], Train Loss: 0.0728, Val Loss: 0.2296\n",
      "Epoch [21/50], Train Loss: 0.0717, Val Loss: 0.2270\n",
      "Epoch [22/50], Train Loss: 0.0705, Val Loss: 0.2245\n",
      "Epoch [23/50], Train Loss: 0.0694, Val Loss: 0.2220\n",
      "Epoch [24/50], Train Loss: 0.0684, Val Loss: 0.2196\n",
      "Epoch [25/50], Train Loss: 0.0673, Val Loss: 0.2173\n",
      "Epoch [26/50], Train Loss: 0.0663, Val Loss: 0.2150\n",
      "Epoch [27/50], Train Loss: 0.0654, Val Loss: 0.2128\n",
      "Epoch [28/50], Train Loss: 0.0644, Val Loss: 0.2106\n",
      "Epoch [29/50], Train Loss: 0.0635, Val Loss: 0.2085\n",
      "Epoch [30/50], Train Loss: 0.0627, Val Loss: 0.2064\n",
      "Epoch [31/50], Train Loss: 0.0618, Val Loss: 0.2044\n",
      "Epoch [32/50], Train Loss: 0.0610, Val Loss: 0.2024\n",
      "Epoch [33/50], Train Loss: 0.0602, Val Loss: 0.2005\n",
      "Epoch [34/50], Train Loss: 0.0594, Val Loss: 0.1986\n",
      "Epoch [35/50], Train Loss: 0.0587, Val Loss: 0.1967\n",
      "Epoch [36/50], Train Loss: 0.0580, Val Loss: 0.1949\n",
      "Epoch [37/50], Train Loss: 0.0573, Val Loss: 0.1931\n",
      "Epoch [38/50], Train Loss: 0.0566, Val Loss: 0.1914\n",
      "Epoch [39/50], Train Loss: 0.0560, Val Loss: 0.1897\n",
      "Epoch [40/50], Train Loss: 0.0554, Val Loss: 0.1881\n",
      "Epoch [41/50], Train Loss: 0.0547, Val Loss: 0.1865\n",
      "Epoch [42/50], Train Loss: 0.0542, Val Loss: 0.1849\n",
      "Epoch [43/50], Train Loss: 0.0536, Val Loss: 0.1833\n",
      "Epoch [44/50], Train Loss: 0.0531, Val Loss: 0.1818\n",
      "Epoch [45/50], Train Loss: 0.0525, Val Loss: 0.1804\n",
      "Epoch [46/50], Train Loss: 0.0520, Val Loss: 0.1789\n",
      "Epoch [47/50], Train Loss: 0.0515, Val Loss: 0.1775\n",
      "Epoch [48/50], Train Loss: 0.0510, Val Loss: 0.1761\n",
      "Epoch [49/50], Train Loss: 0.0506, Val Loss: 0.1748\n",
      "Epoch [50/50], Train Loss: 0.0501, Val Loss: 0.1735\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.2002, Val Loss: 0.4837\n",
      "Epoch [2/50], Train Loss: 0.1950, Val Loss: 0.4754\n",
      "Epoch [3/50], Train Loss: 0.1898, Val Loss: 0.4672\n",
      "Epoch [4/50], Train Loss: 0.1856, Val Loss: 0.4593\n",
      "Epoch [5/50], Train Loss: 0.1806, Val Loss: 0.4516\n",
      "Epoch [6/50], Train Loss: 0.1762, Val Loss: 0.4440\n",
      "Epoch [7/50], Train Loss: 0.1721, Val Loss: 0.4367\n",
      "Epoch [8/50], Train Loss: 0.1675, Val Loss: 0.4296\n",
      "Epoch [9/50], Train Loss: 0.1639, Val Loss: 0.4226\n",
      "Epoch [10/50], Train Loss: 0.1600, Val Loss: 0.4159\n",
      "Epoch [11/50], Train Loss: 0.1564, Val Loss: 0.4092\n",
      "Epoch [12/50], Train Loss: 0.1525, Val Loss: 0.4028\n",
      "Epoch [13/50], Train Loss: 0.1487, Val Loss: 0.3965\n",
      "Epoch [14/50], Train Loss: 0.1453, Val Loss: 0.3904\n",
      "Epoch [15/50], Train Loss: 0.1419, Val Loss: 0.3845\n",
      "Epoch [16/50], Train Loss: 0.1388, Val Loss: 0.3787\n",
      "Epoch [17/50], Train Loss: 0.1360, Val Loss: 0.3730\n",
      "Epoch [18/50], Train Loss: 0.1330, Val Loss: 0.3674\n",
      "Epoch [19/50], Train Loss: 0.1301, Val Loss: 0.3620\n",
      "Epoch [20/50], Train Loss: 0.1268, Val Loss: 0.3568\n",
      "Epoch [21/50], Train Loss: 0.1244, Val Loss: 0.3516\n",
      "Epoch [22/50], Train Loss: 0.1217, Val Loss: 0.3466\n",
      "Epoch [23/50], Train Loss: 0.1191, Val Loss: 0.3417\n",
      "Epoch [24/50], Train Loss: 0.1168, Val Loss: 0.3369\n",
      "Epoch [25/50], Train Loss: 0.1139, Val Loss: 0.3323\n",
      "Epoch [26/50], Train Loss: 0.1120, Val Loss: 0.3277\n",
      "Epoch [27/50], Train Loss: 0.1099, Val Loss: 0.3232\n",
      "Epoch [28/50], Train Loss: 0.1073, Val Loss: 0.3189\n",
      "Epoch [29/50], Train Loss: 0.1054, Val Loss: 0.3146\n",
      "Epoch [30/50], Train Loss: 0.1035, Val Loss: 0.3105\n",
      "Epoch [31/50], Train Loss: 0.1013, Val Loss: 0.3064\n",
      "Epoch [32/50], Train Loss: 0.0992, Val Loss: 0.3025\n",
      "Epoch [33/50], Train Loss: 0.0974, Val Loss: 0.2986\n",
      "Epoch [34/50], Train Loss: 0.0955, Val Loss: 0.2948\n",
      "Epoch [35/50], Train Loss: 0.0938, Val Loss: 0.2912\n",
      "Epoch [36/50], Train Loss: 0.0924, Val Loss: 0.2875\n",
      "Epoch [37/50], Train Loss: 0.0906, Val Loss: 0.2840\n",
      "Epoch [38/50], Train Loss: 0.0890, Val Loss: 0.2806\n",
      "Epoch [39/50], Train Loss: 0.0873, Val Loss: 0.2772\n",
      "Epoch [40/50], Train Loss: 0.0855, Val Loss: 0.2739\n",
      "Epoch [41/50], Train Loss: 0.0842, Val Loss: 0.2707\n",
      "Epoch [42/50], Train Loss: 0.0829, Val Loss: 0.2675\n",
      "Epoch [43/50], Train Loss: 0.0813, Val Loss: 0.2644\n",
      "Epoch [44/50], Train Loss: 0.0801, Val Loss: 0.2614\n",
      "Epoch [45/50], Train Loss: 0.0791, Val Loss: 0.2584\n",
      "Epoch [46/50], Train Loss: 0.0780, Val Loss: 0.2555\n",
      "Epoch [47/50], Train Loss: 0.0766, Val Loss: 0.2527\n",
      "Epoch [48/50], Train Loss: 0.0755, Val Loss: 0.2500\n",
      "Epoch [49/50], Train Loss: 0.0742, Val Loss: 0.2472\n",
      "Epoch [50/50], Train Loss: 0.0730, Val Loss: 0.2446\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.2212, Val Loss: 0.4945\n",
      "Epoch [2/50], Train Loss: 0.2150, Val Loss: 0.4858\n",
      "Epoch [3/50], Train Loss: 0.2098, Val Loss: 0.4773\n",
      "Epoch [4/50], Train Loss: 0.2036, Val Loss: 0.4690\n",
      "Epoch [5/50], Train Loss: 0.1988, Val Loss: 0.4610\n",
      "Epoch [6/50], Train Loss: 0.1943, Val Loss: 0.4531\n",
      "Epoch [7/50], Train Loss: 0.1892, Val Loss: 0.4455\n",
      "Epoch [8/50], Train Loss: 0.1848, Val Loss: 0.4381\n",
      "Epoch [9/50], Train Loss: 0.1802, Val Loss: 0.4308\n",
      "Epoch [10/50], Train Loss: 0.1754, Val Loss: 0.4237\n",
      "Epoch [11/50], Train Loss: 0.1714, Val Loss: 0.4168\n",
      "Epoch [12/50], Train Loss: 0.1670, Val Loss: 0.4101\n",
      "Epoch [13/50], Train Loss: 0.1627, Val Loss: 0.4036\n",
      "Epoch [14/50], Train Loss: 0.1589, Val Loss: 0.3972\n",
      "Epoch [15/50], Train Loss: 0.1551, Val Loss: 0.3910\n",
      "Epoch [16/50], Train Loss: 0.1518, Val Loss: 0.3849\n",
      "Epoch [17/50], Train Loss: 0.1485, Val Loss: 0.3790\n",
      "Epoch [18/50], Train Loss: 0.1449, Val Loss: 0.3733\n",
      "Epoch [19/50], Train Loss: 0.1423, Val Loss: 0.3676\n",
      "Epoch [20/50], Train Loss: 0.1393, Val Loss: 0.3621\n",
      "Epoch [21/50], Train Loss: 0.1352, Val Loss: 0.3567\n",
      "Epoch [22/50], Train Loss: 0.1326, Val Loss: 0.3515\n",
      "Epoch [23/50], Train Loss: 0.1294, Val Loss: 0.3464\n",
      "Epoch [24/50], Train Loss: 0.1283, Val Loss: 0.3414\n",
      "Epoch [25/50], Train Loss: 0.1240, Val Loss: 0.3366\n",
      "Epoch [26/50], Train Loss: 0.1216, Val Loss: 0.3318\n",
      "Epoch [27/50], Train Loss: 0.1188, Val Loss: 0.3272\n",
      "Epoch [28/50], Train Loss: 0.1169, Val Loss: 0.3226\n",
      "Epoch [29/50], Train Loss: 0.1145, Val Loss: 0.3182\n",
      "Epoch [30/50], Train Loss: 0.1114, Val Loss: 0.3139\n",
      "Epoch [31/50], Train Loss: 0.1097, Val Loss: 0.3097\n",
      "Epoch [32/50], Train Loss: 0.1073, Val Loss: 0.3055\n",
      "Epoch [33/50], Train Loss: 0.1050, Val Loss: 0.3015\n",
      "Epoch [34/50], Train Loss: 0.1036, Val Loss: 0.2976\n",
      "Epoch [35/50], Train Loss: 0.1007, Val Loss: 0.2937\n",
      "Epoch [36/50], Train Loss: 0.0991, Val Loss: 0.2900\n",
      "Epoch [37/50], Train Loss: 0.0978, Val Loss: 0.2863\n",
      "Epoch [38/50], Train Loss: 0.0958, Val Loss: 0.2827\n",
      "Epoch [39/50], Train Loss: 0.0938, Val Loss: 0.2792\n",
      "Epoch [40/50], Train Loss: 0.0928, Val Loss: 0.2757\n",
      "Epoch [41/50], Train Loss: 0.0906, Val Loss: 0.2723\n",
      "Epoch [42/50], Train Loss: 0.0886, Val Loss: 0.2691\n",
      "Epoch [43/50], Train Loss: 0.0871, Val Loss: 0.2658\n",
      "Epoch [44/50], Train Loss: 0.0861, Val Loss: 0.2627\n",
      "Epoch [45/50], Train Loss: 0.0842, Val Loss: 0.2597\n",
      "Epoch [46/50], Train Loss: 0.0828, Val Loss: 0.2567\n",
      "Epoch [47/50], Train Loss: 0.0821, Val Loss: 0.2538\n",
      "Epoch [48/50], Train Loss: 0.0800, Val Loss: 0.2509\n",
      "Epoch [49/50], Train Loss: 0.0796, Val Loss: 0.2481\n",
      "Epoch [50/50], Train Loss: 0.0783, Val Loss: 0.2453\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1485, Val Loss: 0.3873\n",
      "Epoch [2/50], Train Loss: 0.1450, Val Loss: 0.3809\n",
      "Epoch [3/50], Train Loss: 0.1416, Val Loss: 0.3748\n",
      "Epoch [4/50], Train Loss: 0.1383, Val Loss: 0.3687\n",
      "Epoch [5/50], Train Loss: 0.1351, Val Loss: 0.3628\n",
      "Epoch [6/50], Train Loss: 0.1320, Val Loss: 0.3571\n",
      "Epoch [7/50], Train Loss: 0.1290, Val Loss: 0.3515\n",
      "Epoch [8/50], Train Loss: 0.1261, Val Loss: 0.3460\n",
      "Epoch [9/50], Train Loss: 0.1233, Val Loss: 0.3407\n",
      "Epoch [10/50], Train Loss: 0.1206, Val Loss: 0.3355\n",
      "Epoch [11/50], Train Loss: 0.1179, Val Loss: 0.3304\n",
      "Epoch [12/50], Train Loss: 0.1153, Val Loss: 0.3254\n",
      "Epoch [13/50], Train Loss: 0.1129, Val Loss: 0.3205\n",
      "Epoch [14/50], Train Loss: 0.1105, Val Loss: 0.3158\n",
      "Epoch [15/50], Train Loss: 0.1081, Val Loss: 0.3111\n",
      "Epoch [16/50], Train Loss: 0.1059, Val Loss: 0.3066\n",
      "Epoch [17/50], Train Loss: 0.1037, Val Loss: 0.3021\n",
      "Epoch [18/50], Train Loss: 0.1015, Val Loss: 0.2978\n",
      "Epoch [19/50], Train Loss: 0.0995, Val Loss: 0.2936\n",
      "Epoch [20/50], Train Loss: 0.0975, Val Loss: 0.2894\n",
      "Epoch [21/50], Train Loss: 0.0955, Val Loss: 0.2854\n",
      "Epoch [22/50], Train Loss: 0.0936, Val Loss: 0.2814\n",
      "Epoch [23/50], Train Loss: 0.0918, Val Loss: 0.2775\n",
      "Epoch [24/50], Train Loss: 0.0900, Val Loss: 0.2737\n",
      "Epoch [25/50], Train Loss: 0.0883, Val Loss: 0.2700\n",
      "Epoch [26/50], Train Loss: 0.0866, Val Loss: 0.2664\n",
      "Epoch [27/50], Train Loss: 0.0850, Val Loss: 0.2628\n",
      "Epoch [28/50], Train Loss: 0.0835, Val Loss: 0.2594\n",
      "Epoch [29/50], Train Loss: 0.0819, Val Loss: 0.2560\n",
      "Epoch [30/50], Train Loss: 0.0805, Val Loss: 0.2527\n",
      "Epoch [31/50], Train Loss: 0.0790, Val Loss: 0.2494\n",
      "Epoch [32/50], Train Loss: 0.0776, Val Loss: 0.2462\n",
      "Epoch [33/50], Train Loss: 0.0763, Val Loss: 0.2431\n",
      "Epoch [34/50], Train Loss: 0.0750, Val Loss: 0.2401\n",
      "Epoch [35/50], Train Loss: 0.0737, Val Loss: 0.2371\n",
      "Epoch [36/50], Train Loss: 0.0725, Val Loss: 0.2341\n",
      "Epoch [37/50], Train Loss: 0.0713, Val Loss: 0.2313\n",
      "Epoch [38/50], Train Loss: 0.0701, Val Loss: 0.2285\n",
      "Epoch [39/50], Train Loss: 0.0690, Val Loss: 0.2258\n",
      "Epoch [40/50], Train Loss: 0.0679, Val Loss: 0.2231\n",
      "Epoch [41/50], Train Loss: 0.0669, Val Loss: 0.2204\n",
      "Epoch [42/50], Train Loss: 0.0658, Val Loss: 0.2179\n",
      "Epoch [43/50], Train Loss: 0.0648, Val Loss: 0.2153\n",
      "Epoch [44/50], Train Loss: 0.0639, Val Loss: 0.2129\n",
      "Epoch [45/50], Train Loss: 0.0629, Val Loss: 0.2105\n",
      "Epoch [46/50], Train Loss: 0.0620, Val Loss: 0.2081\n",
      "Epoch [47/50], Train Loss: 0.0612, Val Loss: 0.2058\n",
      "Epoch [48/50], Train Loss: 0.0603, Val Loss: 0.2035\n",
      "Epoch [49/50], Train Loss: 0.0595, Val Loss: 0.2013\n",
      "Epoch [50/50], Train Loss: 0.0587, Val Loss: 0.1991\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1650, Val Loss: 0.4369\n",
      "Epoch [2/50], Train Loss: 0.1606, Val Loss: 0.4291\n",
      "Epoch [3/50], Train Loss: 0.1566, Val Loss: 0.4215\n",
      "Epoch [4/50], Train Loss: 0.1525, Val Loss: 0.4141\n",
      "Epoch [5/50], Train Loss: 0.1494, Val Loss: 0.4069\n",
      "Epoch [6/50], Train Loss: 0.1451, Val Loss: 0.3998\n",
      "Epoch [7/50], Train Loss: 0.1418, Val Loss: 0.3930\n",
      "Epoch [8/50], Train Loss: 0.1384, Val Loss: 0.3863\n",
      "Epoch [9/50], Train Loss: 0.1347, Val Loss: 0.3798\n",
      "Epoch [10/50], Train Loss: 0.1319, Val Loss: 0.3734\n",
      "Epoch [11/50], Train Loss: 0.1285, Val Loss: 0.3672\n",
      "Epoch [12/50], Train Loss: 0.1256, Val Loss: 0.3611\n",
      "Epoch [13/50], Train Loss: 0.1228, Val Loss: 0.3553\n",
      "Epoch [14/50], Train Loss: 0.1200, Val Loss: 0.3495\n",
      "Epoch [15/50], Train Loss: 0.1167, Val Loss: 0.3439\n",
      "Epoch [16/50], Train Loss: 0.1148, Val Loss: 0.3384\n",
      "Epoch [17/50], Train Loss: 0.1117, Val Loss: 0.3331\n",
      "Epoch [18/50], Train Loss: 0.1094, Val Loss: 0.3279\n",
      "Epoch [19/50], Train Loss: 0.1072, Val Loss: 0.3227\n",
      "Epoch [20/50], Train Loss: 0.1048, Val Loss: 0.3178\n",
      "Epoch [21/50], Train Loss: 0.1022, Val Loss: 0.3129\n",
      "Epoch [22/50], Train Loss: 0.1003, Val Loss: 0.3082\n",
      "Epoch [23/50], Train Loss: 0.0978, Val Loss: 0.3035\n",
      "Epoch [24/50], Train Loss: 0.0959, Val Loss: 0.2990\n",
      "Epoch [25/50], Train Loss: 0.0942, Val Loss: 0.2946\n",
      "Epoch [26/50], Train Loss: 0.0922, Val Loss: 0.2903\n",
      "Epoch [27/50], Train Loss: 0.0904, Val Loss: 0.2860\n",
      "Epoch [28/50], Train Loss: 0.0884, Val Loss: 0.2819\n",
      "Epoch [29/50], Train Loss: 0.0867, Val Loss: 0.2779\n",
      "Epoch [30/50], Train Loss: 0.0849, Val Loss: 0.2740\n",
      "Epoch [31/50], Train Loss: 0.0831, Val Loss: 0.2701\n",
      "Epoch [32/50], Train Loss: 0.0821, Val Loss: 0.2664\n",
      "Epoch [33/50], Train Loss: 0.0802, Val Loss: 0.2627\n",
      "Epoch [34/50], Train Loss: 0.0786, Val Loss: 0.2591\n",
      "Epoch [35/50], Train Loss: 0.0772, Val Loss: 0.2556\n",
      "Epoch [36/50], Train Loss: 0.0757, Val Loss: 0.2522\n",
      "Epoch [37/50], Train Loss: 0.0742, Val Loss: 0.2488\n",
      "Epoch [38/50], Train Loss: 0.0732, Val Loss: 0.2455\n",
      "Epoch [39/50], Train Loss: 0.0721, Val Loss: 0.2424\n",
      "Epoch [40/50], Train Loss: 0.0706, Val Loss: 0.2392\n",
      "Epoch [41/50], Train Loss: 0.0696, Val Loss: 0.2362\n",
      "Epoch [42/50], Train Loss: 0.0682, Val Loss: 0.2332\n",
      "Epoch [43/50], Train Loss: 0.0676, Val Loss: 0.2303\n",
      "Epoch [44/50], Train Loss: 0.0662, Val Loss: 0.2274\n",
      "Epoch [45/50], Train Loss: 0.0651, Val Loss: 0.2246\n",
      "Epoch [46/50], Train Loss: 0.0640, Val Loss: 0.2219\n",
      "Epoch [47/50], Train Loss: 0.0632, Val Loss: 0.2192\n",
      "Epoch [48/50], Train Loss: 0.0622, Val Loss: 0.2166\n",
      "Epoch [49/50], Train Loss: 0.0613, Val Loss: 0.2140\n",
      "Epoch [50/50], Train Loss: 0.0604, Val Loss: 0.2115\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1397, Val Loss: 0.3832\n",
      "Epoch [2/50], Train Loss: 0.1372, Val Loss: 0.3768\n",
      "Epoch [3/50], Train Loss: 0.1333, Val Loss: 0.3706\n",
      "Epoch [4/50], Train Loss: 0.1297, Val Loss: 0.3646\n",
      "Epoch [5/50], Train Loss: 0.1265, Val Loss: 0.3587\n",
      "Epoch [6/50], Train Loss: 0.1243, Val Loss: 0.3529\n",
      "Epoch [7/50], Train Loss: 0.1209, Val Loss: 0.3473\n",
      "Epoch [8/50], Train Loss: 0.1183, Val Loss: 0.3419\n",
      "Epoch [9/50], Train Loss: 0.1165, Val Loss: 0.3365\n",
      "Epoch [10/50], Train Loss: 0.1137, Val Loss: 0.3313\n",
      "Epoch [11/50], Train Loss: 0.1113, Val Loss: 0.3262\n",
      "Epoch [12/50], Train Loss: 0.1088, Val Loss: 0.3212\n",
      "Epoch [13/50], Train Loss: 0.1066, Val Loss: 0.3164\n",
      "Epoch [14/50], Train Loss: 0.1043, Val Loss: 0.3117\n",
      "Epoch [15/50], Train Loss: 0.1018, Val Loss: 0.3071\n",
      "Epoch [16/50], Train Loss: 0.0999, Val Loss: 0.3026\n",
      "Epoch [17/50], Train Loss: 0.0976, Val Loss: 0.2982\n",
      "Epoch [18/50], Train Loss: 0.0959, Val Loss: 0.2939\n",
      "Epoch [19/50], Train Loss: 0.0944, Val Loss: 0.2897\n",
      "Epoch [20/50], Train Loss: 0.0927, Val Loss: 0.2856\n",
      "Epoch [21/50], Train Loss: 0.0905, Val Loss: 0.2816\n",
      "Epoch [22/50], Train Loss: 0.0886, Val Loss: 0.2777\n",
      "Epoch [23/50], Train Loss: 0.0862, Val Loss: 0.2739\n",
      "Epoch [24/50], Train Loss: 0.0856, Val Loss: 0.2701\n",
      "Epoch [25/50], Train Loss: 0.0837, Val Loss: 0.2665\n",
      "Epoch [26/50], Train Loss: 0.0815, Val Loss: 0.2629\n",
      "Epoch [27/50], Train Loss: 0.0797, Val Loss: 0.2594\n",
      "Epoch [28/50], Train Loss: 0.0786, Val Loss: 0.2560\n",
      "Epoch [29/50], Train Loss: 0.0776, Val Loss: 0.2527\n",
      "Epoch [30/50], Train Loss: 0.0768, Val Loss: 0.2494\n",
      "Epoch [31/50], Train Loss: 0.0754, Val Loss: 0.2463\n",
      "Epoch [32/50], Train Loss: 0.0735, Val Loss: 0.2432\n",
      "Epoch [33/50], Train Loss: 0.0726, Val Loss: 0.2402\n",
      "Epoch [34/50], Train Loss: 0.0716, Val Loss: 0.2372\n",
      "Epoch [35/50], Train Loss: 0.0704, Val Loss: 0.2343\n",
      "Epoch [36/50], Train Loss: 0.0687, Val Loss: 0.2314\n",
      "Epoch [37/50], Train Loss: 0.0681, Val Loss: 0.2287\n",
      "Epoch [38/50], Train Loss: 0.0669, Val Loss: 0.2259\n",
      "Epoch [39/50], Train Loss: 0.0663, Val Loss: 0.2233\n",
      "Epoch [40/50], Train Loss: 0.0649, Val Loss: 0.2207\n",
      "Epoch [41/50], Train Loss: 0.0634, Val Loss: 0.2181\n",
      "Epoch [42/50], Train Loss: 0.0630, Val Loss: 0.2157\n",
      "Epoch [43/50], Train Loss: 0.0623, Val Loss: 0.2132\n",
      "Epoch [44/50], Train Loss: 0.0614, Val Loss: 0.2108\n",
      "Epoch [45/50], Train Loss: 0.0610, Val Loss: 0.2085\n",
      "Epoch [46/50], Train Loss: 0.0599, Val Loss: 0.2062\n",
      "Epoch [47/50], Train Loss: 0.0591, Val Loss: 0.2040\n",
      "Epoch [48/50], Train Loss: 0.0581, Val Loss: 0.2018\n",
      "Epoch [49/50], Train Loss: 0.0579, Val Loss: 0.1996\n",
      "Epoch [50/50], Train Loss: 0.0577, Val Loss: 0.1975\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1311, Val Loss: 0.3686\n",
      "Epoch [2/50], Train Loss: 0.1282, Val Loss: 0.3632\n",
      "Epoch [3/50], Train Loss: 0.1254, Val Loss: 0.3579\n",
      "Epoch [4/50], Train Loss: 0.1226, Val Loss: 0.3528\n",
      "Epoch [5/50], Train Loss: 0.1200, Val Loss: 0.3477\n",
      "Epoch [6/50], Train Loss: 0.1174, Val Loss: 0.3428\n",
      "Epoch [7/50], Train Loss: 0.1149, Val Loss: 0.3380\n",
      "Epoch [8/50], Train Loss: 0.1125, Val Loss: 0.3333\n",
      "Epoch [9/50], Train Loss: 0.1102, Val Loss: 0.3287\n",
      "Epoch [10/50], Train Loss: 0.1079, Val Loss: 0.3242\n",
      "Epoch [11/50], Train Loss: 0.1057, Val Loss: 0.3198\n",
      "Epoch [12/50], Train Loss: 0.1036, Val Loss: 0.3155\n",
      "Epoch [13/50], Train Loss: 0.1015, Val Loss: 0.3113\n",
      "Epoch [14/50], Train Loss: 0.0995, Val Loss: 0.3072\n",
      "Epoch [15/50], Train Loss: 0.0975, Val Loss: 0.3031\n",
      "Epoch [16/50], Train Loss: 0.0957, Val Loss: 0.2992\n",
      "Epoch [17/50], Train Loss: 0.0938, Val Loss: 0.2954\n",
      "Epoch [18/50], Train Loss: 0.0920, Val Loss: 0.2916\n",
      "Epoch [19/50], Train Loss: 0.0903, Val Loss: 0.2879\n",
      "Epoch [20/50], Train Loss: 0.0887, Val Loss: 0.2843\n",
      "Epoch [21/50], Train Loss: 0.0870, Val Loss: 0.2808\n",
      "Epoch [22/50], Train Loss: 0.0855, Val Loss: 0.2774\n",
      "Epoch [23/50], Train Loss: 0.0839, Val Loss: 0.2740\n",
      "Epoch [24/50], Train Loss: 0.0825, Val Loss: 0.2707\n",
      "Epoch [25/50], Train Loss: 0.0810, Val Loss: 0.2675\n",
      "Epoch [26/50], Train Loss: 0.0797, Val Loss: 0.2643\n",
      "Epoch [27/50], Train Loss: 0.0783, Val Loss: 0.2613\n",
      "Epoch [28/50], Train Loss: 0.0770, Val Loss: 0.2582\n",
      "Epoch [29/50], Train Loss: 0.0757, Val Loss: 0.2553\n",
      "Epoch [30/50], Train Loss: 0.0745, Val Loss: 0.2524\n",
      "Epoch [31/50], Train Loss: 0.0733, Val Loss: 0.2496\n",
      "Epoch [32/50], Train Loss: 0.0722, Val Loss: 0.2468\n",
      "Epoch [33/50], Train Loss: 0.0711, Val Loss: 0.2441\n",
      "Epoch [34/50], Train Loss: 0.0700, Val Loss: 0.2414\n",
      "Epoch [35/50], Train Loss: 0.0689, Val Loss: 0.2388\n",
      "Epoch [36/50], Train Loss: 0.0679, Val Loss: 0.2363\n",
      "Epoch [37/50], Train Loss: 0.0669, Val Loss: 0.2338\n",
      "Epoch [38/50], Train Loss: 0.0660, Val Loss: 0.2314\n",
      "Epoch [39/50], Train Loss: 0.0650, Val Loss: 0.2290\n",
      "Epoch [40/50], Train Loss: 0.0641, Val Loss: 0.2266\n",
      "Epoch [41/50], Train Loss: 0.0633, Val Loss: 0.2243\n",
      "Epoch [42/50], Train Loss: 0.0624, Val Loss: 0.2221\n",
      "Epoch [43/50], Train Loss: 0.0616, Val Loss: 0.2199\n",
      "Epoch [44/50], Train Loss: 0.0608, Val Loss: 0.2178\n",
      "Epoch [45/50], Train Loss: 0.0600, Val Loss: 0.2157\n",
      "Epoch [46/50], Train Loss: 0.0593, Val Loss: 0.2136\n",
      "Epoch [47/50], Train Loss: 0.0586, Val Loss: 0.2116\n",
      "Epoch [48/50], Train Loss: 0.0579, Val Loss: 0.2096\n",
      "Epoch [49/50], Train Loss: 0.0572, Val Loss: 0.2077\n",
      "Epoch [50/50], Train Loss: 0.0566, Val Loss: 0.2058\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1383, Val Loss: 0.3735\n",
      "Epoch [2/50], Train Loss: 0.1345, Val Loss: 0.3675\n",
      "Epoch [3/50], Train Loss: 0.1311, Val Loss: 0.3616\n",
      "Epoch [4/50], Train Loss: 0.1285, Val Loss: 0.3558\n",
      "Epoch [5/50], Train Loss: 0.1251, Val Loss: 0.3502\n",
      "Epoch [6/50], Train Loss: 0.1224, Val Loss: 0.3447\n",
      "Epoch [7/50], Train Loss: 0.1194, Val Loss: 0.3393\n",
      "Epoch [8/50], Train Loss: 0.1169, Val Loss: 0.3341\n",
      "Epoch [9/50], Train Loss: 0.1141, Val Loss: 0.3290\n",
      "Epoch [10/50], Train Loss: 0.1119, Val Loss: 0.3240\n",
      "Epoch [11/50], Train Loss: 0.1093, Val Loss: 0.3192\n",
      "Epoch [12/50], Train Loss: 0.1066, Val Loss: 0.3145\n",
      "Epoch [13/50], Train Loss: 0.1043, Val Loss: 0.3098\n",
      "Epoch [14/50], Train Loss: 0.1018, Val Loss: 0.3053\n",
      "Epoch [15/50], Train Loss: 0.1001, Val Loss: 0.3009\n",
      "Epoch [16/50], Train Loss: 0.0979, Val Loss: 0.2966\n",
      "Epoch [17/50], Train Loss: 0.0962, Val Loss: 0.2924\n",
      "Epoch [18/50], Train Loss: 0.0937, Val Loss: 0.2883\n",
      "Epoch [19/50], Train Loss: 0.0918, Val Loss: 0.2843\n",
      "Epoch [20/50], Train Loss: 0.0898, Val Loss: 0.2804\n",
      "Epoch [21/50], Train Loss: 0.0881, Val Loss: 0.2766\n",
      "Epoch [22/50], Train Loss: 0.0867, Val Loss: 0.2728\n",
      "Epoch [23/50], Train Loss: 0.0847, Val Loss: 0.2692\n",
      "Epoch [24/50], Train Loss: 0.0834, Val Loss: 0.2656\n",
      "Epoch [25/50], Train Loss: 0.0814, Val Loss: 0.2621\n",
      "Epoch [26/50], Train Loss: 0.0799, Val Loss: 0.2587\n",
      "Epoch [27/50], Train Loss: 0.0791, Val Loss: 0.2554\n",
      "Epoch [28/50], Train Loss: 0.0773, Val Loss: 0.2522\n",
      "Epoch [29/50], Train Loss: 0.0758, Val Loss: 0.2490\n",
      "Epoch [30/50], Train Loss: 0.0747, Val Loss: 0.2459\n",
      "Epoch [31/50], Train Loss: 0.0731, Val Loss: 0.2428\n",
      "Epoch [32/50], Train Loss: 0.0721, Val Loss: 0.2399\n",
      "Epoch [33/50], Train Loss: 0.0707, Val Loss: 0.2370\n",
      "Epoch [34/50], Train Loss: 0.0696, Val Loss: 0.2341\n",
      "Epoch [35/50], Train Loss: 0.0686, Val Loss: 0.2314\n",
      "Epoch [36/50], Train Loss: 0.0675, Val Loss: 0.2286\n",
      "Epoch [37/50], Train Loss: 0.0663, Val Loss: 0.2260\n",
      "Epoch [38/50], Train Loss: 0.0655, Val Loss: 0.2234\n",
      "Epoch [39/50], Train Loss: 0.0646, Val Loss: 0.2209\n",
      "Epoch [40/50], Train Loss: 0.0635, Val Loss: 0.2184\n",
      "Epoch [41/50], Train Loss: 0.0624, Val Loss: 0.2160\n",
      "Epoch [42/50], Train Loss: 0.0617, Val Loss: 0.2136\n",
      "Epoch [43/50], Train Loss: 0.0610, Val Loss: 0.2113\n",
      "Epoch [44/50], Train Loss: 0.0599, Val Loss: 0.2090\n",
      "Epoch [45/50], Train Loss: 0.0589, Val Loss: 0.2068\n",
      "Epoch [46/50], Train Loss: 0.0583, Val Loss: 0.2046\n",
      "Epoch [47/50], Train Loss: 0.0576, Val Loss: 0.2025\n",
      "Epoch [48/50], Train Loss: 0.0569, Val Loss: 0.2004\n",
      "Epoch [49/50], Train Loss: 0.0562, Val Loss: 0.1984\n",
      "Epoch [50/50], Train Loss: 0.0556, Val Loss: 0.1964\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1067, Val Loss: 0.3252\n",
      "Epoch [2/50], Train Loss: 0.1047, Val Loss: 0.3206\n",
      "Epoch [3/50], Train Loss: 0.1024, Val Loss: 0.3161\n",
      "Epoch [4/50], Train Loss: 0.1004, Val Loss: 0.3117\n",
      "Epoch [5/50], Train Loss: 0.0987, Val Loss: 0.3074\n",
      "Epoch [6/50], Train Loss: 0.0971, Val Loss: 0.3032\n",
      "Epoch [7/50], Train Loss: 0.0951, Val Loss: 0.2991\n",
      "Epoch [8/50], Train Loss: 0.0927, Val Loss: 0.2951\n",
      "Epoch [9/50], Train Loss: 0.0908, Val Loss: 0.2912\n",
      "Epoch [10/50], Train Loss: 0.0898, Val Loss: 0.2874\n",
      "Epoch [11/50], Train Loss: 0.0879, Val Loss: 0.2837\n",
      "Epoch [12/50], Train Loss: 0.0859, Val Loss: 0.2801\n",
      "Epoch [13/50], Train Loss: 0.0848, Val Loss: 0.2765\n",
      "Epoch [14/50], Train Loss: 0.0834, Val Loss: 0.2730\n",
      "Epoch [15/50], Train Loss: 0.0819, Val Loss: 0.2696\n",
      "Epoch [16/50], Train Loss: 0.0797, Val Loss: 0.2663\n",
      "Epoch [17/50], Train Loss: 0.0794, Val Loss: 0.2631\n",
      "Epoch [18/50], Train Loss: 0.0778, Val Loss: 0.2599\n",
      "Epoch [19/50], Train Loss: 0.0766, Val Loss: 0.2568\n",
      "Epoch [20/50], Train Loss: 0.0753, Val Loss: 0.2537\n",
      "Epoch [21/50], Train Loss: 0.0737, Val Loss: 0.2508\n",
      "Epoch [22/50], Train Loss: 0.0726, Val Loss: 0.2479\n",
      "Epoch [23/50], Train Loss: 0.0712, Val Loss: 0.2451\n",
      "Epoch [24/50], Train Loss: 0.0703, Val Loss: 0.2423\n",
      "Epoch [25/50], Train Loss: 0.0689, Val Loss: 0.2396\n",
      "Epoch [26/50], Train Loss: 0.0685, Val Loss: 0.2370\n",
      "Epoch [27/50], Train Loss: 0.0675, Val Loss: 0.2344\n",
      "Epoch [28/50], Train Loss: 0.0662, Val Loss: 0.2318\n",
      "Epoch [29/50], Train Loss: 0.0651, Val Loss: 0.2294\n",
      "Epoch [30/50], Train Loss: 0.0649, Val Loss: 0.2269\n",
      "Epoch [31/50], Train Loss: 0.0641, Val Loss: 0.2246\n",
      "Epoch [32/50], Train Loss: 0.0633, Val Loss: 0.2222\n",
      "Epoch [33/50], Train Loss: 0.0618, Val Loss: 0.2200\n",
      "Epoch [34/50], Train Loss: 0.0614, Val Loss: 0.2177\n",
      "Epoch [35/50], Train Loss: 0.0599, Val Loss: 0.2156\n",
      "Epoch [36/50], Train Loss: 0.0599, Val Loss: 0.2134\n",
      "Epoch [37/50], Train Loss: 0.0593, Val Loss: 0.2114\n",
      "Epoch [38/50], Train Loss: 0.0585, Val Loss: 0.2093\n",
      "Epoch [39/50], Train Loss: 0.0577, Val Loss: 0.2073\n",
      "Epoch [40/50], Train Loss: 0.0575, Val Loss: 0.2054\n",
      "Epoch [41/50], Train Loss: 0.0567, Val Loss: 0.2035\n",
      "Epoch [42/50], Train Loss: 0.0562, Val Loss: 0.2016\n",
      "Epoch [43/50], Train Loss: 0.0556, Val Loss: 0.1998\n",
      "Epoch [44/50], Train Loss: 0.0550, Val Loss: 0.1980\n",
      "Epoch [45/50], Train Loss: 0.0542, Val Loss: 0.1962\n",
      "Epoch [46/50], Train Loss: 0.0538, Val Loss: 0.1945\n",
      "Epoch [47/50], Train Loss: 0.0537, Val Loss: 0.1928\n",
      "Epoch [48/50], Train Loss: 0.0531, Val Loss: 0.1912\n",
      "Epoch [49/50], Train Loss: 0.0525, Val Loss: 0.1896\n",
      "Epoch [50/50], Train Loss: 0.0520, Val Loss: 0.1880\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1448, Val Loss: 0.3654\n",
      "Epoch [2/50], Train Loss: 0.1415, Val Loss: 0.3599\n",
      "Epoch [3/50], Train Loss: 0.1383, Val Loss: 0.3546\n",
      "Epoch [4/50], Train Loss: 0.1352, Val Loss: 0.3495\n",
      "Epoch [5/50], Train Loss: 0.1322, Val Loss: 0.3444\n",
      "Epoch [6/50], Train Loss: 0.1293, Val Loss: 0.3395\n",
      "Epoch [7/50], Train Loss: 0.1265, Val Loss: 0.3346\n",
      "Epoch [8/50], Train Loss: 0.1238, Val Loss: 0.3299\n",
      "Epoch [9/50], Train Loss: 0.1211, Val Loss: 0.3253\n",
      "Epoch [10/50], Train Loss: 0.1186, Val Loss: 0.3208\n",
      "Epoch [11/50], Train Loss: 0.1161, Val Loss: 0.3164\n",
      "Epoch [12/50], Train Loss: 0.1136, Val Loss: 0.3121\n",
      "Epoch [13/50], Train Loss: 0.1113, Val Loss: 0.3079\n",
      "Epoch [14/50], Train Loss: 0.1090, Val Loss: 0.3038\n",
      "Epoch [15/50], Train Loss: 0.1068, Val Loss: 0.2998\n",
      "Epoch [16/50], Train Loss: 0.1047, Val Loss: 0.2959\n",
      "Epoch [17/50], Train Loss: 0.1026, Val Loss: 0.2920\n",
      "Epoch [18/50], Train Loss: 0.1006, Val Loss: 0.2883\n",
      "Epoch [19/50], Train Loss: 0.0986, Val Loss: 0.2846\n",
      "Epoch [20/50], Train Loss: 0.0967, Val Loss: 0.2811\n",
      "Epoch [21/50], Train Loss: 0.0949, Val Loss: 0.2776\n",
      "Epoch [22/50], Train Loss: 0.0931, Val Loss: 0.2741\n",
      "Epoch [23/50], Train Loss: 0.0914, Val Loss: 0.2708\n",
      "Epoch [24/50], Train Loss: 0.0897, Val Loss: 0.2675\n",
      "Epoch [25/50], Train Loss: 0.0881, Val Loss: 0.2643\n",
      "Epoch [26/50], Train Loss: 0.0865, Val Loss: 0.2612\n",
      "Epoch [27/50], Train Loss: 0.0849, Val Loss: 0.2581\n",
      "Epoch [28/50], Train Loss: 0.0835, Val Loss: 0.2551\n",
      "Epoch [29/50], Train Loss: 0.0820, Val Loss: 0.2522\n",
      "Epoch [30/50], Train Loss: 0.0806, Val Loss: 0.2493\n",
      "Epoch [31/50], Train Loss: 0.0793, Val Loss: 0.2465\n",
      "Epoch [32/50], Train Loss: 0.0780, Val Loss: 0.2438\n",
      "Epoch [33/50], Train Loss: 0.0767, Val Loss: 0.2411\n",
      "Epoch [34/50], Train Loss: 0.0754, Val Loss: 0.2385\n",
      "Epoch [35/50], Train Loss: 0.0742, Val Loss: 0.2359\n",
      "Epoch [36/50], Train Loss: 0.0731, Val Loss: 0.2334\n",
      "Epoch [37/50], Train Loss: 0.0720, Val Loss: 0.2309\n",
      "Epoch [38/50], Train Loss: 0.0709, Val Loss: 0.2285\n",
      "Epoch [39/50], Train Loss: 0.0698, Val Loss: 0.2261\n",
      "Epoch [40/50], Train Loss: 0.0688, Val Loss: 0.2238\n",
      "Epoch [41/50], Train Loss: 0.0678, Val Loss: 0.2216\n",
      "Epoch [42/50], Train Loss: 0.0668, Val Loss: 0.2194\n",
      "Epoch [43/50], Train Loss: 0.0659, Val Loss: 0.2172\n",
      "Epoch [44/50], Train Loss: 0.0650, Val Loss: 0.2151\n",
      "Epoch [45/50], Train Loss: 0.0641, Val Loss: 0.2130\n",
      "Epoch [46/50], Train Loss: 0.0633, Val Loss: 0.2110\n",
      "Epoch [47/50], Train Loss: 0.0624, Val Loss: 0.2090\n",
      "Epoch [48/50], Train Loss: 0.0616, Val Loss: 0.2071\n",
      "Epoch [49/50], Train Loss: 0.0609, Val Loss: 0.2052\n",
      "Epoch [50/50], Train Loss: 0.0601, Val Loss: 0.2033\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1401, Val Loss: 0.3853\n",
      "Epoch [2/50], Train Loss: 0.1370, Val Loss: 0.3787\n",
      "Epoch [3/50], Train Loss: 0.1331, Val Loss: 0.3723\n",
      "Epoch [4/50], Train Loss: 0.1301, Val Loss: 0.3661\n",
      "Epoch [5/50], Train Loss: 0.1268, Val Loss: 0.3601\n",
      "Epoch [6/50], Train Loss: 0.1236, Val Loss: 0.3542\n",
      "Epoch [7/50], Train Loss: 0.1209, Val Loss: 0.3484\n",
      "Epoch [8/50], Train Loss: 0.1174, Val Loss: 0.3428\n",
      "Epoch [9/50], Train Loss: 0.1153, Val Loss: 0.3374\n",
      "Epoch [10/50], Train Loss: 0.1122, Val Loss: 0.3321\n",
      "Epoch [11/50], Train Loss: 0.1099, Val Loss: 0.3269\n",
      "Epoch [12/50], Train Loss: 0.1069, Val Loss: 0.3219\n",
      "Epoch [13/50], Train Loss: 0.1046, Val Loss: 0.3170\n",
      "Epoch [14/50], Train Loss: 0.1026, Val Loss: 0.3122\n",
      "Epoch [15/50], Train Loss: 0.0998, Val Loss: 0.3075\n",
      "Epoch [16/50], Train Loss: 0.0981, Val Loss: 0.3030\n",
      "Epoch [17/50], Train Loss: 0.0963, Val Loss: 0.2986\n",
      "Epoch [18/50], Train Loss: 0.0943, Val Loss: 0.2942\n",
      "Epoch [19/50], Train Loss: 0.0921, Val Loss: 0.2900\n",
      "Epoch [20/50], Train Loss: 0.0902, Val Loss: 0.2859\n",
      "Epoch [21/50], Train Loss: 0.0882, Val Loss: 0.2819\n",
      "Epoch [22/50], Train Loss: 0.0867, Val Loss: 0.2780\n",
      "Epoch [23/50], Train Loss: 0.0845, Val Loss: 0.2742\n",
      "Epoch [24/50], Train Loss: 0.0830, Val Loss: 0.2705\n",
      "Epoch [25/50], Train Loss: 0.0817, Val Loss: 0.2668\n",
      "Epoch [26/50], Train Loss: 0.0802, Val Loss: 0.2633\n",
      "Epoch [27/50], Train Loss: 0.0783, Val Loss: 0.2599\n",
      "Epoch [28/50], Train Loss: 0.0769, Val Loss: 0.2565\n",
      "Epoch [29/50], Train Loss: 0.0753, Val Loss: 0.2532\n",
      "Epoch [30/50], Train Loss: 0.0739, Val Loss: 0.2500\n",
      "Epoch [31/50], Train Loss: 0.0731, Val Loss: 0.2469\n",
      "Epoch [32/50], Train Loss: 0.0718, Val Loss: 0.2438\n",
      "Epoch [33/50], Train Loss: 0.0704, Val Loss: 0.2408\n",
      "Epoch [34/50], Train Loss: 0.0699, Val Loss: 0.2379\n",
      "Epoch [35/50], Train Loss: 0.0684, Val Loss: 0.2351\n",
      "Epoch [36/50], Train Loss: 0.0671, Val Loss: 0.2323\n",
      "Epoch [37/50], Train Loss: 0.0661, Val Loss: 0.2296\n",
      "Epoch [38/50], Train Loss: 0.0652, Val Loss: 0.2269\n",
      "Epoch [39/50], Train Loss: 0.0639, Val Loss: 0.2244\n",
      "Epoch [40/50], Train Loss: 0.0633, Val Loss: 0.2218\n",
      "Epoch [41/50], Train Loss: 0.0625, Val Loss: 0.2194\n",
      "Epoch [42/50], Train Loss: 0.0615, Val Loss: 0.2170\n",
      "Epoch [43/50], Train Loss: 0.0608, Val Loss: 0.2146\n",
      "Epoch [44/50], Train Loss: 0.0605, Val Loss: 0.2123\n",
      "Epoch [45/50], Train Loss: 0.0591, Val Loss: 0.2101\n",
      "Epoch [46/50], Train Loss: 0.0581, Val Loss: 0.2079\n",
      "Epoch [47/50], Train Loss: 0.0576, Val Loss: 0.2057\n",
      "Epoch [48/50], Train Loss: 0.0568, Val Loss: 0.2036\n",
      "Epoch [49/50], Train Loss: 0.0561, Val Loss: 0.2016\n",
      "Epoch [50/50], Train Loss: 0.0557, Val Loss: 0.1996\n",
      "Testing parameters: lr=0.001, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1573, Val Loss: 0.4247\n",
      "Epoch [2/50], Train Loss: 0.1523, Val Loss: 0.4181\n",
      "Epoch [3/50], Train Loss: 0.1490, Val Loss: 0.4116\n",
      "Epoch [4/50], Train Loss: 0.1458, Val Loss: 0.4052\n",
      "Epoch [5/50], Train Loss: 0.1426, Val Loss: 0.3990\n",
      "Epoch [6/50], Train Loss: 0.1392, Val Loss: 0.3930\n",
      "Epoch [7/50], Train Loss: 0.1368, Val Loss: 0.3871\n",
      "Epoch [8/50], Train Loss: 0.1332, Val Loss: 0.3813\n",
      "Epoch [9/50], Train Loss: 0.1296, Val Loss: 0.3757\n",
      "Epoch [10/50], Train Loss: 0.1277, Val Loss: 0.3702\n",
      "Epoch [11/50], Train Loss: 0.1246, Val Loss: 0.3648\n",
      "Epoch [12/50], Train Loss: 0.1224, Val Loss: 0.3596\n",
      "Epoch [13/50], Train Loss: 0.1193, Val Loss: 0.3544\n",
      "Epoch [14/50], Train Loss: 0.1175, Val Loss: 0.3494\n",
      "Epoch [15/50], Train Loss: 0.1151, Val Loss: 0.3445\n",
      "Epoch [16/50], Train Loss: 0.1125, Val Loss: 0.3397\n",
      "Epoch [17/50], Train Loss: 0.1098, Val Loss: 0.3351\n",
      "Epoch [18/50], Train Loss: 0.1079, Val Loss: 0.3305\n",
      "Epoch [19/50], Train Loss: 0.1059, Val Loss: 0.3260\n",
      "Epoch [20/50], Train Loss: 0.1041, Val Loss: 0.3216\n",
      "Epoch [21/50], Train Loss: 0.1016, Val Loss: 0.3173\n",
      "Epoch [22/50], Train Loss: 0.0997, Val Loss: 0.3132\n",
      "Epoch [23/50], Train Loss: 0.0972, Val Loss: 0.3091\n",
      "Epoch [24/50], Train Loss: 0.0961, Val Loss: 0.3051\n",
      "Epoch [25/50], Train Loss: 0.0944, Val Loss: 0.3012\n",
      "Epoch [26/50], Train Loss: 0.0927, Val Loss: 0.2974\n",
      "Epoch [27/50], Train Loss: 0.0906, Val Loss: 0.2937\n",
      "Epoch [28/50], Train Loss: 0.0888, Val Loss: 0.2901\n",
      "Epoch [29/50], Train Loss: 0.0876, Val Loss: 0.2865\n",
      "Epoch [30/50], Train Loss: 0.0859, Val Loss: 0.2830\n",
      "Epoch [31/50], Train Loss: 0.0845, Val Loss: 0.2796\n",
      "Epoch [32/50], Train Loss: 0.0831, Val Loss: 0.2763\n",
      "Epoch [33/50], Train Loss: 0.0823, Val Loss: 0.2730\n",
      "Epoch [34/50], Train Loss: 0.0806, Val Loss: 0.2698\n",
      "Epoch [35/50], Train Loss: 0.0791, Val Loss: 0.2667\n",
      "Epoch [36/50], Train Loss: 0.0784, Val Loss: 0.2636\n",
      "Epoch [37/50], Train Loss: 0.0763, Val Loss: 0.2606\n",
      "Epoch [38/50], Train Loss: 0.0760, Val Loss: 0.2577\n",
      "Epoch [39/50], Train Loss: 0.0744, Val Loss: 0.2548\n",
      "Epoch [40/50], Train Loss: 0.0730, Val Loss: 0.2520\n",
      "Epoch [41/50], Train Loss: 0.0729, Val Loss: 0.2493\n",
      "Epoch [42/50], Train Loss: 0.0707, Val Loss: 0.2466\n",
      "Epoch [43/50], Train Loss: 0.0702, Val Loss: 0.2439\n",
      "Epoch [44/50], Train Loss: 0.0696, Val Loss: 0.2414\n",
      "Epoch [45/50], Train Loss: 0.0684, Val Loss: 0.2388\n",
      "Epoch [46/50], Train Loss: 0.0675, Val Loss: 0.2364\n",
      "Epoch [47/50], Train Loss: 0.0665, Val Loss: 0.2339\n",
      "Epoch [48/50], Train Loss: 0.0654, Val Loss: 0.2316\n",
      "Epoch [49/50], Train Loss: 0.0648, Val Loss: 0.2292\n",
      "Epoch [50/50], Train Loss: 0.0635, Val Loss: 0.2270\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1209, Val Loss: 0.2691\n",
      "Epoch [2/50], Train Loss: 0.0475, Val Loss: 0.0837\n",
      "Epoch [3/50], Train Loss: 0.0282, Val Loss: 0.0434\n",
      "Epoch [4/50], Train Loss: 0.0280, Val Loss: 0.0346\n",
      "Epoch [5/50], Train Loss: 0.0249, Val Loss: 0.0260\n",
      "Epoch [6/50], Train Loss: 0.0228, Val Loss: 0.0205\n",
      "Epoch [7/50], Train Loss: 0.0207, Val Loss: 0.0165\n",
      "Epoch [8/50], Train Loss: 0.0190, Val Loss: 0.0135\n",
      "Epoch [9/50], Train Loss: 0.0174, Val Loss: 0.0112\n",
      "Epoch [10/50], Train Loss: 0.0160, Val Loss: 0.0094\n",
      "Epoch [11/50], Train Loss: 0.0144, Val Loss: 0.0079\n",
      "Epoch [12/50], Train Loss: 0.0124, Val Loss: 0.0065\n",
      "Epoch [13/50], Train Loss: 0.0095, Val Loss: 0.0046\n",
      "Epoch [14/50], Train Loss: 0.0062, Val Loss: 0.0040\n",
      "Epoch [15/50], Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [16/50], Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [17/50], Train Loss: 0.0029, Val Loss: 0.0046\n",
      "Epoch [18/50], Train Loss: 0.0029, Val Loss: 0.0029\n",
      "Epoch [19/50], Train Loss: 0.0032, Val Loss: 0.0038\n",
      "Epoch [20/50], Train Loss: 0.0025, Val Loss: 0.0029\n",
      "Epoch [21/50], Train Loss: 0.0025, Val Loss: 0.0029\n",
      "Epoch [22/50], Train Loss: 0.0024, Val Loss: 0.0029\n",
      "Epoch [23/50], Train Loss: 0.0026, Val Loss: 0.0038\n",
      "Epoch [24/50], Train Loss: 0.0023, Val Loss: 0.0030\n",
      "Epoch [25/50], Train Loss: 0.0027, Val Loss: 0.0033\n",
      "Epoch [26/50], Train Loss: 0.0026, Val Loss: 0.0034\n",
      "Epoch [27/50], Train Loss: 0.0048, Val Loss: 0.0087\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0787, Val Loss: 0.2123\n",
      "Epoch [2/50], Train Loss: 0.0405, Val Loss: 0.0999\n",
      "Epoch [3/50], Train Loss: 0.0323, Val Loss: 0.0593\n",
      "Epoch [4/50], Train Loss: 0.0283, Val Loss: 0.0377\n",
      "Epoch [5/50], Train Loss: 0.0219, Val Loss: 0.0198\n",
      "Epoch [6/50], Train Loss: 0.0157, Val Loss: 0.0176\n",
      "Epoch [7/50], Train Loss: 0.0131, Val Loss: 0.0142\n",
      "Epoch [8/50], Train Loss: 0.0119, Val Loss: 0.0121\n",
      "Epoch [9/50], Train Loss: 0.0106, Val Loss: 0.0129\n",
      "Epoch [10/50], Train Loss: 0.0098, Val Loss: 0.0170\n",
      "Epoch [11/50], Train Loss: 0.0102, Val Loss: 0.0087\n",
      "Epoch [12/50], Train Loss: 0.0107, Val Loss: 0.0115\n",
      "Epoch [13/50], Train Loss: 0.0102, Val Loss: 0.0125\n",
      "Epoch [14/50], Train Loss: 0.0087, Val Loss: 0.0097\n",
      "Epoch [15/50], Train Loss: 0.0100, Val Loss: 0.0089\n",
      "Epoch [16/50], Train Loss: 0.0080, Val Loss: 0.0128\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1012, Val Loss: 0.2346\n",
      "Epoch [2/50], Train Loss: 0.0606, Val Loss: 0.1259\n",
      "Epoch [3/50], Train Loss: 0.0461, Val Loss: 0.0756\n",
      "Epoch [4/50], Train Loss: 0.0422, Val Loss: 0.0523\n",
      "Epoch [5/50], Train Loss: 0.0343, Val Loss: 0.0293\n",
      "Epoch [6/50], Train Loss: 0.0291, Val Loss: 0.0222\n",
      "Epoch [7/50], Train Loss: 0.0242, Val Loss: 0.0223\n",
      "Epoch [8/50], Train Loss: 0.0225, Val Loss: 0.0161\n",
      "Epoch [9/50], Train Loss: 0.0202, Val Loss: 0.0192\n",
      "Epoch [10/50], Train Loss: 0.0207, Val Loss: 0.0136\n",
      "Epoch [11/50], Train Loss: 0.0191, Val Loss: 0.0123\n",
      "Epoch [12/50], Train Loss: 0.0173, Val Loss: 0.0217\n",
      "Epoch [13/50], Train Loss: 0.0176, Val Loss: 0.0091\n",
      "Epoch [14/50], Train Loss: 0.0160, Val Loss: 0.0154\n",
      "Epoch [15/50], Train Loss: 0.0149, Val Loss: 0.0095\n",
      "Epoch [16/50], Train Loss: 0.0136, Val Loss: 0.0132\n",
      "Epoch [17/50], Train Loss: 0.0139, Val Loss: 0.0091\n",
      "Epoch [18/50], Train Loss: 0.0132, Val Loss: 0.0113\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1267, Val Loss: 0.2115\n",
      "Epoch [2/50], Train Loss: 0.0397, Val Loss: 0.0511\n",
      "Epoch [3/50], Train Loss: 0.0495, Val Loss: 0.0843\n",
      "Epoch [4/50], Train Loss: 0.0373, Val Loss: 0.0661\n",
      "Epoch [5/50], Train Loss: 0.0374, Val Loss: 0.0617\n",
      "Epoch [6/50], Train Loss: 0.0338, Val Loss: 0.0494\n",
      "Epoch [7/50], Train Loss: 0.0298, Val Loss: 0.0364\n",
      "Epoch [8/50], Train Loss: 0.0241, Val Loss: 0.0346\n",
      "Epoch [9/50], Train Loss: 0.0205, Val Loss: 0.0331\n",
      "Epoch [10/50], Train Loss: 0.0186, Val Loss: 0.0304\n",
      "Epoch [11/50], Train Loss: 0.0163, Val Loss: 0.0344\n",
      "Epoch [12/50], Train Loss: 0.0109, Val Loss: 0.0377\n",
      "Epoch [13/50], Train Loss: 0.0090, Val Loss: 0.0262\n",
      "Epoch [14/50], Train Loss: 0.0082, Val Loss: 0.0232\n",
      "Epoch [15/50], Train Loss: 0.0083, Val Loss: 0.0467\n",
      "Epoch [16/50], Train Loss: 0.0053, Val Loss: 0.0234\n",
      "Epoch [17/50], Train Loss: 0.0055, Val Loss: 0.0317\n",
      "Epoch [18/50], Train Loss: 0.0061, Val Loss: 0.0349\n",
      "Epoch [19/50], Train Loss: 0.0044, Val Loss: 0.0239\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1323, Val Loss: 0.2283\n",
      "Epoch [2/50], Train Loss: 0.0446, Val Loss: 0.0655\n",
      "Epoch [3/50], Train Loss: 0.0479, Val Loss: 0.0511\n",
      "Epoch [4/50], Train Loss: 0.0423, Val Loss: 0.0348\n",
      "Epoch [5/50], Train Loss: 0.0355, Val Loss: 0.0190\n",
      "Epoch [6/50], Train Loss: 0.0280, Val Loss: 0.0130\n",
      "Epoch [7/50], Train Loss: 0.0227, Val Loss: 0.0100\n",
      "Epoch [8/50], Train Loss: 0.0193, Val Loss: 0.0360\n",
      "Epoch [9/50], Train Loss: 0.0202, Val Loss: 0.0113\n",
      "Epoch [10/50], Train Loss: 0.0172, Val Loss: 0.0707\n",
      "Epoch [11/50], Train Loss: 0.0162, Val Loss: 0.0231\n",
      "Epoch [12/50], Train Loss: 0.0138, Val Loss: 0.0469\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1417, Val Loss: 0.2586\n",
      "Epoch [2/50], Train Loss: 0.0761, Val Loss: 0.1407\n",
      "Epoch [3/50], Train Loss: 0.0583, Val Loss: 0.1157\n",
      "Epoch [4/50], Train Loss: 0.0524, Val Loss: 0.0929\n",
      "Epoch [5/50], Train Loss: 0.0479, Val Loss: 0.0737\n",
      "Epoch [6/50], Train Loss: 0.0443, Val Loss: 0.0680\n",
      "Epoch [7/50], Train Loss: 0.0400, Val Loss: 0.0581\n",
      "Epoch [8/50], Train Loss: 0.0380, Val Loss: 0.0446\n",
      "Epoch [9/50], Train Loss: 0.0332, Val Loss: 0.0435\n",
      "Epoch [10/50], Train Loss: 0.0303, Val Loss: 0.0487\n",
      "Epoch [11/50], Train Loss: 0.0262, Val Loss: 0.0376\n",
      "Epoch [12/50], Train Loss: 0.0260, Val Loss: 0.0478\n",
      "Epoch [13/50], Train Loss: 0.0252, Val Loss: 0.0382\n",
      "Epoch [14/50], Train Loss: 0.0244, Val Loss: 0.0333\n",
      "Epoch [15/50], Train Loss: 0.0209, Val Loss: 0.0401\n",
      "Epoch [16/50], Train Loss: 0.0222, Val Loss: 0.0307\n",
      "Epoch [17/50], Train Loss: 0.0210, Val Loss: 0.0327\n",
      "Epoch [18/50], Train Loss: 0.0189, Val Loss: 0.0347\n",
      "Epoch [19/50], Train Loss: 0.0189, Val Loss: 0.0313\n",
      "Epoch [20/50], Train Loss: 0.0180, Val Loss: 0.0271\n",
      "Epoch [21/50], Train Loss: 0.0181, Val Loss: 0.0320\n",
      "Epoch [22/50], Train Loss: 0.0175, Val Loss: 0.0295\n",
      "Epoch [23/50], Train Loss: 0.0189, Val Loss: 0.0214\n",
      "Epoch [24/50], Train Loss: 0.0164, Val Loss: 0.0330\n",
      "Epoch [25/50], Train Loss: 0.0165, Val Loss: 0.0258\n",
      "Epoch [26/50], Train Loss: 0.0160, Val Loss: 0.0287\n",
      "Epoch [27/50], Train Loss: 0.0173, Val Loss: 0.0308\n",
      "Epoch [28/50], Train Loss: 0.0178, Val Loss: 0.0292\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0932, Val Loss: 0.1765\n",
      "Epoch [2/50], Train Loss: 0.0384, Val Loss: 0.0676\n",
      "Epoch [3/50], Train Loss: 0.0483, Val Loss: 0.0934\n",
      "Epoch [4/50], Train Loss: 0.0393, Val Loss: 0.0791\n",
      "Epoch [5/50], Train Loss: 0.0388, Val Loss: 0.0716\n",
      "Epoch [6/50], Train Loss: 0.0341, Val Loss: 0.0548\n",
      "Epoch [7/50], Train Loss: 0.0272, Val Loss: 0.0402\n",
      "Epoch [8/50], Train Loss: 0.0230, Val Loss: 0.0360\n",
      "Epoch [9/50], Train Loss: 0.0209, Val Loss: 0.0393\n",
      "Epoch [10/50], Train Loss: 0.0189, Val Loss: 0.0464\n",
      "Epoch [11/50], Train Loss: 0.0140, Val Loss: 0.0451\n",
      "Epoch [12/50], Train Loss: 0.0087, Val Loss: 0.0370\n",
      "Epoch [13/50], Train Loss: 0.0111, Val Loss: 0.0281\n",
      "Epoch [14/50], Train Loss: 0.0060, Val Loss: 0.0511\n",
      "Epoch [15/50], Train Loss: 0.0079, Val Loss: 0.0391\n",
      "Epoch [16/50], Train Loss: 0.0069, Val Loss: 0.0363\n",
      "Epoch [17/50], Train Loss: 0.0058, Val Loss: 0.0382\n",
      "Epoch [18/50], Train Loss: 0.0055, Val Loss: 0.0372\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1080, Val Loss: 0.2476\n",
      "Epoch [2/50], Train Loss: 0.0455, Val Loss: 0.0708\n",
      "Epoch [3/50], Train Loss: 0.0590, Val Loss: 0.1088\n",
      "Epoch [4/50], Train Loss: 0.0455, Val Loss: 0.0788\n",
      "Epoch [5/50], Train Loss: 0.0428, Val Loss: 0.0576\n",
      "Epoch [6/50], Train Loss: 0.0363, Val Loss: 0.0528\n",
      "Epoch [7/50], Train Loss: 0.0306, Val Loss: 0.0552\n",
      "Epoch [8/50], Train Loss: 0.0298, Val Loss: 0.0453\n",
      "Epoch [9/50], Train Loss: 0.0286, Val Loss: 0.0337\n",
      "Epoch [10/50], Train Loss: 0.0283, Val Loss: 0.0611\n",
      "Epoch [11/50], Train Loss: 0.0265, Val Loss: 0.0487\n",
      "Epoch [12/50], Train Loss: 0.0257, Val Loss: 0.0477\n",
      "Epoch [13/50], Train Loss: 0.0235, Val Loss: 0.0526\n",
      "Epoch [14/50], Train Loss: 0.0213, Val Loss: 0.0469\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1413, Val Loss: 0.2932\n",
      "Epoch [2/50], Train Loss: 0.0726, Val Loss: 0.1060\n",
      "Epoch [3/50], Train Loss: 0.0708, Val Loss: 0.1078\n",
      "Epoch [4/50], Train Loss: 0.0582, Val Loss: 0.0775\n",
      "Epoch [5/50], Train Loss: 0.0510, Val Loss: 0.0505\n",
      "Epoch [6/50], Train Loss: 0.0399, Val Loss: 0.0457\n",
      "Epoch [7/50], Train Loss: 0.0375, Val Loss: 0.0490\n",
      "Epoch [8/50], Train Loss: 0.0344, Val Loss: 0.0467\n",
      "Epoch [9/50], Train Loss: 0.0332, Val Loss: 0.0429\n",
      "Epoch [10/50], Train Loss: 0.0295, Val Loss: 0.0497\n",
      "Epoch [11/50], Train Loss: 0.0293, Val Loss: 0.0428\n",
      "Epoch [12/50], Train Loss: 0.0301, Val Loss: 0.0434\n",
      "Epoch [13/50], Train Loss: 0.0288, Val Loss: 0.0380\n",
      "Epoch [14/50], Train Loss: 0.0275, Val Loss: 0.0345\n",
      "Epoch [15/50], Train Loss: 0.0267, Val Loss: 0.0350\n",
      "Epoch [16/50], Train Loss: 0.0270, Val Loss: 0.0243\n",
      "Epoch [17/50], Train Loss: 0.0261, Val Loss: 0.0340\n",
      "Epoch [18/50], Train Loss: 0.0244, Val Loss: 0.0496\n",
      "Epoch [19/50], Train Loss: 0.0233, Val Loss: 0.0330\n",
      "Epoch [20/50], Train Loss: 0.0220, Val Loss: 0.0352\n",
      "Epoch [21/50], Train Loss: 0.0277, Val Loss: 0.0545\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1266, Val Loss: 0.1809\n",
      "Epoch [2/50], Train Loss: 0.0270, Val Loss: 0.0413\n",
      "Epoch [3/50], Train Loss: 0.0392, Val Loss: 0.0276\n",
      "Epoch [4/50], Train Loss: 0.0287, Val Loss: 0.0190\n",
      "Epoch [5/50], Train Loss: 0.0180, Val Loss: 0.0124\n",
      "Epoch [6/50], Train Loss: 0.0091, Val Loss: 0.0139\n",
      "Epoch [7/50], Train Loss: 0.0044, Val Loss: 0.0093\n",
      "Epoch [8/50], Train Loss: 0.0040, Val Loss: 0.0097\n",
      "Epoch [9/50], Train Loss: 0.0042, Val Loss: 0.0094\n",
      "Epoch [10/50], Train Loss: 0.0046, Val Loss: 0.0102\n",
      "Epoch [11/50], Train Loss: 0.0044, Val Loss: 0.0171\n",
      "Epoch [12/50], Train Loss: 0.0038, Val Loss: 0.0079\n",
      "Epoch [13/50], Train Loss: 0.0032, Val Loss: 0.0045\n",
      "Epoch [14/50], Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [15/50], Train Loss: 0.0034, Val Loss: 0.0096\n",
      "Epoch [16/50], Train Loss: 0.0034, Val Loss: 0.0135\n",
      "Epoch [17/50], Train Loss: 0.0026, Val Loss: 0.0063\n",
      "Epoch [18/50], Train Loss: 0.0033, Val Loss: 0.0036\n",
      "Epoch [19/50], Train Loss: 0.0029, Val Loss: 0.0052\n",
      "Epoch [20/50], Train Loss: 0.0038, Val Loss: 0.0145\n",
      "Epoch [21/50], Train Loss: 0.0033, Val Loss: 0.0095\n",
      "Epoch [22/50], Train Loss: 0.0036, Val Loss: 0.0050\n",
      "Epoch [23/50], Train Loss: 0.0047, Val Loss: 0.0029\n",
      "Epoch [24/50], Train Loss: 0.0034, Val Loss: 0.0077\n",
      "Epoch [25/50], Train Loss: 0.0046, Val Loss: 0.0196\n",
      "Epoch [26/50], Train Loss: 0.0030, Val Loss: 0.0061\n",
      "Epoch [27/50], Train Loss: 0.0035, Val Loss: 0.0028\n",
      "Epoch [28/50], Train Loss: 0.0025, Val Loss: 0.0033\n",
      "Epoch [29/50], Train Loss: 0.0034, Val Loss: 0.0129\n",
      "Epoch [30/50], Train Loss: 0.0028, Val Loss: 0.0111\n",
      "Epoch [31/50], Train Loss: 0.0044, Val Loss: 0.0029\n",
      "Epoch [32/50], Train Loss: 0.0045, Val Loss: 0.0081\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1344, Val Loss: 0.2102\n",
      "Epoch [2/50], Train Loss: 0.0334, Val Loss: 0.0547\n",
      "Epoch [3/50], Train Loss: 0.0345, Val Loss: 0.0239\n",
      "Epoch [4/50], Train Loss: 0.0337, Val Loss: 0.0292\n",
      "Epoch [5/50], Train Loss: 0.0261, Val Loss: 0.0223\n",
      "Epoch [6/50], Train Loss: 0.0219, Val Loss: 0.0143\n",
      "Epoch [7/50], Train Loss: 0.0178, Val Loss: 0.0073\n",
      "Epoch [8/50], Train Loss: 0.0115, Val Loss: 0.0027\n",
      "Epoch [9/50], Train Loss: 0.0100, Val Loss: 0.0091\n",
      "Epoch [10/50], Train Loss: 0.0105, Val Loss: 0.0027\n",
      "Epoch [11/50], Train Loss: 0.0089, Val Loss: 0.0054\n",
      "Epoch [12/50], Train Loss: 0.0103, Val Loss: 0.0042\n",
      "Epoch [13/50], Train Loss: 0.0078, Val Loss: 0.0040\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0887, Val Loss: 0.1403\n",
      "Epoch [2/50], Train Loss: 0.0394, Val Loss: 0.0645\n",
      "Epoch [3/50], Train Loss: 0.0388, Val Loss: 0.0503\n",
      "Epoch [4/50], Train Loss: 0.0352, Val Loss: 0.0461\n",
      "Epoch [5/50], Train Loss: 0.0298, Val Loss: 0.0284\n",
      "Epoch [6/50], Train Loss: 0.0261, Val Loss: 0.0177\n",
      "Epoch [7/50], Train Loss: 0.0201, Val Loss: 0.0132\n",
      "Epoch [8/50], Train Loss: 0.0198, Val Loss: 0.0087\n",
      "Epoch [9/50], Train Loss: 0.0169, Val Loss: 0.0232\n",
      "Epoch [10/50], Train Loss: 0.0144, Val Loss: 0.0053\n",
      "Epoch [11/50], Train Loss: 0.0179, Val Loss: 0.0036\n",
      "Epoch [12/50], Train Loss: 0.0123, Val Loss: 0.0068\n",
      "Epoch [13/50], Train Loss: 0.0126, Val Loss: 0.0098\n",
      "Epoch [14/50], Train Loss: 0.0113, Val Loss: 0.0063\n",
      "Epoch [15/50], Train Loss: 0.0125, Val Loss: 0.0056\n",
      "Epoch [16/50], Train Loss: 0.0102, Val Loss: 0.0103\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0900, Val Loss: 0.1756\n",
      "Epoch [2/50], Train Loss: 0.0334, Val Loss: 0.0302\n",
      "Epoch [3/50], Train Loss: 0.0558, Val Loss: 0.0855\n",
      "Epoch [4/50], Train Loss: 0.0294, Val Loss: 0.0278\n",
      "Epoch [5/50], Train Loss: 0.0287, Val Loss: 0.0053\n",
      "Epoch [6/50], Train Loss: 0.0173, Val Loss: 0.0237\n",
      "Epoch [7/50], Train Loss: 0.0111, Val Loss: 0.0246\n",
      "Epoch [8/50], Train Loss: 0.0074, Val Loss: 0.0268\n",
      "Epoch [9/50], Train Loss: 0.0089, Val Loss: 0.0182\n",
      "Epoch [10/50], Train Loss: 0.0052, Val Loss: 0.0256\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0703, Val Loss: 0.0992\n",
      "Epoch [2/50], Train Loss: 0.0437, Val Loss: 0.0488\n",
      "Epoch [3/50], Train Loss: 0.0412, Val Loss: 0.0277\n",
      "Epoch [4/50], Train Loss: 0.0316, Val Loss: 0.0139\n",
      "Epoch [5/50], Train Loss: 0.0244, Val Loss: 0.0109\n",
      "Epoch [6/50], Train Loss: 0.0177, Val Loss: 0.0313\n",
      "Epoch [7/50], Train Loss: 0.0174, Val Loss: 0.0360\n",
      "Epoch [8/50], Train Loss: 0.0101, Val Loss: 0.0246\n",
      "Epoch [9/50], Train Loss: 0.0092, Val Loss: 0.0349\n",
      "Epoch [10/50], Train Loss: 0.0085, Val Loss: 0.0294\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0603, Val Loss: 0.1233\n",
      "Epoch [2/50], Train Loss: 0.0405, Val Loss: 0.0577\n",
      "Epoch [3/50], Train Loss: 0.0394, Val Loss: 0.0306\n",
      "Epoch [4/50], Train Loss: 0.0301, Val Loss: 0.0250\n",
      "Epoch [5/50], Train Loss: 0.0237, Val Loss: 0.0430\n",
      "Epoch [6/50], Train Loss: 0.0210, Val Loss: 0.0383\n",
      "Epoch [7/50], Train Loss: 0.0148, Val Loss: 0.0366\n",
      "Epoch [8/50], Train Loss: 0.0147, Val Loss: 0.0471\n",
      "Epoch [9/50], Train Loss: 0.0132, Val Loss: 0.0407\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1097, Val Loss: 0.0442\n",
      "Epoch [2/50], Train Loss: 0.0671, Val Loss: 0.0956\n",
      "Epoch [3/50], Train Loss: 0.0424, Val Loss: 0.0746\n",
      "Epoch [4/50], Train Loss: 0.0450, Val Loss: 0.0716\n",
      "Epoch [5/50], Train Loss: 0.0412, Val Loss: 0.0591\n",
      "Epoch [6/50], Train Loss: 0.0358, Val Loss: 0.0519\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0690, Val Loss: 0.0451\n",
      "Epoch [2/50], Train Loss: 0.0652, Val Loss: 0.1017\n",
      "Epoch [3/50], Train Loss: 0.0403, Val Loss: 0.0646\n",
      "Epoch [4/50], Train Loss: 0.0424, Val Loss: 0.0482\n",
      "Epoch [5/50], Train Loss: 0.0360, Val Loss: 0.0322\n",
      "Epoch [6/50], Train Loss: 0.0274, Val Loss: 0.0300\n",
      "Epoch [7/50], Train Loss: 0.0246, Val Loss: 0.0368\n",
      "Epoch [8/50], Train Loss: 0.0230, Val Loss: 0.0298\n",
      "Epoch [9/50], Train Loss: 0.0245, Val Loss: 0.0303\n",
      "Epoch [10/50], Train Loss: 0.0232, Val Loss: 0.0478\n",
      "Epoch [11/50], Train Loss: 0.0222, Val Loss: 0.0448\n",
      "Epoch [12/50], Train Loss: 0.0251, Val Loss: 0.0270\n",
      "Epoch [13/50], Train Loss: 0.0167, Val Loss: 0.0406\n",
      "Epoch [14/50], Train Loss: 0.0137, Val Loss: 0.0230\n",
      "Epoch [15/50], Train Loss: 0.0124, Val Loss: 0.0577\n",
      "Epoch [16/50], Train Loss: 0.0122, Val Loss: 0.0578\n",
      "Epoch [17/50], Train Loss: 0.0149, Val Loss: 0.0327\n",
      "Epoch [18/50], Train Loss: 0.0102, Val Loss: 0.0671\n",
      "Epoch [19/50], Train Loss: 0.0107, Val Loss: 0.0303\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0785, Val Loss: 0.0451\n",
      "Epoch [2/50], Train Loss: 0.0776, Val Loss: 0.1219\n",
      "Epoch [3/50], Train Loss: 0.0500, Val Loss: 0.0582\n",
      "Epoch [4/50], Train Loss: 0.0558, Val Loss: 0.0417\n",
      "Epoch [5/50], Train Loss: 0.0418, Val Loss: 0.0281\n",
      "Epoch [6/50], Train Loss: 0.0329, Val Loss: 0.0181\n",
      "Epoch [7/50], Train Loss: 0.0329, Val Loss: 0.0130\n",
      "Epoch [8/50], Train Loss: 0.0304, Val Loss: 0.0184\n",
      "Epoch [9/50], Train Loss: 0.0301, Val Loss: 0.0549\n",
      "Epoch [10/50], Train Loss: 0.0291, Val Loss: 0.0255\n",
      "Epoch [11/50], Train Loss: 0.0310, Val Loss: 0.0207\n",
      "Epoch [12/50], Train Loss: 0.0267, Val Loss: 0.0247\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0503, Val Loss: 0.0437\n",
      "Epoch [2/50], Train Loss: 0.0423, Val Loss: 0.0447\n",
      "Epoch [3/50], Train Loss: 0.0273, Val Loss: 0.0181\n",
      "Epoch [4/50], Train Loss: 0.0215, Val Loss: 0.0059\n",
      "Epoch [5/50], Train Loss: 0.0170, Val Loss: 0.0119\n",
      "Epoch [6/50], Train Loss: 0.0063, Val Loss: 0.0131\n",
      "Epoch [7/50], Train Loss: 0.0071, Val Loss: 0.0208\n",
      "Epoch [8/50], Train Loss: 0.0111, Val Loss: 0.0026\n",
      "Epoch [9/50], Train Loss: 0.0066, Val Loss: 0.0042\n",
      "Epoch [10/50], Train Loss: 0.0138, Val Loss: 0.0468\n",
      "Epoch [11/50], Train Loss: 0.0092, Val Loss: 0.0096\n",
      "Epoch [12/50], Train Loss: 0.0089, Val Loss: 0.0127\n",
      "Epoch [13/50], Train Loss: 0.0048, Val Loss: 0.0074\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0595, Val Loss: 0.0447\n",
      "Epoch [2/50], Train Loss: 0.0466, Val Loss: 0.0440\n",
      "Epoch [3/50], Train Loss: 0.0322, Val Loss: 0.0298\n",
      "Epoch [4/50], Train Loss: 0.0261, Val Loss: 0.0097\n",
      "Epoch [5/50], Train Loss: 0.0209, Val Loss: 0.0042\n",
      "Epoch [6/50], Train Loss: 0.0125, Val Loss: 0.0229\n",
      "Epoch [7/50], Train Loss: 0.0114, Val Loss: 0.0135\n",
      "Epoch [8/50], Train Loss: 0.0067, Val Loss: 0.0111\n",
      "Epoch [9/50], Train Loss: 0.0072, Val Loss: 0.0156\n",
      "Epoch [10/50], Train Loss: 0.0080, Val Loss: 0.0113\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0653, Val Loss: 0.0524\n",
      "Epoch [2/50], Train Loss: 0.0518, Val Loss: 0.0392\n",
      "Epoch [3/50], Train Loss: 0.0397, Val Loss: 0.0351\n",
      "Epoch [4/50], Train Loss: 0.0297, Val Loss: 0.0138\n",
      "Epoch [5/50], Train Loss: 0.0267, Val Loss: 0.0049\n",
      "Epoch [6/50], Train Loss: 0.0193, Val Loss: 0.0090\n",
      "Epoch [7/50], Train Loss: 0.0127, Val Loss: 0.0083\n",
      "Epoch [8/50], Train Loss: 0.0129, Val Loss: 0.0058\n",
      "Epoch [9/50], Train Loss: 0.0123, Val Loss: 0.0079\n",
      "Epoch [10/50], Train Loss: 0.0099, Val Loss: 0.0081\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0525, Val Loss: 0.1074\n",
      "Epoch [2/50], Train Loss: 0.0484, Val Loss: 0.0233\n",
      "Epoch [3/50], Train Loss: 0.0578, Val Loss: 0.0589\n",
      "Epoch [4/50], Train Loss: 0.0329, Val Loss: 0.0284\n",
      "Epoch [5/50], Train Loss: 0.0274, Val Loss: 0.0129\n",
      "Epoch [6/50], Train Loss: 0.0212, Val Loss: 0.0096\n",
      "Epoch [7/50], Train Loss: 0.0183, Val Loss: 0.0041\n",
      "Epoch [8/50], Train Loss: 0.0167, Val Loss: 0.0323\n",
      "Epoch [9/50], Train Loss: 0.0048, Val Loss: 0.0105\n",
      "Epoch [10/50], Train Loss: 0.0045, Val Loss: 0.0300\n",
      "Epoch [11/50], Train Loss: 0.0045, Val Loss: 0.0160\n",
      "Epoch [12/50], Train Loss: 0.0052, Val Loss: 0.0214\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0547, Val Loss: 0.0668\n",
      "Epoch [2/50], Train Loss: 0.0669, Val Loss: 0.1016\n",
      "Epoch [3/50], Train Loss: 0.0372, Val Loss: 0.0383\n",
      "Epoch [4/50], Train Loss: 0.0405, Val Loss: 0.0148\n",
      "Epoch [5/50], Train Loss: 0.0283, Val Loss: 0.0047\n",
      "Epoch [6/50], Train Loss: 0.0294, Val Loss: 0.0262\n",
      "Epoch [7/50], Train Loss: 0.0183, Val Loss: 0.0236\n",
      "Epoch [8/50], Train Loss: 0.0145, Val Loss: 0.0315\n",
      "Epoch [9/50], Train Loss: 0.0192, Val Loss: 0.0233\n",
      "Epoch [10/50], Train Loss: 0.0081, Val Loss: 0.0255\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0501, Val Loss: 0.1016\n",
      "Epoch [2/50], Train Loss: 0.0555, Val Loss: 0.0507\n",
      "Epoch [3/50], Train Loss: 0.0475, Val Loss: 0.0439\n",
      "Epoch [4/50], Train Loss: 0.0379, Val Loss: 0.0174\n",
      "Epoch [5/50], Train Loss: 0.0289, Val Loss: 0.0077\n",
      "Epoch [6/50], Train Loss: 0.0273, Val Loss: 0.0098\n",
      "Epoch [7/50], Train Loss: 0.0188, Val Loss: 0.0370\n",
      "Epoch [8/50], Train Loss: 0.0150, Val Loss: 0.0070\n",
      "Epoch [9/50], Train Loss: 0.0188, Val Loss: 0.0083\n",
      "Epoch [10/50], Train Loss: 0.0153, Val Loss: 0.0108\n",
      "Epoch [11/50], Train Loss: 0.0263, Val Loss: 0.0880\n",
      "Epoch [12/50], Train Loss: 0.0163, Val Loss: 0.0199\n",
      "Epoch [13/50], Train Loss: 0.0179, Val Loss: 0.0103\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0488, Val Loss: 0.1098\n",
      "Epoch [2/50], Train Loss: 0.0575, Val Loss: 0.0696\n",
      "Epoch [3/50], Train Loss: 0.0526, Val Loss: 0.0875\n",
      "Epoch [4/50], Train Loss: 0.0419, Val Loss: 0.0662\n",
      "Epoch [5/50], Train Loss: 0.0398, Val Loss: 0.0348\n",
      "Epoch [6/50], Train Loss: 0.0300, Val Loss: 0.0261\n",
      "Epoch [7/50], Train Loss: 0.0246, Val Loss: 0.0193\n",
      "Epoch [8/50], Train Loss: 0.0207, Val Loss: 0.0494\n",
      "Epoch [9/50], Train Loss: 0.0211, Val Loss: 0.0317\n",
      "Epoch [10/50], Train Loss: 0.0197, Val Loss: 0.0124\n",
      "Epoch [11/50], Train Loss: 0.0147, Val Loss: 0.0225\n",
      "Epoch [12/50], Train Loss: 0.0078, Val Loss: 0.0301\n",
      "Epoch [13/50], Train Loss: 0.0142, Val Loss: 0.0518\n",
      "Epoch [14/50], Train Loss: 0.0111, Val Loss: 0.0255\n",
      "Epoch [15/50], Train Loss: 0.0162, Val Loss: 0.0114\n",
      "Epoch [16/50], Train Loss: 0.0221, Val Loss: 0.0337\n",
      "Epoch [17/50], Train Loss: 0.0137, Val Loss: 0.0132\n",
      "Epoch [18/50], Train Loss: 0.0067, Val Loss: 0.0186\n",
      "Epoch [19/50], Train Loss: 0.0116, Val Loss: 0.0379\n",
      "Epoch [20/50], Train Loss: 0.0077, Val Loss: 0.0133\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0421, Val Loss: 0.1044\n",
      "Epoch [2/50], Train Loss: 0.0605, Val Loss: 0.0825\n",
      "Epoch [3/50], Train Loss: 0.0473, Val Loss: 0.0464\n",
      "Epoch [4/50], Train Loss: 0.0387, Val Loss: 0.0340\n",
      "Epoch [5/50], Train Loss: 0.0273, Val Loss: 0.0147\n",
      "Epoch [6/50], Train Loss: 0.0216, Val Loss: 0.0172\n",
      "Epoch [7/50], Train Loss: 0.0221, Val Loss: 0.0093\n",
      "Epoch [8/50], Train Loss: 0.0189, Val Loss: 0.0261\n",
      "Epoch [9/50], Train Loss: 0.0201, Val Loss: 0.0635\n",
      "Epoch [10/50], Train Loss: 0.0205, Val Loss: 0.0582\n",
      "Epoch [11/50], Train Loss: 0.0170, Val Loss: 0.0796\n",
      "Epoch [12/50], Train Loss: 0.0080, Val Loss: 0.0567\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.001, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0502, Val Loss: 0.0920\n",
      "Epoch [2/50], Train Loss: 0.0651, Val Loss: 0.0992\n",
      "Epoch [3/50], Train Loss: 0.0486, Val Loss: 0.0761\n",
      "Epoch [4/50], Train Loss: 0.0421, Val Loss: 0.0319\n",
      "Epoch [5/50], Train Loss: 0.0318, Val Loss: 0.0213\n",
      "Epoch [6/50], Train Loss: 0.0245, Val Loss: 0.0213\n",
      "Epoch [7/50], Train Loss: 0.0270, Val Loss: 0.0428\n",
      "Epoch [8/50], Train Loss: 0.0227, Val Loss: 0.0436\n",
      "Epoch [9/50], Train Loss: 0.0181, Val Loss: 0.0460\n",
      "Epoch [10/50], Train Loss: 0.0191, Val Loss: 0.0711\n",
      "Epoch [11/50], Train Loss: 0.0124, Val Loss: 0.0434\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1605, Val Loss: 0.3967\n",
      "Epoch [2/50], Train Loss: 0.1187, Val Loss: 0.3091\n",
      "Epoch [3/50], Train Loss: 0.0800, Val Loss: 0.2078\n",
      "Epoch [4/50], Train Loss: 0.0458, Val Loss: 0.1068\n",
      "Epoch [5/50], Train Loss: 0.0315, Val Loss: 0.0609\n",
      "Epoch [6/50], Train Loss: 0.0307, Val Loss: 0.0548\n",
      "Epoch [7/50], Train Loss: 0.0286, Val Loss: 0.0511\n",
      "Epoch [8/50], Train Loss: 0.0265, Val Loss: 0.0460\n",
      "Epoch [9/50], Train Loss: 0.0246, Val Loss: 0.0407\n",
      "Epoch [10/50], Train Loss: 0.0227, Val Loss: 0.0352\n",
      "Epoch [11/50], Train Loss: 0.0207, Val Loss: 0.0297\n",
      "Epoch [12/50], Train Loss: 0.0184, Val Loss: 0.0244\n",
      "Epoch [13/50], Train Loss: 0.0161, Val Loss: 0.0198\n",
      "Epoch [14/50], Train Loss: 0.0137, Val Loss: 0.0159\n",
      "Epoch [15/50], Train Loss: 0.0113, Val Loss: 0.0130\n",
      "Epoch [16/50], Train Loss: 0.0089, Val Loss: 0.0130\n",
      "Epoch [17/50], Train Loss: 0.0069, Val Loss: 0.0168\n",
      "Epoch [18/50], Train Loss: 0.0057, Val Loss: 0.0187\n",
      "Epoch [19/50], Train Loss: 0.0049, Val Loss: 0.0176\n",
      "Epoch [20/50], Train Loss: 0.0044, Val Loss: 0.0175\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1203, Val Loss: 0.3097\n",
      "Epoch [2/50], Train Loss: 0.0849, Val Loss: 0.2313\n",
      "Epoch [3/50], Train Loss: 0.0632, Val Loss: 0.1670\n",
      "Epoch [4/50], Train Loss: 0.0486, Val Loss: 0.1162\n",
      "Epoch [5/50], Train Loss: 0.0405, Val Loss: 0.0815\n",
      "Epoch [6/50], Train Loss: 0.0372, Val Loss: 0.0617\n",
      "Epoch [7/50], Train Loss: 0.0342, Val Loss: 0.0520\n",
      "Epoch [8/50], Train Loss: 0.0316, Val Loss: 0.0428\n",
      "Epoch [9/50], Train Loss: 0.0301, Val Loss: 0.0357\n",
      "Epoch [10/50], Train Loss: 0.0283, Val Loss: 0.0276\n",
      "Epoch [11/50], Train Loss: 0.0259, Val Loss: 0.0231\n",
      "Epoch [12/50], Train Loss: 0.0209, Val Loss: 0.0211\n",
      "Epoch [13/50], Train Loss: 0.0178, Val Loss: 0.0174\n",
      "Epoch [14/50], Train Loss: 0.0163, Val Loss: 0.0138\n",
      "Epoch [15/50], Train Loss: 0.0134, Val Loss: 0.0123\n",
      "Epoch [16/50], Train Loss: 0.0146, Val Loss: 0.0089\n",
      "Epoch [17/50], Train Loss: 0.0137, Val Loss: 0.0086\n",
      "Epoch [18/50], Train Loss: 0.0124, Val Loss: 0.0073\n",
      "Epoch [19/50], Train Loss: 0.0120, Val Loss: 0.0063\n",
      "Epoch [20/50], Train Loss: 0.0107, Val Loss: 0.0053\n",
      "Epoch [21/50], Train Loss: 0.0103, Val Loss: 0.0048\n",
      "Epoch [22/50], Train Loss: 0.0099, Val Loss: 0.0038\n",
      "Epoch [23/50], Train Loss: 0.0098, Val Loss: 0.0040\n",
      "Epoch [24/50], Train Loss: 0.0107, Val Loss: 0.0034\n",
      "Epoch [25/50], Train Loss: 0.0106, Val Loss: 0.0042\n",
      "Epoch [26/50], Train Loss: 0.0097, Val Loss: 0.0038\n",
      "Epoch [27/50], Train Loss: 0.0094, Val Loss: 0.0034\n",
      "Epoch [28/50], Train Loss: 0.0091, Val Loss: 0.0030\n",
      "Epoch [29/50], Train Loss: 0.0093, Val Loss: 0.0031\n",
      "Epoch [30/50], Train Loss: 0.0102, Val Loss: 0.0041\n",
      "Epoch [31/50], Train Loss: 0.0096, Val Loss: 0.0038\n",
      "Epoch [32/50], Train Loss: 0.0086, Val Loss: 0.0034\n",
      "Epoch [33/50], Train Loss: 0.0083, Val Loss: 0.0030\n",
      "Epoch [34/50], Train Loss: 0.0082, Val Loss: 0.0026\n",
      "Epoch [35/50], Train Loss: 0.0075, Val Loss: 0.0024\n",
      "Epoch [36/50], Train Loss: 0.0078, Val Loss: 0.0027\n",
      "Epoch [37/50], Train Loss: 0.0075, Val Loss: 0.0024\n",
      "Epoch [38/50], Train Loss: 0.0081, Val Loss: 0.0027\n",
      "Epoch [39/50], Train Loss: 0.0090, Val Loss: 0.0028\n",
      "Epoch [40/50], Train Loss: 0.0077, Val Loss: 0.0026\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1940, Val Loss: 0.3626\n",
      "Epoch [2/50], Train Loss: 0.1560, Val Loss: 0.2975\n",
      "Epoch [3/50], Train Loss: 0.1222, Val Loss: 0.2319\n",
      "Epoch [4/50], Train Loss: 0.0930, Val Loss: 0.1664\n",
      "Epoch [5/50], Train Loss: 0.0733, Val Loss: 0.1203\n",
      "Epoch [6/50], Train Loss: 0.0610, Val Loss: 0.0982\n",
      "Epoch [7/50], Train Loss: 0.0547, Val Loss: 0.0858\n",
      "Epoch [8/50], Train Loss: 0.0519, Val Loss: 0.0763\n",
      "Epoch [9/50], Train Loss: 0.0460, Val Loss: 0.0659\n",
      "Epoch [10/50], Train Loss: 0.0418, Val Loss: 0.0624\n",
      "Epoch [11/50], Train Loss: 0.0415, Val Loss: 0.0582\n",
      "Epoch [12/50], Train Loss: 0.0392, Val Loss: 0.0514\n",
      "Epoch [13/50], Train Loss: 0.0364, Val Loss: 0.0474\n",
      "Epoch [14/50], Train Loss: 0.0342, Val Loss: 0.0425\n",
      "Epoch [15/50], Train Loss: 0.0326, Val Loss: 0.0375\n",
      "Epoch [16/50], Train Loss: 0.0303, Val Loss: 0.0344\n",
      "Epoch [17/50], Train Loss: 0.0301, Val Loss: 0.0334\n",
      "Epoch [18/50], Train Loss: 0.0274, Val Loss: 0.0332\n",
      "Epoch [19/50], Train Loss: 0.0239, Val Loss: 0.0321\n",
      "Epoch [20/50], Train Loss: 0.0225, Val Loss: 0.0316\n",
      "Epoch [21/50], Train Loss: 0.0228, Val Loss: 0.0318\n",
      "Epoch [22/50], Train Loss: 0.0223, Val Loss: 0.0300\n",
      "Epoch [23/50], Train Loss: 0.0212, Val Loss: 0.0283\n",
      "Epoch [24/50], Train Loss: 0.0209, Val Loss: 0.0281\n",
      "Epoch [25/50], Train Loss: 0.0185, Val Loss: 0.0318\n",
      "Epoch [26/50], Train Loss: 0.0199, Val Loss: 0.0269\n",
      "Epoch [27/50], Train Loss: 0.0185, Val Loss: 0.0263\n",
      "Epoch [28/50], Train Loss: 0.0184, Val Loss: 0.0273\n",
      "Epoch [29/50], Train Loss: 0.0195, Val Loss: 0.0280\n",
      "Epoch [30/50], Train Loss: 0.0179, Val Loss: 0.0264\n",
      "Epoch [31/50], Train Loss: 0.0177, Val Loss: 0.0271\n",
      "Epoch [32/50], Train Loss: 0.0170, Val Loss: 0.0213\n",
      "Epoch [33/50], Train Loss: 0.0178, Val Loss: 0.0253\n",
      "Epoch [34/50], Train Loss: 0.0159, Val Loss: 0.0213\n",
      "Epoch [35/50], Train Loss: 0.0167, Val Loss: 0.0227\n",
      "Epoch [36/50], Train Loss: 0.0160, Val Loss: 0.0217\n",
      "Epoch [37/50], Train Loss: 0.0155, Val Loss: 0.0205\n",
      "Epoch [38/50], Train Loss: 0.0159, Val Loss: 0.0200\n",
      "Epoch [39/50], Train Loss: 0.0154, Val Loss: 0.0192\n",
      "Epoch [40/50], Train Loss: 0.0151, Val Loss: 0.0217\n",
      "Epoch [41/50], Train Loss: 0.0137, Val Loss: 0.0182\n",
      "Epoch [42/50], Train Loss: 0.0153, Val Loss: 0.0229\n",
      "Epoch [43/50], Train Loss: 0.0153, Val Loss: 0.0184\n",
      "Epoch [44/50], Train Loss: 0.0139, Val Loss: 0.0175\n",
      "Epoch [45/50], Train Loss: 0.0143, Val Loss: 0.0198\n",
      "Epoch [46/50], Train Loss: 0.0131, Val Loss: 0.0162\n",
      "Epoch [47/50], Train Loss: 0.0137, Val Loss: 0.0204\n",
      "Epoch [48/50], Train Loss: 0.0141, Val Loss: 0.0158\n",
      "Epoch [49/50], Train Loss: 0.0134, Val Loss: 0.0171\n",
      "Epoch [50/50], Train Loss: 0.0131, Val Loss: 0.0167\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0832, Val Loss: 0.2376\n",
      "Epoch [2/50], Train Loss: 0.0596, Val Loss: 0.1742\n",
      "Epoch [3/50], Train Loss: 0.0408, Val Loss: 0.1069\n",
      "Epoch [4/50], Train Loss: 0.0348, Val Loss: 0.0731\n",
      "Epoch [5/50], Train Loss: 0.0349, Val Loss: 0.0642\n",
      "Epoch [6/50], Train Loss: 0.0329, Val Loss: 0.0552\n",
      "Epoch [7/50], Train Loss: 0.0305, Val Loss: 0.0439\n",
      "Epoch [8/50], Train Loss: 0.0276, Val Loss: 0.0299\n",
      "Epoch [9/50], Train Loss: 0.0239, Val Loss: 0.0177\n",
      "Epoch [10/50], Train Loss: 0.0199, Val Loss: 0.0136\n",
      "Epoch [11/50], Train Loss: 0.0171, Val Loss: 0.0127\n",
      "Epoch [12/50], Train Loss: 0.0149, Val Loss: 0.0150\n",
      "Epoch [13/50], Train Loss: 0.0128, Val Loss: 0.0144\n",
      "Epoch [14/50], Train Loss: 0.0105, Val Loss: 0.0080\n",
      "Epoch [15/50], Train Loss: 0.0086, Val Loss: 0.0144\n",
      "Epoch [16/50], Train Loss: 0.0075, Val Loss: 0.0279\n",
      "Epoch [17/50], Train Loss: 0.0058, Val Loss: 0.0073\n",
      "Epoch [18/50], Train Loss: 0.0051, Val Loss: 0.0144\n",
      "Epoch [19/50], Train Loss: 0.0086, Val Loss: 0.0171\n",
      "Epoch [20/50], Train Loss: 0.0071, Val Loss: 0.0219\n",
      "Epoch [21/50], Train Loss: 0.0056, Val Loss: 0.0162\n",
      "Epoch [22/50], Train Loss: 0.0054, Val Loss: 0.0186\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0907, Val Loss: 0.2561\n",
      "Epoch [2/50], Train Loss: 0.0673, Val Loss: 0.1986\n",
      "Epoch [3/50], Train Loss: 0.0489, Val Loss: 0.1351\n",
      "Epoch [4/50], Train Loss: 0.0401, Val Loss: 0.0940\n",
      "Epoch [5/50], Train Loss: 0.0383, Val Loss: 0.0776\n",
      "Epoch [6/50], Train Loss: 0.0355, Val Loss: 0.0626\n",
      "Epoch [7/50], Train Loss: 0.0306, Val Loss: 0.0492\n",
      "Epoch [8/50], Train Loss: 0.0267, Val Loss: 0.0405\n",
      "Epoch [9/50], Train Loss: 0.0248, Val Loss: 0.0346\n",
      "Epoch [10/50], Train Loss: 0.0220, Val Loss: 0.0318\n",
      "Epoch [11/50], Train Loss: 0.0207, Val Loss: 0.0302\n",
      "Epoch [12/50], Train Loss: 0.0186, Val Loss: 0.0272\n",
      "Epoch [13/50], Train Loss: 0.0174, Val Loss: 0.0262\n",
      "Epoch [14/50], Train Loss: 0.0146, Val Loss: 0.0219\n",
      "Epoch [15/50], Train Loss: 0.0116, Val Loss: 0.0191\n",
      "Epoch [16/50], Train Loss: 0.0107, Val Loss: 0.0137\n",
      "Epoch [17/50], Train Loss: 0.0098, Val Loss: 0.0154\n",
      "Epoch [18/50], Train Loss: 0.0088, Val Loss: 0.0185\n",
      "Epoch [19/50], Train Loss: 0.0090, Val Loss: 0.0122\n",
      "Epoch [20/50], Train Loss: 0.0086, Val Loss: 0.0153\n",
      "Epoch [21/50], Train Loss: 0.0086, Val Loss: 0.0152\n",
      "Epoch [22/50], Train Loss: 0.0079, Val Loss: 0.0129\n",
      "Epoch [23/50], Train Loss: 0.0078, Val Loss: 0.0118\n",
      "Epoch [24/50], Train Loss: 0.0078, Val Loss: 0.0147\n",
      "Epoch [25/50], Train Loss: 0.0076, Val Loss: 0.0103\n",
      "Epoch [26/50], Train Loss: 0.0074, Val Loss: 0.0113\n",
      "Epoch [27/50], Train Loss: 0.0078, Val Loss: 0.0142\n",
      "Epoch [28/50], Train Loss: 0.0073, Val Loss: 0.0104\n",
      "Epoch [29/50], Train Loss: 0.0071, Val Loss: 0.0120\n",
      "Epoch [30/50], Train Loss: 0.0077, Val Loss: 0.0125\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0979, Val Loss: 0.2753\n",
      "Epoch [2/50], Train Loss: 0.0775, Val Loss: 0.2257\n",
      "Epoch [3/50], Train Loss: 0.0614, Val Loss: 0.1756\n",
      "Epoch [4/50], Train Loss: 0.0532, Val Loss: 0.1418\n",
      "Epoch [5/50], Train Loss: 0.0502, Val Loss: 0.1228\n",
      "Epoch [6/50], Train Loss: 0.0485, Val Loss: 0.1123\n",
      "Epoch [7/50], Train Loss: 0.0454, Val Loss: 0.0992\n",
      "Epoch [8/50], Train Loss: 0.0432, Val Loss: 0.0844\n",
      "Epoch [9/50], Train Loss: 0.0400, Val Loss: 0.0649\n",
      "Epoch [10/50], Train Loss: 0.0366, Val Loss: 0.0511\n",
      "Epoch [11/50], Train Loss: 0.0338, Val Loss: 0.0508\n",
      "Epoch [12/50], Train Loss: 0.0306, Val Loss: 0.0464\n",
      "Epoch [13/50], Train Loss: 0.0293, Val Loss: 0.0309\n",
      "Epoch [14/50], Train Loss: 0.0282, Val Loss: 0.0300\n",
      "Epoch [15/50], Train Loss: 0.0250, Val Loss: 0.0308\n",
      "Epoch [16/50], Train Loss: 0.0244, Val Loss: 0.0274\n",
      "Epoch [17/50], Train Loss: 0.0232, Val Loss: 0.0270\n",
      "Epoch [18/50], Train Loss: 0.0215, Val Loss: 0.0319\n",
      "Epoch [19/50], Train Loss: 0.0207, Val Loss: 0.0273\n",
      "Epoch [20/50], Train Loss: 0.0206, Val Loss: 0.0282\n",
      "Epoch [21/50], Train Loss: 0.0191, Val Loss: 0.0267\n",
      "Epoch [22/50], Train Loss: 0.0183, Val Loss: 0.0242\n",
      "Epoch [23/50], Train Loss: 0.0183, Val Loss: 0.0244\n",
      "Epoch [24/50], Train Loss: 0.0184, Val Loss: 0.0243\n",
      "Epoch [25/50], Train Loss: 0.0181, Val Loss: 0.0271\n",
      "Epoch [26/50], Train Loss: 0.0177, Val Loss: 0.0267\n",
      "Epoch [27/50], Train Loss: 0.0174, Val Loss: 0.0240\n",
      "Epoch [28/50], Train Loss: 0.0176, Val Loss: 0.0292\n",
      "Epoch [29/50], Train Loss: 0.0173, Val Loss: 0.0228\n",
      "Epoch [30/50], Train Loss: 0.0170, Val Loss: 0.0260\n",
      "Epoch [31/50], Train Loss: 0.0164, Val Loss: 0.0211\n",
      "Epoch [32/50], Train Loss: 0.0159, Val Loss: 0.0253\n",
      "Epoch [33/50], Train Loss: 0.0150, Val Loss: 0.0224\n",
      "Epoch [34/50], Train Loss: 0.0152, Val Loss: 0.0234\n",
      "Epoch [35/50], Train Loss: 0.0144, Val Loss: 0.0233\n",
      "Epoch [36/50], Train Loss: 0.0145, Val Loss: 0.0243\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1580, Val Loss: 0.3714\n",
      "Epoch [2/50], Train Loss: 0.1118, Val Loss: 0.2739\n",
      "Epoch [3/50], Train Loss: 0.0588, Val Loss: 0.1208\n",
      "Epoch [4/50], Train Loss: 0.0476, Val Loss: 0.1004\n",
      "Epoch [5/50], Train Loss: 0.0408, Val Loss: 0.0881\n",
      "Epoch [6/50], Train Loss: 0.0383, Val Loss: 0.0791\n",
      "Epoch [7/50], Train Loss: 0.0352, Val Loss: 0.0651\n",
      "Epoch [8/50], Train Loss: 0.0309, Val Loss: 0.0465\n",
      "Epoch [9/50], Train Loss: 0.0260, Val Loss: 0.0340\n",
      "Epoch [10/50], Train Loss: 0.0228, Val Loss: 0.0300\n",
      "Epoch [11/50], Train Loss: 0.0210, Val Loss: 0.0308\n",
      "Epoch [12/50], Train Loss: 0.0199, Val Loss: 0.0308\n",
      "Epoch [13/50], Train Loss: 0.0192, Val Loss: 0.0278\n",
      "Epoch [14/50], Train Loss: 0.0188, Val Loss: 0.0266\n",
      "Epoch [15/50], Train Loss: 0.0185, Val Loss: 0.0259\n",
      "Epoch [16/50], Train Loss: 0.0182, Val Loss: 0.0263\n",
      "Epoch [17/50], Train Loss: 0.0179, Val Loss: 0.0264\n",
      "Epoch [18/50], Train Loss: 0.0177, Val Loss: 0.0258\n",
      "Epoch [19/50], Train Loss: 0.0176, Val Loss: 0.0250\n",
      "Epoch [20/50], Train Loss: 0.0175, Val Loss: 0.0246\n",
      "Epoch [21/50], Train Loss: 0.0174, Val Loss: 0.0247\n",
      "Epoch [22/50], Train Loss: 0.0173, Val Loss: 0.0248\n",
      "Epoch [23/50], Train Loss: 0.0172, Val Loss: 0.0245\n",
      "Epoch [24/50], Train Loss: 0.0171, Val Loss: 0.0238\n",
      "Epoch [25/50], Train Loss: 0.0170, Val Loss: 0.0233\n",
      "Epoch [26/50], Train Loss: 0.0169, Val Loss: 0.0231\n",
      "Epoch [27/50], Train Loss: 0.0168, Val Loss: 0.0232\n",
      "Epoch [28/50], Train Loss: 0.0167, Val Loss: 0.0233\n",
      "Epoch [29/50], Train Loss: 0.0165, Val Loss: 0.0228\n",
      "Epoch [30/50], Train Loss: 0.0163, Val Loss: 0.0220\n",
      "Epoch [31/50], Train Loss: 0.0161, Val Loss: 0.0212\n",
      "Epoch [32/50], Train Loss: 0.0158, Val Loss: 0.0205\n",
      "Epoch [33/50], Train Loss: 0.0153, Val Loss: 0.0197\n",
      "Epoch [34/50], Train Loss: 0.0125, Val Loss: 0.0188\n",
      "Epoch [35/50], Train Loss: 0.0073, Val Loss: 0.0148\n",
      "Epoch [36/50], Train Loss: 0.0083, Val Loss: 0.0078\n",
      "Epoch [37/50], Train Loss: 0.0084, Val Loss: 0.0299\n",
      "Epoch [38/50], Train Loss: 0.0065, Val Loss: 0.0181\n",
      "Epoch [39/50], Train Loss: 0.0067, Val Loss: 0.0224\n",
      "Epoch [40/50], Train Loss: 0.0074, Val Loss: 0.0168\n",
      "Epoch [41/50], Train Loss: 0.0062, Val Loss: 0.0172\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1672, Val Loss: 0.3686\n",
      "Epoch [2/50], Train Loss: 0.1004, Val Loss: 0.1951\n",
      "Epoch [3/50], Train Loss: 0.0512, Val Loss: 0.0973\n",
      "Epoch [4/50], Train Loss: 0.0519, Val Loss: 0.0966\n",
      "Epoch [5/50], Train Loss: 0.0492, Val Loss: 0.0876\n",
      "Epoch [6/50], Train Loss: 0.0461, Val Loss: 0.0789\n",
      "Epoch [7/50], Train Loss: 0.0431, Val Loss: 0.0642\n",
      "Epoch [8/50], Train Loss: 0.0392, Val Loss: 0.0527\n",
      "Epoch [9/50], Train Loss: 0.0353, Val Loss: 0.0433\n",
      "Epoch [10/50], Train Loss: 0.0328, Val Loss: 0.0376\n",
      "Epoch [11/50], Train Loss: 0.0314, Val Loss: 0.0390\n",
      "Epoch [12/50], Train Loss: 0.0296, Val Loss: 0.0378\n",
      "Epoch [13/50], Train Loss: 0.0281, Val Loss: 0.0349\n",
      "Epoch [14/50], Train Loss: 0.0265, Val Loss: 0.0310\n",
      "Epoch [15/50], Train Loss: 0.0203, Val Loss: 0.0338\n",
      "Epoch [16/50], Train Loss: 0.0201, Val Loss: 0.0503\n",
      "Epoch [17/50], Train Loss: 0.0162, Val Loss: 0.0355\n",
      "Epoch [18/50], Train Loss: 0.0162, Val Loss: 0.0384\n",
      "Epoch [19/50], Train Loss: 0.0183, Val Loss: 0.0445\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0906, Val Loss: 0.2185\n",
      "Epoch [2/50], Train Loss: 0.0689, Val Loss: 0.1717\n",
      "Epoch [3/50], Train Loss: 0.0606, Val Loss: 0.1480\n",
      "Epoch [4/50], Train Loss: 0.0595, Val Loss: 0.1376\n",
      "Epoch [5/50], Train Loss: 0.0557, Val Loss: 0.1276\n",
      "Epoch [6/50], Train Loss: 0.0524, Val Loss: 0.1182\n",
      "Epoch [7/50], Train Loss: 0.0517, Val Loss: 0.1065\n",
      "Epoch [8/50], Train Loss: 0.0489, Val Loss: 0.0888\n",
      "Epoch [9/50], Train Loss: 0.0458, Val Loss: 0.0694\n",
      "Epoch [10/50], Train Loss: 0.0411, Val Loss: 0.0543\n",
      "Epoch [11/50], Train Loss: 0.0393, Val Loss: 0.0539\n",
      "Epoch [12/50], Train Loss: 0.0376, Val Loss: 0.0551\n",
      "Epoch [13/50], Train Loss: 0.0343, Val Loss: 0.0451\n",
      "Epoch [14/50], Train Loss: 0.0300, Val Loss: 0.0390\n",
      "Epoch [15/50], Train Loss: 0.0272, Val Loss: 0.0517\n",
      "Epoch [16/50], Train Loss: 0.0272, Val Loss: 0.0435\n",
      "Epoch [17/50], Train Loss: 0.0251, Val Loss: 0.0435\n",
      "Epoch [18/50], Train Loss: 0.0240, Val Loss: 0.0416\n",
      "Epoch [19/50], Train Loss: 0.0234, Val Loss: 0.0396\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1060, Val Loss: 0.2666\n",
      "Epoch [2/50], Train Loss: 0.0619, Val Loss: 0.1532\n",
      "Epoch [3/50], Train Loss: 0.0306, Val Loss: 0.0579\n",
      "Epoch [4/50], Train Loss: 0.0275, Val Loss: 0.0395\n",
      "Epoch [5/50], Train Loss: 0.0240, Val Loss: 0.0263\n",
      "Epoch [6/50], Train Loss: 0.0200, Val Loss: 0.0148\n",
      "Epoch [7/50], Train Loss: 0.0161, Val Loss: 0.0079\n",
      "Epoch [8/50], Train Loss: 0.0121, Val Loss: 0.0076\n",
      "Epoch [9/50], Train Loss: 0.0080, Val Loss: 0.0169\n",
      "Epoch [10/50], Train Loss: 0.0055, Val Loss: 0.0218\n",
      "Epoch [11/50], Train Loss: 0.0050, Val Loss: 0.0158\n",
      "Epoch [12/50], Train Loss: 0.0044, Val Loss: 0.0183\n",
      "Epoch [13/50], Train Loss: 0.0048, Val Loss: 0.0239\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1681, Val Loss: 0.3977\n",
      "Epoch [2/50], Train Loss: 0.0960, Val Loss: 0.1875\n",
      "Epoch [3/50], Train Loss: 0.0334, Val Loss: 0.0196\n",
      "Epoch [4/50], Train Loss: 0.0447, Val Loss: 0.0433\n",
      "Epoch [5/50], Train Loss: 0.0300, Val Loss: 0.0218\n",
      "Epoch [6/50], Train Loss: 0.0286, Val Loss: 0.0156\n",
      "Epoch [7/50], Train Loss: 0.0251, Val Loss: 0.0100\n",
      "Epoch [8/50], Train Loss: 0.0234, Val Loss: 0.0067\n",
      "Epoch [9/50], Train Loss: 0.0223, Val Loss: 0.0063\n",
      "Epoch [10/50], Train Loss: 0.0202, Val Loss: 0.0067\n",
      "Epoch [11/50], Train Loss: 0.0204, Val Loss: 0.0054\n",
      "Epoch [12/50], Train Loss: 0.0187, Val Loss: 0.0049\n",
      "Epoch [13/50], Train Loss: 0.0172, Val Loss: 0.0051\n",
      "Epoch [14/50], Train Loss: 0.0160, Val Loss: 0.0045\n",
      "Epoch [15/50], Train Loss: 0.0135, Val Loss: 0.0087\n",
      "Epoch [16/50], Train Loss: 0.0115, Val Loss: 0.0100\n",
      "Epoch [17/50], Train Loss: 0.0098, Val Loss: 0.0157\n",
      "Epoch [18/50], Train Loss: 0.0094, Val Loss: 0.0132\n",
      "Epoch [19/50], Train Loss: 0.0095, Val Loss: 0.0132\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1106, Val Loss: 0.2403\n",
      "Epoch [2/50], Train Loss: 0.0774, Val Loss: 0.1600\n",
      "Epoch [3/50], Train Loss: 0.0495, Val Loss: 0.0695\n",
      "Epoch [4/50], Train Loss: 0.0382, Val Loss: 0.0412\n",
      "Epoch [5/50], Train Loss: 0.0333, Val Loss: 0.0290\n",
      "Epoch [6/50], Train Loss: 0.0284, Val Loss: 0.0161\n",
      "Epoch [7/50], Train Loss: 0.0230, Val Loss: 0.0101\n",
      "Epoch [8/50], Train Loss: 0.0207, Val Loss: 0.0146\n",
      "Epoch [9/50], Train Loss: 0.0190, Val Loss: 0.0137\n",
      "Epoch [10/50], Train Loss: 0.0163, Val Loss: 0.0132\n",
      "Epoch [11/50], Train Loss: 0.0153, Val Loss: 0.0105\n",
      "Epoch [12/50], Train Loss: 0.0143, Val Loss: 0.0151\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0991, Val Loss: 0.2281\n",
      "Epoch [2/50], Train Loss: 0.0380, Val Loss: 0.0751\n",
      "Epoch [3/50], Train Loss: 0.0383, Val Loss: 0.0670\n",
      "Epoch [4/50], Train Loss: 0.0316, Val Loss: 0.0435\n",
      "Epoch [5/50], Train Loss: 0.0278, Val Loss: 0.0234\n",
      "Epoch [6/50], Train Loss: 0.0212, Val Loss: 0.0181\n",
      "Epoch [7/50], Train Loss: 0.0158, Val Loss: 0.0301\n",
      "Epoch [8/50], Train Loss: 0.0113, Val Loss: 0.0361\n",
      "Epoch [9/50], Train Loss: 0.0103, Val Loss: 0.0239\n",
      "Epoch [10/50], Train Loss: 0.0079, Val Loss: 0.0271\n",
      "Epoch [11/50], Train Loss: 0.0085, Val Loss: 0.0363\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1413, Val Loss: 0.2923\n",
      "Epoch [2/50], Train Loss: 0.0612, Val Loss: 0.0875\n",
      "Epoch [3/50], Train Loss: 0.0483, Val Loss: 0.0776\n",
      "Epoch [4/50], Train Loss: 0.0390, Val Loss: 0.0607\n",
      "Epoch [5/50], Train Loss: 0.0373, Val Loss: 0.0497\n",
      "Epoch [6/50], Train Loss: 0.0345, Val Loss: 0.0392\n",
      "Epoch [7/50], Train Loss: 0.0311, Val Loss: 0.0287\n",
      "Epoch [8/50], Train Loss: 0.0278, Val Loss: 0.0246\n",
      "Epoch [9/50], Train Loss: 0.0251, Val Loss: 0.0178\n",
      "Epoch [10/50], Train Loss: 0.0210, Val Loss: 0.0147\n",
      "Epoch [11/50], Train Loss: 0.0181, Val Loss: 0.0289\n",
      "Epoch [12/50], Train Loss: 0.0145, Val Loss: 0.0055\n",
      "Epoch [13/50], Train Loss: 0.0127, Val Loss: 0.0082\n",
      "Epoch [14/50], Train Loss: 0.0149, Val Loss: 0.0060\n",
      "Epoch [15/50], Train Loss: 0.0133, Val Loss: 0.0226\n",
      "Epoch [16/50], Train Loss: 0.0112, Val Loss: 0.0068\n",
      "Epoch [17/50], Train Loss: 0.0104, Val Loss: 0.0108\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1176, Val Loss: 0.2560\n",
      "Epoch [2/50], Train Loss: 0.0531, Val Loss: 0.0848\n",
      "Epoch [3/50], Train Loss: 0.0491, Val Loss: 0.0742\n",
      "Epoch [4/50], Train Loss: 0.0442, Val Loss: 0.0540\n",
      "Epoch [5/50], Train Loss: 0.0408, Val Loss: 0.0435\n",
      "Epoch [6/50], Train Loss: 0.0353, Val Loss: 0.0319\n",
      "Epoch [7/50], Train Loss: 0.0339, Val Loss: 0.0247\n",
      "Epoch [8/50], Train Loss: 0.0314, Val Loss: 0.0250\n",
      "Epoch [9/50], Train Loss: 0.0303, Val Loss: 0.0268\n",
      "Epoch [10/50], Train Loss: 0.0291, Val Loss: 0.0301\n",
      "Epoch [11/50], Train Loss: 0.0281, Val Loss: 0.0263\n",
      "Epoch [12/50], Train Loss: 0.0274, Val Loss: 0.0202\n",
      "Epoch [13/50], Train Loss: 0.0274, Val Loss: 0.0188\n",
      "Epoch [14/50], Train Loss: 0.0249, Val Loss: 0.0214\n",
      "Epoch [15/50], Train Loss: 0.0235, Val Loss: 0.0134\n",
      "Epoch [16/50], Train Loss: 0.0213, Val Loss: 0.0060\n",
      "Epoch [17/50], Train Loss: 0.0165, Val Loss: 0.0047\n",
      "Epoch [18/50], Train Loss: 0.0169, Val Loss: 0.0190\n",
      "Epoch [19/50], Train Loss: 0.0150, Val Loss: 0.0087\n",
      "Epoch [20/50], Train Loss: 0.0150, Val Loss: 0.0066\n",
      "Epoch [21/50], Train Loss: 0.0160, Val Loss: 0.0320\n",
      "Epoch [22/50], Train Loss: 0.0139, Val Loss: 0.0090\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1201, Val Loss: 0.2434\n",
      "Epoch [2/50], Train Loss: 0.0299, Val Loss: 0.0366\n",
      "Epoch [3/50], Train Loss: 0.0566, Val Loss: 0.0870\n",
      "Epoch [4/50], Train Loss: 0.0352, Val Loss: 0.0494\n",
      "Epoch [5/50], Train Loss: 0.0377, Val Loss: 0.0408\n",
      "Epoch [6/50], Train Loss: 0.0310, Val Loss: 0.0223\n",
      "Epoch [7/50], Train Loss: 0.0245, Val Loss: 0.0163\n",
      "Epoch [8/50], Train Loss: 0.0209, Val Loss: 0.0166\n",
      "Epoch [9/50], Train Loss: 0.0207, Val Loss: 0.0181\n",
      "Epoch [10/50], Train Loss: 0.0211, Val Loss: 0.0244\n",
      "Epoch [11/50], Train Loss: 0.0210, Val Loss: 0.0413\n",
      "Epoch [12/50], Train Loss: 0.0205, Val Loss: 0.0298\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0665, Val Loss: 0.1909\n",
      "Epoch [2/50], Train Loss: 0.0418, Val Loss: 0.1131\n",
      "Epoch [3/50], Train Loss: 0.0411, Val Loss: 0.0970\n",
      "Epoch [4/50], Train Loss: 0.0408, Val Loss: 0.0867\n",
      "Epoch [5/50], Train Loss: 0.0374, Val Loss: 0.0476\n",
      "Epoch [6/50], Train Loss: 0.0312, Val Loss: 0.0317\n",
      "Epoch [7/50], Train Loss: 0.0237, Val Loss: 0.0452\n",
      "Epoch [8/50], Train Loss: 0.0208, Val Loss: 0.0337\n",
      "Epoch [9/50], Train Loss: 0.0178, Val Loss: 0.0433\n",
      "Epoch [10/50], Train Loss: 0.0133, Val Loss: 0.0512\n",
      "Epoch [11/50], Train Loss: 0.0154, Val Loss: 0.0274\n",
      "Epoch [12/50], Train Loss: 0.0096, Val Loss: 0.0462\n",
      "Epoch [13/50], Train Loss: 0.0099, Val Loss: 0.0362\n",
      "Epoch [14/50], Train Loss: 0.0093, Val Loss: 0.0332\n",
      "Epoch [15/50], Train Loss: 0.0136, Val Loss: 0.0382\n",
      "Epoch [16/50], Train Loss: 0.0107, Val Loss: 0.0435\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1206, Val Loss: 0.2834\n",
      "Epoch [2/50], Train Loss: 0.0558, Val Loss: 0.0738\n",
      "Epoch [3/50], Train Loss: 0.0664, Val Loss: 0.1181\n",
      "Epoch [4/50], Train Loss: 0.0497, Val Loss: 0.0643\n",
      "Epoch [5/50], Train Loss: 0.0474, Val Loss: 0.0426\n",
      "Epoch [6/50], Train Loss: 0.0411, Val Loss: 0.0347\n",
      "Epoch [7/50], Train Loss: 0.0361, Val Loss: 0.0415\n",
      "Epoch [8/50], Train Loss: 0.0329, Val Loss: 0.0208\n",
      "Epoch [9/50], Train Loss: 0.0320, Val Loss: 0.0178\n",
      "Epoch [10/50], Train Loss: 0.0322, Val Loss: 0.0295\n",
      "Epoch [11/50], Train Loss: 0.0309, Val Loss: 0.0429\n",
      "Epoch [12/50], Train Loss: 0.0288, Val Loss: 0.0253\n",
      "Epoch [13/50], Train Loss: 0.0287, Val Loss: 0.0235\n",
      "Epoch [14/50], Train Loss: 0.0285, Val Loss: 0.0396\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0853, Val Loss: 0.2314\n",
      "Epoch [2/50], Train Loss: 0.0389, Val Loss: 0.0618\n",
      "Epoch [3/50], Train Loss: 0.0315, Val Loss: 0.0365\n",
      "Epoch [4/50], Train Loss: 0.0260, Val Loss: 0.0195\n",
      "Epoch [5/50], Train Loss: 0.0211, Val Loss: 0.0100\n",
      "Epoch [6/50], Train Loss: 0.0179, Val Loss: 0.0171\n",
      "Epoch [7/50], Train Loss: 0.0095, Val Loss: 0.0152\n",
      "Epoch [8/50], Train Loss: 0.0074, Val Loss: 0.0176\n",
      "Epoch [9/50], Train Loss: 0.0059, Val Loss: 0.0282\n",
      "Epoch [10/50], Train Loss: 0.0068, Val Loss: 0.0114\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1110, Val Loss: 0.1973\n",
      "Epoch [2/50], Train Loss: 0.0307, Val Loss: 0.0447\n",
      "Epoch [3/50], Train Loss: 0.0313, Val Loss: 0.0145\n",
      "Epoch [4/50], Train Loss: 0.0308, Val Loss: 0.0195\n",
      "Epoch [5/50], Train Loss: 0.0242, Val Loss: 0.0165\n",
      "Epoch [6/50], Train Loss: 0.0207, Val Loss: 0.0125\n",
      "Epoch [7/50], Train Loss: 0.0199, Val Loss: 0.0112\n",
      "Epoch [8/50], Train Loss: 0.0173, Val Loss: 0.0068\n",
      "Epoch [9/50], Train Loss: 0.0149, Val Loss: 0.0038\n",
      "Epoch [10/50], Train Loss: 0.0132, Val Loss: 0.0279\n",
      "Epoch [11/50], Train Loss: 0.0093, Val Loss: 0.0057\n",
      "Epoch [12/50], Train Loss: 0.0083, Val Loss: 0.0075\n",
      "Epoch [13/50], Train Loss: 0.0081, Val Loss: 0.0157\n",
      "Epoch [14/50], Train Loss: 0.0066, Val Loss: 0.0059\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1290, Val Loss: 0.2612\n",
      "Epoch [2/50], Train Loss: 0.0450, Val Loss: 0.0503\n",
      "Epoch [3/50], Train Loss: 0.0493, Val Loss: 0.0630\n",
      "Epoch [4/50], Train Loss: 0.0369, Val Loss: 0.0415\n",
      "Epoch [5/50], Train Loss: 0.0329, Val Loss: 0.0253\n",
      "Epoch [6/50], Train Loss: 0.0303, Val Loss: 0.0116\n",
      "Epoch [7/50], Train Loss: 0.0251, Val Loss: 0.0053\n",
      "Epoch [8/50], Train Loss: 0.0183, Val Loss: 0.0162\n",
      "Epoch [9/50], Train Loss: 0.0142, Val Loss: 0.0142\n",
      "Epoch [10/50], Train Loss: 0.0166, Val Loss: 0.0338\n",
      "Epoch [11/50], Train Loss: 0.0185, Val Loss: 0.0037\n",
      "Epoch [12/50], Train Loss: 0.0134, Val Loss: 0.0071\n",
      "Epoch [13/50], Train Loss: 0.0117, Val Loss: 0.0120\n",
      "Epoch [14/50], Train Loss: 0.0118, Val Loss: 0.0152\n",
      "Epoch [15/50], Train Loss: 0.0144, Val Loss: 0.0017\n",
      "Epoch [16/50], Train Loss: 0.0104, Val Loss: 0.0088\n",
      "Epoch [17/50], Train Loss: 0.0103, Val Loss: 0.0071\n",
      "Epoch [18/50], Train Loss: 0.0097, Val Loss: 0.0117\n",
      "Epoch [19/50], Train Loss: 0.0125, Val Loss: 0.0022\n",
      "Epoch [20/50], Train Loss: 0.0089, Val Loss: 0.0089\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0695, Val Loss: 0.1156\n",
      "Epoch [2/50], Train Loss: 0.0357, Val Loss: 0.0418\n",
      "Epoch [3/50], Train Loss: 0.0386, Val Loss: 0.0336\n",
      "Epoch [4/50], Train Loss: 0.0307, Val Loss: 0.0125\n",
      "Epoch [5/50], Train Loss: 0.0240, Val Loss: 0.0068\n",
      "Epoch [6/50], Train Loss: 0.0160, Val Loss: 0.0389\n",
      "Epoch [7/50], Train Loss: 0.0121, Val Loss: 0.0210\n",
      "Epoch [8/50], Train Loss: 0.0136, Val Loss: 0.0177\n",
      "Epoch [9/50], Train Loss: 0.0089, Val Loss: 0.0348\n",
      "Epoch [10/50], Train Loss: 0.0082, Val Loss: 0.0110\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0816, Val Loss: 0.0583\n",
      "Epoch [2/50], Train Loss: 0.0498, Val Loss: 0.0503\n",
      "Epoch [3/50], Train Loss: 0.0390, Val Loss: 0.0359\n",
      "Epoch [4/50], Train Loss: 0.0353, Val Loss: 0.0205\n",
      "Epoch [5/50], Train Loss: 0.0303, Val Loss: 0.0146\n",
      "Epoch [6/50], Train Loss: 0.0250, Val Loss: 0.0207\n",
      "Epoch [7/50], Train Loss: 0.0226, Val Loss: 0.0197\n",
      "Epoch [8/50], Train Loss: 0.0192, Val Loss: 0.0153\n",
      "Epoch [9/50], Train Loss: 0.0133, Val Loss: 0.0229\n",
      "Epoch [10/50], Train Loss: 0.0194, Val Loss: 0.0611\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1143, Val Loss: 0.1767\n",
      "Epoch [2/50], Train Loss: 0.0433, Val Loss: 0.0577\n",
      "Epoch [3/50], Train Loss: 0.0524, Val Loss: 0.0349\n",
      "Epoch [4/50], Train Loss: 0.0457, Val Loss: 0.0278\n",
      "Epoch [5/50], Train Loss: 0.0361, Val Loss: 0.0094\n",
      "Epoch [6/50], Train Loss: 0.0302, Val Loss: 0.0040\n",
      "Epoch [7/50], Train Loss: 0.0259, Val Loss: 0.0053\n",
      "Epoch [8/50], Train Loss: 0.0182, Val Loss: 0.0186\n",
      "Epoch [9/50], Train Loss: 0.0161, Val Loss: 0.0137\n",
      "Epoch [10/50], Train Loss: 0.0190, Val Loss: 0.0581\n",
      "Epoch [11/50], Train Loss: 0.0186, Val Loss: 0.0115\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0649, Val Loss: 0.0428\n",
      "Epoch [2/50], Train Loss: 0.0642, Val Loss: 0.1154\n",
      "Epoch [3/50], Train Loss: 0.0366, Val Loss: 0.0522\n",
      "Epoch [4/50], Train Loss: 0.0452, Val Loss: 0.0564\n",
      "Epoch [5/50], Train Loss: 0.0363, Val Loss: 0.0238\n",
      "Epoch [6/50], Train Loss: 0.0319, Val Loss: 0.0138\n",
      "Epoch [7/50], Train Loss: 0.0245, Val Loss: 0.0085\n",
      "Epoch [8/50], Train Loss: 0.0228, Val Loss: 0.0111\n",
      "Epoch [9/50], Train Loss: 0.0208, Val Loss: 0.0136\n",
      "Epoch [10/50], Train Loss: 0.0199, Val Loss: 0.0161\n",
      "Epoch [11/50], Train Loss: 0.0204, Val Loss: 0.0294\n",
      "Epoch [12/50], Train Loss: 0.0175, Val Loss: 0.0549\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0735, Val Loss: 0.0942\n",
      "Epoch [2/50], Train Loss: 0.0520, Val Loss: 0.0789\n",
      "Epoch [3/50], Train Loss: 0.0444, Val Loss: 0.0598\n",
      "Epoch [4/50], Train Loss: 0.0409, Val Loss: 0.0367\n",
      "Epoch [5/50], Train Loss: 0.0349, Val Loss: 0.0287\n",
      "Epoch [6/50], Train Loss: 0.0274, Val Loss: 0.0195\n",
      "Epoch [7/50], Train Loss: 0.0250, Val Loss: 0.0186\n",
      "Epoch [8/50], Train Loss: 0.0234, Val Loss: 0.0176\n",
      "Epoch [9/50], Train Loss: 0.0225, Val Loss: 0.0188\n",
      "Epoch [10/50], Train Loss: 0.0224, Val Loss: 0.0603\n",
      "Epoch [11/50], Train Loss: 0.0213, Val Loss: 0.0332\n",
      "Epoch [12/50], Train Loss: 0.0187, Val Loss: 0.0352\n",
      "Epoch [13/50], Train Loss: 0.0117, Val Loss: 0.0416\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0823, Val Loss: 0.0840\n",
      "Epoch [2/50], Train Loss: 0.0550, Val Loss: 0.0775\n",
      "Epoch [3/50], Train Loss: 0.0505, Val Loss: 0.0591\n",
      "Epoch [4/50], Train Loss: 0.0449, Val Loss: 0.0313\n",
      "Epoch [5/50], Train Loss: 0.0381, Val Loss: 0.0158\n",
      "Epoch [6/50], Train Loss: 0.0329, Val Loss: 0.0236\n",
      "Epoch [7/50], Train Loss: 0.0331, Val Loss: 0.0295\n",
      "Epoch [8/50], Train Loss: 0.0279, Val Loss: 0.0385\n",
      "Epoch [9/50], Train Loss: 0.0267, Val Loss: 0.0445\n",
      "Epoch [10/50], Train Loss: 0.0247, Val Loss: 0.0279\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1192, Val Loss: 0.2991\n",
      "Epoch [2/50], Train Loss: 0.1178, Val Loss: 0.2966\n",
      "Epoch [3/50], Train Loss: 0.1164, Val Loss: 0.2942\n",
      "Epoch [4/50], Train Loss: 0.1151, Val Loss: 0.2917\n",
      "Epoch [5/50], Train Loss: 0.1137, Val Loss: 0.2893\n",
      "Epoch [6/50], Train Loss: 0.1124, Val Loss: 0.2869\n",
      "Epoch [7/50], Train Loss: 0.1112, Val Loss: 0.2846\n",
      "Epoch [8/50], Train Loss: 0.1099, Val Loss: 0.2822\n",
      "Epoch [9/50], Train Loss: 0.1087, Val Loss: 0.2799\n",
      "Epoch [10/50], Train Loss: 0.1074, Val Loss: 0.2777\n",
      "Epoch [11/50], Train Loss: 0.1062, Val Loss: 0.2754\n",
      "Epoch [12/50], Train Loss: 0.1050, Val Loss: 0.2732\n",
      "Epoch [13/50], Train Loss: 0.1039, Val Loss: 0.2710\n",
      "Epoch [14/50], Train Loss: 0.1027, Val Loss: 0.2689\n",
      "Epoch [15/50], Train Loss: 0.1016, Val Loss: 0.2667\n",
      "Epoch [16/50], Train Loss: 0.1005, Val Loss: 0.2646\n",
      "Epoch [17/50], Train Loss: 0.0994, Val Loss: 0.2626\n",
      "Epoch [18/50], Train Loss: 0.0983, Val Loss: 0.2605\n",
      "Epoch [19/50], Train Loss: 0.0972, Val Loss: 0.2584\n",
      "Epoch [20/50], Train Loss: 0.0962, Val Loss: 0.2564\n",
      "Epoch [21/50], Train Loss: 0.0952, Val Loss: 0.2545\n",
      "Epoch [22/50], Train Loss: 0.0942, Val Loss: 0.2525\n",
      "Epoch [23/50], Train Loss: 0.0932, Val Loss: 0.2506\n",
      "Epoch [24/50], Train Loss: 0.0922, Val Loss: 0.2487\n",
      "Epoch [25/50], Train Loss: 0.0912, Val Loss: 0.2468\n",
      "Epoch [26/50], Train Loss: 0.0903, Val Loss: 0.2449\n",
      "Epoch [27/50], Train Loss: 0.0893, Val Loss: 0.2430\n",
      "Epoch [28/50], Train Loss: 0.0884, Val Loss: 0.2412\n",
      "Epoch [29/50], Train Loss: 0.0875, Val Loss: 0.2394\n",
      "Epoch [30/50], Train Loss: 0.0866, Val Loss: 0.2376\n",
      "Epoch [31/50], Train Loss: 0.0857, Val Loss: 0.2359\n",
      "Epoch [32/50], Train Loss: 0.0848, Val Loss: 0.2342\n",
      "Epoch [33/50], Train Loss: 0.0840, Val Loss: 0.2324\n",
      "Epoch [34/50], Train Loss: 0.0832, Val Loss: 0.2307\n",
      "Epoch [35/50], Train Loss: 0.0823, Val Loss: 0.2291\n",
      "Epoch [36/50], Train Loss: 0.0815, Val Loss: 0.2274\n",
      "Epoch [37/50], Train Loss: 0.0807, Val Loss: 0.2258\n",
      "Epoch [38/50], Train Loss: 0.0799, Val Loss: 0.2242\n",
      "Epoch [39/50], Train Loss: 0.0791, Val Loss: 0.2226\n",
      "Epoch [40/50], Train Loss: 0.0784, Val Loss: 0.2210\n",
      "Epoch [41/50], Train Loss: 0.0776, Val Loss: 0.2194\n",
      "Epoch [42/50], Train Loss: 0.0769, Val Loss: 0.2179\n",
      "Epoch [43/50], Train Loss: 0.0762, Val Loss: 0.2164\n",
      "Epoch [44/50], Train Loss: 0.0754, Val Loss: 0.2149\n",
      "Epoch [45/50], Train Loss: 0.0747, Val Loss: 0.2134\n",
      "Epoch [46/50], Train Loss: 0.0740, Val Loss: 0.2119\n",
      "Epoch [47/50], Train Loss: 0.0734, Val Loss: 0.2105\n",
      "Epoch [48/50], Train Loss: 0.0727, Val Loss: 0.2091\n",
      "Epoch [49/50], Train Loss: 0.0720, Val Loss: 0.2076\n",
      "Epoch [50/50], Train Loss: 0.0714, Val Loss: 0.2063\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1165, Val Loss: 0.3352\n",
      "Epoch [2/50], Train Loss: 0.1147, Val Loss: 0.3325\n",
      "Epoch [3/50], Train Loss: 0.1149, Val Loss: 0.3298\n",
      "Epoch [4/50], Train Loss: 0.1130, Val Loss: 0.3271\n",
      "Epoch [5/50], Train Loss: 0.1117, Val Loss: 0.3245\n",
      "Epoch [6/50], Train Loss: 0.1111, Val Loss: 0.3219\n",
      "Epoch [7/50], Train Loss: 0.1086, Val Loss: 0.3194\n",
      "Epoch [8/50], Train Loss: 0.1081, Val Loss: 0.3168\n",
      "Epoch [9/50], Train Loss: 0.1073, Val Loss: 0.3143\n",
      "Epoch [10/50], Train Loss: 0.1057, Val Loss: 0.3119\n",
      "Epoch [11/50], Train Loss: 0.1039, Val Loss: 0.3094\n",
      "Epoch [12/50], Train Loss: 0.1028, Val Loss: 0.3071\n",
      "Epoch [13/50], Train Loss: 0.1018, Val Loss: 0.3047\n",
      "Epoch [14/50], Train Loss: 0.1009, Val Loss: 0.3023\n",
      "Epoch [15/50], Train Loss: 0.0997, Val Loss: 0.3000\n",
      "Epoch [16/50], Train Loss: 0.0990, Val Loss: 0.2977\n",
      "Epoch [17/50], Train Loss: 0.0978, Val Loss: 0.2955\n",
      "Epoch [18/50], Train Loss: 0.0971, Val Loss: 0.2933\n",
      "Epoch [19/50], Train Loss: 0.0962, Val Loss: 0.2910\n",
      "Epoch [20/50], Train Loss: 0.0952, Val Loss: 0.2889\n",
      "Epoch [21/50], Train Loss: 0.0939, Val Loss: 0.2867\n",
      "Epoch [22/50], Train Loss: 0.0929, Val Loss: 0.2846\n",
      "Epoch [23/50], Train Loss: 0.0919, Val Loss: 0.2825\n",
      "Epoch [24/50], Train Loss: 0.0909, Val Loss: 0.2805\n",
      "Epoch [25/50], Train Loss: 0.0909, Val Loss: 0.2784\n",
      "Epoch [26/50], Train Loss: 0.0896, Val Loss: 0.2764\n",
      "Epoch [27/50], Train Loss: 0.0881, Val Loss: 0.2744\n",
      "Epoch [28/50], Train Loss: 0.0873, Val Loss: 0.2725\n",
      "Epoch [29/50], Train Loss: 0.0867, Val Loss: 0.2705\n",
      "Epoch [30/50], Train Loss: 0.0858, Val Loss: 0.2686\n",
      "Epoch [31/50], Train Loss: 0.0850, Val Loss: 0.2667\n",
      "Epoch [32/50], Train Loss: 0.0844, Val Loss: 0.2648\n",
      "Epoch [33/50], Train Loss: 0.0830, Val Loss: 0.2630\n",
      "Epoch [34/50], Train Loss: 0.0824, Val Loss: 0.2612\n",
      "Epoch [35/50], Train Loss: 0.0817, Val Loss: 0.2594\n",
      "Epoch [36/50], Train Loss: 0.0811, Val Loss: 0.2576\n",
      "Epoch [37/50], Train Loss: 0.0805, Val Loss: 0.2558\n",
      "Epoch [38/50], Train Loss: 0.0805, Val Loss: 0.2541\n",
      "Epoch [39/50], Train Loss: 0.0786, Val Loss: 0.2523\n",
      "Epoch [40/50], Train Loss: 0.0786, Val Loss: 0.2506\n",
      "Epoch [41/50], Train Loss: 0.0776, Val Loss: 0.2490\n",
      "Epoch [42/50], Train Loss: 0.0767, Val Loss: 0.2473\n",
      "Epoch [43/50], Train Loss: 0.0762, Val Loss: 0.2456\n",
      "Epoch [44/50], Train Loss: 0.0757, Val Loss: 0.2440\n",
      "Epoch [45/50], Train Loss: 0.0746, Val Loss: 0.2424\n",
      "Epoch [46/50], Train Loss: 0.0734, Val Loss: 0.2408\n",
      "Epoch [47/50], Train Loss: 0.0740, Val Loss: 0.2393\n",
      "Epoch [48/50], Train Loss: 0.0728, Val Loss: 0.2377\n",
      "Epoch [49/50], Train Loss: 0.0718, Val Loss: 0.2362\n",
      "Epoch [50/50], Train Loss: 0.0717, Val Loss: 0.2347\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1435, Val Loss: 0.3045\n",
      "Epoch [2/50], Train Loss: 0.1416, Val Loss: 0.3021\n",
      "Epoch [3/50], Train Loss: 0.1398, Val Loss: 0.2998\n",
      "Epoch [4/50], Train Loss: 0.1381, Val Loss: 0.2975\n",
      "Epoch [5/50], Train Loss: 0.1377, Val Loss: 0.2952\n",
      "Epoch [6/50], Train Loss: 0.1355, Val Loss: 0.2929\n",
      "Epoch [7/50], Train Loss: 0.1327, Val Loss: 0.2907\n",
      "Epoch [8/50], Train Loss: 0.1328, Val Loss: 0.2885\n",
      "Epoch [9/50], Train Loss: 0.1313, Val Loss: 0.2863\n",
      "Epoch [10/50], Train Loss: 0.1308, Val Loss: 0.2842\n",
      "Epoch [11/50], Train Loss: 0.1291, Val Loss: 0.2820\n",
      "Epoch [12/50], Train Loss: 0.1276, Val Loss: 0.2800\n",
      "Epoch [13/50], Train Loss: 0.1258, Val Loss: 0.2779\n",
      "Epoch [14/50], Train Loss: 0.1245, Val Loss: 0.2759\n",
      "Epoch [15/50], Train Loss: 0.1241, Val Loss: 0.2738\n",
      "Epoch [16/50], Train Loss: 0.1210, Val Loss: 0.2719\n",
      "Epoch [17/50], Train Loss: 0.1198, Val Loss: 0.2699\n",
      "Epoch [18/50], Train Loss: 0.1199, Val Loss: 0.2680\n",
      "Epoch [19/50], Train Loss: 0.1179, Val Loss: 0.2661\n",
      "Epoch [20/50], Train Loss: 0.1179, Val Loss: 0.2642\n",
      "Epoch [21/50], Train Loss: 0.1160, Val Loss: 0.2624\n",
      "Epoch [22/50], Train Loss: 0.1137, Val Loss: 0.2606\n",
      "Epoch [23/50], Train Loss: 0.1123, Val Loss: 0.2588\n",
      "Epoch [24/50], Train Loss: 0.1129, Val Loss: 0.2570\n",
      "Epoch [25/50], Train Loss: 0.1121, Val Loss: 0.2553\n",
      "Epoch [26/50], Train Loss: 0.1111, Val Loss: 0.2535\n",
      "Epoch [27/50], Train Loss: 0.1094, Val Loss: 0.2518\n",
      "Epoch [28/50], Train Loss: 0.1087, Val Loss: 0.2501\n",
      "Epoch [29/50], Train Loss: 0.1080, Val Loss: 0.2485\n",
      "Epoch [30/50], Train Loss: 0.1066, Val Loss: 0.2468\n",
      "Epoch [31/50], Train Loss: 0.1047, Val Loss: 0.2452\n",
      "Epoch [32/50], Train Loss: 0.1040, Val Loss: 0.2436\n",
      "Epoch [33/50], Train Loss: 0.1035, Val Loss: 0.2420\n",
      "Epoch [34/50], Train Loss: 0.1027, Val Loss: 0.2405\n",
      "Epoch [35/50], Train Loss: 0.1003, Val Loss: 0.2389\n",
      "Epoch [36/50], Train Loss: 0.1011, Val Loss: 0.2374\n",
      "Epoch [37/50], Train Loss: 0.0986, Val Loss: 0.2359\n",
      "Epoch [38/50], Train Loss: 0.0982, Val Loss: 0.2344\n",
      "Epoch [39/50], Train Loss: 0.0975, Val Loss: 0.2330\n",
      "Epoch [40/50], Train Loss: 0.0957, Val Loss: 0.2316\n",
      "Epoch [41/50], Train Loss: 0.0967, Val Loss: 0.2301\n",
      "Epoch [42/50], Train Loss: 0.0962, Val Loss: 0.2287\n",
      "Epoch [43/50], Train Loss: 0.0943, Val Loss: 0.2273\n",
      "Epoch [44/50], Train Loss: 0.0933, Val Loss: 0.2259\n",
      "Epoch [45/50], Train Loss: 0.0929, Val Loss: 0.2245\n",
      "Epoch [46/50], Train Loss: 0.0923, Val Loss: 0.2232\n",
      "Epoch [47/50], Train Loss: 0.0909, Val Loss: 0.2219\n",
      "Epoch [48/50], Train Loss: 0.0906, Val Loss: 0.2206\n",
      "Epoch [49/50], Train Loss: 0.0901, Val Loss: 0.2193\n",
      "Epoch [50/50], Train Loss: 0.0889, Val Loss: 0.2180\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1856, Val Loss: 0.4847\n",
      "Epoch [2/50], Train Loss: 0.1835, Val Loss: 0.4809\n",
      "Epoch [3/50], Train Loss: 0.1814, Val Loss: 0.4772\n",
      "Epoch [4/50], Train Loss: 0.1793, Val Loss: 0.4736\n",
      "Epoch [5/50], Train Loss: 0.1773, Val Loss: 0.4699\n",
      "Epoch [6/50], Train Loss: 0.1753, Val Loss: 0.4664\n",
      "Epoch [7/50], Train Loss: 0.1733, Val Loss: 0.4628\n",
      "Epoch [8/50], Train Loss: 0.1713, Val Loss: 0.4593\n",
      "Epoch [9/50], Train Loss: 0.1694, Val Loss: 0.4558\n",
      "Epoch [10/50], Train Loss: 0.1675, Val Loss: 0.4524\n",
      "Epoch [11/50], Train Loss: 0.1656, Val Loss: 0.4490\n",
      "Epoch [12/50], Train Loss: 0.1638, Val Loss: 0.4456\n",
      "Epoch [13/50], Train Loss: 0.1619, Val Loss: 0.4423\n",
      "Epoch [14/50], Train Loss: 0.1601, Val Loss: 0.4390\n",
      "Epoch [15/50], Train Loss: 0.1584, Val Loss: 0.4358\n",
      "Epoch [16/50], Train Loss: 0.1566, Val Loss: 0.4325\n",
      "Epoch [17/50], Train Loss: 0.1549, Val Loss: 0.4294\n",
      "Epoch [18/50], Train Loss: 0.1532, Val Loss: 0.4262\n",
      "Epoch [19/50], Train Loss: 0.1515, Val Loss: 0.4231\n",
      "Epoch [20/50], Train Loss: 0.1499, Val Loss: 0.4200\n",
      "Epoch [21/50], Train Loss: 0.1483, Val Loss: 0.4170\n",
      "Epoch [22/50], Train Loss: 0.1467, Val Loss: 0.4139\n",
      "Epoch [23/50], Train Loss: 0.1451, Val Loss: 0.4110\n",
      "Epoch [24/50], Train Loss: 0.1435, Val Loss: 0.4080\n",
      "Epoch [25/50], Train Loss: 0.1420, Val Loss: 0.4051\n",
      "Epoch [26/50], Train Loss: 0.1405, Val Loss: 0.4022\n",
      "Epoch [27/50], Train Loss: 0.1390, Val Loss: 0.3993\n",
      "Epoch [28/50], Train Loss: 0.1375, Val Loss: 0.3965\n",
      "Epoch [29/50], Train Loss: 0.1361, Val Loss: 0.3937\n",
      "Epoch [30/50], Train Loss: 0.1346, Val Loss: 0.3909\n",
      "Epoch [31/50], Train Loss: 0.1332, Val Loss: 0.3882\n",
      "Epoch [32/50], Train Loss: 0.1318, Val Loss: 0.3855\n",
      "Epoch [33/50], Train Loss: 0.1305, Val Loss: 0.3828\n",
      "Epoch [34/50], Train Loss: 0.1291, Val Loss: 0.3801\n",
      "Epoch [35/50], Train Loss: 0.1278, Val Loss: 0.3775\n",
      "Epoch [36/50], Train Loss: 0.1265, Val Loss: 0.3749\n",
      "Epoch [37/50], Train Loss: 0.1252, Val Loss: 0.3723\n",
      "Epoch [38/50], Train Loss: 0.1239, Val Loss: 0.3698\n",
      "Epoch [39/50], Train Loss: 0.1226, Val Loss: 0.3672\n",
      "Epoch [40/50], Train Loss: 0.1214, Val Loss: 0.3647\n",
      "Epoch [41/50], Train Loss: 0.1202, Val Loss: 0.3623\n",
      "Epoch [42/50], Train Loss: 0.1190, Val Loss: 0.3598\n",
      "Epoch [43/50], Train Loss: 0.1178, Val Loss: 0.3574\n",
      "Epoch [44/50], Train Loss: 0.1166, Val Loss: 0.3550\n",
      "Epoch [45/50], Train Loss: 0.1154, Val Loss: 0.3526\n",
      "Epoch [46/50], Train Loss: 0.1143, Val Loss: 0.3503\n",
      "Epoch [47/50], Train Loss: 0.1132, Val Loss: 0.3480\n",
      "Epoch [48/50], Train Loss: 0.1121, Val Loss: 0.3457\n",
      "Epoch [49/50], Train Loss: 0.1110, Val Loss: 0.3434\n",
      "Epoch [50/50], Train Loss: 0.1099, Val Loss: 0.3412\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.2485, Val Loss: 0.5460\n",
      "Epoch [2/50], Train Loss: 0.2460, Val Loss: 0.5409\n",
      "Epoch [3/50], Train Loss: 0.2423, Val Loss: 0.5360\n",
      "Epoch [4/50], Train Loss: 0.2395, Val Loss: 0.5311\n",
      "Epoch [5/50], Train Loss: 0.2356, Val Loss: 0.5263\n",
      "Epoch [6/50], Train Loss: 0.2330, Val Loss: 0.5216\n",
      "Epoch [7/50], Train Loss: 0.2300, Val Loss: 0.5169\n",
      "Epoch [8/50], Train Loss: 0.2256, Val Loss: 0.5123\n",
      "Epoch [9/50], Train Loss: 0.2242, Val Loss: 0.5077\n",
      "Epoch [10/50], Train Loss: 0.2217, Val Loss: 0.5033\n",
      "Epoch [11/50], Train Loss: 0.2176, Val Loss: 0.4989\n",
      "Epoch [12/50], Train Loss: 0.2157, Val Loss: 0.4945\n",
      "Epoch [13/50], Train Loss: 0.2129, Val Loss: 0.4902\n",
      "Epoch [14/50], Train Loss: 0.2088, Val Loss: 0.4860\n",
      "Epoch [15/50], Train Loss: 0.2070, Val Loss: 0.4818\n",
      "Epoch [16/50], Train Loss: 0.2046, Val Loss: 0.4776\n",
      "Epoch [17/50], Train Loss: 0.2015, Val Loss: 0.4736\n",
      "Epoch [18/50], Train Loss: 0.1994, Val Loss: 0.4696\n",
      "Epoch [19/50], Train Loss: 0.1968, Val Loss: 0.4656\n",
      "Epoch [20/50], Train Loss: 0.1943, Val Loss: 0.4617\n",
      "Epoch [21/50], Train Loss: 0.1923, Val Loss: 0.4578\n",
      "Epoch [22/50], Train Loss: 0.1896, Val Loss: 0.4540\n",
      "Epoch [23/50], Train Loss: 0.1879, Val Loss: 0.4502\n",
      "Epoch [24/50], Train Loss: 0.1850, Val Loss: 0.4465\n",
      "Epoch [25/50], Train Loss: 0.1826, Val Loss: 0.4428\n",
      "Epoch [26/50], Train Loss: 0.1805, Val Loss: 0.4392\n",
      "Epoch [27/50], Train Loss: 0.1783, Val Loss: 0.4356\n",
      "Epoch [28/50], Train Loss: 0.1760, Val Loss: 0.4321\n",
      "Epoch [29/50], Train Loss: 0.1745, Val Loss: 0.4286\n",
      "Epoch [30/50], Train Loss: 0.1720, Val Loss: 0.4252\n",
      "Epoch [31/50], Train Loss: 0.1699, Val Loss: 0.4218\n",
      "Epoch [32/50], Train Loss: 0.1678, Val Loss: 0.4184\n",
      "Epoch [33/50], Train Loss: 0.1662, Val Loss: 0.4151\n",
      "Epoch [34/50], Train Loss: 0.1640, Val Loss: 0.4119\n",
      "Epoch [35/50], Train Loss: 0.1622, Val Loss: 0.4086\n",
      "Epoch [36/50], Train Loss: 0.1604, Val Loss: 0.4054\n",
      "Epoch [37/50], Train Loss: 0.1587, Val Loss: 0.4023\n",
      "Epoch [38/50], Train Loss: 0.1563, Val Loss: 0.3992\n",
      "Epoch [39/50], Train Loss: 0.1548, Val Loss: 0.3961\n",
      "Epoch [40/50], Train Loss: 0.1535, Val Loss: 0.3930\n",
      "Epoch [41/50], Train Loss: 0.1511, Val Loss: 0.3900\n",
      "Epoch [42/50], Train Loss: 0.1496, Val Loss: 0.3871\n",
      "Epoch [43/50], Train Loss: 0.1482, Val Loss: 0.3841\n",
      "Epoch [44/50], Train Loss: 0.1466, Val Loss: 0.3812\n",
      "Epoch [45/50], Train Loss: 0.1448, Val Loss: 0.3784\n",
      "Epoch [46/50], Train Loss: 0.1427, Val Loss: 0.3756\n",
      "Epoch [47/50], Train Loss: 0.1409, Val Loss: 0.3728\n",
      "Epoch [48/50], Train Loss: 0.1399, Val Loss: 0.3700\n",
      "Epoch [49/50], Train Loss: 0.1385, Val Loss: 0.3673\n",
      "Epoch [50/50], Train Loss: 0.1371, Val Loss: 0.3646\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1359, Val Loss: 0.3843\n",
      "Epoch [2/50], Train Loss: 0.1345, Val Loss: 0.3818\n",
      "Epoch [3/50], Train Loss: 0.1329, Val Loss: 0.3793\n",
      "Epoch [4/50], Train Loss: 0.1307, Val Loss: 0.3768\n",
      "Epoch [5/50], Train Loss: 0.1305, Val Loss: 0.3744\n",
      "Epoch [6/50], Train Loss: 0.1295, Val Loss: 0.3719\n",
      "Epoch [7/50], Train Loss: 0.1275, Val Loss: 0.3696\n",
      "Epoch [8/50], Train Loss: 0.1267, Val Loss: 0.3672\n",
      "Epoch [9/50], Train Loss: 0.1256, Val Loss: 0.3649\n",
      "Epoch [10/50], Train Loss: 0.1241, Val Loss: 0.3626\n",
      "Epoch [11/50], Train Loss: 0.1222, Val Loss: 0.3603\n",
      "Epoch [12/50], Train Loss: 0.1224, Val Loss: 0.3580\n",
      "Epoch [13/50], Train Loss: 0.1203, Val Loss: 0.3558\n",
      "Epoch [14/50], Train Loss: 0.1191, Val Loss: 0.3536\n",
      "Epoch [15/50], Train Loss: 0.1185, Val Loss: 0.3514\n",
      "Epoch [16/50], Train Loss: 0.1171, Val Loss: 0.3493\n",
      "Epoch [17/50], Train Loss: 0.1156, Val Loss: 0.3472\n",
      "Epoch [18/50], Train Loss: 0.1148, Val Loss: 0.3451\n",
      "Epoch [19/50], Train Loss: 0.1139, Val Loss: 0.3430\n",
      "Epoch [20/50], Train Loss: 0.1134, Val Loss: 0.3409\n",
      "Epoch [21/50], Train Loss: 0.1123, Val Loss: 0.3388\n",
      "Epoch [22/50], Train Loss: 0.1110, Val Loss: 0.3368\n",
      "Epoch [23/50], Train Loss: 0.1100, Val Loss: 0.3348\n",
      "Epoch [24/50], Train Loss: 0.1096, Val Loss: 0.3328\n",
      "Epoch [25/50], Train Loss: 0.1078, Val Loss: 0.3309\n",
      "Epoch [26/50], Train Loss: 0.1065, Val Loss: 0.3290\n",
      "Epoch [27/50], Train Loss: 0.1066, Val Loss: 0.3270\n",
      "Epoch [28/50], Train Loss: 0.1052, Val Loss: 0.3251\n",
      "Epoch [29/50], Train Loss: 0.1044, Val Loss: 0.3233\n",
      "Epoch [30/50], Train Loss: 0.1040, Val Loss: 0.3214\n",
      "Epoch [31/50], Train Loss: 0.1026, Val Loss: 0.3195\n",
      "Epoch [32/50], Train Loss: 0.1018, Val Loss: 0.3177\n",
      "Epoch [33/50], Train Loss: 0.1009, Val Loss: 0.3159\n",
      "Epoch [34/50], Train Loss: 0.1006, Val Loss: 0.3141\n",
      "Epoch [35/50], Train Loss: 0.1004, Val Loss: 0.3123\n",
      "Epoch [36/50], Train Loss: 0.0984, Val Loss: 0.3106\n",
      "Epoch [37/50], Train Loss: 0.0978, Val Loss: 0.3089\n",
      "Epoch [38/50], Train Loss: 0.0977, Val Loss: 0.3071\n",
      "Epoch [39/50], Train Loss: 0.0965, Val Loss: 0.3054\n",
      "Epoch [40/50], Train Loss: 0.0951, Val Loss: 0.3038\n",
      "Epoch [41/50], Train Loss: 0.0942, Val Loss: 0.3021\n",
      "Epoch [42/50], Train Loss: 0.0940, Val Loss: 0.3005\n",
      "Epoch [43/50], Train Loss: 0.0926, Val Loss: 0.2989\n",
      "Epoch [44/50], Train Loss: 0.0926, Val Loss: 0.2973\n",
      "Epoch [45/50], Train Loss: 0.0921, Val Loss: 0.2957\n",
      "Epoch [46/50], Train Loss: 0.0916, Val Loss: 0.2941\n",
      "Epoch [47/50], Train Loss: 0.0915, Val Loss: 0.2925\n",
      "Epoch [48/50], Train Loss: 0.0893, Val Loss: 0.2909\n",
      "Epoch [49/50], Train Loss: 0.0893, Val Loss: 0.2894\n",
      "Epoch [50/50], Train Loss: 0.0882, Val Loss: 0.2879\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1359, Val Loss: 0.3681\n",
      "Epoch [2/50], Train Loss: 0.1342, Val Loss: 0.3651\n",
      "Epoch [3/50], Train Loss: 0.1326, Val Loss: 0.3621\n",
      "Epoch [4/50], Train Loss: 0.1310, Val Loss: 0.3592\n",
      "Epoch [5/50], Train Loss: 0.1294, Val Loss: 0.3563\n",
      "Epoch [6/50], Train Loss: 0.1279, Val Loss: 0.3534\n",
      "Epoch [7/50], Train Loss: 0.1263, Val Loss: 0.3505\n",
      "Epoch [8/50], Train Loss: 0.1248, Val Loss: 0.3477\n",
      "Epoch [9/50], Train Loss: 0.1234, Val Loss: 0.3450\n",
      "Epoch [10/50], Train Loss: 0.1219, Val Loss: 0.3422\n",
      "Epoch [11/50], Train Loss: 0.1205, Val Loss: 0.3395\n",
      "Epoch [12/50], Train Loss: 0.1191, Val Loss: 0.3369\n",
      "Epoch [13/50], Train Loss: 0.1177, Val Loss: 0.3342\n",
      "Epoch [14/50], Train Loss: 0.1164, Val Loss: 0.3316\n",
      "Epoch [15/50], Train Loss: 0.1150, Val Loss: 0.3291\n",
      "Epoch [16/50], Train Loss: 0.1137, Val Loss: 0.3265\n",
      "Epoch [17/50], Train Loss: 0.1124, Val Loss: 0.3240\n",
      "Epoch [18/50], Train Loss: 0.1112, Val Loss: 0.3216\n",
      "Epoch [19/50], Train Loss: 0.1099, Val Loss: 0.3191\n",
      "Epoch [20/50], Train Loss: 0.1087, Val Loss: 0.3167\n",
      "Epoch [21/50], Train Loss: 0.1075, Val Loss: 0.3144\n",
      "Epoch [22/50], Train Loss: 0.1063, Val Loss: 0.3120\n",
      "Epoch [23/50], Train Loss: 0.1052, Val Loss: 0.3097\n",
      "Epoch [24/50], Train Loss: 0.1040, Val Loss: 0.3074\n",
      "Epoch [25/50], Train Loss: 0.1029, Val Loss: 0.3051\n",
      "Epoch [26/50], Train Loss: 0.1018, Val Loss: 0.3029\n",
      "Epoch [27/50], Train Loss: 0.1007, Val Loss: 0.3007\n",
      "Epoch [28/50], Train Loss: 0.0996, Val Loss: 0.2985\n",
      "Epoch [29/50], Train Loss: 0.0986, Val Loss: 0.2964\n",
      "Epoch [30/50], Train Loss: 0.0975, Val Loss: 0.2943\n",
      "Epoch [31/50], Train Loss: 0.0965, Val Loss: 0.2922\n",
      "Epoch [32/50], Train Loss: 0.0955, Val Loss: 0.2901\n",
      "Epoch [33/50], Train Loss: 0.0945, Val Loss: 0.2880\n",
      "Epoch [34/50], Train Loss: 0.0936, Val Loss: 0.2860\n",
      "Epoch [35/50], Train Loss: 0.0926, Val Loss: 0.2840\n",
      "Epoch [36/50], Train Loss: 0.0917, Val Loss: 0.2821\n",
      "Epoch [37/50], Train Loss: 0.0908, Val Loss: 0.2801\n",
      "Epoch [38/50], Train Loss: 0.0899, Val Loss: 0.2782\n",
      "Epoch [39/50], Train Loss: 0.0890, Val Loss: 0.2763\n",
      "Epoch [40/50], Train Loss: 0.0881, Val Loss: 0.2744\n",
      "Epoch [41/50], Train Loss: 0.0872, Val Loss: 0.2726\n",
      "Epoch [42/50], Train Loss: 0.0864, Val Loss: 0.2707\n",
      "Epoch [43/50], Train Loss: 0.0856, Val Loss: 0.2689\n",
      "Epoch [44/50], Train Loss: 0.0847, Val Loss: 0.2671\n",
      "Epoch [45/50], Train Loss: 0.0839, Val Loss: 0.2654\n",
      "Epoch [46/50], Train Loss: 0.0832, Val Loss: 0.2636\n",
      "Epoch [47/50], Train Loss: 0.0824, Val Loss: 0.2619\n",
      "Epoch [48/50], Train Loss: 0.0816, Val Loss: 0.2602\n",
      "Epoch [49/50], Train Loss: 0.0809, Val Loss: 0.2585\n",
      "Epoch [50/50], Train Loss: 0.0801, Val Loss: 0.2569\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0874, Val Loss: 0.2517\n",
      "Epoch [2/50], Train Loss: 0.0861, Val Loss: 0.2501\n",
      "Epoch [3/50], Train Loss: 0.0860, Val Loss: 0.2484\n",
      "Epoch [4/50], Train Loss: 0.0859, Val Loss: 0.2468\n",
      "Epoch [5/50], Train Loss: 0.0846, Val Loss: 0.2452\n",
      "Epoch [6/50], Train Loss: 0.0834, Val Loss: 0.2436\n",
      "Epoch [7/50], Train Loss: 0.0826, Val Loss: 0.2421\n",
      "Epoch [8/50], Train Loss: 0.0824, Val Loss: 0.2405\n",
      "Epoch [9/50], Train Loss: 0.0810, Val Loss: 0.2390\n",
      "Epoch [10/50], Train Loss: 0.0810, Val Loss: 0.2375\n",
      "Epoch [11/50], Train Loss: 0.0803, Val Loss: 0.2361\n",
      "Epoch [12/50], Train Loss: 0.0786, Val Loss: 0.2346\n",
      "Epoch [13/50], Train Loss: 0.0785, Val Loss: 0.2332\n",
      "Epoch [14/50], Train Loss: 0.0774, Val Loss: 0.2318\n",
      "Epoch [15/50], Train Loss: 0.0765, Val Loss: 0.2304\n",
      "Epoch [16/50], Train Loss: 0.0764, Val Loss: 0.2290\n",
      "Epoch [17/50], Train Loss: 0.0758, Val Loss: 0.2276\n",
      "Epoch [18/50], Train Loss: 0.0757, Val Loss: 0.2263\n",
      "Epoch [19/50], Train Loss: 0.0746, Val Loss: 0.2249\n",
      "Epoch [20/50], Train Loss: 0.0741, Val Loss: 0.2236\n",
      "Epoch [21/50], Train Loss: 0.0728, Val Loss: 0.2223\n",
      "Epoch [22/50], Train Loss: 0.0738, Val Loss: 0.2210\n",
      "Epoch [23/50], Train Loss: 0.0719, Val Loss: 0.2197\n",
      "Epoch [24/50], Train Loss: 0.0717, Val Loss: 0.2185\n",
      "Epoch [25/50], Train Loss: 0.0708, Val Loss: 0.2173\n",
      "Epoch [26/50], Train Loss: 0.0706, Val Loss: 0.2160\n",
      "Epoch [27/50], Train Loss: 0.0697, Val Loss: 0.2148\n",
      "Epoch [28/50], Train Loss: 0.0701, Val Loss: 0.2136\n",
      "Epoch [29/50], Train Loss: 0.0687, Val Loss: 0.2125\n",
      "Epoch [30/50], Train Loss: 0.0690, Val Loss: 0.2113\n",
      "Epoch [31/50], Train Loss: 0.0682, Val Loss: 0.2102\n",
      "Epoch [32/50], Train Loss: 0.0676, Val Loss: 0.2090\n",
      "Epoch [33/50], Train Loss: 0.0671, Val Loss: 0.2079\n",
      "Epoch [34/50], Train Loss: 0.0663, Val Loss: 0.2068\n",
      "Epoch [35/50], Train Loss: 0.0665, Val Loss: 0.2057\n",
      "Epoch [36/50], Train Loss: 0.0659, Val Loss: 0.2047\n",
      "Epoch [37/50], Train Loss: 0.0654, Val Loss: 0.2036\n",
      "Epoch [38/50], Train Loss: 0.0648, Val Loss: 0.2025\n",
      "Epoch [39/50], Train Loss: 0.0641, Val Loss: 0.2015\n",
      "Epoch [40/50], Train Loss: 0.0647, Val Loss: 0.2005\n",
      "Epoch [41/50], Train Loss: 0.0636, Val Loss: 0.1995\n",
      "Epoch [42/50], Train Loss: 0.0638, Val Loss: 0.1985\n",
      "Epoch [43/50], Train Loss: 0.0629, Val Loss: 0.1975\n",
      "Epoch [44/50], Train Loss: 0.0617, Val Loss: 0.1965\n",
      "Epoch [45/50], Train Loss: 0.0628, Val Loss: 0.1955\n",
      "Epoch [46/50], Train Loss: 0.0615, Val Loss: 0.1946\n",
      "Epoch [47/50], Train Loss: 0.0612, Val Loss: 0.1936\n",
      "Epoch [48/50], Train Loss: 0.0609, Val Loss: 0.1927\n",
      "Epoch [49/50], Train Loss: 0.0603, Val Loss: 0.1918\n",
      "Epoch [50/50], Train Loss: 0.0601, Val Loss: 0.1909\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1428, Val Loss: 0.3635\n",
      "Epoch [2/50], Train Loss: 0.1416, Val Loss: 0.3608\n",
      "Epoch [3/50], Train Loss: 0.1399, Val Loss: 0.3582\n",
      "Epoch [4/50], Train Loss: 0.1378, Val Loss: 0.3556\n",
      "Epoch [5/50], Train Loss: 0.1375, Val Loss: 0.3530\n",
      "Epoch [6/50], Train Loss: 0.1354, Val Loss: 0.3505\n",
      "Epoch [7/50], Train Loss: 0.1344, Val Loss: 0.3480\n",
      "Epoch [8/50], Train Loss: 0.1331, Val Loss: 0.3455\n",
      "Epoch [9/50], Train Loss: 0.1314, Val Loss: 0.3431\n",
      "Epoch [10/50], Train Loss: 0.1308, Val Loss: 0.3406\n",
      "Epoch [11/50], Train Loss: 0.1293, Val Loss: 0.3383\n",
      "Epoch [12/50], Train Loss: 0.1269, Val Loss: 0.3359\n",
      "Epoch [13/50], Train Loss: 0.1260, Val Loss: 0.3336\n",
      "Epoch [14/50], Train Loss: 0.1253, Val Loss: 0.3313\n",
      "Epoch [15/50], Train Loss: 0.1237, Val Loss: 0.3290\n",
      "Epoch [16/50], Train Loss: 0.1220, Val Loss: 0.3267\n",
      "Epoch [17/50], Train Loss: 0.1205, Val Loss: 0.3245\n",
      "Epoch [18/50], Train Loss: 0.1199, Val Loss: 0.3223\n",
      "Epoch [19/50], Train Loss: 0.1186, Val Loss: 0.3201\n",
      "Epoch [20/50], Train Loss: 0.1182, Val Loss: 0.3180\n",
      "Epoch [21/50], Train Loss: 0.1166, Val Loss: 0.3159\n",
      "Epoch [22/50], Train Loss: 0.1156, Val Loss: 0.3138\n",
      "Epoch [23/50], Train Loss: 0.1152, Val Loss: 0.3117\n",
      "Epoch [24/50], Train Loss: 0.1129, Val Loss: 0.3097\n",
      "Epoch [25/50], Train Loss: 0.1108, Val Loss: 0.3077\n",
      "Epoch [26/50], Train Loss: 0.1103, Val Loss: 0.3057\n",
      "Epoch [27/50], Train Loss: 0.1088, Val Loss: 0.3037\n",
      "Epoch [28/50], Train Loss: 0.1090, Val Loss: 0.3018\n",
      "Epoch [29/50], Train Loss: 0.1076, Val Loss: 0.2998\n",
      "Epoch [30/50], Train Loss: 0.1066, Val Loss: 0.2979\n",
      "Epoch [31/50], Train Loss: 0.1060, Val Loss: 0.2960\n",
      "Epoch [32/50], Train Loss: 0.1051, Val Loss: 0.2942\n",
      "Epoch [33/50], Train Loss: 0.1031, Val Loss: 0.2923\n",
      "Epoch [34/50], Train Loss: 0.1032, Val Loss: 0.2905\n",
      "Epoch [35/50], Train Loss: 0.1026, Val Loss: 0.2887\n",
      "Epoch [36/50], Train Loss: 0.1009, Val Loss: 0.2870\n",
      "Epoch [37/50], Train Loss: 0.0995, Val Loss: 0.2852\n",
      "Epoch [38/50], Train Loss: 0.0994, Val Loss: 0.2835\n",
      "Epoch [39/50], Train Loss: 0.0982, Val Loss: 0.2818\n",
      "Epoch [40/50], Train Loss: 0.0983, Val Loss: 0.2801\n",
      "Epoch [41/50], Train Loss: 0.0966, Val Loss: 0.2784\n",
      "Epoch [42/50], Train Loss: 0.0956, Val Loss: 0.2767\n",
      "Epoch [43/50], Train Loss: 0.0951, Val Loss: 0.2751\n",
      "Epoch [44/50], Train Loss: 0.0944, Val Loss: 0.2734\n",
      "Epoch [45/50], Train Loss: 0.0935, Val Loss: 0.2718\n",
      "Epoch [46/50], Train Loss: 0.0926, Val Loss: 0.2702\n",
      "Epoch [47/50], Train Loss: 0.0921, Val Loss: 0.2687\n",
      "Epoch [48/50], Train Loss: 0.0920, Val Loss: 0.2671\n",
      "Epoch [49/50], Train Loss: 0.0905, Val Loss: 0.2656\n",
      "Epoch [50/50], Train Loss: 0.0895, Val Loss: 0.2641\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1712, Val Loss: 0.4111\n",
      "Epoch [2/50], Train Loss: 0.1692, Val Loss: 0.4077\n",
      "Epoch [3/50], Train Loss: 0.1671, Val Loss: 0.4042\n",
      "Epoch [4/50], Train Loss: 0.1651, Val Loss: 0.4009\n",
      "Epoch [5/50], Train Loss: 0.1631, Val Loss: 0.3975\n",
      "Epoch [6/50], Train Loss: 0.1612, Val Loss: 0.3942\n",
      "Epoch [7/50], Train Loss: 0.1592, Val Loss: 0.3909\n",
      "Epoch [8/50], Train Loss: 0.1573, Val Loss: 0.3877\n",
      "Epoch [9/50], Train Loss: 0.1555, Val Loss: 0.3845\n",
      "Epoch [10/50], Train Loss: 0.1536, Val Loss: 0.3814\n",
      "Epoch [11/50], Train Loss: 0.1518, Val Loss: 0.3783\n",
      "Epoch [12/50], Train Loss: 0.1500, Val Loss: 0.3752\n",
      "Epoch [13/50], Train Loss: 0.1483, Val Loss: 0.3722\n",
      "Epoch [14/50], Train Loss: 0.1466, Val Loss: 0.3692\n",
      "Epoch [15/50], Train Loss: 0.1449, Val Loss: 0.3662\n",
      "Epoch [16/50], Train Loss: 0.1432, Val Loss: 0.3633\n",
      "Epoch [17/50], Train Loss: 0.1415, Val Loss: 0.3604\n",
      "Epoch [18/50], Train Loss: 0.1399, Val Loss: 0.3576\n",
      "Epoch [19/50], Train Loss: 0.1383, Val Loss: 0.3547\n",
      "Epoch [20/50], Train Loss: 0.1367, Val Loss: 0.3520\n",
      "Epoch [21/50], Train Loss: 0.1352, Val Loss: 0.3492\n",
      "Epoch [22/50], Train Loss: 0.1336, Val Loss: 0.3465\n",
      "Epoch [23/50], Train Loss: 0.1321, Val Loss: 0.3438\n",
      "Epoch [24/50], Train Loss: 0.1307, Val Loss: 0.3411\n",
      "Epoch [25/50], Train Loss: 0.1292, Val Loss: 0.3385\n",
      "Epoch [26/50], Train Loss: 0.1277, Val Loss: 0.3359\n",
      "Epoch [27/50], Train Loss: 0.1263, Val Loss: 0.3334\n",
      "Epoch [28/50], Train Loss: 0.1249, Val Loss: 0.3309\n",
      "Epoch [29/50], Train Loss: 0.1236, Val Loss: 0.3284\n",
      "Epoch [30/50], Train Loss: 0.1222, Val Loss: 0.3259\n",
      "Epoch [31/50], Train Loss: 0.1209, Val Loss: 0.3234\n",
      "Epoch [32/50], Train Loss: 0.1196, Val Loss: 0.3210\n",
      "Epoch [33/50], Train Loss: 0.1183, Val Loss: 0.3186\n",
      "Epoch [34/50], Train Loss: 0.1170, Val Loss: 0.3163\n",
      "Epoch [35/50], Train Loss: 0.1157, Val Loss: 0.3139\n",
      "Epoch [36/50], Train Loss: 0.1145, Val Loss: 0.3116\n",
      "Epoch [37/50], Train Loss: 0.1133, Val Loss: 0.3094\n",
      "Epoch [38/50], Train Loss: 0.1121, Val Loss: 0.3071\n",
      "Epoch [39/50], Train Loss: 0.1109, Val Loss: 0.3049\n",
      "Epoch [40/50], Train Loss: 0.1097, Val Loss: 0.3027\n",
      "Epoch [41/50], Train Loss: 0.1086, Val Loss: 0.3005\n",
      "Epoch [42/50], Train Loss: 0.1074, Val Loss: 0.2984\n",
      "Epoch [43/50], Train Loss: 0.1063, Val Loss: 0.2963\n",
      "Epoch [44/50], Train Loss: 0.1052, Val Loss: 0.2942\n",
      "Epoch [45/50], Train Loss: 0.1042, Val Loss: 0.2921\n",
      "Epoch [46/50], Train Loss: 0.1031, Val Loss: 0.2900\n",
      "Epoch [47/50], Train Loss: 0.1020, Val Loss: 0.2880\n",
      "Epoch [48/50], Train Loss: 0.1010, Val Loss: 0.2860\n",
      "Epoch [49/50], Train Loss: 0.1000, Val Loss: 0.2840\n",
      "Epoch [50/50], Train Loss: 0.0990, Val Loss: 0.2821\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0976, Val Loss: 0.2705\n",
      "Epoch [2/50], Train Loss: 0.0961, Val Loss: 0.2687\n",
      "Epoch [3/50], Train Loss: 0.0952, Val Loss: 0.2669\n",
      "Epoch [4/50], Train Loss: 0.0940, Val Loss: 0.2651\n",
      "Epoch [5/50], Train Loss: 0.0936, Val Loss: 0.2634\n",
      "Epoch [6/50], Train Loss: 0.0925, Val Loss: 0.2616\n",
      "Epoch [7/50], Train Loss: 0.0918, Val Loss: 0.2599\n",
      "Epoch [8/50], Train Loss: 0.0904, Val Loss: 0.2582\n",
      "Epoch [9/50], Train Loss: 0.0899, Val Loss: 0.2565\n",
      "Epoch [10/50], Train Loss: 0.0892, Val Loss: 0.2549\n",
      "Epoch [11/50], Train Loss: 0.0884, Val Loss: 0.2532\n",
      "Epoch [12/50], Train Loss: 0.0876, Val Loss: 0.2516\n",
      "Epoch [13/50], Train Loss: 0.0866, Val Loss: 0.2500\n",
      "Epoch [14/50], Train Loss: 0.0856, Val Loss: 0.2484\n",
      "Epoch [15/50], Train Loss: 0.0849, Val Loss: 0.2469\n",
      "Epoch [16/50], Train Loss: 0.0849, Val Loss: 0.2453\n",
      "Epoch [17/50], Train Loss: 0.0836, Val Loss: 0.2438\n",
      "Epoch [18/50], Train Loss: 0.0829, Val Loss: 0.2423\n",
      "Epoch [19/50], Train Loss: 0.0826, Val Loss: 0.2408\n",
      "Epoch [20/50], Train Loss: 0.0813, Val Loss: 0.2393\n",
      "Epoch [21/50], Train Loss: 0.0807, Val Loss: 0.2378\n",
      "Epoch [22/50], Train Loss: 0.0797, Val Loss: 0.2364\n",
      "Epoch [23/50], Train Loss: 0.0791, Val Loss: 0.2350\n",
      "Epoch [24/50], Train Loss: 0.0787, Val Loss: 0.2336\n",
      "Epoch [25/50], Train Loss: 0.0776, Val Loss: 0.2322\n",
      "Epoch [26/50], Train Loss: 0.0771, Val Loss: 0.2308\n",
      "Epoch [27/50], Train Loss: 0.0765, Val Loss: 0.2295\n",
      "Epoch [28/50], Train Loss: 0.0760, Val Loss: 0.2281\n",
      "Epoch [29/50], Train Loss: 0.0757, Val Loss: 0.2268\n",
      "Epoch [30/50], Train Loss: 0.0748, Val Loss: 0.2255\n",
      "Epoch [31/50], Train Loss: 0.0743, Val Loss: 0.2242\n",
      "Epoch [32/50], Train Loss: 0.0734, Val Loss: 0.2229\n",
      "Epoch [33/50], Train Loss: 0.0733, Val Loss: 0.2216\n",
      "Epoch [34/50], Train Loss: 0.0723, Val Loss: 0.2204\n",
      "Epoch [35/50], Train Loss: 0.0719, Val Loss: 0.2191\n",
      "Epoch [36/50], Train Loss: 0.0714, Val Loss: 0.2179\n",
      "Epoch [37/50], Train Loss: 0.0709, Val Loss: 0.2167\n",
      "Epoch [38/50], Train Loss: 0.0699, Val Loss: 0.2155\n",
      "Epoch [39/50], Train Loss: 0.0699, Val Loss: 0.2143\n",
      "Epoch [40/50], Train Loss: 0.0689, Val Loss: 0.2131\n",
      "Epoch [41/50], Train Loss: 0.0684, Val Loss: 0.2120\n",
      "Epoch [42/50], Train Loss: 0.0681, Val Loss: 0.2108\n",
      "Epoch [43/50], Train Loss: 0.0675, Val Loss: 0.2097\n",
      "Epoch [44/50], Train Loss: 0.0672, Val Loss: 0.2086\n",
      "Epoch [45/50], Train Loss: 0.0670, Val Loss: 0.2075\n",
      "Epoch [46/50], Train Loss: 0.0663, Val Loss: 0.2064\n",
      "Epoch [47/50], Train Loss: 0.0660, Val Loss: 0.2053\n",
      "Epoch [48/50], Train Loss: 0.0654, Val Loss: 0.2042\n",
      "Epoch [49/50], Train Loss: 0.0647, Val Loss: 0.2031\n",
      "Epoch [50/50], Train Loss: 0.0644, Val Loss: 0.2021\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1235, Val Loss: 0.3333\n",
      "Epoch [2/50], Train Loss: 0.1226, Val Loss: 0.3305\n",
      "Epoch [3/50], Train Loss: 0.1208, Val Loss: 0.3277\n",
      "Epoch [4/50], Train Loss: 0.1202, Val Loss: 0.3249\n",
      "Epoch [5/50], Train Loss: 0.1200, Val Loss: 0.3222\n",
      "Epoch [6/50], Train Loss: 0.1167, Val Loss: 0.3195\n",
      "Epoch [7/50], Train Loss: 0.1161, Val Loss: 0.3169\n",
      "Epoch [8/50], Train Loss: 0.1137, Val Loss: 0.3143\n",
      "Epoch [9/50], Train Loss: 0.1126, Val Loss: 0.3117\n",
      "Epoch [10/50], Train Loss: 0.1125, Val Loss: 0.3092\n",
      "Epoch [11/50], Train Loss: 0.1090, Val Loss: 0.3067\n",
      "Epoch [12/50], Train Loss: 0.1092, Val Loss: 0.3042\n",
      "Epoch [13/50], Train Loss: 0.1090, Val Loss: 0.3017\n",
      "Epoch [14/50], Train Loss: 0.1070, Val Loss: 0.2993\n",
      "Epoch [15/50], Train Loss: 0.1061, Val Loss: 0.2970\n",
      "Epoch [16/50], Train Loss: 0.1047, Val Loss: 0.2946\n",
      "Epoch [17/50], Train Loss: 0.1028, Val Loss: 0.2923\n",
      "Epoch [18/50], Train Loss: 0.1029, Val Loss: 0.2900\n",
      "Epoch [19/50], Train Loss: 0.1006, Val Loss: 0.2878\n",
      "Epoch [20/50], Train Loss: 0.1003, Val Loss: 0.2855\n",
      "Epoch [21/50], Train Loss: 0.0991, Val Loss: 0.2834\n",
      "Epoch [22/50], Train Loss: 0.0988, Val Loss: 0.2812\n",
      "Epoch [23/50], Train Loss: 0.0974, Val Loss: 0.2790\n",
      "Epoch [24/50], Train Loss: 0.0967, Val Loss: 0.2769\n",
      "Epoch [25/50], Train Loss: 0.0949, Val Loss: 0.2748\n",
      "Epoch [26/50], Train Loss: 0.0947, Val Loss: 0.2728\n",
      "Epoch [27/50], Train Loss: 0.0933, Val Loss: 0.2707\n",
      "Epoch [28/50], Train Loss: 0.0914, Val Loss: 0.2687\n",
      "Epoch [29/50], Train Loss: 0.0927, Val Loss: 0.2667\n",
      "Epoch [30/50], Train Loss: 0.0905, Val Loss: 0.2648\n",
      "Epoch [31/50], Train Loss: 0.0900, Val Loss: 0.2628\n",
      "Epoch [32/50], Train Loss: 0.0895, Val Loss: 0.2609\n",
      "Epoch [33/50], Train Loss: 0.0879, Val Loss: 0.2590\n",
      "Epoch [34/50], Train Loss: 0.0871, Val Loss: 0.2571\n",
      "Epoch [35/50], Train Loss: 0.0858, Val Loss: 0.2553\n",
      "Epoch [36/50], Train Loss: 0.0848, Val Loss: 0.2535\n",
      "Epoch [37/50], Train Loss: 0.0854, Val Loss: 0.2517\n",
      "Epoch [38/50], Train Loss: 0.0845, Val Loss: 0.2499\n",
      "Epoch [39/50], Train Loss: 0.0835, Val Loss: 0.2481\n",
      "Epoch [40/50], Train Loss: 0.0827, Val Loss: 0.2464\n",
      "Epoch [41/50], Train Loss: 0.0815, Val Loss: 0.2447\n",
      "Epoch [42/50], Train Loss: 0.0808, Val Loss: 0.2430\n",
      "Epoch [43/50], Train Loss: 0.0796, Val Loss: 0.2413\n",
      "Epoch [44/50], Train Loss: 0.0793, Val Loss: 0.2397\n",
      "Epoch [45/50], Train Loss: 0.0782, Val Loss: 0.2380\n",
      "Epoch [46/50], Train Loss: 0.0784, Val Loss: 0.2364\n",
      "Epoch [47/50], Train Loss: 0.0772, Val Loss: 0.2348\n",
      "Epoch [48/50], Train Loss: 0.0761, Val Loss: 0.2332\n",
      "Epoch [49/50], Train Loss: 0.0765, Val Loss: 0.2317\n",
      "Epoch [50/50], Train Loss: 0.0766, Val Loss: 0.2301\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1487, Val Loss: 0.3898\n",
      "Epoch [2/50], Train Loss: 0.1469, Val Loss: 0.3866\n",
      "Epoch [3/50], Train Loss: 0.1451, Val Loss: 0.3835\n",
      "Epoch [4/50], Train Loss: 0.1433, Val Loss: 0.3804\n",
      "Epoch [5/50], Train Loss: 0.1416, Val Loss: 0.3773\n",
      "Epoch [6/50], Train Loss: 0.1399, Val Loss: 0.3743\n",
      "Epoch [7/50], Train Loss: 0.1382, Val Loss: 0.3713\n",
      "Epoch [8/50], Train Loss: 0.1366, Val Loss: 0.3684\n",
      "Epoch [9/50], Train Loss: 0.1349, Val Loss: 0.3655\n",
      "Epoch [10/50], Train Loss: 0.1334, Val Loss: 0.3626\n",
      "Epoch [11/50], Train Loss: 0.1318, Val Loss: 0.3598\n",
      "Epoch [12/50], Train Loss: 0.1302, Val Loss: 0.3570\n",
      "Epoch [13/50], Train Loss: 0.1287, Val Loss: 0.3543\n",
      "Epoch [14/50], Train Loss: 0.1272, Val Loss: 0.3515\n",
      "Epoch [15/50], Train Loss: 0.1258, Val Loss: 0.3489\n",
      "Epoch [16/50], Train Loss: 0.1243, Val Loss: 0.3462\n",
      "Epoch [17/50], Train Loss: 0.1229, Val Loss: 0.3436\n",
      "Epoch [18/50], Train Loss: 0.1215, Val Loss: 0.3410\n",
      "Epoch [19/50], Train Loss: 0.1202, Val Loss: 0.3384\n",
      "Epoch [20/50], Train Loss: 0.1188, Val Loss: 0.3359\n",
      "Epoch [21/50], Train Loss: 0.1175, Val Loss: 0.3334\n",
      "Epoch [22/50], Train Loss: 0.1162, Val Loss: 0.3310\n",
      "Epoch [23/50], Train Loss: 0.1149, Val Loss: 0.3285\n",
      "Epoch [24/50], Train Loss: 0.1136, Val Loss: 0.3261\n",
      "Epoch [25/50], Train Loss: 0.1124, Val Loss: 0.3238\n",
      "Epoch [26/50], Train Loss: 0.1112, Val Loss: 0.3214\n",
      "Epoch [27/50], Train Loss: 0.1100, Val Loss: 0.3191\n",
      "Epoch [28/50], Train Loss: 0.1088, Val Loss: 0.3168\n",
      "Epoch [29/50], Train Loss: 0.1076, Val Loss: 0.3146\n",
      "Epoch [30/50], Train Loss: 0.1065, Val Loss: 0.3124\n",
      "Epoch [31/50], Train Loss: 0.1053, Val Loss: 0.3101\n",
      "Epoch [32/50], Train Loss: 0.1042, Val Loss: 0.3080\n",
      "Epoch [33/50], Train Loss: 0.1032, Val Loss: 0.3058\n",
      "Epoch [34/50], Train Loss: 0.1021, Val Loss: 0.3037\n",
      "Epoch [35/50], Train Loss: 0.1010, Val Loss: 0.3016\n",
      "Epoch [36/50], Train Loss: 0.1000, Val Loss: 0.2995\n",
      "Epoch [37/50], Train Loss: 0.0990, Val Loss: 0.2975\n",
      "Epoch [38/50], Train Loss: 0.0980, Val Loss: 0.2955\n",
      "Epoch [39/50], Train Loss: 0.0970, Val Loss: 0.2935\n",
      "Epoch [40/50], Train Loss: 0.0960, Val Loss: 0.2915\n",
      "Epoch [41/50], Train Loss: 0.0951, Val Loss: 0.2895\n",
      "Epoch [42/50], Train Loss: 0.0941, Val Loss: 0.2876\n",
      "Epoch [43/50], Train Loss: 0.0932, Val Loss: 0.2857\n",
      "Epoch [44/50], Train Loss: 0.0923, Val Loss: 0.2838\n",
      "Epoch [45/50], Train Loss: 0.0914, Val Loss: 0.2820\n",
      "Epoch [46/50], Train Loss: 0.0905, Val Loss: 0.2801\n",
      "Epoch [47/50], Train Loss: 0.0896, Val Loss: 0.2783\n",
      "Epoch [48/50], Train Loss: 0.0888, Val Loss: 0.2765\n",
      "Epoch [49/50], Train Loss: 0.0879, Val Loss: 0.2747\n",
      "Epoch [50/50], Train Loss: 0.0871, Val Loss: 0.2730\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.2105, Val Loss: 0.4937\n",
      "Epoch [2/50], Train Loss: 0.2079, Val Loss: 0.4891\n",
      "Epoch [3/50], Train Loss: 0.2048, Val Loss: 0.4846\n",
      "Epoch [4/50], Train Loss: 0.2025, Val Loss: 0.4802\n",
      "Epoch [5/50], Train Loss: 0.1991, Val Loss: 0.4758\n",
      "Epoch [6/50], Train Loss: 0.1972, Val Loss: 0.4715\n",
      "Epoch [7/50], Train Loss: 0.1945, Val Loss: 0.4672\n",
      "Epoch [8/50], Train Loss: 0.1910, Val Loss: 0.4631\n",
      "Epoch [9/50], Train Loss: 0.1890, Val Loss: 0.4590\n",
      "Epoch [10/50], Train Loss: 0.1866, Val Loss: 0.4549\n",
      "Epoch [11/50], Train Loss: 0.1845, Val Loss: 0.4509\n",
      "Epoch [12/50], Train Loss: 0.1816, Val Loss: 0.4470\n",
      "Epoch [13/50], Train Loss: 0.1794, Val Loss: 0.4431\n",
      "Epoch [14/50], Train Loss: 0.1767, Val Loss: 0.4392\n",
      "Epoch [15/50], Train Loss: 0.1746, Val Loss: 0.4355\n",
      "Epoch [16/50], Train Loss: 0.1723, Val Loss: 0.4318\n",
      "Epoch [17/50], Train Loss: 0.1704, Val Loss: 0.4281\n",
      "Epoch [18/50], Train Loss: 0.1672, Val Loss: 0.4245\n",
      "Epoch [19/50], Train Loss: 0.1659, Val Loss: 0.4209\n",
      "Epoch [20/50], Train Loss: 0.1639, Val Loss: 0.4174\n",
      "Epoch [21/50], Train Loss: 0.1622, Val Loss: 0.4139\n",
      "Epoch [22/50], Train Loss: 0.1607, Val Loss: 0.4104\n",
      "Epoch [23/50], Train Loss: 0.1576, Val Loss: 0.4071\n",
      "Epoch [24/50], Train Loss: 0.1563, Val Loss: 0.4037\n",
      "Epoch [25/50], Train Loss: 0.1540, Val Loss: 0.4004\n",
      "Epoch [26/50], Train Loss: 0.1526, Val Loss: 0.3972\n",
      "Epoch [27/50], Train Loss: 0.1501, Val Loss: 0.3940\n",
      "Epoch [28/50], Train Loss: 0.1486, Val Loss: 0.3908\n",
      "Epoch [29/50], Train Loss: 0.1469, Val Loss: 0.3877\n",
      "Epoch [30/50], Train Loss: 0.1447, Val Loss: 0.3846\n",
      "Epoch [31/50], Train Loss: 0.1433, Val Loss: 0.3815\n",
      "Epoch [32/50], Train Loss: 0.1417, Val Loss: 0.3785\n",
      "Epoch [33/50], Train Loss: 0.1401, Val Loss: 0.3756\n",
      "Epoch [34/50], Train Loss: 0.1384, Val Loss: 0.3727\n",
      "Epoch [35/50], Train Loss: 0.1366, Val Loss: 0.3698\n",
      "Epoch [36/50], Train Loss: 0.1347, Val Loss: 0.3669\n",
      "Epoch [37/50], Train Loss: 0.1330, Val Loss: 0.3641\n",
      "Epoch [38/50], Train Loss: 0.1317, Val Loss: 0.3614\n",
      "Epoch [39/50], Train Loss: 0.1302, Val Loss: 0.3586\n",
      "Epoch [40/50], Train Loss: 0.1290, Val Loss: 0.3559\n",
      "Epoch [41/50], Train Loss: 0.1272, Val Loss: 0.3533\n",
      "Epoch [42/50], Train Loss: 0.1261, Val Loss: 0.3506\n",
      "Epoch [43/50], Train Loss: 0.1240, Val Loss: 0.3480\n",
      "Epoch [44/50], Train Loss: 0.1232, Val Loss: 0.3455\n",
      "Epoch [45/50], Train Loss: 0.1223, Val Loss: 0.3429\n",
      "Epoch [46/50], Train Loss: 0.1206, Val Loss: 0.3404\n",
      "Epoch [47/50], Train Loss: 0.1188, Val Loss: 0.3380\n",
      "Epoch [48/50], Train Loss: 0.1176, Val Loss: 0.3355\n",
      "Epoch [49/50], Train Loss: 0.1169, Val Loss: 0.3331\n",
      "Epoch [50/50], Train Loss: 0.1150, Val Loss: 0.3307\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1348, Val Loss: 0.3619\n",
      "Epoch [2/50], Train Loss: 0.1330, Val Loss: 0.3591\n",
      "Epoch [3/50], Train Loss: 0.1307, Val Loss: 0.3565\n",
      "Epoch [4/50], Train Loss: 0.1308, Val Loss: 0.3538\n",
      "Epoch [5/50], Train Loss: 0.1291, Val Loss: 0.3512\n",
      "Epoch [6/50], Train Loss: 0.1269, Val Loss: 0.3486\n",
      "Epoch [7/50], Train Loss: 0.1262, Val Loss: 0.3461\n",
      "Epoch [8/50], Train Loss: 0.1242, Val Loss: 0.3436\n",
      "Epoch [9/50], Train Loss: 0.1230, Val Loss: 0.3411\n",
      "Epoch [10/50], Train Loss: 0.1212, Val Loss: 0.3386\n",
      "Epoch [11/50], Train Loss: 0.1198, Val Loss: 0.3362\n",
      "Epoch [12/50], Train Loss: 0.1186, Val Loss: 0.3339\n",
      "Epoch [13/50], Train Loss: 0.1176, Val Loss: 0.3315\n",
      "Epoch [14/50], Train Loss: 0.1179, Val Loss: 0.3292\n",
      "Epoch [15/50], Train Loss: 0.1161, Val Loss: 0.3268\n",
      "Epoch [16/50], Train Loss: 0.1146, Val Loss: 0.3246\n",
      "Epoch [17/50], Train Loss: 0.1133, Val Loss: 0.3223\n",
      "Epoch [18/50], Train Loss: 0.1120, Val Loss: 0.3201\n",
      "Epoch [19/50], Train Loss: 0.1111, Val Loss: 0.3179\n",
      "Epoch [20/50], Train Loss: 0.1096, Val Loss: 0.3157\n",
      "Epoch [21/50], Train Loss: 0.1095, Val Loss: 0.3136\n",
      "Epoch [22/50], Train Loss: 0.1084, Val Loss: 0.3114\n",
      "Epoch [23/50], Train Loss: 0.1062, Val Loss: 0.3094\n",
      "Epoch [24/50], Train Loss: 0.1064, Val Loss: 0.3073\n",
      "Epoch [25/50], Train Loss: 0.1050, Val Loss: 0.3052\n",
      "Epoch [26/50], Train Loss: 0.1031, Val Loss: 0.3032\n",
      "Epoch [27/50], Train Loss: 0.1020, Val Loss: 0.3012\n",
      "Epoch [28/50], Train Loss: 0.1012, Val Loss: 0.2992\n",
      "Epoch [29/50], Train Loss: 0.1000, Val Loss: 0.2973\n",
      "Epoch [30/50], Train Loss: 0.0997, Val Loss: 0.2954\n",
      "Epoch [31/50], Train Loss: 0.0983, Val Loss: 0.2935\n",
      "Epoch [32/50], Train Loss: 0.0975, Val Loss: 0.2916\n",
      "Epoch [33/50], Train Loss: 0.0959, Val Loss: 0.2898\n",
      "Epoch [34/50], Train Loss: 0.0960, Val Loss: 0.2879\n",
      "Epoch [35/50], Train Loss: 0.0949, Val Loss: 0.2861\n",
      "Epoch [36/50], Train Loss: 0.0946, Val Loss: 0.2843\n",
      "Epoch [37/50], Train Loss: 0.0927, Val Loss: 0.2825\n",
      "Epoch [38/50], Train Loss: 0.0923, Val Loss: 0.2808\n",
      "Epoch [39/50], Train Loss: 0.0924, Val Loss: 0.2791\n",
      "Epoch [40/50], Train Loss: 0.0910, Val Loss: 0.2773\n",
      "Epoch [41/50], Train Loss: 0.0895, Val Loss: 0.2757\n",
      "Epoch [42/50], Train Loss: 0.0892, Val Loss: 0.2740\n",
      "Epoch [43/50], Train Loss: 0.0882, Val Loss: 0.2723\n",
      "Epoch [44/50], Train Loss: 0.0871, Val Loss: 0.2707\n",
      "Epoch [45/50], Train Loss: 0.0870, Val Loss: 0.2690\n",
      "Epoch [46/50], Train Loss: 0.0856, Val Loss: 0.2675\n",
      "Epoch [47/50], Train Loss: 0.0850, Val Loss: 0.2659\n",
      "Epoch [48/50], Train Loss: 0.0843, Val Loss: 0.2643\n",
      "Epoch [49/50], Train Loss: 0.0837, Val Loss: 0.2628\n",
      "Epoch [50/50], Train Loss: 0.0839, Val Loss: 0.2612\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1676, Val Loss: 0.4393\n",
      "Epoch [2/50], Train Loss: 0.1656, Val Loss: 0.4357\n",
      "Epoch [3/50], Train Loss: 0.1636, Val Loss: 0.4323\n",
      "Epoch [4/50], Train Loss: 0.1616, Val Loss: 0.4288\n",
      "Epoch [5/50], Train Loss: 0.1597, Val Loss: 0.4254\n",
      "Epoch [6/50], Train Loss: 0.1578, Val Loss: 0.4220\n",
      "Epoch [7/50], Train Loss: 0.1559, Val Loss: 0.4187\n",
      "Epoch [8/50], Train Loss: 0.1540, Val Loss: 0.4154\n",
      "Epoch [9/50], Train Loss: 0.1522, Val Loss: 0.4122\n",
      "Epoch [10/50], Train Loss: 0.1504, Val Loss: 0.4089\n",
      "Epoch [11/50], Train Loss: 0.1487, Val Loss: 0.4058\n",
      "Epoch [12/50], Train Loss: 0.1469, Val Loss: 0.4026\n",
      "Epoch [13/50], Train Loss: 0.1452, Val Loss: 0.3995\n",
      "Epoch [14/50], Train Loss: 0.1435, Val Loss: 0.3965\n",
      "Epoch [15/50], Train Loss: 0.1419, Val Loss: 0.3935\n",
      "Epoch [16/50], Train Loss: 0.1402, Val Loss: 0.3905\n",
      "Epoch [17/50], Train Loss: 0.1386, Val Loss: 0.3875\n",
      "Epoch [18/50], Train Loss: 0.1371, Val Loss: 0.3846\n",
      "Epoch [19/50], Train Loss: 0.1355, Val Loss: 0.3817\n",
      "Epoch [20/50], Train Loss: 0.1340, Val Loss: 0.3789\n",
      "Epoch [21/50], Train Loss: 0.1325, Val Loss: 0.3761\n",
      "Epoch [22/50], Train Loss: 0.1310, Val Loss: 0.3733\n",
      "Epoch [23/50], Train Loss: 0.1295, Val Loss: 0.3705\n",
      "Epoch [24/50], Train Loss: 0.1281, Val Loss: 0.3678\n",
      "Epoch [25/50], Train Loss: 0.1267, Val Loss: 0.3651\n",
      "Epoch [26/50], Train Loss: 0.1253, Val Loss: 0.3625\n",
      "Epoch [27/50], Train Loss: 0.1239, Val Loss: 0.3598\n",
      "Epoch [28/50], Train Loss: 0.1225, Val Loss: 0.3572\n",
      "Epoch [29/50], Train Loss: 0.1212, Val Loss: 0.3547\n",
      "Epoch [30/50], Train Loss: 0.1199, Val Loss: 0.3522\n",
      "Epoch [31/50], Train Loss: 0.1186, Val Loss: 0.3496\n",
      "Epoch [32/50], Train Loss: 0.1173, Val Loss: 0.3472\n",
      "Epoch [33/50], Train Loss: 0.1161, Val Loss: 0.3447\n",
      "Epoch [34/50], Train Loss: 0.1149, Val Loss: 0.3423\n",
      "Epoch [35/50], Train Loss: 0.1136, Val Loss: 0.3399\n",
      "Epoch [36/50], Train Loss: 0.1124, Val Loss: 0.3375\n",
      "Epoch [37/50], Train Loss: 0.1113, Val Loss: 0.3352\n",
      "Epoch [38/50], Train Loss: 0.1101, Val Loss: 0.3329\n",
      "Epoch [39/50], Train Loss: 0.1090, Val Loss: 0.3306\n",
      "Epoch [40/50], Train Loss: 0.1078, Val Loss: 0.3283\n",
      "Epoch [41/50], Train Loss: 0.1067, Val Loss: 0.3261\n",
      "Epoch [42/50], Train Loss: 0.1057, Val Loss: 0.3239\n",
      "Epoch [43/50], Train Loss: 0.1046, Val Loss: 0.3217\n",
      "Epoch [44/50], Train Loss: 0.1035, Val Loss: 0.3195\n",
      "Epoch [45/50], Train Loss: 0.1025, Val Loss: 0.3174\n",
      "Epoch [46/50], Train Loss: 0.1015, Val Loss: 0.3153\n",
      "Epoch [47/50], Train Loss: 0.1005, Val Loss: 0.3132\n",
      "Epoch [48/50], Train Loss: 0.0995, Val Loss: 0.3111\n",
      "Epoch [49/50], Train Loss: 0.0985, Val Loss: 0.3091\n",
      "Epoch [50/50], Train Loss: 0.0975, Val Loss: 0.3071\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1060, Val Loss: 0.2758\n",
      "Epoch [2/50], Train Loss: 0.1046, Val Loss: 0.2740\n",
      "Epoch [3/50], Train Loss: 0.1031, Val Loss: 0.2722\n",
      "Epoch [4/50], Train Loss: 0.1024, Val Loss: 0.2704\n",
      "Epoch [5/50], Train Loss: 0.1015, Val Loss: 0.2687\n",
      "Epoch [6/50], Train Loss: 0.1008, Val Loss: 0.2669\n",
      "Epoch [7/50], Train Loss: 0.0994, Val Loss: 0.2652\n",
      "Epoch [8/50], Train Loss: 0.0984, Val Loss: 0.2636\n",
      "Epoch [9/50], Train Loss: 0.0975, Val Loss: 0.2619\n",
      "Epoch [10/50], Train Loss: 0.0966, Val Loss: 0.2603\n",
      "Epoch [11/50], Train Loss: 0.0958, Val Loss: 0.2587\n",
      "Epoch [12/50], Train Loss: 0.0948, Val Loss: 0.2571\n",
      "Epoch [13/50], Train Loss: 0.0940, Val Loss: 0.2555\n",
      "Epoch [14/50], Train Loss: 0.0932, Val Loss: 0.2539\n",
      "Epoch [15/50], Train Loss: 0.0921, Val Loss: 0.2524\n",
      "Epoch [16/50], Train Loss: 0.0911, Val Loss: 0.2509\n",
      "Epoch [17/50], Train Loss: 0.0906, Val Loss: 0.2494\n",
      "Epoch [18/50], Train Loss: 0.0895, Val Loss: 0.2479\n",
      "Epoch [19/50], Train Loss: 0.0890, Val Loss: 0.2464\n",
      "Epoch [20/50], Train Loss: 0.0880, Val Loss: 0.2450\n",
      "Epoch [21/50], Train Loss: 0.0874, Val Loss: 0.2435\n",
      "Epoch [22/50], Train Loss: 0.0867, Val Loss: 0.2421\n",
      "Epoch [23/50], Train Loss: 0.0859, Val Loss: 0.2407\n",
      "Epoch [24/50], Train Loss: 0.0852, Val Loss: 0.2393\n",
      "Epoch [25/50], Train Loss: 0.0844, Val Loss: 0.2380\n",
      "Epoch [26/50], Train Loss: 0.0837, Val Loss: 0.2366\n",
      "Epoch [27/50], Train Loss: 0.0832, Val Loss: 0.2353\n",
      "Epoch [28/50], Train Loss: 0.0825, Val Loss: 0.2340\n",
      "Epoch [29/50], Train Loss: 0.0813, Val Loss: 0.2327\n",
      "Epoch [30/50], Train Loss: 0.0808, Val Loss: 0.2314\n",
      "Epoch [31/50], Train Loss: 0.0800, Val Loss: 0.2301\n",
      "Epoch [32/50], Train Loss: 0.0798, Val Loss: 0.2289\n",
      "Epoch [33/50], Train Loss: 0.0792, Val Loss: 0.2276\n",
      "Epoch [34/50], Train Loss: 0.0783, Val Loss: 0.2264\n",
      "Epoch [35/50], Train Loss: 0.0776, Val Loss: 0.2252\n",
      "Epoch [36/50], Train Loss: 0.0769, Val Loss: 0.2240\n",
      "Epoch [37/50], Train Loss: 0.0764, Val Loss: 0.2228\n",
      "Epoch [38/50], Train Loss: 0.0762, Val Loss: 0.2216\n",
      "Epoch [39/50], Train Loss: 0.0752, Val Loss: 0.2205\n",
      "Epoch [40/50], Train Loss: 0.0747, Val Loss: 0.2193\n",
      "Epoch [41/50], Train Loss: 0.0744, Val Loss: 0.2182\n",
      "Epoch [42/50], Train Loss: 0.0732, Val Loss: 0.2171\n",
      "Epoch [43/50], Train Loss: 0.0733, Val Loss: 0.2160\n",
      "Epoch [44/50], Train Loss: 0.0725, Val Loss: 0.2149\n",
      "Epoch [45/50], Train Loss: 0.0717, Val Loss: 0.2138\n",
      "Epoch [46/50], Train Loss: 0.0714, Val Loss: 0.2128\n",
      "Epoch [47/50], Train Loss: 0.0709, Val Loss: 0.2117\n",
      "Epoch [48/50], Train Loss: 0.0704, Val Loss: 0.2107\n",
      "Epoch [49/50], Train Loss: 0.0697, Val Loss: 0.2096\n",
      "Epoch [50/50], Train Loss: 0.0693, Val Loss: 0.2086\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1641, Val Loss: 0.3761\n",
      "Epoch [2/50], Train Loss: 0.1616, Val Loss: 0.3732\n",
      "Epoch [3/50], Train Loss: 0.1606, Val Loss: 0.3702\n",
      "Epoch [4/50], Train Loss: 0.1585, Val Loss: 0.3674\n",
      "Epoch [5/50], Train Loss: 0.1559, Val Loss: 0.3645\n",
      "Epoch [6/50], Train Loss: 0.1543, Val Loss: 0.3617\n",
      "Epoch [7/50], Train Loss: 0.1525, Val Loss: 0.3589\n",
      "Epoch [8/50], Train Loss: 0.1513, Val Loss: 0.3562\n",
      "Epoch [9/50], Train Loss: 0.1483, Val Loss: 0.3535\n",
      "Epoch [10/50], Train Loss: 0.1465, Val Loss: 0.3509\n",
      "Epoch [11/50], Train Loss: 0.1457, Val Loss: 0.3483\n",
      "Epoch [12/50], Train Loss: 0.1437, Val Loss: 0.3457\n",
      "Epoch [13/50], Train Loss: 0.1425, Val Loss: 0.3431\n",
      "Epoch [14/50], Train Loss: 0.1408, Val Loss: 0.3406\n",
      "Epoch [15/50], Train Loss: 0.1394, Val Loss: 0.3381\n",
      "Epoch [16/50], Train Loss: 0.1367, Val Loss: 0.3356\n",
      "Epoch [17/50], Train Loss: 0.1358, Val Loss: 0.3332\n",
      "Epoch [18/50], Train Loss: 0.1343, Val Loss: 0.3308\n",
      "Epoch [19/50], Train Loss: 0.1325, Val Loss: 0.3285\n",
      "Epoch [20/50], Train Loss: 0.1321, Val Loss: 0.3261\n",
      "Epoch [21/50], Train Loss: 0.1301, Val Loss: 0.3238\n",
      "Epoch [22/50], Train Loss: 0.1285, Val Loss: 0.3215\n",
      "Epoch [23/50], Train Loss: 0.1268, Val Loss: 0.3193\n",
      "Epoch [24/50], Train Loss: 0.1262, Val Loss: 0.3171\n",
      "Epoch [25/50], Train Loss: 0.1252, Val Loss: 0.3149\n",
      "Epoch [26/50], Train Loss: 0.1236, Val Loss: 0.3127\n",
      "Epoch [27/50], Train Loss: 0.1223, Val Loss: 0.3106\n",
      "Epoch [28/50], Train Loss: 0.1210, Val Loss: 0.3085\n",
      "Epoch [29/50], Train Loss: 0.1192, Val Loss: 0.3064\n",
      "Epoch [30/50], Train Loss: 0.1195, Val Loss: 0.3043\n",
      "Epoch [31/50], Train Loss: 0.1168, Val Loss: 0.3023\n",
      "Epoch [32/50], Train Loss: 0.1162, Val Loss: 0.3003\n",
      "Epoch [33/50], Train Loss: 0.1143, Val Loss: 0.2983\n",
      "Epoch [34/50], Train Loss: 0.1138, Val Loss: 0.2963\n",
      "Epoch [35/50], Train Loss: 0.1121, Val Loss: 0.2944\n",
      "Epoch [36/50], Train Loss: 0.1117, Val Loss: 0.2925\n",
      "Epoch [37/50], Train Loss: 0.1106, Val Loss: 0.2906\n",
      "Epoch [38/50], Train Loss: 0.1093, Val Loss: 0.2887\n",
      "Epoch [39/50], Train Loss: 0.1080, Val Loss: 0.2868\n",
      "Epoch [40/50], Train Loss: 0.1079, Val Loss: 0.2850\n",
      "Epoch [41/50], Train Loss: 0.1058, Val Loss: 0.2832\n",
      "Epoch [42/50], Train Loss: 0.1052, Val Loss: 0.2814\n",
      "Epoch [43/50], Train Loss: 0.1039, Val Loss: 0.2797\n",
      "Epoch [44/50], Train Loss: 0.1034, Val Loss: 0.2779\n",
      "Epoch [45/50], Train Loss: 0.1015, Val Loss: 0.2762\n",
      "Epoch [46/50], Train Loss: 0.1010, Val Loss: 0.2745\n",
      "Epoch [47/50], Train Loss: 0.1008, Val Loss: 0.2728\n",
      "Epoch [48/50], Train Loss: 0.0990, Val Loss: 0.2712\n",
      "Epoch [49/50], Train Loss: 0.0989, Val Loss: 0.2695\n",
      "Epoch [50/50], Train Loss: 0.0986, Val Loss: 0.2679\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1278, Val Loss: 0.3623\n",
      "Epoch [2/50], Train Loss: 0.1262, Val Loss: 0.3591\n",
      "Epoch [3/50], Train Loss: 0.1246, Val Loss: 0.3560\n",
      "Epoch [4/50], Train Loss: 0.1231, Val Loss: 0.3529\n",
      "Epoch [5/50], Train Loss: 0.1215, Val Loss: 0.3499\n",
      "Epoch [6/50], Train Loss: 0.1201, Val Loss: 0.3469\n",
      "Epoch [7/50], Train Loss: 0.1186, Val Loss: 0.3440\n",
      "Epoch [8/50], Train Loss: 0.1171, Val Loss: 0.3411\n",
      "Epoch [9/50], Train Loss: 0.1157, Val Loss: 0.3382\n",
      "Epoch [10/50], Train Loss: 0.1143, Val Loss: 0.3354\n",
      "Epoch [11/50], Train Loss: 0.1130, Val Loss: 0.3326\n",
      "Epoch [12/50], Train Loss: 0.1116, Val Loss: 0.3298\n",
      "Epoch [13/50], Train Loss: 0.1103, Val Loss: 0.3271\n",
      "Epoch [14/50], Train Loss: 0.1090, Val Loss: 0.3244\n",
      "Epoch [15/50], Train Loss: 0.1077, Val Loss: 0.3218\n",
      "Epoch [16/50], Train Loss: 0.1065, Val Loss: 0.3192\n",
      "Epoch [17/50], Train Loss: 0.1053, Val Loss: 0.3166\n",
      "Epoch [18/50], Train Loss: 0.1041, Val Loss: 0.3141\n",
      "Epoch [19/50], Train Loss: 0.1029, Val Loss: 0.3116\n",
      "Epoch [20/50], Train Loss: 0.1017, Val Loss: 0.3091\n",
      "Epoch [21/50], Train Loss: 0.1006, Val Loss: 0.3066\n",
      "Epoch [22/50], Train Loss: 0.0994, Val Loss: 0.3042\n",
      "Epoch [23/50], Train Loss: 0.0983, Val Loss: 0.3018\n",
      "Epoch [24/50], Train Loss: 0.0972, Val Loss: 0.2995\n",
      "Epoch [25/50], Train Loss: 0.0962, Val Loss: 0.2972\n",
      "Epoch [26/50], Train Loss: 0.0951, Val Loss: 0.2949\n",
      "Epoch [27/50], Train Loss: 0.0941, Val Loss: 0.2926\n",
      "Epoch [28/50], Train Loss: 0.0931, Val Loss: 0.2904\n",
      "Epoch [29/50], Train Loss: 0.0921, Val Loss: 0.2882\n",
      "Epoch [30/50], Train Loss: 0.0911, Val Loss: 0.2861\n",
      "Epoch [31/50], Train Loss: 0.0901, Val Loss: 0.2839\n",
      "Epoch [32/50], Train Loss: 0.0892, Val Loss: 0.2818\n",
      "Epoch [33/50], Train Loss: 0.0883, Val Loss: 0.2797\n",
      "Epoch [34/50], Train Loss: 0.0873, Val Loss: 0.2776\n",
      "Epoch [35/50], Train Loss: 0.0864, Val Loss: 0.2756\n",
      "Epoch [36/50], Train Loss: 0.0856, Val Loss: 0.2736\n",
      "Epoch [37/50], Train Loss: 0.0847, Val Loss: 0.2716\n",
      "Epoch [38/50], Train Loss: 0.0838, Val Loss: 0.2696\n",
      "Epoch [39/50], Train Loss: 0.0830, Val Loss: 0.2677\n",
      "Epoch [40/50], Train Loss: 0.0822, Val Loss: 0.2658\n",
      "Epoch [41/50], Train Loss: 0.0814, Val Loss: 0.2639\n",
      "Epoch [42/50], Train Loss: 0.0806, Val Loss: 0.2620\n",
      "Epoch [43/50], Train Loss: 0.0798, Val Loss: 0.2602\n",
      "Epoch [44/50], Train Loss: 0.0790, Val Loss: 0.2584\n",
      "Epoch [45/50], Train Loss: 0.0783, Val Loss: 0.2566\n",
      "Epoch [46/50], Train Loss: 0.0775, Val Loss: 0.2548\n",
      "Epoch [47/50], Train Loss: 0.0768, Val Loss: 0.2531\n",
      "Epoch [48/50], Train Loss: 0.0761, Val Loss: 0.2513\n",
      "Epoch [49/50], Train Loss: 0.0754, Val Loss: 0.2496\n",
      "Epoch [50/50], Train Loss: 0.0747, Val Loss: 0.2479\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1067, Val Loss: 0.3123\n",
      "Epoch [2/50], Train Loss: 0.1065, Val Loss: 0.3099\n",
      "Epoch [3/50], Train Loss: 0.1046, Val Loss: 0.3075\n",
      "Epoch [4/50], Train Loss: 0.1039, Val Loss: 0.3052\n",
      "Epoch [5/50], Train Loss: 0.1027, Val Loss: 0.3029\n",
      "Epoch [6/50], Train Loss: 0.1018, Val Loss: 0.3006\n",
      "Epoch [7/50], Train Loss: 0.1003, Val Loss: 0.2984\n",
      "Epoch [8/50], Train Loss: 0.0994, Val Loss: 0.2962\n",
      "Epoch [9/50], Train Loss: 0.0983, Val Loss: 0.2940\n",
      "Epoch [10/50], Train Loss: 0.0971, Val Loss: 0.2918\n",
      "Epoch [11/50], Train Loss: 0.0959, Val Loss: 0.2897\n",
      "Epoch [12/50], Train Loss: 0.0954, Val Loss: 0.2876\n",
      "Epoch [13/50], Train Loss: 0.0947, Val Loss: 0.2855\n",
      "Epoch [14/50], Train Loss: 0.0935, Val Loss: 0.2834\n",
      "Epoch [15/50], Train Loss: 0.0924, Val Loss: 0.2814\n",
      "Epoch [16/50], Train Loss: 0.0919, Val Loss: 0.2794\n",
      "Epoch [17/50], Train Loss: 0.0905, Val Loss: 0.2774\n",
      "Epoch [18/50], Train Loss: 0.0896, Val Loss: 0.2754\n",
      "Epoch [19/50], Train Loss: 0.0891, Val Loss: 0.2735\n",
      "Epoch [20/50], Train Loss: 0.0880, Val Loss: 0.2716\n",
      "Epoch [21/50], Train Loss: 0.0871, Val Loss: 0.2697\n",
      "Epoch [22/50], Train Loss: 0.0864, Val Loss: 0.2678\n",
      "Epoch [23/50], Train Loss: 0.0854, Val Loss: 0.2660\n",
      "Epoch [24/50], Train Loss: 0.0848, Val Loss: 0.2641\n",
      "Epoch [25/50], Train Loss: 0.0840, Val Loss: 0.2623\n",
      "Epoch [26/50], Train Loss: 0.0828, Val Loss: 0.2606\n",
      "Epoch [27/50], Train Loss: 0.0824, Val Loss: 0.2588\n",
      "Epoch [28/50], Train Loss: 0.0819, Val Loss: 0.2570\n",
      "Epoch [29/50], Train Loss: 0.0811, Val Loss: 0.2553\n",
      "Epoch [30/50], Train Loss: 0.0801, Val Loss: 0.2536\n",
      "Epoch [31/50], Train Loss: 0.0795, Val Loss: 0.2519\n",
      "Epoch [32/50], Train Loss: 0.0789, Val Loss: 0.2503\n",
      "Epoch [33/50], Train Loss: 0.0779, Val Loss: 0.2486\n",
      "Epoch [34/50], Train Loss: 0.0777, Val Loss: 0.2470\n",
      "Epoch [35/50], Train Loss: 0.0766, Val Loss: 0.2454\n",
      "Epoch [36/50], Train Loss: 0.0760, Val Loss: 0.2438\n",
      "Epoch [37/50], Train Loss: 0.0753, Val Loss: 0.2422\n",
      "Epoch [38/50], Train Loss: 0.0746, Val Loss: 0.2407\n",
      "Epoch [39/50], Train Loss: 0.0741, Val Loss: 0.2392\n",
      "Epoch [40/50], Train Loss: 0.0737, Val Loss: 0.2376\n",
      "Epoch [41/50], Train Loss: 0.0729, Val Loss: 0.2362\n",
      "Epoch [42/50], Train Loss: 0.0724, Val Loss: 0.2347\n",
      "Epoch [43/50], Train Loss: 0.0717, Val Loss: 0.2332\n",
      "Epoch [44/50], Train Loss: 0.0708, Val Loss: 0.2318\n",
      "Epoch [45/50], Train Loss: 0.0707, Val Loss: 0.2303\n",
      "Epoch [46/50], Train Loss: 0.0701, Val Loss: 0.2289\n",
      "Epoch [47/50], Train Loss: 0.0696, Val Loss: 0.2275\n",
      "Epoch [48/50], Train Loss: 0.0689, Val Loss: 0.2261\n",
      "Epoch [49/50], Train Loss: 0.0683, Val Loss: 0.2248\n",
      "Epoch [50/50], Train Loss: 0.0677, Val Loss: 0.2234\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1491, Val Loss: 0.3649\n",
      "Epoch [2/50], Train Loss: 0.1480, Val Loss: 0.3618\n",
      "Epoch [3/50], Train Loss: 0.1453, Val Loss: 0.3587\n",
      "Epoch [4/50], Train Loss: 0.1435, Val Loss: 0.3557\n",
      "Epoch [5/50], Train Loss: 0.1423, Val Loss: 0.3528\n",
      "Epoch [6/50], Train Loss: 0.1403, Val Loss: 0.3498\n",
      "Epoch [7/50], Train Loss: 0.1389, Val Loss: 0.3469\n",
      "Epoch [8/50], Train Loss: 0.1374, Val Loss: 0.3441\n",
      "Epoch [9/50], Train Loss: 0.1354, Val Loss: 0.3413\n",
      "Epoch [10/50], Train Loss: 0.1334, Val Loss: 0.3385\n",
      "Epoch [11/50], Train Loss: 0.1318, Val Loss: 0.3358\n",
      "Epoch [12/50], Train Loss: 0.1315, Val Loss: 0.3330\n",
      "Epoch [13/50], Train Loss: 0.1296, Val Loss: 0.3303\n",
      "Epoch [14/50], Train Loss: 0.1279, Val Loss: 0.3277\n",
      "Epoch [15/50], Train Loss: 0.1268, Val Loss: 0.3251\n",
      "Epoch [16/50], Train Loss: 0.1255, Val Loss: 0.3225\n",
      "Epoch [17/50], Train Loss: 0.1233, Val Loss: 0.3199\n",
      "Epoch [18/50], Train Loss: 0.1220, Val Loss: 0.3174\n",
      "Epoch [19/50], Train Loss: 0.1210, Val Loss: 0.3149\n",
      "Epoch [20/50], Train Loss: 0.1196, Val Loss: 0.3124\n",
      "Epoch [21/50], Train Loss: 0.1185, Val Loss: 0.3100\n",
      "Epoch [22/50], Train Loss: 0.1170, Val Loss: 0.3076\n",
      "Epoch [23/50], Train Loss: 0.1155, Val Loss: 0.3052\n",
      "Epoch [24/50], Train Loss: 0.1138, Val Loss: 0.3029\n",
      "Epoch [25/50], Train Loss: 0.1127, Val Loss: 0.3006\n",
      "Epoch [26/50], Train Loss: 0.1116, Val Loss: 0.2983\n",
      "Epoch [27/50], Train Loss: 0.1104, Val Loss: 0.2960\n",
      "Epoch [28/50], Train Loss: 0.1095, Val Loss: 0.2938\n",
      "Epoch [29/50], Train Loss: 0.1092, Val Loss: 0.2916\n",
      "Epoch [30/50], Train Loss: 0.1075, Val Loss: 0.2894\n",
      "Epoch [31/50], Train Loss: 0.1060, Val Loss: 0.2872\n",
      "Epoch [32/50], Train Loss: 0.1049, Val Loss: 0.2851\n",
      "Epoch [33/50], Train Loss: 0.1042, Val Loss: 0.2830\n",
      "Epoch [34/50], Train Loss: 0.1023, Val Loss: 0.2809\n",
      "Epoch [35/50], Train Loss: 0.1020, Val Loss: 0.2789\n",
      "Epoch [36/50], Train Loss: 0.1007, Val Loss: 0.2768\n",
      "Epoch [37/50], Train Loss: 0.1001, Val Loss: 0.2748\n",
      "Epoch [38/50], Train Loss: 0.0986, Val Loss: 0.2728\n",
      "Epoch [39/50], Train Loss: 0.0976, Val Loss: 0.2709\n",
      "Epoch [40/50], Train Loss: 0.0968, Val Loss: 0.2689\n",
      "Epoch [41/50], Train Loss: 0.0956, Val Loss: 0.2670\n",
      "Epoch [42/50], Train Loss: 0.0941, Val Loss: 0.2651\n",
      "Epoch [43/50], Train Loss: 0.0933, Val Loss: 0.2632\n",
      "Epoch [44/50], Train Loss: 0.0930, Val Loss: 0.2614\n",
      "Epoch [45/50], Train Loss: 0.0922, Val Loss: 0.2595\n",
      "Epoch [46/50], Train Loss: 0.0912, Val Loss: 0.2577\n",
      "Epoch [47/50], Train Loss: 0.0904, Val Loss: 0.2559\n",
      "Epoch [48/50], Train Loss: 0.0890, Val Loss: 0.2542\n",
      "Epoch [49/50], Train Loss: 0.0884, Val Loss: 0.2524\n",
      "Epoch [50/50], Train Loss: 0.0880, Val Loss: 0.2507\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1605, Val Loss: 0.4169\n",
      "Epoch [2/50], Train Loss: 0.1585, Val Loss: 0.4133\n",
      "Epoch [3/50], Train Loss: 0.1565, Val Loss: 0.4098\n",
      "Epoch [4/50], Train Loss: 0.1545, Val Loss: 0.4064\n",
      "Epoch [5/50], Train Loss: 0.1526, Val Loss: 0.4030\n",
      "Epoch [6/50], Train Loss: 0.1507, Val Loss: 0.3996\n",
      "Epoch [7/50], Train Loss: 0.1488, Val Loss: 0.3963\n",
      "Epoch [8/50], Train Loss: 0.1470, Val Loss: 0.3931\n",
      "Epoch [9/50], Train Loss: 0.1452, Val Loss: 0.3898\n",
      "Epoch [10/50], Train Loss: 0.1434, Val Loss: 0.3866\n",
      "Epoch [11/50], Train Loss: 0.1417, Val Loss: 0.3835\n",
      "Epoch [12/50], Train Loss: 0.1400, Val Loss: 0.3804\n",
      "Epoch [13/50], Train Loss: 0.1383, Val Loss: 0.3773\n",
      "Epoch [14/50], Train Loss: 0.1366, Val Loss: 0.3743\n",
      "Epoch [15/50], Train Loss: 0.1350, Val Loss: 0.3713\n",
      "Epoch [16/50], Train Loss: 0.1334, Val Loss: 0.3684\n",
      "Epoch [17/50], Train Loss: 0.1318, Val Loss: 0.3655\n",
      "Epoch [18/50], Train Loss: 0.1302, Val Loss: 0.3626\n",
      "Epoch [19/50], Train Loss: 0.1287, Val Loss: 0.3597\n",
      "Epoch [20/50], Train Loss: 0.1272, Val Loss: 0.3569\n",
      "Epoch [21/50], Train Loss: 0.1257, Val Loss: 0.3542\n",
      "Epoch [22/50], Train Loss: 0.1243, Val Loss: 0.3514\n",
      "Epoch [23/50], Train Loss: 0.1228, Val Loss: 0.3487\n",
      "Epoch [24/50], Train Loss: 0.1214, Val Loss: 0.3461\n",
      "Epoch [25/50], Train Loss: 0.1201, Val Loss: 0.3434\n",
      "Epoch [26/50], Train Loss: 0.1187, Val Loss: 0.3408\n",
      "Epoch [27/50], Train Loss: 0.1174, Val Loss: 0.3383\n",
      "Epoch [28/50], Train Loss: 0.1160, Val Loss: 0.3357\n",
      "Epoch [29/50], Train Loss: 0.1147, Val Loss: 0.3332\n",
      "Epoch [30/50], Train Loss: 0.1135, Val Loss: 0.3307\n",
      "Epoch [31/50], Train Loss: 0.1122, Val Loss: 0.3283\n",
      "Epoch [32/50], Train Loss: 0.1110, Val Loss: 0.3259\n",
      "Epoch [33/50], Train Loss: 0.1098, Val Loss: 0.3235\n",
      "Epoch [34/50], Train Loss: 0.1086, Val Loss: 0.3211\n",
      "Epoch [35/50], Train Loss: 0.1074, Val Loss: 0.3188\n",
      "Epoch [36/50], Train Loss: 0.1062, Val Loss: 0.3165\n",
      "Epoch [37/50], Train Loss: 0.1051, Val Loss: 0.3142\n",
      "Epoch [38/50], Train Loss: 0.1040, Val Loss: 0.3120\n",
      "Epoch [39/50], Train Loss: 0.1029, Val Loss: 0.3098\n",
      "Epoch [40/50], Train Loss: 0.1018, Val Loss: 0.3076\n",
      "Epoch [41/50], Train Loss: 0.1007, Val Loss: 0.3054\n",
      "Epoch [42/50], Train Loss: 0.0997, Val Loss: 0.3033\n",
      "Epoch [43/50], Train Loss: 0.0986, Val Loss: 0.3011\n",
      "Epoch [44/50], Train Loss: 0.0976, Val Loss: 0.2991\n",
      "Epoch [45/50], Train Loss: 0.0966, Val Loss: 0.2970\n",
      "Epoch [46/50], Train Loss: 0.0956, Val Loss: 0.2949\n",
      "Epoch [47/50], Train Loss: 0.0947, Val Loss: 0.2929\n",
      "Epoch [48/50], Train Loss: 0.0937, Val Loss: 0.2909\n",
      "Epoch [49/50], Train Loss: 0.0928, Val Loss: 0.2890\n",
      "Epoch [50/50], Train Loss: 0.0919, Val Loss: 0.2870\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1106, Val Loss: 0.3225\n",
      "Epoch [2/50], Train Loss: 0.1098, Val Loss: 0.3203\n",
      "Epoch [3/50], Train Loss: 0.1082, Val Loss: 0.3182\n",
      "Epoch [4/50], Train Loss: 0.1073, Val Loss: 0.3161\n",
      "Epoch [5/50], Train Loss: 0.1067, Val Loss: 0.3140\n",
      "Epoch [6/50], Train Loss: 0.1052, Val Loss: 0.3119\n",
      "Epoch [7/50], Train Loss: 0.1044, Val Loss: 0.3099\n",
      "Epoch [8/50], Train Loss: 0.1031, Val Loss: 0.3079\n",
      "Epoch [9/50], Train Loss: 0.1024, Val Loss: 0.3059\n",
      "Epoch [10/50], Train Loss: 0.1013, Val Loss: 0.3039\n",
      "Epoch [11/50], Train Loss: 0.1004, Val Loss: 0.3019\n",
      "Epoch [12/50], Train Loss: 0.0993, Val Loss: 0.3000\n",
      "Epoch [13/50], Train Loss: 0.0985, Val Loss: 0.2981\n",
      "Epoch [14/50], Train Loss: 0.0971, Val Loss: 0.2962\n",
      "Epoch [15/50], Train Loss: 0.0963, Val Loss: 0.2944\n",
      "Epoch [16/50], Train Loss: 0.0953, Val Loss: 0.2925\n",
      "Epoch [17/50], Train Loss: 0.0946, Val Loss: 0.2907\n",
      "Epoch [18/50], Train Loss: 0.0938, Val Loss: 0.2889\n",
      "Epoch [19/50], Train Loss: 0.0928, Val Loss: 0.2871\n",
      "Epoch [20/50], Train Loss: 0.0921, Val Loss: 0.2854\n",
      "Epoch [21/50], Train Loss: 0.0910, Val Loss: 0.2836\n",
      "Epoch [22/50], Train Loss: 0.0903, Val Loss: 0.2819\n",
      "Epoch [23/50], Train Loss: 0.0892, Val Loss: 0.2802\n",
      "Epoch [24/50], Train Loss: 0.0888, Val Loss: 0.2785\n",
      "Epoch [25/50], Train Loss: 0.0880, Val Loss: 0.2768\n",
      "Epoch [26/50], Train Loss: 0.0873, Val Loss: 0.2752\n",
      "Epoch [27/50], Train Loss: 0.0861, Val Loss: 0.2736\n",
      "Epoch [28/50], Train Loss: 0.0855, Val Loss: 0.2720\n",
      "Epoch [29/50], Train Loss: 0.0849, Val Loss: 0.2704\n",
      "Epoch [30/50], Train Loss: 0.0839, Val Loss: 0.2688\n",
      "Epoch [31/50], Train Loss: 0.0835, Val Loss: 0.2672\n",
      "Epoch [32/50], Train Loss: 0.0828, Val Loss: 0.2657\n",
      "Epoch [33/50], Train Loss: 0.0821, Val Loss: 0.2642\n",
      "Epoch [34/50], Train Loss: 0.0811, Val Loss: 0.2626\n",
      "Epoch [35/50], Train Loss: 0.0806, Val Loss: 0.2612\n",
      "Epoch [36/50], Train Loss: 0.0798, Val Loss: 0.2597\n",
      "Epoch [37/50], Train Loss: 0.0792, Val Loss: 0.2582\n",
      "Epoch [38/50], Train Loss: 0.0785, Val Loss: 0.2568\n",
      "Epoch [39/50], Train Loss: 0.0780, Val Loss: 0.2553\n",
      "Epoch [40/50], Train Loss: 0.0776, Val Loss: 0.2539\n",
      "Epoch [41/50], Train Loss: 0.0768, Val Loss: 0.2525\n",
      "Epoch [42/50], Train Loss: 0.0760, Val Loss: 0.2511\n",
      "Epoch [43/50], Train Loss: 0.0756, Val Loss: 0.2498\n",
      "Epoch [44/50], Train Loss: 0.0750, Val Loss: 0.2484\n",
      "Epoch [45/50], Train Loss: 0.0744, Val Loss: 0.2471\n",
      "Epoch [46/50], Train Loss: 0.0739, Val Loss: 0.2457\n",
      "Epoch [47/50], Train Loss: 0.0733, Val Loss: 0.2444\n",
      "Epoch [48/50], Train Loss: 0.0726, Val Loss: 0.2431\n",
      "Epoch [49/50], Train Loss: 0.0722, Val Loss: 0.2418\n",
      "Epoch [50/50], Train Loss: 0.0714, Val Loss: 0.2406\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1456, Val Loss: 0.3566\n",
      "Epoch [2/50], Train Loss: 0.1437, Val Loss: 0.3539\n",
      "Epoch [3/50], Train Loss: 0.1422, Val Loss: 0.3511\n",
      "Epoch [4/50], Train Loss: 0.1403, Val Loss: 0.3485\n",
      "Epoch [5/50], Train Loss: 0.1394, Val Loss: 0.3458\n",
      "Epoch [6/50], Train Loss: 0.1372, Val Loss: 0.3432\n",
      "Epoch [7/50], Train Loss: 0.1361, Val Loss: 0.3406\n",
      "Epoch [8/50], Train Loss: 0.1341, Val Loss: 0.3380\n",
      "Epoch [9/50], Train Loss: 0.1326, Val Loss: 0.3355\n",
      "Epoch [10/50], Train Loss: 0.1312, Val Loss: 0.3330\n",
      "Epoch [11/50], Train Loss: 0.1296, Val Loss: 0.3306\n",
      "Epoch [12/50], Train Loss: 0.1293, Val Loss: 0.3281\n",
      "Epoch [13/50], Train Loss: 0.1262, Val Loss: 0.3257\n",
      "Epoch [14/50], Train Loss: 0.1263, Val Loss: 0.3234\n",
      "Epoch [15/50], Train Loss: 0.1244, Val Loss: 0.3210\n",
      "Epoch [16/50], Train Loss: 0.1223, Val Loss: 0.3187\n",
      "Epoch [17/50], Train Loss: 0.1207, Val Loss: 0.3164\n",
      "Epoch [18/50], Train Loss: 0.1205, Val Loss: 0.3142\n",
      "Epoch [19/50], Train Loss: 0.1194, Val Loss: 0.3120\n",
      "Epoch [20/50], Train Loss: 0.1175, Val Loss: 0.3098\n",
      "Epoch [21/50], Train Loss: 0.1159, Val Loss: 0.3076\n",
      "Epoch [22/50], Train Loss: 0.1164, Val Loss: 0.3055\n",
      "Epoch [23/50], Train Loss: 0.1145, Val Loss: 0.3034\n",
      "Epoch [24/50], Train Loss: 0.1129, Val Loss: 0.3013\n",
      "Epoch [25/50], Train Loss: 0.1113, Val Loss: 0.2992\n",
      "Epoch [26/50], Train Loss: 0.1107, Val Loss: 0.2972\n",
      "Epoch [27/50], Train Loss: 0.1093, Val Loss: 0.2952\n",
      "Epoch [28/50], Train Loss: 0.1083, Val Loss: 0.2932\n",
      "Epoch [29/50], Train Loss: 0.1065, Val Loss: 0.2912\n",
      "Epoch [30/50], Train Loss: 0.1054, Val Loss: 0.2893\n",
      "Epoch [31/50], Train Loss: 0.1049, Val Loss: 0.2874\n",
      "Epoch [32/50], Train Loss: 0.1040, Val Loss: 0.2855\n",
      "Epoch [33/50], Train Loss: 0.1024, Val Loss: 0.2836\n",
      "Epoch [34/50], Train Loss: 0.1015, Val Loss: 0.2818\n",
      "Epoch [35/50], Train Loss: 0.1006, Val Loss: 0.2800\n",
      "Epoch [36/50], Train Loss: 0.0997, Val Loss: 0.2782\n",
      "Epoch [37/50], Train Loss: 0.0990, Val Loss: 0.2764\n",
      "Epoch [38/50], Train Loss: 0.0980, Val Loss: 0.2746\n",
      "Epoch [39/50], Train Loss: 0.0973, Val Loss: 0.2729\n",
      "Epoch [40/50], Train Loss: 0.0961, Val Loss: 0.2712\n",
      "Epoch [41/50], Train Loss: 0.0949, Val Loss: 0.2695\n",
      "Epoch [42/50], Train Loss: 0.0938, Val Loss: 0.2678\n",
      "Epoch [43/50], Train Loss: 0.0933, Val Loss: 0.2661\n",
      "Epoch [44/50], Train Loss: 0.0922, Val Loss: 0.2645\n",
      "Epoch [45/50], Train Loss: 0.0918, Val Loss: 0.2629\n",
      "Epoch [46/50], Train Loss: 0.0913, Val Loss: 0.2613\n",
      "Epoch [47/50], Train Loss: 0.0895, Val Loss: 0.2597\n",
      "Epoch [48/50], Train Loss: 0.0885, Val Loss: 0.2582\n",
      "Epoch [49/50], Train Loss: 0.0889, Val Loss: 0.2566\n",
      "Epoch [50/50], Train Loss: 0.0871, Val Loss: 0.2551\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1686, Val Loss: 0.4262\n",
      "Epoch [2/50], Train Loss: 0.1666, Val Loss: 0.4228\n",
      "Epoch [3/50], Train Loss: 0.1646, Val Loss: 0.4194\n",
      "Epoch [4/50], Train Loss: 0.1626, Val Loss: 0.4161\n",
      "Epoch [5/50], Train Loss: 0.1607, Val Loss: 0.4128\n",
      "Epoch [6/50], Train Loss: 0.1588, Val Loss: 0.4095\n",
      "Epoch [7/50], Train Loss: 0.1570, Val Loss: 0.4063\n",
      "Epoch [8/50], Train Loss: 0.1551, Val Loss: 0.4032\n",
      "Epoch [9/50], Train Loss: 0.1533, Val Loss: 0.4000\n",
      "Epoch [10/50], Train Loss: 0.1516, Val Loss: 0.3969\n",
      "Epoch [11/50], Train Loss: 0.1498, Val Loss: 0.3939\n",
      "Epoch [12/50], Train Loss: 0.1481, Val Loss: 0.3908\n",
      "Epoch [13/50], Train Loss: 0.1464, Val Loss: 0.3879\n",
      "Epoch [14/50], Train Loss: 0.1447, Val Loss: 0.3849\n",
      "Epoch [15/50], Train Loss: 0.1431, Val Loss: 0.3820\n",
      "Epoch [16/50], Train Loss: 0.1415, Val Loss: 0.3791\n",
      "Epoch [17/50], Train Loss: 0.1399, Val Loss: 0.3762\n",
      "Epoch [18/50], Train Loss: 0.1383, Val Loss: 0.3734\n",
      "Epoch [19/50], Train Loss: 0.1368, Val Loss: 0.3706\n",
      "Epoch [20/50], Train Loss: 0.1352, Val Loss: 0.3679\n",
      "Epoch [21/50], Train Loss: 0.1337, Val Loss: 0.3652\n",
      "Epoch [22/50], Train Loss: 0.1322, Val Loss: 0.3625\n",
      "Epoch [23/50], Train Loss: 0.1308, Val Loss: 0.3598\n",
      "Epoch [24/50], Train Loss: 0.1294, Val Loss: 0.3572\n",
      "Epoch [25/50], Train Loss: 0.1279, Val Loss: 0.3546\n",
      "Epoch [26/50], Train Loss: 0.1265, Val Loss: 0.3520\n",
      "Epoch [27/50], Train Loss: 0.1252, Val Loss: 0.3495\n",
      "Epoch [28/50], Train Loss: 0.1238, Val Loss: 0.3469\n",
      "Epoch [29/50], Train Loss: 0.1225, Val Loss: 0.3445\n",
      "Epoch [30/50], Train Loss: 0.1212, Val Loss: 0.3420\n",
      "Epoch [31/50], Train Loss: 0.1199, Val Loss: 0.3396\n",
      "Epoch [32/50], Train Loss: 0.1186, Val Loss: 0.3372\n",
      "Epoch [33/50], Train Loss: 0.1174, Val Loss: 0.3348\n",
      "Epoch [34/50], Train Loss: 0.1161, Val Loss: 0.3325\n",
      "Epoch [35/50], Train Loss: 0.1149, Val Loss: 0.3301\n",
      "Epoch [36/50], Train Loss: 0.1137, Val Loss: 0.3278\n",
      "Epoch [37/50], Train Loss: 0.1125, Val Loss: 0.3256\n",
      "Epoch [38/50], Train Loss: 0.1114, Val Loss: 0.3233\n",
      "Epoch [39/50], Train Loss: 0.1102, Val Loss: 0.3211\n",
      "Epoch [40/50], Train Loss: 0.1091, Val Loss: 0.3189\n",
      "Epoch [41/50], Train Loss: 0.1080, Val Loss: 0.3167\n",
      "Epoch [42/50], Train Loss: 0.1069, Val Loss: 0.3146\n",
      "Epoch [43/50], Train Loss: 0.1058, Val Loss: 0.3125\n",
      "Epoch [44/50], Train Loss: 0.1048, Val Loss: 0.3104\n",
      "Epoch [45/50], Train Loss: 0.1037, Val Loss: 0.3083\n",
      "Epoch [46/50], Train Loss: 0.1027, Val Loss: 0.3063\n",
      "Epoch [47/50], Train Loss: 0.1017, Val Loss: 0.3042\n",
      "Epoch [48/50], Train Loss: 0.1007, Val Loss: 0.3022\n",
      "Epoch [49/50], Train Loss: 0.0997, Val Loss: 0.3002\n",
      "Epoch [50/50], Train Loss: 0.0987, Val Loss: 0.2983\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1665, Val Loss: 0.4255\n",
      "Epoch [2/50], Train Loss: 0.1643, Val Loss: 0.4223\n",
      "Epoch [3/50], Train Loss: 0.1627, Val Loss: 0.4190\n",
      "Epoch [4/50], Train Loss: 0.1607, Val Loss: 0.4159\n",
      "Epoch [5/50], Train Loss: 0.1594, Val Loss: 0.4127\n",
      "Epoch [6/50], Train Loss: 0.1572, Val Loss: 0.4096\n",
      "Epoch [7/50], Train Loss: 0.1553, Val Loss: 0.4065\n",
      "Epoch [8/50], Train Loss: 0.1541, Val Loss: 0.4035\n",
      "Epoch [9/50], Train Loss: 0.1517, Val Loss: 0.4005\n",
      "Epoch [10/50], Train Loss: 0.1503, Val Loss: 0.3975\n",
      "Epoch [11/50], Train Loss: 0.1487, Val Loss: 0.3946\n",
      "Epoch [12/50], Train Loss: 0.1471, Val Loss: 0.3917\n",
      "Epoch [13/50], Train Loss: 0.1454, Val Loss: 0.3888\n",
      "Epoch [14/50], Train Loss: 0.1436, Val Loss: 0.3860\n",
      "Epoch [15/50], Train Loss: 0.1421, Val Loss: 0.3832\n",
      "Epoch [16/50], Train Loss: 0.1406, Val Loss: 0.3804\n",
      "Epoch [17/50], Train Loss: 0.1392, Val Loss: 0.3777\n",
      "Epoch [18/50], Train Loss: 0.1375, Val Loss: 0.3749\n",
      "Epoch [19/50], Train Loss: 0.1362, Val Loss: 0.3723\n",
      "Epoch [20/50], Train Loss: 0.1346, Val Loss: 0.3696\n",
      "Epoch [21/50], Train Loss: 0.1330, Val Loss: 0.3670\n",
      "Epoch [22/50], Train Loss: 0.1317, Val Loss: 0.3644\n",
      "Epoch [23/50], Train Loss: 0.1303, Val Loss: 0.3619\n",
      "Epoch [24/50], Train Loss: 0.1288, Val Loss: 0.3593\n",
      "Epoch [25/50], Train Loss: 0.1276, Val Loss: 0.3568\n",
      "Epoch [26/50], Train Loss: 0.1266, Val Loss: 0.3543\n",
      "Epoch [27/50], Train Loss: 0.1249, Val Loss: 0.3519\n",
      "Epoch [28/50], Train Loss: 0.1236, Val Loss: 0.3495\n",
      "Epoch [29/50], Train Loss: 0.1222, Val Loss: 0.3471\n",
      "Epoch [30/50], Train Loss: 0.1211, Val Loss: 0.3447\n",
      "Epoch [31/50], Train Loss: 0.1198, Val Loss: 0.3423\n",
      "Epoch [32/50], Train Loss: 0.1186, Val Loss: 0.3400\n",
      "Epoch [33/50], Train Loss: 0.1173, Val Loss: 0.3377\n",
      "Epoch [34/50], Train Loss: 0.1162, Val Loss: 0.3355\n",
      "Epoch [35/50], Train Loss: 0.1150, Val Loss: 0.3332\n",
      "Epoch [36/50], Train Loss: 0.1139, Val Loss: 0.3310\n",
      "Epoch [37/50], Train Loss: 0.1127, Val Loss: 0.3288\n",
      "Epoch [38/50], Train Loss: 0.1118, Val Loss: 0.3266\n",
      "Epoch [39/50], Train Loss: 0.1105, Val Loss: 0.3245\n",
      "Epoch [40/50], Train Loss: 0.1094, Val Loss: 0.3224\n",
      "Epoch [41/50], Train Loss: 0.1085, Val Loss: 0.3203\n",
      "Epoch [42/50], Train Loss: 0.1076, Val Loss: 0.3182\n",
      "Epoch [43/50], Train Loss: 0.1062, Val Loss: 0.3161\n",
      "Epoch [44/50], Train Loss: 0.1052, Val Loss: 0.3141\n",
      "Epoch [45/50], Train Loss: 0.1037, Val Loss: 0.3121\n",
      "Epoch [46/50], Train Loss: 0.1032, Val Loss: 0.3101\n",
      "Epoch [47/50], Train Loss: 0.1021, Val Loss: 0.3081\n",
      "Epoch [48/50], Train Loss: 0.1013, Val Loss: 0.3062\n",
      "Epoch [49/50], Train Loss: 0.1003, Val Loss: 0.3043\n",
      "Epoch [50/50], Train Loss: 0.0995, Val Loss: 0.3024\n",
      "Testing parameters: lr=0.0005, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1467, Val Loss: 0.3813\n",
      "Epoch [2/50], Train Loss: 0.1445, Val Loss: 0.3783\n",
      "Epoch [3/50], Train Loss: 0.1430, Val Loss: 0.3754\n",
      "Epoch [4/50], Train Loss: 0.1411, Val Loss: 0.3726\n",
      "Epoch [5/50], Train Loss: 0.1388, Val Loss: 0.3697\n",
      "Epoch [6/50], Train Loss: 0.1378, Val Loss: 0.3669\n",
      "Epoch [7/50], Train Loss: 0.1369, Val Loss: 0.3642\n",
      "Epoch [8/50], Train Loss: 0.1341, Val Loss: 0.3614\n",
      "Epoch [9/50], Train Loss: 0.1331, Val Loss: 0.3588\n",
      "Epoch [10/50], Train Loss: 0.1323, Val Loss: 0.3561\n",
      "Epoch [11/50], Train Loss: 0.1298, Val Loss: 0.3535\n",
      "Epoch [12/50], Train Loss: 0.1295, Val Loss: 0.3509\n",
      "Epoch [13/50], Train Loss: 0.1271, Val Loss: 0.3483\n",
      "Epoch [14/50], Train Loss: 0.1264, Val Loss: 0.3458\n",
      "Epoch [15/50], Train Loss: 0.1255, Val Loss: 0.3432\n",
      "Epoch [16/50], Train Loss: 0.1239, Val Loss: 0.3408\n",
      "Epoch [17/50], Train Loss: 0.1218, Val Loss: 0.3383\n",
      "Epoch [18/50], Train Loss: 0.1215, Val Loss: 0.3359\n",
      "Epoch [19/50], Train Loss: 0.1201, Val Loss: 0.3335\n",
      "Epoch [20/50], Train Loss: 0.1187, Val Loss: 0.3311\n",
      "Epoch [21/50], Train Loss: 0.1172, Val Loss: 0.3288\n",
      "Epoch [22/50], Train Loss: 0.1154, Val Loss: 0.3265\n",
      "Epoch [23/50], Train Loss: 0.1151, Val Loss: 0.3242\n",
      "Epoch [24/50], Train Loss: 0.1140, Val Loss: 0.3219\n",
      "Epoch [25/50], Train Loss: 0.1128, Val Loss: 0.3197\n",
      "Epoch [26/50], Train Loss: 0.1102, Val Loss: 0.3175\n",
      "Epoch [27/50], Train Loss: 0.1105, Val Loss: 0.3153\n",
      "Epoch [28/50], Train Loss: 0.1086, Val Loss: 0.3132\n",
      "Epoch [29/50], Train Loss: 0.1078, Val Loss: 0.3111\n",
      "Epoch [30/50], Train Loss: 0.1071, Val Loss: 0.3090\n",
      "Epoch [31/50], Train Loss: 0.1060, Val Loss: 0.3069\n",
      "Epoch [32/50], Train Loss: 0.1049, Val Loss: 0.3048\n",
      "Epoch [33/50], Train Loss: 0.1038, Val Loss: 0.3028\n",
      "Epoch [34/50], Train Loss: 0.1025, Val Loss: 0.3008\n",
      "Epoch [35/50], Train Loss: 0.1016, Val Loss: 0.2988\n",
      "Epoch [36/50], Train Loss: 0.1001, Val Loss: 0.2968\n",
      "Epoch [37/50], Train Loss: 0.0993, Val Loss: 0.2949\n",
      "Epoch [38/50], Train Loss: 0.0990, Val Loss: 0.2930\n",
      "Epoch [39/50], Train Loss: 0.0983, Val Loss: 0.2911\n",
      "Epoch [40/50], Train Loss: 0.0970, Val Loss: 0.2892\n",
      "Epoch [41/50], Train Loss: 0.0957, Val Loss: 0.2874\n",
      "Epoch [42/50], Train Loss: 0.0954, Val Loss: 0.2855\n",
      "Epoch [43/50], Train Loss: 0.0937, Val Loss: 0.2837\n",
      "Epoch [44/50], Train Loss: 0.0927, Val Loss: 0.2820\n",
      "Epoch [45/50], Train Loss: 0.0922, Val Loss: 0.2802\n",
      "Epoch [46/50], Train Loss: 0.0908, Val Loss: 0.2785\n",
      "Epoch [47/50], Train Loss: 0.0909, Val Loss: 0.2767\n",
      "Epoch [48/50], Train Loss: 0.0901, Val Loss: 0.2750\n",
      "Epoch [49/50], Train Loss: 0.0889, Val Loss: 0.2733\n",
      "Epoch [50/50], Train Loss: 0.0879, Val Loss: 0.2717\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0998, Val Loss: 0.2739\n",
      "Epoch [2/50], Train Loss: 0.0685, Val Loss: 0.1971\n",
      "Epoch [3/50], Train Loss: 0.0454, Val Loss: 0.1280\n",
      "Epoch [4/50], Train Loss: 0.0329, Val Loss: 0.0835\n",
      "Epoch [5/50], Train Loss: 0.0288, Val Loss: 0.0621\n",
      "Epoch [6/50], Train Loss: 0.0254, Val Loss: 0.0486\n",
      "Epoch [7/50], Train Loss: 0.0225, Val Loss: 0.0382\n",
      "Epoch [8/50], Train Loss: 0.0199, Val Loss: 0.0297\n",
      "Epoch [9/50], Train Loss: 0.0177, Val Loss: 0.0230\n",
      "Epoch [10/50], Train Loss: 0.0160, Val Loss: 0.0183\n",
      "Epoch [11/50], Train Loss: 0.0148, Val Loss: 0.0155\n",
      "Epoch [12/50], Train Loss: 0.0140, Val Loss: 0.0141\n",
      "Epoch [13/50], Train Loss: 0.0135, Val Loss: 0.0133\n",
      "Epoch [14/50], Train Loss: 0.0131, Val Loss: 0.0128\n",
      "Epoch [15/50], Train Loss: 0.0126, Val Loss: 0.0125\n",
      "Epoch [16/50], Train Loss: 0.0121, Val Loss: 0.0123\n",
      "Epoch [17/50], Train Loss: 0.0116, Val Loss: 0.0124\n",
      "Epoch [18/50], Train Loss: 0.0111, Val Loss: 0.0127\n",
      "Epoch [19/50], Train Loss: 0.0105, Val Loss: 0.0132\n",
      "Epoch [20/50], Train Loss: 0.0098, Val Loss: 0.0138\n",
      "Epoch [21/50], Train Loss: 0.0092, Val Loss: 0.0146\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0616, Val Loss: 0.1961\n",
      "Epoch [2/50], Train Loss: 0.0474, Val Loss: 0.1563\n",
      "Epoch [3/50], Train Loss: 0.0400, Val Loss: 0.1235\n",
      "Epoch [4/50], Train Loss: 0.0349, Val Loss: 0.0973\n",
      "Epoch [5/50], Train Loss: 0.0330, Val Loss: 0.0788\n",
      "Epoch [6/50], Train Loss: 0.0307, Val Loss: 0.0643\n",
      "Epoch [7/50], Train Loss: 0.0281, Val Loss: 0.0509\n",
      "Epoch [8/50], Train Loss: 0.0266, Val Loss: 0.0389\n",
      "Epoch [9/50], Train Loss: 0.0238, Val Loss: 0.0285\n",
      "Epoch [10/50], Train Loss: 0.0205, Val Loss: 0.0220\n",
      "Epoch [11/50], Train Loss: 0.0178, Val Loss: 0.0182\n",
      "Epoch [12/50], Train Loss: 0.0163, Val Loss: 0.0154\n",
      "Epoch [13/50], Train Loss: 0.0143, Val Loss: 0.0145\n",
      "Epoch [14/50], Train Loss: 0.0124, Val Loss: 0.0160\n",
      "Epoch [15/50], Train Loss: 0.0106, Val Loss: 0.0182\n",
      "Epoch [16/50], Train Loss: 0.0091, Val Loss: 0.0212\n",
      "Epoch [17/50], Train Loss: 0.0089, Val Loss: 0.0183\n",
      "Epoch [18/50], Train Loss: 0.0084, Val Loss: 0.0194\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.2193, Val Loss: 0.4758\n",
      "Epoch [2/50], Train Loss: 0.1765, Val Loss: 0.3926\n",
      "Epoch [3/50], Train Loss: 0.1314, Val Loss: 0.2797\n",
      "Epoch [4/50], Train Loss: 0.0852, Val Loss: 0.1477\n",
      "Epoch [5/50], Train Loss: 0.0633, Val Loss: 0.0955\n",
      "Epoch [6/50], Train Loss: 0.0603, Val Loss: 0.0761\n",
      "Epoch [7/50], Train Loss: 0.0560, Val Loss: 0.0655\n",
      "Epoch [8/50], Train Loss: 0.0487, Val Loss: 0.0512\n",
      "Epoch [9/50], Train Loss: 0.0471, Val Loss: 0.0454\n",
      "Epoch [10/50], Train Loss: 0.0464, Val Loss: 0.0384\n",
      "Epoch [11/50], Train Loss: 0.0435, Val Loss: 0.0328\n",
      "Epoch [12/50], Train Loss: 0.0415, Val Loss: 0.0342\n",
      "Epoch [13/50], Train Loss: 0.0396, Val Loss: 0.0276\n",
      "Epoch [14/50], Train Loss: 0.0384, Val Loss: 0.0240\n",
      "Epoch [15/50], Train Loss: 0.0362, Val Loss: 0.0263\n",
      "Epoch [16/50], Train Loss: 0.0355, Val Loss: 0.0222\n",
      "Epoch [17/50], Train Loss: 0.0344, Val Loss: 0.0187\n",
      "Epoch [18/50], Train Loss: 0.0345, Val Loss: 0.0184\n",
      "Epoch [19/50], Train Loss: 0.0314, Val Loss: 0.0167\n",
      "Epoch [20/50], Train Loss: 0.0321, Val Loss: 0.0163\n",
      "Epoch [21/50], Train Loss: 0.0304, Val Loss: 0.0146\n",
      "Epoch [22/50], Train Loss: 0.0308, Val Loss: 0.0132\n",
      "Epoch [23/50], Train Loss: 0.0288, Val Loss: 0.0107\n",
      "Epoch [24/50], Train Loss: 0.0276, Val Loss: 0.0097\n",
      "Epoch [25/50], Train Loss: 0.0260, Val Loss: 0.0107\n",
      "Epoch [26/50], Train Loss: 0.0248, Val Loss: 0.0062\n",
      "Epoch [27/50], Train Loss: 0.0248, Val Loss: 0.0136\n",
      "Epoch [28/50], Train Loss: 0.0244, Val Loss: 0.0056\n",
      "Epoch [29/50], Train Loss: 0.0229, Val Loss: 0.0062\n",
      "Epoch [30/50], Train Loss: 0.0221, Val Loss: 0.0088\n",
      "Epoch [31/50], Train Loss: 0.0205, Val Loss: 0.0098\n",
      "Epoch [32/50], Train Loss: 0.0199, Val Loss: 0.0118\n",
      "Epoch [33/50], Train Loss: 0.0193, Val Loss: 0.0119\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1077, Val Loss: 0.2544\n",
      "Epoch [2/50], Train Loss: 0.0754, Val Loss: 0.2000\n",
      "Epoch [3/50], Train Loss: 0.0536, Val Loss: 0.1474\n",
      "Epoch [4/50], Train Loss: 0.0416, Val Loss: 0.1110\n",
      "Epoch [5/50], Train Loss: 0.0380, Val Loss: 0.0961\n",
      "Epoch [6/50], Train Loss: 0.0361, Val Loss: 0.0888\n",
      "Epoch [7/50], Train Loss: 0.0344, Val Loss: 0.0836\n",
      "Epoch [8/50], Train Loss: 0.0323, Val Loss: 0.0788\n",
      "Epoch [9/50], Train Loss: 0.0293, Val Loss: 0.0742\n",
      "Epoch [10/50], Train Loss: 0.0254, Val Loss: 0.0700\n",
      "Epoch [11/50], Train Loss: 0.0226, Val Loss: 0.0705\n",
      "Epoch [12/50], Train Loss: 0.0198, Val Loss: 0.0610\n",
      "Epoch [13/50], Train Loss: 0.0180, Val Loss: 0.0512\n",
      "Epoch [14/50], Train Loss: 0.0161, Val Loss: 0.0433\n",
      "Epoch [15/50], Train Loss: 0.0138, Val Loss: 0.0357\n",
      "Epoch [16/50], Train Loss: 0.0115, Val Loss: 0.0297\n",
      "Epoch [17/50], Train Loss: 0.0094, Val Loss: 0.0267\n",
      "Epoch [18/50], Train Loss: 0.0077, Val Loss: 0.0249\n",
      "Epoch [19/50], Train Loss: 0.0065, Val Loss: 0.0240\n",
      "Epoch [20/50], Train Loss: 0.0057, Val Loss: 0.0236\n",
      "Epoch [21/50], Train Loss: 0.0051, Val Loss: 0.0233\n",
      "Epoch [22/50], Train Loss: 0.0047, Val Loss: 0.0231\n",
      "Epoch [23/50], Train Loss: 0.0044, Val Loss: 0.0228\n",
      "Epoch [24/50], Train Loss: 0.0041, Val Loss: 0.0224\n",
      "Epoch [25/50], Train Loss: 0.0039, Val Loss: 0.0222\n",
      "Epoch [26/50], Train Loss: 0.0037, Val Loss: 0.0219\n",
      "Epoch [27/50], Train Loss: 0.0036, Val Loss: 0.0213\n",
      "Epoch [28/50], Train Loss: 0.0035, Val Loss: 0.0211\n",
      "Epoch [29/50], Train Loss: 0.0034, Val Loss: 0.0210\n",
      "Epoch [30/50], Train Loss: 0.0033, Val Loss: 0.0203\n",
      "Epoch [31/50], Train Loss: 0.0032, Val Loss: 0.0198\n",
      "Epoch [32/50], Train Loss: 0.0032, Val Loss: 0.0200\n",
      "Epoch [33/50], Train Loss: 0.0031, Val Loss: 0.0195\n",
      "Epoch [34/50], Train Loss: 0.0031, Val Loss: 0.0186\n",
      "Epoch [35/50], Train Loss: 0.0031, Val Loss: 0.0189\n",
      "Epoch [36/50], Train Loss: 0.0030, Val Loss: 0.0190\n",
      "Epoch [37/50], Train Loss: 0.0029, Val Loss: 0.0176\n",
      "Epoch [38/50], Train Loss: 0.0029, Val Loss: 0.0173\n",
      "Epoch [39/50], Train Loss: 0.0030, Val Loss: 0.0186\n",
      "Epoch [40/50], Train Loss: 0.0029, Val Loss: 0.0173\n",
      "Epoch [41/50], Train Loss: 0.0029, Val Loss: 0.0156\n",
      "Epoch [42/50], Train Loss: 0.0030, Val Loss: 0.0176\n",
      "Epoch [43/50], Train Loss: 0.0029, Val Loss: 0.0179\n",
      "Epoch [44/50], Train Loss: 0.0028, Val Loss: 0.0146\n",
      "Epoch [45/50], Train Loss: 0.0029, Val Loss: 0.0151\n",
      "Epoch [46/50], Train Loss: 0.0032, Val Loss: 0.0195\n",
      "Epoch [47/50], Train Loss: 0.0028, Val Loss: 0.0148\n",
      "Epoch [48/50], Train Loss: 0.0031, Val Loss: 0.0123\n",
      "Epoch [49/50], Train Loss: 0.0035, Val Loss: 0.0203\n",
      "Epoch [50/50], Train Loss: 0.0034, Val Loss: 0.0160\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1087, Val Loss: 0.2603\n",
      "Epoch [2/50], Train Loss: 0.0743, Val Loss: 0.1770\n",
      "Epoch [3/50], Train Loss: 0.0435, Val Loss: 0.0950\n",
      "Epoch [4/50], Train Loss: 0.0381, Val Loss: 0.0742\n",
      "Epoch [5/50], Train Loss: 0.0363, Val Loss: 0.0658\n",
      "Epoch [6/50], Train Loss: 0.0344, Val Loss: 0.0558\n",
      "Epoch [7/50], Train Loss: 0.0316, Val Loss: 0.0436\n",
      "Epoch [8/50], Train Loss: 0.0271, Val Loss: 0.0334\n",
      "Epoch [9/50], Train Loss: 0.0218, Val Loss: 0.0249\n",
      "Epoch [10/50], Train Loss: 0.0175, Val Loss: 0.0242\n",
      "Epoch [11/50], Train Loss: 0.0146, Val Loss: 0.0205\n",
      "Epoch [12/50], Train Loss: 0.0134, Val Loss: 0.0218\n",
      "Epoch [13/50], Train Loss: 0.0132, Val Loss: 0.0166\n",
      "Epoch [14/50], Train Loss: 0.0135, Val Loss: 0.0220\n",
      "Epoch [15/50], Train Loss: 0.0117, Val Loss: 0.0152\n",
      "Epoch [16/50], Train Loss: 0.0115, Val Loss: 0.0219\n",
      "Epoch [17/50], Train Loss: 0.0104, Val Loss: 0.0137\n",
      "Epoch [18/50], Train Loss: 0.0104, Val Loss: 0.0175\n",
      "Epoch [19/50], Train Loss: 0.0104, Val Loss: 0.0186\n",
      "Epoch [20/50], Train Loss: 0.0099, Val Loss: 0.0155\n",
      "Epoch [21/50], Train Loss: 0.0102, Val Loss: 0.0153\n",
      "Epoch [22/50], Train Loss: 0.0097, Val Loss: 0.0205\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1061, Val Loss: 0.2245\n",
      "Epoch [2/50], Train Loss: 0.0826, Val Loss: 0.1767\n",
      "Epoch [3/50], Train Loss: 0.0665, Val Loss: 0.1229\n",
      "Epoch [4/50], Train Loss: 0.0551, Val Loss: 0.0850\n",
      "Epoch [5/50], Train Loss: 0.0466, Val Loss: 0.0686\n",
      "Epoch [6/50], Train Loss: 0.0444, Val Loss: 0.0578\n",
      "Epoch [7/50], Train Loss: 0.0383, Val Loss: 0.0468\n",
      "Epoch [8/50], Train Loss: 0.0366, Val Loss: 0.0418\n",
      "Epoch [9/50], Train Loss: 0.0331, Val Loss: 0.0375\n",
      "Epoch [10/50], Train Loss: 0.0309, Val Loss: 0.0339\n",
      "Epoch [11/50], Train Loss: 0.0296, Val Loss: 0.0336\n",
      "Epoch [12/50], Train Loss: 0.0276, Val Loss: 0.0367\n",
      "Epoch [13/50], Train Loss: 0.0260, Val Loss: 0.0358\n",
      "Epoch [14/50], Train Loss: 0.0239, Val Loss: 0.0342\n",
      "Epoch [15/50], Train Loss: 0.0204, Val Loss: 0.0357\n",
      "Epoch [16/50], Train Loss: 0.0196, Val Loss: 0.0324\n",
      "Epoch [17/50], Train Loss: 0.0187, Val Loss: 0.0353\n",
      "Epoch [18/50], Train Loss: 0.0174, Val Loss: 0.0343\n",
      "Epoch [19/50], Train Loss: 0.0182, Val Loss: 0.0300\n",
      "Epoch [20/50], Train Loss: 0.0169, Val Loss: 0.0289\n",
      "Epoch [21/50], Train Loss: 0.0173, Val Loss: 0.0297\n",
      "Epoch [22/50], Train Loss: 0.0170, Val Loss: 0.0302\n",
      "Epoch [23/50], Train Loss: 0.0174, Val Loss: 0.0298\n",
      "Epoch [24/50], Train Loss: 0.0161, Val Loss: 0.0279\n",
      "Epoch [25/50], Train Loss: 0.0164, Val Loss: 0.0253\n",
      "Epoch [26/50], Train Loss: 0.0152, Val Loss: 0.0276\n",
      "Epoch [27/50], Train Loss: 0.0145, Val Loss: 0.0243\n",
      "Epoch [28/50], Train Loss: 0.0146, Val Loss: 0.0244\n",
      "Epoch [29/50], Train Loss: 0.0140, Val Loss: 0.0270\n",
      "Epoch [30/50], Train Loss: 0.0134, Val Loss: 0.0267\n",
      "Epoch [31/50], Train Loss: 0.0138, Val Loss: 0.0240\n",
      "Epoch [32/50], Train Loss: 0.0125, Val Loss: 0.0269\n",
      "Epoch [33/50], Train Loss: 0.0128, Val Loss: 0.0250\n",
      "Epoch [34/50], Train Loss: 0.0129, Val Loss: 0.0256\n",
      "Epoch [35/50], Train Loss: 0.0127, Val Loss: 0.0254\n",
      "Epoch [36/50], Train Loss: 0.0127, Val Loss: 0.0259\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1754, Val Loss: 0.3652\n",
      "Epoch [2/50], Train Loss: 0.1101, Val Loss: 0.2158\n",
      "Epoch [3/50], Train Loss: 0.0472, Val Loss: 0.0815\n",
      "Epoch [4/50], Train Loss: 0.0431, Val Loss: 0.0870\n",
      "Epoch [5/50], Train Loss: 0.0399, Val Loss: 0.0888\n",
      "Epoch [6/50], Train Loss: 0.0377, Val Loss: 0.0835\n",
      "Epoch [7/50], Train Loss: 0.0358, Val Loss: 0.0767\n",
      "Epoch [8/50], Train Loss: 0.0331, Val Loss: 0.0676\n",
      "Epoch [9/50], Train Loss: 0.0294, Val Loss: 0.0583\n",
      "Epoch [10/50], Train Loss: 0.0258, Val Loss: 0.0510\n",
      "Epoch [11/50], Train Loss: 0.0238, Val Loss: 0.0460\n",
      "Epoch [12/50], Train Loss: 0.0226, Val Loss: 0.0421\n",
      "Epoch [13/50], Train Loss: 0.0217, Val Loss: 0.0382\n",
      "Epoch [14/50], Train Loss: 0.0209, Val Loss: 0.0345\n",
      "Epoch [15/50], Train Loss: 0.0204, Val Loss: 0.0319\n",
      "Epoch [16/50], Train Loss: 0.0199, Val Loss: 0.0309\n",
      "Epoch [17/50], Train Loss: 0.0194, Val Loss: 0.0317\n",
      "Epoch [18/50], Train Loss: 0.0188, Val Loss: 0.0328\n",
      "Epoch [19/50], Train Loss: 0.0181, Val Loss: 0.0323\n",
      "Epoch [20/50], Train Loss: 0.0174, Val Loss: 0.0309\n",
      "Epoch [21/50], Train Loss: 0.0165, Val Loss: 0.0320\n",
      "Epoch [22/50], Train Loss: 0.0149, Val Loss: 0.0415\n",
      "Epoch [23/50], Train Loss: 0.0120, Val Loss: 0.0553\n",
      "Epoch [24/50], Train Loss: 0.0085, Val Loss: 0.0463\n",
      "Epoch [25/50], Train Loss: 0.0067, Val Loss: 0.0505\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1645, Val Loss: 0.3769\n",
      "Epoch [2/50], Train Loss: 0.1089, Val Loss: 0.2520\n",
      "Epoch [3/50], Train Loss: 0.0535, Val Loss: 0.1076\n",
      "Epoch [4/50], Train Loss: 0.0524, Val Loss: 0.1014\n",
      "Epoch [5/50], Train Loss: 0.0495, Val Loss: 0.0918\n",
      "Epoch [6/50], Train Loss: 0.0483, Val Loss: 0.0896\n",
      "Epoch [7/50], Train Loss: 0.0457, Val Loss: 0.0783\n",
      "Epoch [8/50], Train Loss: 0.0434, Val Loss: 0.0653\n",
      "Epoch [9/50], Train Loss: 0.0409, Val Loss: 0.0507\n",
      "Epoch [10/50], Train Loss: 0.0364, Val Loss: 0.0422\n",
      "Epoch [11/50], Train Loss: 0.0343, Val Loss: 0.0417\n",
      "Epoch [12/50], Train Loss: 0.0319, Val Loss: 0.0341\n",
      "Epoch [13/50], Train Loss: 0.0312, Val Loss: 0.0295\n",
      "Epoch [14/50], Train Loss: 0.0300, Val Loss: 0.0311\n",
      "Epoch [15/50], Train Loss: 0.0277, Val Loss: 0.0316\n",
      "Epoch [16/50], Train Loss: 0.0269, Val Loss: 0.0292\n",
      "Epoch [17/50], Train Loss: 0.0237, Val Loss: 0.0324\n",
      "Epoch [18/50], Train Loss: 0.0212, Val Loss: 0.0312\n",
      "Epoch [19/50], Train Loss: 0.0199, Val Loss: 0.0290\n",
      "Epoch [20/50], Train Loss: 0.0180, Val Loss: 0.0430\n",
      "Epoch [21/50], Train Loss: 0.0172, Val Loss: 0.0378\n",
      "Epoch [22/50], Train Loss: 0.0175, Val Loss: 0.0264\n",
      "Epoch [23/50], Train Loss: 0.0154, Val Loss: 0.0440\n",
      "Epoch [24/50], Train Loss: 0.0146, Val Loss: 0.0367\n",
      "Epoch [25/50], Train Loss: 0.0150, Val Loss: 0.0380\n",
      "Epoch [26/50], Train Loss: 0.0158, Val Loss: 0.0378\n",
      "Epoch [27/50], Train Loss: 0.0144, Val Loss: 0.0331\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1051, Val Loss: 0.2856\n",
      "Epoch [2/50], Train Loss: 0.0764, Val Loss: 0.2019\n",
      "Epoch [3/50], Train Loss: 0.0600, Val Loss: 0.1268\n",
      "Epoch [4/50], Train Loss: 0.0608, Val Loss: 0.1143\n",
      "Epoch [5/50], Train Loss: 0.0573, Val Loss: 0.1036\n",
      "Epoch [6/50], Train Loss: 0.0540, Val Loss: 0.0882\n",
      "Epoch [7/50], Train Loss: 0.0478, Val Loss: 0.0586\n",
      "Epoch [8/50], Train Loss: 0.0421, Val Loss: 0.0385\n",
      "Epoch [9/50], Train Loss: 0.0373, Val Loss: 0.0443\n",
      "Epoch [10/50], Train Loss: 0.0362, Val Loss: 0.0370\n",
      "Epoch [11/50], Train Loss: 0.0355, Val Loss: 0.0357\n",
      "Epoch [12/50], Train Loss: 0.0335, Val Loss: 0.0413\n",
      "Epoch [13/50], Train Loss: 0.0325, Val Loss: 0.0389\n",
      "Epoch [14/50], Train Loss: 0.0328, Val Loss: 0.0354\n",
      "Epoch [15/50], Train Loss: 0.0310, Val Loss: 0.0409\n",
      "Epoch [16/50], Train Loss: 0.0319, Val Loss: 0.0359\n",
      "Epoch [17/50], Train Loss: 0.0297, Val Loss: 0.0373\n",
      "Epoch [18/50], Train Loss: 0.0294, Val Loss: 0.0366\n",
      "Epoch [19/50], Train Loss: 0.0296, Val Loss: 0.0330\n",
      "Epoch [20/50], Train Loss: 0.0290, Val Loss: 0.0347\n",
      "Epoch [21/50], Train Loss: 0.0274, Val Loss: 0.0328\n",
      "Epoch [22/50], Train Loss: 0.0268, Val Loss: 0.0284\n",
      "Epoch [23/50], Train Loss: 0.0265, Val Loss: 0.0296\n",
      "Epoch [24/50], Train Loss: 0.0248, Val Loss: 0.0244\n",
      "Epoch [25/50], Train Loss: 0.0248, Val Loss: 0.0238\n",
      "Epoch [26/50], Train Loss: 0.0217, Val Loss: 0.0280\n",
      "Epoch [27/50], Train Loss: 0.0204, Val Loss: 0.0221\n",
      "Epoch [28/50], Train Loss: 0.0222, Val Loss: 0.0389\n",
      "Epoch [29/50], Train Loss: 0.0200, Val Loss: 0.0330\n",
      "Epoch [30/50], Train Loss: 0.0192, Val Loss: 0.0363\n",
      "Epoch [31/50], Train Loss: 0.0204, Val Loss: 0.0367\n",
      "Epoch [32/50], Train Loss: 0.0210, Val Loss: 0.0340\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1500, Val Loss: 0.3159\n",
      "Epoch [2/50], Train Loss: 0.0846, Val Loss: 0.1464\n",
      "Epoch [3/50], Train Loss: 0.0274, Val Loss: 0.0347\n",
      "Epoch [4/50], Train Loss: 0.0264, Val Loss: 0.0311\n",
      "Epoch [5/50], Train Loss: 0.0211, Val Loss: 0.0192\n",
      "Epoch [6/50], Train Loss: 0.0162, Val Loss: 0.0097\n",
      "Epoch [7/50], Train Loss: 0.0092, Val Loss: 0.0114\n",
      "Epoch [8/50], Train Loss: 0.0053, Val Loss: 0.0113\n",
      "Epoch [9/50], Train Loss: 0.0056, Val Loss: 0.0087\n",
      "Epoch [10/50], Train Loss: 0.0038, Val Loss: 0.0128\n",
      "Epoch [11/50], Train Loss: 0.0034, Val Loss: 0.0112\n",
      "Epoch [12/50], Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [13/50], Train Loss: 0.0052, Val Loss: 0.0176\n",
      "Epoch [14/50], Train Loss: 0.0086, Val Loss: 0.0066\n",
      "Epoch [15/50], Train Loss: 0.0052, Val Loss: 0.0139\n",
      "Epoch [16/50], Train Loss: 0.0041, Val Loss: 0.0102\n",
      "Epoch [17/50], Train Loss: 0.0038, Val Loss: 0.0101\n",
      "Epoch [18/50], Train Loss: 0.0033, Val Loss: 0.0115\n",
      "Epoch [19/50], Train Loss: 0.0031, Val Loss: 0.0095\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1261, Val Loss: 0.2980\n",
      "Epoch [2/50], Train Loss: 0.0805, Val Loss: 0.1834\n",
      "Epoch [3/50], Train Loss: 0.0399, Val Loss: 0.0766\n",
      "Epoch [4/50], Train Loss: 0.0375, Val Loss: 0.0688\n",
      "Epoch [5/50], Train Loss: 0.0341, Val Loss: 0.0558\n",
      "Epoch [6/50], Train Loss: 0.0305, Val Loss: 0.0462\n",
      "Epoch [7/50], Train Loss: 0.0274, Val Loss: 0.0373\n",
      "Epoch [8/50], Train Loss: 0.0229, Val Loss: 0.0254\n",
      "Epoch [9/50], Train Loss: 0.0189, Val Loss: 0.0156\n",
      "Epoch [10/50], Train Loss: 0.0135, Val Loss: 0.0125\n",
      "Epoch [11/50], Train Loss: 0.0108, Val Loss: 0.0123\n",
      "Epoch [12/50], Train Loss: 0.0100, Val Loss: 0.0074\n",
      "Epoch [13/50], Train Loss: 0.0095, Val Loss: 0.0095\n",
      "Epoch [14/50], Train Loss: 0.0150, Val Loss: 0.0069\n",
      "Epoch [15/50], Train Loss: 0.0105, Val Loss: 0.0084\n",
      "Epoch [16/50], Train Loss: 0.0089, Val Loss: 0.0080\n",
      "Epoch [17/50], Train Loss: 0.0083, Val Loss: 0.0092\n",
      "Epoch [18/50], Train Loss: 0.0080, Val Loss: 0.0070\n",
      "Epoch [19/50], Train Loss: 0.0080, Val Loss: 0.0070\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0855, Val Loss: 0.2374\n",
      "Epoch [2/50], Train Loss: 0.0587, Val Loss: 0.1728\n",
      "Epoch [3/50], Train Loss: 0.0438, Val Loss: 0.1164\n",
      "Epoch [4/50], Train Loss: 0.0368, Val Loss: 0.0811\n",
      "Epoch [5/50], Train Loss: 0.0341, Val Loss: 0.0646\n",
      "Epoch [6/50], Train Loss: 0.0303, Val Loss: 0.0517\n",
      "Epoch [7/50], Train Loss: 0.0264, Val Loss: 0.0386\n",
      "Epoch [8/50], Train Loss: 0.0217, Val Loss: 0.0304\n",
      "Epoch [9/50], Train Loss: 0.0189, Val Loss: 0.0221\n",
      "Epoch [10/50], Train Loss: 0.0171, Val Loss: 0.0156\n",
      "Epoch [11/50], Train Loss: 0.0151, Val Loss: 0.0167\n",
      "Epoch [12/50], Train Loss: 0.0140, Val Loss: 0.0151\n",
      "Epoch [13/50], Train Loss: 0.0128, Val Loss: 0.0140\n",
      "Epoch [14/50], Train Loss: 0.0122, Val Loss: 0.0216\n",
      "Epoch [15/50], Train Loss: 0.0121, Val Loss: 0.0065\n",
      "Epoch [16/50], Train Loss: 0.0108, Val Loss: 0.0160\n",
      "Epoch [17/50], Train Loss: 0.0105, Val Loss: 0.0099\n",
      "Epoch [18/50], Train Loss: 0.0106, Val Loss: 0.0087\n",
      "Epoch [19/50], Train Loss: 0.0101, Val Loss: 0.0124\n",
      "Epoch [20/50], Train Loss: 0.0102, Val Loss: 0.0119\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1088, Val Loss: 0.2847\n",
      "Epoch [2/50], Train Loss: 0.0536, Val Loss: 0.1151\n",
      "Epoch [3/50], Train Loss: 0.0354, Val Loss: 0.0506\n",
      "Epoch [4/50], Train Loss: 0.0377, Val Loss: 0.0453\n",
      "Epoch [5/50], Train Loss: 0.0312, Val Loss: 0.0246\n",
      "Epoch [6/50], Train Loss: 0.0272, Val Loss: 0.0107\n",
      "Epoch [7/50], Train Loss: 0.0220, Val Loss: 0.0059\n",
      "Epoch [8/50], Train Loss: 0.0154, Val Loss: 0.0084\n",
      "Epoch [9/50], Train Loss: 0.0120, Val Loss: 0.0093\n",
      "Epoch [10/50], Train Loss: 0.0100, Val Loss: 0.0432\n",
      "Epoch [11/50], Train Loss: 0.0081, Val Loss: 0.0159\n",
      "Epoch [12/50], Train Loss: 0.0057, Val Loss: 0.0143\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0940, Val Loss: 0.2321\n",
      "Epoch [2/50], Train Loss: 0.0469, Val Loss: 0.0970\n",
      "Epoch [3/50], Train Loss: 0.0403, Val Loss: 0.0706\n",
      "Epoch [4/50], Train Loss: 0.0392, Val Loss: 0.0620\n",
      "Epoch [5/50], Train Loss: 0.0343, Val Loss: 0.0412\n",
      "Epoch [6/50], Train Loss: 0.0304, Val Loss: 0.0197\n",
      "Epoch [7/50], Train Loss: 0.0257, Val Loss: 0.0085\n",
      "Epoch [8/50], Train Loss: 0.0221, Val Loss: 0.0062\n",
      "Epoch [9/50], Train Loss: 0.0147, Val Loss: 0.0161\n",
      "Epoch [10/50], Train Loss: 0.0124, Val Loss: 0.0184\n",
      "Epoch [11/50], Train Loss: 0.0122, Val Loss: 0.0146\n",
      "Epoch [12/50], Train Loss: 0.0097, Val Loss: 0.0229\n",
      "Epoch [13/50], Train Loss: 0.0094, Val Loss: 0.0141\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1451, Val Loss: 0.2820\n",
      "Epoch [2/50], Train Loss: 0.0688, Val Loss: 0.0781\n",
      "Epoch [3/50], Train Loss: 0.0550, Val Loss: 0.0713\n",
      "Epoch [4/50], Train Loss: 0.0498, Val Loss: 0.0582\n",
      "Epoch [5/50], Train Loss: 0.0460, Val Loss: 0.0456\n",
      "Epoch [6/50], Train Loss: 0.0411, Val Loss: 0.0347\n",
      "Epoch [7/50], Train Loss: 0.0372, Val Loss: 0.0267\n",
      "Epoch [8/50], Train Loss: 0.0335, Val Loss: 0.0212\n",
      "Epoch [9/50], Train Loss: 0.0270, Val Loss: 0.0192\n",
      "Epoch [10/50], Train Loss: 0.0250, Val Loss: 0.0254\n",
      "Epoch [11/50], Train Loss: 0.0211, Val Loss: 0.0170\n",
      "Epoch [12/50], Train Loss: 0.0204, Val Loss: 0.0093\n",
      "Epoch [13/50], Train Loss: 0.0216, Val Loss: 0.0283\n",
      "Epoch [14/50], Train Loss: 0.0194, Val Loss: 0.0194\n",
      "Epoch [15/50], Train Loss: 0.0233, Val Loss: 0.0104\n",
      "Epoch [16/50], Train Loss: 0.0197, Val Loss: 0.0235\n",
      "Epoch [17/50], Train Loss: 0.0218, Val Loss: 0.0153\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1499, Val Loss: 0.3098\n",
      "Epoch [2/50], Train Loss: 0.0459, Val Loss: 0.0587\n",
      "Epoch [3/50], Train Loss: 0.0511, Val Loss: 0.0847\n",
      "Epoch [4/50], Train Loss: 0.0365, Val Loss: 0.0561\n",
      "Epoch [5/50], Train Loss: 0.0372, Val Loss: 0.0453\n",
      "Epoch [6/50], Train Loss: 0.0303, Val Loss: 0.0318\n",
      "Epoch [7/50], Train Loss: 0.0233, Val Loss: 0.0251\n",
      "Epoch [8/50], Train Loss: 0.0210, Val Loss: 0.0235\n",
      "Epoch [9/50], Train Loss: 0.0205, Val Loss: 0.0247\n",
      "Epoch [10/50], Train Loss: 0.0204, Val Loss: 0.0321\n",
      "Epoch [11/50], Train Loss: 0.0200, Val Loss: 0.0490\n",
      "Epoch [12/50], Train Loss: 0.0208, Val Loss: 0.0297\n",
      "Epoch [13/50], Train Loss: 0.0196, Val Loss: 0.0234\n",
      "Epoch [14/50], Train Loss: 0.0168, Val Loss: 0.0242\n",
      "Epoch [15/50], Train Loss: 0.0139, Val Loss: 0.0415\n",
      "Epoch [16/50], Train Loss: 0.0082, Val Loss: 0.0430\n",
      "Epoch [17/50], Train Loss: 0.0161, Val Loss: 0.0326\n",
      "Epoch [18/50], Train Loss: 0.0058, Val Loss: 0.0451\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0957, Val Loss: 0.2294\n",
      "Epoch [2/50], Train Loss: 0.0434, Val Loss: 0.0758\n",
      "Epoch [3/50], Train Loss: 0.0504, Val Loss: 0.0967\n",
      "Epoch [4/50], Train Loss: 0.0416, Val Loss: 0.0738\n",
      "Epoch [5/50], Train Loss: 0.0423, Val Loss: 0.0667\n",
      "Epoch [6/50], Train Loss: 0.0375, Val Loss: 0.0477\n",
      "Epoch [7/50], Train Loss: 0.0340, Val Loss: 0.0306\n",
      "Epoch [8/50], Train Loss: 0.0283, Val Loss: 0.0259\n",
      "Epoch [9/50], Train Loss: 0.0258, Val Loss: 0.0221\n",
      "Epoch [10/50], Train Loss: 0.0237, Val Loss: 0.0300\n",
      "Epoch [11/50], Train Loss: 0.0226, Val Loss: 0.0346\n",
      "Epoch [12/50], Train Loss: 0.0210, Val Loss: 0.0565\n",
      "Epoch [13/50], Train Loss: 0.0162, Val Loss: 0.0331\n",
      "Epoch [14/50], Train Loss: 0.0133, Val Loss: 0.0476\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0901, Val Loss: 0.2338\n",
      "Epoch [2/50], Train Loss: 0.0504, Val Loss: 0.0945\n",
      "Epoch [3/50], Train Loss: 0.0532, Val Loss: 0.1052\n",
      "Epoch [4/50], Train Loss: 0.0482, Val Loss: 0.0869\n",
      "Epoch [5/50], Train Loss: 0.0445, Val Loss: 0.0657\n",
      "Epoch [6/50], Train Loss: 0.0430, Val Loss: 0.0401\n",
      "Epoch [7/50], Train Loss: 0.0368, Val Loss: 0.0242\n",
      "Epoch [8/50], Train Loss: 0.0339, Val Loss: 0.0195\n",
      "Epoch [9/50], Train Loss: 0.0287, Val Loss: 0.0208\n",
      "Epoch [10/50], Train Loss: 0.0240, Val Loss: 0.0721\n",
      "Epoch [11/50], Train Loss: 0.0232, Val Loss: 0.0373\n",
      "Epoch [12/50], Train Loss: 0.0222, Val Loss: 0.0591\n",
      "Epoch [13/50], Train Loss: 0.0193, Val Loss: 0.0577\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0683, Val Loss: 0.1690\n",
      "Epoch [2/50], Train Loss: 0.0344, Val Loss: 0.0689\n",
      "Epoch [3/50], Train Loss: 0.0319, Val Loss: 0.0439\n",
      "Epoch [4/50], Train Loss: 0.0277, Val Loss: 0.0164\n",
      "Epoch [5/50], Train Loss: 0.0228, Val Loss: 0.0089\n",
      "Epoch [6/50], Train Loss: 0.0169, Val Loss: 0.0291\n",
      "Epoch [7/50], Train Loss: 0.0128, Val Loss: 0.0175\n",
      "Epoch [8/50], Train Loss: 0.0108, Val Loss: 0.0202\n",
      "Epoch [9/50], Train Loss: 0.0073, Val Loss: 0.0198\n",
      "Epoch [10/50], Train Loss: 0.0151, Val Loss: 0.0045\n",
      "Epoch [11/50], Train Loss: 0.0058, Val Loss: 0.0164\n",
      "Epoch [12/50], Train Loss: 0.0080, Val Loss: 0.0121\n",
      "Epoch [13/50], Train Loss: 0.0045, Val Loss: 0.0181\n",
      "Epoch [14/50], Train Loss: 0.0037, Val Loss: 0.0145\n",
      "Epoch [15/50], Train Loss: 0.0033, Val Loss: 0.0161\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0895, Val Loss: 0.2055\n",
      "Epoch [2/50], Train Loss: 0.0298, Val Loss: 0.0317\n",
      "Epoch [3/50], Train Loss: 0.0421, Val Loss: 0.0523\n",
      "Epoch [4/50], Train Loss: 0.0283, Val Loss: 0.0210\n",
      "Epoch [5/50], Train Loss: 0.0259, Val Loss: 0.0103\n",
      "Epoch [6/50], Train Loss: 0.0219, Val Loss: 0.0063\n",
      "Epoch [7/50], Train Loss: 0.0178, Val Loss: 0.0131\n",
      "Epoch [8/50], Train Loss: 0.0159, Val Loss: 0.0081\n",
      "Epoch [9/50], Train Loss: 0.0124, Val Loss: 0.0053\n",
      "Epoch [10/50], Train Loss: 0.0119, Val Loss: 0.0097\n",
      "Epoch [11/50], Train Loss: 0.0077, Val Loss: 0.0152\n",
      "Epoch [12/50], Train Loss: 0.0087, Val Loss: 0.0129\n",
      "Epoch [13/50], Train Loss: 0.0070, Val Loss: 0.0088\n",
      "Epoch [14/50], Train Loss: 0.0060, Val Loss: 0.0153\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0955, Val Loss: 0.2163\n",
      "Epoch [2/50], Train Loss: 0.0389, Val Loss: 0.0472\n",
      "Epoch [3/50], Train Loss: 0.0401, Val Loss: 0.0409\n",
      "Epoch [4/50], Train Loss: 0.0324, Val Loss: 0.0228\n",
      "Epoch [5/50], Train Loss: 0.0277, Val Loss: 0.0093\n",
      "Epoch [6/50], Train Loss: 0.0238, Val Loss: 0.0081\n",
      "Epoch [7/50], Train Loss: 0.0185, Val Loss: 0.0110\n",
      "Epoch [8/50], Train Loss: 0.0150, Val Loss: 0.0270\n",
      "Epoch [9/50], Train Loss: 0.0136, Val Loss: 0.0082\n",
      "Epoch [10/50], Train Loss: 0.0133, Val Loss: 0.0232\n",
      "Epoch [11/50], Train Loss: 0.0119, Val Loss: 0.0134\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0877, Val Loss: 0.1770\n",
      "Epoch [2/50], Train Loss: 0.0324, Val Loss: 0.0401\n",
      "Epoch [3/50], Train Loss: 0.0474, Val Loss: 0.0616\n",
      "Epoch [4/50], Train Loss: 0.0327, Val Loss: 0.0302\n",
      "Epoch [5/50], Train Loss: 0.0293, Val Loss: 0.0093\n",
      "Epoch [6/50], Train Loss: 0.0229, Val Loss: 0.0047\n",
      "Epoch [7/50], Train Loss: 0.0173, Val Loss: 0.0346\n",
      "Epoch [8/50], Train Loss: 0.0076, Val Loss: 0.0120\n",
      "Epoch [9/50], Train Loss: 0.0118, Val Loss: 0.0074\n",
      "Epoch [10/50], Train Loss: 0.0074, Val Loss: 0.0404\n",
      "Epoch [11/50], Train Loss: 0.0060, Val Loss: 0.0124\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0778, Val Loss: 0.1619\n",
      "Epoch [2/50], Train Loss: 0.0338, Val Loss: 0.0356\n",
      "Epoch [3/50], Train Loss: 0.0439, Val Loss: 0.0397\n",
      "Epoch [4/50], Train Loss: 0.0263, Val Loss: 0.0174\n",
      "Epoch [5/50], Train Loss: 0.0190, Val Loss: 0.0381\n",
      "Epoch [6/50], Train Loss: 0.0162, Val Loss: 0.0403\n",
      "Epoch [7/50], Train Loss: 0.0102, Val Loss: 0.0426\n",
      "Epoch [8/50], Train Loss: 0.0096, Val Loss: 0.0502\n",
      "Epoch [9/50], Train Loss: 0.0191, Val Loss: 0.0357\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0838, Val Loss: 0.1583\n",
      "Epoch [2/50], Train Loss: 0.0426, Val Loss: 0.0444\n",
      "Epoch [3/50], Train Loss: 0.0504, Val Loss: 0.0496\n",
      "Epoch [4/50], Train Loss: 0.0357, Val Loss: 0.0146\n",
      "Epoch [5/50], Train Loss: 0.0293, Val Loss: 0.0161\n",
      "Epoch [6/50], Train Loss: 0.0271, Val Loss: 0.0106\n",
      "Epoch [7/50], Train Loss: 0.0252, Val Loss: 0.0080\n",
      "Epoch [8/50], Train Loss: 0.0236, Val Loss: 0.0566\n",
      "Epoch [9/50], Train Loss: 0.0188, Val Loss: 0.0095\n",
      "Epoch [10/50], Train Loss: 0.0175, Val Loss: 0.0130\n",
      "Epoch [11/50], Train Loss: 0.0130, Val Loss: 0.0155\n",
      "Epoch [12/50], Train Loss: 0.0117, Val Loss: 0.0077\n",
      "Epoch [13/50], Train Loss: 0.0113, Val Loss: 0.0165\n",
      "Epoch [14/50], Train Loss: 0.0154, Val Loss: 0.0172\n",
      "Epoch [15/50], Train Loss: 0.0115, Val Loss: 0.0090\n",
      "Epoch [16/50], Train Loss: 0.0108, Val Loss: 0.0133\n",
      "Epoch [17/50], Train Loss: 0.0105, Val Loss: 0.0145\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0726, Val Loss: 0.1075\n",
      "Epoch [2/50], Train Loss: 0.0466, Val Loss: 0.0573\n",
      "Epoch [3/50], Train Loss: 0.0476, Val Loss: 0.0655\n",
      "Epoch [4/50], Train Loss: 0.0378, Val Loss: 0.0272\n",
      "Epoch [5/50], Train Loss: 0.0345, Val Loss: 0.0113\n",
      "Epoch [6/50], Train Loss: 0.0277, Val Loss: 0.0058\n",
      "Epoch [7/50], Train Loss: 0.0255, Val Loss: 0.0090\n",
      "Epoch [8/50], Train Loss: 0.0235, Val Loss: 0.0126\n",
      "Epoch [9/50], Train Loss: 0.0219, Val Loss: 0.0197\n",
      "Epoch [10/50], Train Loss: 0.0219, Val Loss: 0.0607\n",
      "Epoch [11/50], Train Loss: 0.0203, Val Loss: 0.0242\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.0736, Val Loss: 0.0447\n",
      "Epoch [2/50], Train Loss: 0.0664, Val Loss: 0.1023\n",
      "Epoch [3/50], Train Loss: 0.0382, Val Loss: 0.0366\n",
      "Epoch [4/50], Train Loss: 0.0417, Val Loss: 0.0137\n",
      "Epoch [5/50], Train Loss: 0.0332, Val Loss: 0.0103\n",
      "Epoch [6/50], Train Loss: 0.0286, Val Loss: 0.0132\n",
      "Epoch [7/50], Train Loss: 0.0275, Val Loss: 0.0224\n",
      "Epoch [8/50], Train Loss: 0.0265, Val Loss: 0.0686\n",
      "Epoch [9/50], Train Loss: 0.0254, Val Loss: 0.0167\n",
      "Epoch [10/50], Train Loss: 0.0258, Val Loss: 0.0121\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0005, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1106, Val Loss: 0.1346\n",
      "Epoch [2/50], Train Loss: 0.0545, Val Loss: 0.0727\n",
      "Epoch [3/50], Train Loss: 0.0543, Val Loss: 0.0509\n",
      "Epoch [4/50], Train Loss: 0.0509, Val Loss: 0.0380\n",
      "Epoch [5/50], Train Loss: 0.0417, Val Loss: 0.0162\n",
      "Epoch [6/50], Train Loss: 0.0339, Val Loss: 0.0143\n",
      "Epoch [7/50], Train Loss: 0.0328, Val Loss: 0.0200\n",
      "Epoch [8/50], Train Loss: 0.0280, Val Loss: 0.0198\n",
      "Epoch [9/50], Train Loss: 0.0260, Val Loss: 0.0474\n",
      "Epoch [10/50], Train Loss: 0.0192, Val Loss: 0.0319\n",
      "Epoch [11/50], Train Loss: 0.0248, Val Loss: 0.0050\n",
      "Epoch [12/50], Train Loss: 0.0258, Val Loss: 0.0684\n",
      "Epoch [13/50], Train Loss: 0.0244, Val Loss: 0.0494\n",
      "Epoch [14/50], Train Loss: 0.0201, Val Loss: 0.0371\n",
      "Epoch [15/50], Train Loss: 0.0156, Val Loss: 0.0347\n",
      "Epoch [16/50], Train Loss: 0.0123, Val Loss: 0.0189\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0796, Val Loss: 0.2384\n",
      "Epoch [2/50], Train Loss: 0.0740, Val Loss: 0.2273\n",
      "Epoch [3/50], Train Loss: 0.0692, Val Loss: 0.2168\n",
      "Epoch [4/50], Train Loss: 0.0647, Val Loss: 0.2068\n",
      "Epoch [5/50], Train Loss: 0.0606, Val Loss: 0.1972\n",
      "Epoch [6/50], Train Loss: 0.0568, Val Loss: 0.1879\n",
      "Epoch [7/50], Train Loss: 0.0533, Val Loss: 0.1788\n",
      "Epoch [8/50], Train Loss: 0.0500, Val Loss: 0.1700\n",
      "Epoch [9/50], Train Loss: 0.0469, Val Loss: 0.1614\n",
      "Epoch [10/50], Train Loss: 0.0441, Val Loss: 0.1530\n",
      "Epoch [11/50], Train Loss: 0.0416, Val Loss: 0.1449\n",
      "Epoch [12/50], Train Loss: 0.0394, Val Loss: 0.1371\n",
      "Epoch [13/50], Train Loss: 0.0375, Val Loss: 0.1297\n",
      "Epoch [14/50], Train Loss: 0.0359, Val Loss: 0.1228\n",
      "Epoch [15/50], Train Loss: 0.0345, Val Loss: 0.1164\n",
      "Epoch [16/50], Train Loss: 0.0333, Val Loss: 0.1104\n",
      "Epoch [17/50], Train Loss: 0.0324, Val Loss: 0.1049\n",
      "Epoch [18/50], Train Loss: 0.0315, Val Loss: 0.0999\n",
      "Epoch [19/50], Train Loss: 0.0308, Val Loss: 0.0953\n",
      "Epoch [20/50], Train Loss: 0.0301, Val Loss: 0.0910\n",
      "Epoch [21/50], Train Loss: 0.0295, Val Loss: 0.0872\n",
      "Epoch [22/50], Train Loss: 0.0290, Val Loss: 0.0836\n",
      "Epoch [23/50], Train Loss: 0.0285, Val Loss: 0.0803\n",
      "Epoch [24/50], Train Loss: 0.0280, Val Loss: 0.0772\n",
      "Epoch [25/50], Train Loss: 0.0275, Val Loss: 0.0743\n",
      "Epoch [26/50], Train Loss: 0.0271, Val Loss: 0.0717\n",
      "Epoch [27/50], Train Loss: 0.0266, Val Loss: 0.0691\n",
      "Epoch [28/50], Train Loss: 0.0262, Val Loss: 0.0668\n",
      "Epoch [29/50], Train Loss: 0.0258, Val Loss: 0.0645\n",
      "Epoch [30/50], Train Loss: 0.0254, Val Loss: 0.0624\n",
      "Epoch [31/50], Train Loss: 0.0249, Val Loss: 0.0603\n",
      "Epoch [32/50], Train Loss: 0.0245, Val Loss: 0.0583\n",
      "Epoch [33/50], Train Loss: 0.0241, Val Loss: 0.0564\n",
      "Epoch [34/50], Train Loss: 0.0236, Val Loss: 0.0546\n",
      "Epoch [35/50], Train Loss: 0.0232, Val Loss: 0.0528\n",
      "Epoch [36/50], Train Loss: 0.0227, Val Loss: 0.0511\n",
      "Epoch [37/50], Train Loss: 0.0223, Val Loss: 0.0494\n",
      "Epoch [38/50], Train Loss: 0.0218, Val Loss: 0.0477\n",
      "Epoch [39/50], Train Loss: 0.0213, Val Loss: 0.0461\n",
      "Epoch [40/50], Train Loss: 0.0208, Val Loss: 0.0446\n",
      "Epoch [41/50], Train Loss: 0.0204, Val Loss: 0.0430\n",
      "Epoch [42/50], Train Loss: 0.0199, Val Loss: 0.0415\n",
      "Epoch [43/50], Train Loss: 0.0194, Val Loss: 0.0400\n",
      "Epoch [44/50], Train Loss: 0.0188, Val Loss: 0.0386\n",
      "Epoch [45/50], Train Loss: 0.0183, Val Loss: 0.0372\n",
      "Epoch [46/50], Train Loss: 0.0178, Val Loss: 0.0357\n",
      "Epoch [47/50], Train Loss: 0.0173, Val Loss: 0.0343\n",
      "Epoch [48/50], Train Loss: 0.0167, Val Loss: 0.0329\n",
      "Epoch [49/50], Train Loss: 0.0162, Val Loss: 0.0315\n",
      "Epoch [50/50], Train Loss: 0.0157, Val Loss: 0.0301\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1300, Val Loss: 0.3498\n",
      "Epoch [2/50], Train Loss: 0.1235, Val Loss: 0.3335\n",
      "Epoch [3/50], Train Loss: 0.1170, Val Loss: 0.3186\n",
      "Epoch [4/50], Train Loss: 0.1103, Val Loss: 0.3047\n",
      "Epoch [5/50], Train Loss: 0.1055, Val Loss: 0.2916\n",
      "Epoch [6/50], Train Loss: 0.0995, Val Loss: 0.2790\n",
      "Epoch [7/50], Train Loss: 0.0951, Val Loss: 0.2669\n",
      "Epoch [8/50], Train Loss: 0.0894, Val Loss: 0.2552\n",
      "Epoch [9/50], Train Loss: 0.0855, Val Loss: 0.2438\n",
      "Epoch [10/50], Train Loss: 0.0809, Val Loss: 0.2327\n",
      "Epoch [11/50], Train Loss: 0.0775, Val Loss: 0.2221\n",
      "Epoch [12/50], Train Loss: 0.0732, Val Loss: 0.2118\n",
      "Epoch [13/50], Train Loss: 0.0688, Val Loss: 0.2016\n",
      "Epoch [14/50], Train Loss: 0.0658, Val Loss: 0.1917\n",
      "Epoch [15/50], Train Loss: 0.0623, Val Loss: 0.1820\n",
      "Epoch [16/50], Train Loss: 0.0584, Val Loss: 0.1727\n",
      "Epoch [17/50], Train Loss: 0.0562, Val Loss: 0.1638\n",
      "Epoch [18/50], Train Loss: 0.0525, Val Loss: 0.1552\n",
      "Epoch [19/50], Train Loss: 0.0508, Val Loss: 0.1472\n",
      "Epoch [20/50], Train Loss: 0.0487, Val Loss: 0.1394\n",
      "Epoch [21/50], Train Loss: 0.0467, Val Loss: 0.1324\n",
      "Epoch [22/50], Train Loss: 0.0452, Val Loss: 0.1259\n",
      "Epoch [23/50], Train Loss: 0.0436, Val Loss: 0.1200\n",
      "Epoch [24/50], Train Loss: 0.0423, Val Loss: 0.1149\n",
      "Epoch [25/50], Train Loss: 0.0408, Val Loss: 0.1103\n",
      "Epoch [26/50], Train Loss: 0.0394, Val Loss: 0.1060\n",
      "Epoch [27/50], Train Loss: 0.0394, Val Loss: 0.1022\n",
      "Epoch [28/50], Train Loss: 0.0378, Val Loss: 0.0986\n",
      "Epoch [29/50], Train Loss: 0.0366, Val Loss: 0.0953\n",
      "Epoch [30/50], Train Loss: 0.0367, Val Loss: 0.0920\n",
      "Epoch [31/50], Train Loss: 0.0358, Val Loss: 0.0889\n",
      "Epoch [32/50], Train Loss: 0.0343, Val Loss: 0.0862\n",
      "Epoch [33/50], Train Loss: 0.0347, Val Loss: 0.0833\n",
      "Epoch [34/50], Train Loss: 0.0337, Val Loss: 0.0805\n",
      "Epoch [35/50], Train Loss: 0.0332, Val Loss: 0.0780\n",
      "Epoch [36/50], Train Loss: 0.0322, Val Loss: 0.0750\n",
      "Epoch [37/50], Train Loss: 0.0315, Val Loss: 0.0722\n",
      "Epoch [38/50], Train Loss: 0.0320, Val Loss: 0.0694\n",
      "Epoch [39/50], Train Loss: 0.0299, Val Loss: 0.0669\n",
      "Epoch [40/50], Train Loss: 0.0305, Val Loss: 0.0643\n",
      "Epoch [41/50], Train Loss: 0.0287, Val Loss: 0.0615\n",
      "Epoch [42/50], Train Loss: 0.0278, Val Loss: 0.0586\n",
      "Epoch [43/50], Train Loss: 0.0276, Val Loss: 0.0558\n",
      "Epoch [44/50], Train Loss: 0.0266, Val Loss: 0.0536\n",
      "Epoch [45/50], Train Loss: 0.0254, Val Loss: 0.0514\n",
      "Epoch [46/50], Train Loss: 0.0246, Val Loss: 0.0492\n",
      "Epoch [47/50], Train Loss: 0.0242, Val Loss: 0.0473\n",
      "Epoch [48/50], Train Loss: 0.0232, Val Loss: 0.0458\n",
      "Epoch [49/50], Train Loss: 0.0234, Val Loss: 0.0444\n",
      "Epoch [50/50], Train Loss: 0.0226, Val Loss: 0.0429\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1216, Val Loss: 0.3240\n",
      "Epoch [2/50], Train Loss: 0.1148, Val Loss: 0.3132\n",
      "Epoch [3/50], Train Loss: 0.1091, Val Loss: 0.3029\n",
      "Epoch [4/50], Train Loss: 0.1060, Val Loss: 0.2929\n",
      "Epoch [5/50], Train Loss: 0.1004, Val Loss: 0.2829\n",
      "Epoch [6/50], Train Loss: 0.0975, Val Loss: 0.2728\n",
      "Epoch [7/50], Train Loss: 0.0931, Val Loss: 0.2628\n",
      "Epoch [8/50], Train Loss: 0.0881, Val Loss: 0.2527\n",
      "Epoch [9/50], Train Loss: 0.0834, Val Loss: 0.2421\n",
      "Epoch [10/50], Train Loss: 0.0798, Val Loss: 0.2313\n",
      "Epoch [11/50], Train Loss: 0.0766, Val Loss: 0.2203\n",
      "Epoch [12/50], Train Loss: 0.0717, Val Loss: 0.2093\n",
      "Epoch [13/50], Train Loss: 0.0676, Val Loss: 0.1979\n",
      "Epoch [14/50], Train Loss: 0.0632, Val Loss: 0.1864\n",
      "Epoch [15/50], Train Loss: 0.0612, Val Loss: 0.1753\n",
      "Epoch [16/50], Train Loss: 0.0585, Val Loss: 0.1648\n",
      "Epoch [17/50], Train Loss: 0.0562, Val Loss: 0.1547\n",
      "Epoch [18/50], Train Loss: 0.0529, Val Loss: 0.1452\n",
      "Epoch [19/50], Train Loss: 0.0509, Val Loss: 0.1359\n",
      "Epoch [20/50], Train Loss: 0.0506, Val Loss: 0.1282\n",
      "Epoch [21/50], Train Loss: 0.0471, Val Loss: 0.1216\n",
      "Epoch [22/50], Train Loss: 0.0458, Val Loss: 0.1157\n",
      "Epoch [23/50], Train Loss: 0.0449, Val Loss: 0.1106\n",
      "Epoch [24/50], Train Loss: 0.0447, Val Loss: 0.1063\n",
      "Epoch [25/50], Train Loss: 0.0435, Val Loss: 0.1030\n",
      "Epoch [26/50], Train Loss: 0.0427, Val Loss: 0.0997\n",
      "Epoch [27/50], Train Loss: 0.0416, Val Loss: 0.0969\n",
      "Epoch [28/50], Train Loss: 0.0417, Val Loss: 0.0942\n",
      "Epoch [29/50], Train Loss: 0.0407, Val Loss: 0.0913\n",
      "Epoch [30/50], Train Loss: 0.0393, Val Loss: 0.0891\n",
      "Epoch [31/50], Train Loss: 0.0397, Val Loss: 0.0870\n",
      "Epoch [32/50], Train Loss: 0.0384, Val Loss: 0.0849\n",
      "Epoch [33/50], Train Loss: 0.0388, Val Loss: 0.0834\n",
      "Epoch [34/50], Train Loss: 0.0382, Val Loss: 0.0817\n",
      "Epoch [35/50], Train Loss: 0.0372, Val Loss: 0.0801\n",
      "Epoch [36/50], Train Loss: 0.0375, Val Loss: 0.0779\n",
      "Epoch [37/50], Train Loss: 0.0363, Val Loss: 0.0769\n",
      "Epoch [38/50], Train Loss: 0.0370, Val Loss: 0.0757\n",
      "Epoch [39/50], Train Loss: 0.0348, Val Loss: 0.0743\n",
      "Epoch [40/50], Train Loss: 0.0355, Val Loss: 0.0726\n",
      "Epoch [41/50], Train Loss: 0.0351, Val Loss: 0.0706\n",
      "Epoch [42/50], Train Loss: 0.0333, Val Loss: 0.0688\n",
      "Epoch [43/50], Train Loss: 0.0346, Val Loss: 0.0691\n",
      "Epoch [44/50], Train Loss: 0.0350, Val Loss: 0.0682\n",
      "Epoch [45/50], Train Loss: 0.0330, Val Loss: 0.0666\n",
      "Epoch [46/50], Train Loss: 0.0332, Val Loss: 0.0659\n",
      "Epoch [47/50], Train Loss: 0.0331, Val Loss: 0.0641\n",
      "Epoch [48/50], Train Loss: 0.0330, Val Loss: 0.0629\n",
      "Epoch [49/50], Train Loss: 0.0338, Val Loss: 0.0626\n",
      "Epoch [50/50], Train Loss: 0.0318, Val Loss: 0.0615\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1287, Val Loss: 0.3304\n",
      "Epoch [2/50], Train Loss: 0.1211, Val Loss: 0.3171\n",
      "Epoch [3/50], Train Loss: 0.1139, Val Loss: 0.3033\n",
      "Epoch [4/50], Train Loss: 0.1065, Val Loss: 0.2886\n",
      "Epoch [5/50], Train Loss: 0.0986, Val Loss: 0.2724\n",
      "Epoch [6/50], Train Loss: 0.0901, Val Loss: 0.2541\n",
      "Epoch [7/50], Train Loss: 0.0810, Val Loss: 0.2333\n",
      "Epoch [8/50], Train Loss: 0.0712, Val Loss: 0.2098\n",
      "Epoch [9/50], Train Loss: 0.0609, Val Loss: 0.1840\n",
      "Epoch [10/50], Train Loss: 0.0512, Val Loss: 0.1577\n",
      "Epoch [11/50], Train Loss: 0.0433, Val Loss: 0.1345\n",
      "Epoch [12/50], Train Loss: 0.0382, Val Loss: 0.1171\n",
      "Epoch [13/50], Train Loss: 0.0355, Val Loss: 0.1056\n",
      "Epoch [14/50], Train Loss: 0.0342, Val Loss: 0.0983\n",
      "Epoch [15/50], Train Loss: 0.0333, Val Loss: 0.0932\n",
      "Epoch [16/50], Train Loss: 0.0327, Val Loss: 0.0893\n",
      "Epoch [17/50], Train Loss: 0.0322, Val Loss: 0.0862\n",
      "Epoch [18/50], Train Loss: 0.0317, Val Loss: 0.0834\n",
      "Epoch [19/50], Train Loss: 0.0312, Val Loss: 0.0810\n",
      "Epoch [20/50], Train Loss: 0.0307, Val Loss: 0.0787\n",
      "Epoch [21/50], Train Loss: 0.0303, Val Loss: 0.0766\n",
      "Epoch [22/50], Train Loss: 0.0297, Val Loss: 0.0745\n",
      "Epoch [23/50], Train Loss: 0.0292, Val Loss: 0.0725\n",
      "Epoch [24/50], Train Loss: 0.0286, Val Loss: 0.0706\n",
      "Epoch [25/50], Train Loss: 0.0280, Val Loss: 0.0688\n",
      "Epoch [26/50], Train Loss: 0.0273, Val Loss: 0.0670\n",
      "Epoch [27/50], Train Loss: 0.0267, Val Loss: 0.0653\n",
      "Epoch [28/50], Train Loss: 0.0259, Val Loss: 0.0637\n",
      "Epoch [29/50], Train Loss: 0.0252, Val Loss: 0.0621\n",
      "Epoch [30/50], Train Loss: 0.0244, Val Loss: 0.0605\n",
      "Epoch [31/50], Train Loss: 0.0235, Val Loss: 0.0589\n",
      "Epoch [32/50], Train Loss: 0.0226, Val Loss: 0.0573\n",
      "Epoch [33/50], Train Loss: 0.0216, Val Loss: 0.0557\n",
      "Epoch [34/50], Train Loss: 0.0206, Val Loss: 0.0540\n",
      "Epoch [35/50], Train Loss: 0.0195, Val Loss: 0.0523\n",
      "Epoch [36/50], Train Loss: 0.0184, Val Loss: 0.0505\n",
      "Epoch [37/50], Train Loss: 0.0173, Val Loss: 0.0487\n",
      "Epoch [38/50], Train Loss: 0.0162, Val Loss: 0.0470\n",
      "Epoch [39/50], Train Loss: 0.0151, Val Loss: 0.0453\n",
      "Epoch [40/50], Train Loss: 0.0141, Val Loss: 0.0438\n",
      "Epoch [41/50], Train Loss: 0.0133, Val Loss: 0.0428\n",
      "Epoch [42/50], Train Loss: 0.0131, Val Loss: 0.0410\n",
      "Epoch [43/50], Train Loss: 0.0141, Val Loss: 0.0407\n",
      "Epoch [44/50], Train Loss: 0.0116, Val Loss: 0.0401\n",
      "Epoch [45/50], Train Loss: 0.0113, Val Loss: 0.0399\n",
      "Epoch [46/50], Train Loss: 0.0108, Val Loss: 0.0389\n",
      "Epoch [47/50], Train Loss: 0.0107, Val Loss: 0.0386\n",
      "Epoch [48/50], Train Loss: 0.0098, Val Loss: 0.0381\n",
      "Epoch [49/50], Train Loss: 0.0095, Val Loss: 0.0379\n",
      "Epoch [50/50], Train Loss: 0.0089, Val Loss: 0.0375\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1196, Val Loss: 0.3118\n",
      "Epoch [2/50], Train Loss: 0.1130, Val Loss: 0.2989\n",
      "Epoch [3/50], Train Loss: 0.1060, Val Loss: 0.2854\n",
      "Epoch [4/50], Train Loss: 0.0996, Val Loss: 0.2708\n",
      "Epoch [5/50], Train Loss: 0.0923, Val Loss: 0.2548\n",
      "Epoch [6/50], Train Loss: 0.0850, Val Loss: 0.2370\n",
      "Epoch [7/50], Train Loss: 0.0767, Val Loss: 0.2172\n",
      "Epoch [8/50], Train Loss: 0.0693, Val Loss: 0.1958\n",
      "Epoch [9/50], Train Loss: 0.0616, Val Loss: 0.1735\n",
      "Epoch [10/50], Train Loss: 0.0543, Val Loss: 0.1517\n",
      "Epoch [11/50], Train Loss: 0.0493, Val Loss: 0.1322\n",
      "Epoch [12/50], Train Loss: 0.0453, Val Loss: 0.1168\n",
      "Epoch [13/50], Train Loss: 0.0425, Val Loss: 0.1054\n",
      "Epoch [14/50], Train Loss: 0.0401, Val Loss: 0.0968\n",
      "Epoch [15/50], Train Loss: 0.0392, Val Loss: 0.0905\n",
      "Epoch [16/50], Train Loss: 0.0375, Val Loss: 0.0848\n",
      "Epoch [17/50], Train Loss: 0.0361, Val Loss: 0.0800\n",
      "Epoch [18/50], Train Loss: 0.0354, Val Loss: 0.0751\n",
      "Epoch [19/50], Train Loss: 0.0340, Val Loss: 0.0711\n",
      "Epoch [20/50], Train Loss: 0.0339, Val Loss: 0.0678\n",
      "Epoch [21/50], Train Loss: 0.0321, Val Loss: 0.0646\n",
      "Epoch [22/50], Train Loss: 0.0316, Val Loss: 0.0607\n",
      "Epoch [23/50], Train Loss: 0.0311, Val Loss: 0.0568\n",
      "Epoch [24/50], Train Loss: 0.0303, Val Loss: 0.0530\n",
      "Epoch [25/50], Train Loss: 0.0299, Val Loss: 0.0502\n",
      "Epoch [26/50], Train Loss: 0.0291, Val Loss: 0.0471\n",
      "Epoch [27/50], Train Loss: 0.0279, Val Loss: 0.0439\n",
      "Epoch [28/50], Train Loss: 0.0275, Val Loss: 0.0411\n",
      "Epoch [29/50], Train Loss: 0.0267, Val Loss: 0.0381\n",
      "Epoch [30/50], Train Loss: 0.0273, Val Loss: 0.0339\n",
      "Epoch [31/50], Train Loss: 0.0262, Val Loss: 0.0311\n",
      "Epoch [32/50], Train Loss: 0.0247, Val Loss: 0.0286\n",
      "Epoch [33/50], Train Loss: 0.0250, Val Loss: 0.0263\n",
      "Epoch [34/50], Train Loss: 0.0243, Val Loss: 0.0234\n",
      "Epoch [35/50], Train Loss: 0.0235, Val Loss: 0.0212\n",
      "Epoch [36/50], Train Loss: 0.0229, Val Loss: 0.0186\n",
      "Epoch [37/50], Train Loss: 0.0221, Val Loss: 0.0165\n",
      "Epoch [38/50], Train Loss: 0.0209, Val Loss: 0.0144\n",
      "Epoch [39/50], Train Loss: 0.0205, Val Loss: 0.0129\n",
      "Epoch [40/50], Train Loss: 0.0194, Val Loss: 0.0125\n",
      "Epoch [41/50], Train Loss: 0.0189, Val Loss: 0.0129\n",
      "Epoch [42/50], Train Loss: 0.0176, Val Loss: 0.0119\n",
      "Epoch [43/50], Train Loss: 0.0167, Val Loss: 0.0119\n",
      "Epoch [44/50], Train Loss: 0.0157, Val Loss: 0.0116\n",
      "Epoch [45/50], Train Loss: 0.0163, Val Loss: 0.0120\n",
      "Epoch [46/50], Train Loss: 0.0154, Val Loss: 0.0120\n",
      "Epoch [47/50], Train Loss: 0.0138, Val Loss: 0.0123\n",
      "Epoch [48/50], Train Loss: 0.0146, Val Loss: 0.0121\n",
      "Epoch [49/50], Train Loss: 0.0148, Val Loss: 0.0119\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1269, Val Loss: 0.3248\n",
      "Epoch [2/50], Train Loss: 0.1218, Val Loss: 0.3137\n",
      "Epoch [3/50], Train Loss: 0.1165, Val Loss: 0.3023\n",
      "Epoch [4/50], Train Loss: 0.1111, Val Loss: 0.2900\n",
      "Epoch [5/50], Train Loss: 0.1033, Val Loss: 0.2767\n",
      "Epoch [6/50], Train Loss: 0.0982, Val Loss: 0.2615\n",
      "Epoch [7/50], Train Loss: 0.0925, Val Loss: 0.2445\n",
      "Epoch [8/50], Train Loss: 0.0865, Val Loss: 0.2255\n",
      "Epoch [9/50], Train Loss: 0.0777, Val Loss: 0.2037\n",
      "Epoch [10/50], Train Loss: 0.0726, Val Loss: 0.1806\n",
      "Epoch [11/50], Train Loss: 0.0673, Val Loss: 0.1578\n",
      "Epoch [12/50], Train Loss: 0.0647, Val Loss: 0.1409\n",
      "Epoch [13/50], Train Loss: 0.0615, Val Loss: 0.1268\n",
      "Epoch [14/50], Train Loss: 0.0593, Val Loss: 0.1163\n",
      "Epoch [15/50], Train Loss: 0.0584, Val Loss: 0.1091\n",
      "Epoch [16/50], Train Loss: 0.0558, Val Loss: 0.1036\n",
      "Epoch [17/50], Train Loss: 0.0553, Val Loss: 0.0989\n",
      "Epoch [18/50], Train Loss: 0.0542, Val Loss: 0.0945\n",
      "Epoch [19/50], Train Loss: 0.0553, Val Loss: 0.0892\n",
      "Epoch [20/50], Train Loss: 0.0527, Val Loss: 0.0852\n",
      "Epoch [21/50], Train Loss: 0.0504, Val Loss: 0.0819\n",
      "Epoch [22/50], Train Loss: 0.0515, Val Loss: 0.0783\n",
      "Epoch [23/50], Train Loss: 0.0518, Val Loss: 0.0749\n",
      "Epoch [24/50], Train Loss: 0.0479, Val Loss: 0.0725\n",
      "Epoch [25/50], Train Loss: 0.0476, Val Loss: 0.0680\n",
      "Epoch [26/50], Train Loss: 0.0488, Val Loss: 0.0669\n",
      "Epoch [27/50], Train Loss: 0.0487, Val Loss: 0.0623\n",
      "Epoch [28/50], Train Loss: 0.0481, Val Loss: 0.0586\n",
      "Epoch [29/50], Train Loss: 0.0456, Val Loss: 0.0564\n",
      "Epoch [30/50], Train Loss: 0.0434, Val Loss: 0.0545\n",
      "Epoch [31/50], Train Loss: 0.0445, Val Loss: 0.0517\n",
      "Epoch [32/50], Train Loss: 0.0444, Val Loss: 0.0487\n",
      "Epoch [33/50], Train Loss: 0.0432, Val Loss: 0.0455\n",
      "Epoch [34/50], Train Loss: 0.0413, Val Loss: 0.0423\n",
      "Epoch [35/50], Train Loss: 0.0428, Val Loss: 0.0417\n",
      "Epoch [36/50], Train Loss: 0.0402, Val Loss: 0.0421\n",
      "Epoch [37/50], Train Loss: 0.0393, Val Loss: 0.0417\n",
      "Epoch [38/50], Train Loss: 0.0395, Val Loss: 0.0417\n",
      "Epoch [39/50], Train Loss: 0.0383, Val Loss: 0.0412\n",
      "Epoch [40/50], Train Loss: 0.0357, Val Loss: 0.0421\n",
      "Epoch [41/50], Train Loss: 0.0354, Val Loss: 0.0445\n",
      "Epoch [42/50], Train Loss: 0.0341, Val Loss: 0.0479\n",
      "Epoch [43/50], Train Loss: 0.0355, Val Loss: 0.0495\n",
      "Epoch [44/50], Train Loss: 0.0351, Val Loss: 0.0500\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1489, Val Loss: 0.3724\n",
      "Epoch [2/50], Train Loss: 0.1394, Val Loss: 0.3562\n",
      "Epoch [3/50], Train Loss: 0.1308, Val Loss: 0.3402\n",
      "Epoch [4/50], Train Loss: 0.1221, Val Loss: 0.3233\n",
      "Epoch [5/50], Train Loss: 0.1127, Val Loss: 0.3045\n",
      "Epoch [6/50], Train Loss: 0.1020, Val Loss: 0.2823\n",
      "Epoch [7/50], Train Loss: 0.0897, Val Loss: 0.2547\n",
      "Epoch [8/50], Train Loss: 0.0755, Val Loss: 0.2207\n",
      "Epoch [9/50], Train Loss: 0.0617, Val Loss: 0.1854\n",
      "Epoch [10/50], Train Loss: 0.0514, Val Loss: 0.1572\n",
      "Epoch [11/50], Train Loss: 0.0455, Val Loss: 0.1382\n",
      "Epoch [12/50], Train Loss: 0.0422, Val Loss: 0.1260\n",
      "Epoch [13/50], Train Loss: 0.0403, Val Loss: 0.1183\n",
      "Epoch [14/50], Train Loss: 0.0392, Val Loss: 0.1134\n",
      "Epoch [15/50], Train Loss: 0.0385, Val Loss: 0.1102\n",
      "Epoch [16/50], Train Loss: 0.0381, Val Loss: 0.1081\n",
      "Epoch [17/50], Train Loss: 0.0377, Val Loss: 0.1066\n",
      "Epoch [18/50], Train Loss: 0.0374, Val Loss: 0.1055\n",
      "Epoch [19/50], Train Loss: 0.0372, Val Loss: 0.1046\n",
      "Epoch [20/50], Train Loss: 0.0370, Val Loss: 0.1037\n",
      "Epoch [21/50], Train Loss: 0.0367, Val Loss: 0.1028\n",
      "Epoch [22/50], Train Loss: 0.0364, Val Loss: 0.1019\n",
      "Epoch [23/50], Train Loss: 0.0361, Val Loss: 0.1008\n",
      "Epoch [24/50], Train Loss: 0.0357, Val Loss: 0.0996\n",
      "Epoch [25/50], Train Loss: 0.0353, Val Loss: 0.0982\n",
      "Epoch [26/50], Train Loss: 0.0347, Val Loss: 0.0965\n",
      "Epoch [27/50], Train Loss: 0.0342, Val Loss: 0.0945\n",
      "Epoch [28/50], Train Loss: 0.0335, Val Loss: 0.0923\n",
      "Epoch [29/50], Train Loss: 0.0327, Val Loss: 0.0898\n",
      "Epoch [30/50], Train Loss: 0.0319, Val Loss: 0.0871\n",
      "Epoch [31/50], Train Loss: 0.0310, Val Loss: 0.0842\n",
      "Epoch [32/50], Train Loss: 0.0300, Val Loss: 0.0811\n",
      "Epoch [33/50], Train Loss: 0.0290, Val Loss: 0.0779\n",
      "Epoch [34/50], Train Loss: 0.0280, Val Loss: 0.0745\n",
      "Epoch [35/50], Train Loss: 0.0270, Val Loss: 0.0712\n",
      "Epoch [36/50], Train Loss: 0.0261, Val Loss: 0.0678\n",
      "Epoch [37/50], Train Loss: 0.0253, Val Loss: 0.0647\n",
      "Epoch [38/50], Train Loss: 0.0245, Val Loss: 0.0617\n",
      "Epoch [39/50], Train Loss: 0.0239, Val Loss: 0.0589\n",
      "Epoch [40/50], Train Loss: 0.0233, Val Loss: 0.0564\n",
      "Epoch [41/50], Train Loss: 0.0228, Val Loss: 0.0541\n",
      "Epoch [42/50], Train Loss: 0.0224, Val Loss: 0.0520\n",
      "Epoch [43/50], Train Loss: 0.0220, Val Loss: 0.0501\n",
      "Epoch [44/50], Train Loss: 0.0216, Val Loss: 0.0483\n",
      "Epoch [45/50], Train Loss: 0.0213, Val Loss: 0.0467\n",
      "Epoch [46/50], Train Loss: 0.0210, Val Loss: 0.0453\n",
      "Epoch [47/50], Train Loss: 0.0208, Val Loss: 0.0440\n",
      "Epoch [48/50], Train Loss: 0.0205, Val Loss: 0.0429\n",
      "Epoch [49/50], Train Loss: 0.0203, Val Loss: 0.0419\n",
      "Epoch [50/50], Train Loss: 0.0201, Val Loss: 0.0410\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1862, Val Loss: 0.4753\n",
      "Epoch [2/50], Train Loss: 0.1794, Val Loss: 0.4636\n",
      "Epoch [3/50], Train Loss: 0.1726, Val Loss: 0.4516\n",
      "Epoch [4/50], Train Loss: 0.1661, Val Loss: 0.4383\n",
      "Epoch [5/50], Train Loss: 0.1583, Val Loss: 0.4228\n",
      "Epoch [6/50], Train Loss: 0.1492, Val Loss: 0.4028\n",
      "Epoch [7/50], Train Loss: 0.1370, Val Loss: 0.3745\n",
      "Epoch [8/50], Train Loss: 0.1213, Val Loss: 0.3318\n",
      "Epoch [9/50], Train Loss: 0.1002, Val Loss: 0.2733\n",
      "Epoch [10/50], Train Loss: 0.0777, Val Loss: 0.2143\n",
      "Epoch [11/50], Train Loss: 0.0647, Val Loss: 0.1729\n",
      "Epoch [12/50], Train Loss: 0.0602, Val Loss: 0.1495\n",
      "Epoch [13/50], Train Loss: 0.0564, Val Loss: 0.1363\n",
      "Epoch [14/50], Train Loss: 0.0545, Val Loss: 0.1283\n",
      "Epoch [15/50], Train Loss: 0.0536, Val Loss: 0.1228\n",
      "Epoch [16/50], Train Loss: 0.0529, Val Loss: 0.1192\n",
      "Epoch [17/50], Train Loss: 0.0518, Val Loss: 0.1151\n",
      "Epoch [18/50], Train Loss: 0.0504, Val Loss: 0.1117\n",
      "Epoch [19/50], Train Loss: 0.0483, Val Loss: 0.1087\n",
      "Epoch [20/50], Train Loss: 0.0478, Val Loss: 0.1052\n",
      "Epoch [21/50], Train Loss: 0.0491, Val Loss: 0.1026\n",
      "Epoch [22/50], Train Loss: 0.0463, Val Loss: 0.0989\n",
      "Epoch [23/50], Train Loss: 0.0453, Val Loss: 0.0957\n",
      "Epoch [24/50], Train Loss: 0.0439, Val Loss: 0.0919\n",
      "Epoch [25/50], Train Loss: 0.0445, Val Loss: 0.0884\n",
      "Epoch [26/50], Train Loss: 0.0433, Val Loss: 0.0838\n",
      "Epoch [27/50], Train Loss: 0.0406, Val Loss: 0.0801\n",
      "Epoch [28/50], Train Loss: 0.0431, Val Loss: 0.0784\n",
      "Epoch [29/50], Train Loss: 0.0409, Val Loss: 0.0743\n",
      "Epoch [30/50], Train Loss: 0.0393, Val Loss: 0.0705\n",
      "Epoch [31/50], Train Loss: 0.0389, Val Loss: 0.0669\n",
      "Epoch [32/50], Train Loss: 0.0373, Val Loss: 0.0639\n",
      "Epoch [33/50], Train Loss: 0.0373, Val Loss: 0.0603\n",
      "Epoch [34/50], Train Loss: 0.0359, Val Loss: 0.0570\n",
      "Epoch [35/50], Train Loss: 0.0350, Val Loss: 0.0544\n",
      "Epoch [36/50], Train Loss: 0.0347, Val Loss: 0.0512\n",
      "Epoch [37/50], Train Loss: 0.0337, Val Loss: 0.0482\n",
      "Epoch [38/50], Train Loss: 0.0338, Val Loss: 0.0454\n",
      "Epoch [39/50], Train Loss: 0.0331, Val Loss: 0.0432\n",
      "Epoch [40/50], Train Loss: 0.0321, Val Loss: 0.0412\n",
      "Epoch [41/50], Train Loss: 0.0318, Val Loss: 0.0388\n",
      "Epoch [42/50], Train Loss: 0.0332, Val Loss: 0.0365\n",
      "Epoch [43/50], Train Loss: 0.0307, Val Loss: 0.0353\n",
      "Epoch [44/50], Train Loss: 0.0317, Val Loss: 0.0333\n",
      "Epoch [45/50], Train Loss: 0.0307, Val Loss: 0.0322\n",
      "Epoch [46/50], Train Loss: 0.0298, Val Loss: 0.0306\n",
      "Epoch [47/50], Train Loss: 0.0308, Val Loss: 0.0302\n",
      "Epoch [48/50], Train Loss: 0.0304, Val Loss: 0.0284\n",
      "Epoch [49/50], Train Loss: 0.0297, Val Loss: 0.0276\n",
      "Epoch [50/50], Train Loss: 0.0296, Val Loss: 0.0262\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1357, Val Loss: 0.3177\n",
      "Epoch [2/50], Train Loss: 0.1298, Val Loss: 0.3109\n",
      "Epoch [3/50], Train Loss: 0.1240, Val Loss: 0.3046\n",
      "Epoch [4/50], Train Loss: 0.1203, Val Loss: 0.2988\n",
      "Epoch [5/50], Train Loss: 0.1153, Val Loss: 0.2930\n",
      "Epoch [6/50], Train Loss: 0.1117, Val Loss: 0.2873\n",
      "Epoch [7/50], Train Loss: 0.1074, Val Loss: 0.2813\n",
      "Epoch [8/50], Train Loss: 0.1033, Val Loss: 0.2752\n",
      "Epoch [9/50], Train Loss: 0.0994, Val Loss: 0.2686\n",
      "Epoch [10/50], Train Loss: 0.0951, Val Loss: 0.2613\n",
      "Epoch [11/50], Train Loss: 0.0909, Val Loss: 0.2533\n",
      "Epoch [12/50], Train Loss: 0.0880, Val Loss: 0.2444\n",
      "Epoch [13/50], Train Loss: 0.0822, Val Loss: 0.2341\n",
      "Epoch [14/50], Train Loss: 0.0772, Val Loss: 0.2216\n",
      "Epoch [15/50], Train Loss: 0.0728, Val Loss: 0.2076\n",
      "Epoch [16/50], Train Loss: 0.0680, Val Loss: 0.1945\n",
      "Epoch [17/50], Train Loss: 0.0683, Val Loss: 0.1840\n",
      "Epoch [18/50], Train Loss: 0.0641, Val Loss: 0.1738\n",
      "Epoch [19/50], Train Loss: 0.0611, Val Loss: 0.1650\n",
      "Epoch [20/50], Train Loss: 0.0614, Val Loss: 0.1583\n",
      "Epoch [21/50], Train Loss: 0.0591, Val Loss: 0.1531\n",
      "Epoch [22/50], Train Loss: 0.0572, Val Loss: 0.1484\n",
      "Epoch [23/50], Train Loss: 0.0563, Val Loss: 0.1428\n",
      "Epoch [24/50], Train Loss: 0.0585, Val Loss: 0.1410\n",
      "Epoch [25/50], Train Loss: 0.0557, Val Loss: 0.1384\n",
      "Epoch [26/50], Train Loss: 0.0554, Val Loss: 0.1361\n",
      "Epoch [27/50], Train Loss: 0.0552, Val Loss: 0.1324\n",
      "Epoch [28/50], Train Loss: 0.0552, Val Loss: 0.1309\n",
      "Epoch [29/50], Train Loss: 0.0558, Val Loss: 0.1287\n",
      "Epoch [30/50], Train Loss: 0.0532, Val Loss: 0.1265\n",
      "Epoch [31/50], Train Loss: 0.0521, Val Loss: 0.1242\n",
      "Epoch [32/50], Train Loss: 0.0521, Val Loss: 0.1225\n",
      "Epoch [33/50], Train Loss: 0.0507, Val Loss: 0.1198\n",
      "Epoch [34/50], Train Loss: 0.0510, Val Loss: 0.1190\n",
      "Epoch [35/50], Train Loss: 0.0499, Val Loss: 0.1172\n",
      "Epoch [36/50], Train Loss: 0.0507, Val Loss: 0.1160\n",
      "Epoch [37/50], Train Loss: 0.0493, Val Loss: 0.1156\n",
      "Epoch [38/50], Train Loss: 0.0483, Val Loss: 0.1124\n",
      "Epoch [39/50], Train Loss: 0.0492, Val Loss: 0.1100\n",
      "Epoch [40/50], Train Loss: 0.0473, Val Loss: 0.1063\n",
      "Epoch [41/50], Train Loss: 0.0467, Val Loss: 0.1029\n",
      "Epoch [42/50], Train Loss: 0.0449, Val Loss: 0.0990\n",
      "Epoch [43/50], Train Loss: 0.0451, Val Loss: 0.0973\n",
      "Epoch [44/50], Train Loss: 0.0461, Val Loss: 0.0943\n",
      "Epoch [45/50], Train Loss: 0.0436, Val Loss: 0.0901\n",
      "Epoch [46/50], Train Loss: 0.0445, Val Loss: 0.0859\n",
      "Epoch [47/50], Train Loss: 0.0432, Val Loss: 0.0830\n",
      "Epoch [48/50], Train Loss: 0.0430, Val Loss: 0.0810\n",
      "Epoch [49/50], Train Loss: 0.0414, Val Loss: 0.0760\n",
      "Epoch [50/50], Train Loss: 0.0407, Val Loss: 0.0726\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1294, Val Loss: 0.3239\n",
      "Epoch [2/50], Train Loss: 0.1189, Val Loss: 0.3028\n",
      "Epoch [3/50], Train Loss: 0.1088, Val Loss: 0.2816\n",
      "Epoch [4/50], Train Loss: 0.0987, Val Loss: 0.2594\n",
      "Epoch [5/50], Train Loss: 0.0883, Val Loss: 0.2356\n",
      "Epoch [6/50], Train Loss: 0.0776, Val Loss: 0.2098\n",
      "Epoch [7/50], Train Loss: 0.0665, Val Loss: 0.1817\n",
      "Epoch [8/50], Train Loss: 0.0555, Val Loss: 0.1518\n",
      "Epoch [9/50], Train Loss: 0.0455, Val Loss: 0.1223\n",
      "Epoch [10/50], Train Loss: 0.0379, Val Loss: 0.0975\n",
      "Epoch [11/50], Train Loss: 0.0337, Val Loss: 0.0808\n",
      "Epoch [12/50], Train Loss: 0.0317, Val Loss: 0.0712\n",
      "Epoch [13/50], Train Loss: 0.0305, Val Loss: 0.0652\n",
      "Epoch [14/50], Train Loss: 0.0294, Val Loss: 0.0608\n",
      "Epoch [15/50], Train Loss: 0.0286, Val Loss: 0.0572\n",
      "Epoch [16/50], Train Loss: 0.0279, Val Loss: 0.0542\n",
      "Epoch [17/50], Train Loss: 0.0272, Val Loss: 0.0516\n",
      "Epoch [18/50], Train Loss: 0.0267, Val Loss: 0.0492\n",
      "Epoch [19/50], Train Loss: 0.0261, Val Loss: 0.0470\n",
      "Epoch [20/50], Train Loss: 0.0256, Val Loss: 0.0449\n",
      "Epoch [21/50], Train Loss: 0.0251, Val Loss: 0.0429\n",
      "Epoch [22/50], Train Loss: 0.0246, Val Loss: 0.0410\n",
      "Epoch [23/50], Train Loss: 0.0241, Val Loss: 0.0391\n",
      "Epoch [24/50], Train Loss: 0.0236, Val Loss: 0.0373\n",
      "Epoch [25/50], Train Loss: 0.0231, Val Loss: 0.0355\n",
      "Epoch [26/50], Train Loss: 0.0226, Val Loss: 0.0337\n",
      "Epoch [27/50], Train Loss: 0.0221, Val Loss: 0.0321\n",
      "Epoch [28/50], Train Loss: 0.0217, Val Loss: 0.0305\n",
      "Epoch [29/50], Train Loss: 0.0212, Val Loss: 0.0291\n",
      "Epoch [30/50], Train Loss: 0.0208, Val Loss: 0.0277\n",
      "Epoch [31/50], Train Loss: 0.0204, Val Loss: 0.0265\n",
      "Epoch [32/50], Train Loss: 0.0200, Val Loss: 0.0253\n",
      "Epoch [33/50], Train Loss: 0.0196, Val Loss: 0.0243\n",
      "Epoch [34/50], Train Loss: 0.0193, Val Loss: 0.0234\n",
      "Epoch [35/50], Train Loss: 0.0189, Val Loss: 0.0225\n",
      "Epoch [36/50], Train Loss: 0.0186, Val Loss: 0.0217\n",
      "Epoch [37/50], Train Loss: 0.0182, Val Loss: 0.0209\n",
      "Epoch [38/50], Train Loss: 0.0179, Val Loss: 0.0201\n",
      "Epoch [39/50], Train Loss: 0.0175, Val Loss: 0.0192\n",
      "Epoch [40/50], Train Loss: 0.0171, Val Loss: 0.0182\n",
      "Epoch [41/50], Train Loss: 0.0167, Val Loss: 0.0170\n",
      "Epoch [42/50], Train Loss: 0.0162, Val Loss: 0.0157\n",
      "Epoch [43/50], Train Loss: 0.0156, Val Loss: 0.0142\n",
      "Epoch [44/50], Train Loss: 0.0149, Val Loss: 0.0124\n",
      "Epoch [45/50], Train Loss: 0.0141, Val Loss: 0.0104\n",
      "Epoch [46/50], Train Loss: 0.0131, Val Loss: 0.0084\n",
      "Epoch [47/50], Train Loss: 0.0120, Val Loss: 0.0067\n",
      "Epoch [48/50], Train Loss: 0.0108, Val Loss: 0.0056\n",
      "Epoch [49/50], Train Loss: 0.0097, Val Loss: 0.0050\n",
      "Epoch [50/50], Train Loss: 0.0087, Val Loss: 0.0049\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1073, Val Loss: 0.3058\n",
      "Epoch [2/50], Train Loss: 0.0985, Val Loss: 0.2863\n",
      "Epoch [3/50], Train Loss: 0.0909, Val Loss: 0.2684\n",
      "Epoch [4/50], Train Loss: 0.0831, Val Loss: 0.2511\n",
      "Epoch [5/50], Train Loss: 0.0768, Val Loss: 0.2337\n",
      "Epoch [6/50], Train Loss: 0.0698, Val Loss: 0.2158\n",
      "Epoch [7/50], Train Loss: 0.0630, Val Loss: 0.1974\n",
      "Epoch [8/50], Train Loss: 0.0569, Val Loss: 0.1784\n",
      "Epoch [9/50], Train Loss: 0.0517, Val Loss: 0.1592\n",
      "Epoch [10/50], Train Loss: 0.0462, Val Loss: 0.1404\n",
      "Epoch [11/50], Train Loss: 0.0422, Val Loss: 0.1233\n",
      "Epoch [12/50], Train Loss: 0.0383, Val Loss: 0.1087\n",
      "Epoch [13/50], Train Loss: 0.0363, Val Loss: 0.0968\n",
      "Epoch [14/50], Train Loss: 0.0342, Val Loss: 0.0872\n",
      "Epoch [15/50], Train Loss: 0.0328, Val Loss: 0.0801\n",
      "Epoch [16/50], Train Loss: 0.0319, Val Loss: 0.0741\n",
      "Epoch [17/50], Train Loss: 0.0310, Val Loss: 0.0689\n",
      "Epoch [18/50], Train Loss: 0.0288, Val Loss: 0.0640\n",
      "Epoch [19/50], Train Loss: 0.0282, Val Loss: 0.0594\n",
      "Epoch [20/50], Train Loss: 0.0274, Val Loss: 0.0553\n",
      "Epoch [21/50], Train Loss: 0.0272, Val Loss: 0.0511\n",
      "Epoch [22/50], Train Loss: 0.0259, Val Loss: 0.0469\n",
      "Epoch [23/50], Train Loss: 0.0250, Val Loss: 0.0433\n",
      "Epoch [24/50], Train Loss: 0.0247, Val Loss: 0.0394\n",
      "Epoch [25/50], Train Loss: 0.0226, Val Loss: 0.0348\n",
      "Epoch [26/50], Train Loss: 0.0224, Val Loss: 0.0306\n",
      "Epoch [27/50], Train Loss: 0.0203, Val Loss: 0.0254\n",
      "Epoch [28/50], Train Loss: 0.0196, Val Loss: 0.0212\n",
      "Epoch [29/50], Train Loss: 0.0188, Val Loss: 0.0181\n",
      "Epoch [30/50], Train Loss: 0.0172, Val Loss: 0.0158\n",
      "Epoch [31/50], Train Loss: 0.0163, Val Loss: 0.0146\n",
      "Epoch [32/50], Train Loss: 0.0155, Val Loss: 0.0143\n",
      "Epoch [33/50], Train Loss: 0.0140, Val Loss: 0.0145\n",
      "Epoch [34/50], Train Loss: 0.0134, Val Loss: 0.0147\n",
      "Epoch [35/50], Train Loss: 0.0126, Val Loss: 0.0147\n",
      "Epoch [36/50], Train Loss: 0.0117, Val Loss: 0.0145\n",
      "Epoch [37/50], Train Loss: 0.0110, Val Loss: 0.0147\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1462, Val Loss: 0.4037\n",
      "Epoch [2/50], Train Loss: 0.1350, Val Loss: 0.3820\n",
      "Epoch [3/50], Train Loss: 0.1274, Val Loss: 0.3616\n",
      "Epoch [4/50], Train Loss: 0.1177, Val Loss: 0.3410\n",
      "Epoch [5/50], Train Loss: 0.1090, Val Loss: 0.3195\n",
      "Epoch [6/50], Train Loss: 0.0997, Val Loss: 0.2966\n",
      "Epoch [7/50], Train Loss: 0.0904, Val Loss: 0.2714\n",
      "Epoch [8/50], Train Loss: 0.0831, Val Loss: 0.2433\n",
      "Epoch [9/50], Train Loss: 0.0731, Val Loss: 0.2116\n",
      "Epoch [10/50], Train Loss: 0.0628, Val Loss: 0.1756\n",
      "Epoch [11/50], Train Loss: 0.0525, Val Loss: 0.1383\n",
      "Epoch [12/50], Train Loss: 0.0467, Val Loss: 0.1059\n",
      "Epoch [13/50], Train Loss: 0.0437, Val Loss: 0.0839\n",
      "Epoch [14/50], Train Loss: 0.0412, Val Loss: 0.0722\n",
      "Epoch [15/50], Train Loss: 0.0402, Val Loss: 0.0654\n",
      "Epoch [16/50], Train Loss: 0.0384, Val Loss: 0.0585\n",
      "Epoch [17/50], Train Loss: 0.0360, Val Loss: 0.0549\n",
      "Epoch [18/50], Train Loss: 0.0354, Val Loss: 0.0502\n",
      "Epoch [19/50], Train Loss: 0.0350, Val Loss: 0.0457\n",
      "Epoch [20/50], Train Loss: 0.0326, Val Loss: 0.0402\n",
      "Epoch [21/50], Train Loss: 0.0323, Val Loss: 0.0378\n",
      "Epoch [22/50], Train Loss: 0.0321, Val Loss: 0.0351\n",
      "Epoch [23/50], Train Loss: 0.0310, Val Loss: 0.0305\n",
      "Epoch [24/50], Train Loss: 0.0295, Val Loss: 0.0278\n",
      "Epoch [25/50], Train Loss: 0.0289, Val Loss: 0.0256\n",
      "Epoch [26/50], Train Loss: 0.0299, Val Loss: 0.0229\n",
      "Epoch [27/50], Train Loss: 0.0287, Val Loss: 0.0197\n",
      "Epoch [28/50], Train Loss: 0.0271, Val Loss: 0.0194\n",
      "Epoch [29/50], Train Loss: 0.0269, Val Loss: 0.0169\n",
      "Epoch [30/50], Train Loss: 0.0261, Val Loss: 0.0151\n",
      "Epoch [31/50], Train Loss: 0.0269, Val Loss: 0.0142\n",
      "Epoch [32/50], Train Loss: 0.0245, Val Loss: 0.0117\n",
      "Epoch [33/50], Train Loss: 0.0242, Val Loss: 0.0101\n",
      "Epoch [34/50], Train Loss: 0.0233, Val Loss: 0.0094\n",
      "Epoch [35/50], Train Loss: 0.0227, Val Loss: 0.0085\n",
      "Epoch [36/50], Train Loss: 0.0218, Val Loss: 0.0074\n",
      "Epoch [37/50], Train Loss: 0.0225, Val Loss: 0.0061\n",
      "Epoch [38/50], Train Loss: 0.0218, Val Loss: 0.0063\n",
      "Epoch [39/50], Train Loss: 0.0199, Val Loss: 0.0049\n",
      "Epoch [40/50], Train Loss: 0.0194, Val Loss: 0.0045\n",
      "Epoch [41/50], Train Loss: 0.0200, Val Loss: 0.0041\n",
      "Epoch [42/50], Train Loss: 0.0192, Val Loss: 0.0039\n",
      "Epoch [43/50], Train Loss: 0.0180, Val Loss: 0.0042\n",
      "Epoch [44/50], Train Loss: 0.0181, Val Loss: 0.0040\n",
      "Epoch [45/50], Train Loss: 0.0171, Val Loss: 0.0036\n",
      "Epoch [46/50], Train Loss: 0.0177, Val Loss: 0.0052\n",
      "Epoch [47/50], Train Loss: 0.0167, Val Loss: 0.0050\n",
      "Epoch [48/50], Train Loss: 0.0166, Val Loss: 0.0041\n",
      "Epoch [49/50], Train Loss: 0.0166, Val Loss: 0.0048\n",
      "Epoch [50/50], Train Loss: 0.0163, Val Loss: 0.0041\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1303, Val Loss: 0.3696\n",
      "Epoch [2/50], Train Loss: 0.1179, Val Loss: 0.3466\n",
      "Epoch [3/50], Train Loss: 0.1063, Val Loss: 0.3226\n",
      "Epoch [4/50], Train Loss: 0.0944, Val Loss: 0.2954\n",
      "Epoch [5/50], Train Loss: 0.0814, Val Loss: 0.2625\n",
      "Epoch [6/50], Train Loss: 0.0670, Val Loss: 0.2209\n",
      "Epoch [7/50], Train Loss: 0.0518, Val Loss: 0.1699\n",
      "Epoch [8/50], Train Loss: 0.0397, Val Loss: 0.1212\n",
      "Epoch [9/50], Train Loss: 0.0345, Val Loss: 0.0916\n",
      "Epoch [10/50], Train Loss: 0.0331, Val Loss: 0.0774\n",
      "Epoch [11/50], Train Loss: 0.0320, Val Loss: 0.0690\n",
      "Epoch [12/50], Train Loss: 0.0309, Val Loss: 0.0625\n",
      "Epoch [13/50], Train Loss: 0.0298, Val Loss: 0.0568\n",
      "Epoch [14/50], Train Loss: 0.0287, Val Loss: 0.0516\n",
      "Epoch [15/50], Train Loss: 0.0276, Val Loss: 0.0466\n",
      "Epoch [16/50], Train Loss: 0.0265, Val Loss: 0.0418\n",
      "Epoch [17/50], Train Loss: 0.0253, Val Loss: 0.0373\n",
      "Epoch [18/50], Train Loss: 0.0240, Val Loss: 0.0330\n",
      "Epoch [19/50], Train Loss: 0.0228, Val Loss: 0.0290\n",
      "Epoch [20/50], Train Loss: 0.0216, Val Loss: 0.0253\n",
      "Epoch [21/50], Train Loss: 0.0204, Val Loss: 0.0220\n",
      "Epoch [22/50], Train Loss: 0.0192, Val Loss: 0.0191\n",
      "Epoch [23/50], Train Loss: 0.0181, Val Loss: 0.0167\n",
      "Epoch [24/50], Train Loss: 0.0171, Val Loss: 0.0147\n",
      "Epoch [25/50], Train Loss: 0.0161, Val Loss: 0.0133\n",
      "Epoch [26/50], Train Loss: 0.0151, Val Loss: 0.0125\n",
      "Epoch [27/50], Train Loss: 0.0138, Val Loss: 0.0125\n",
      "Epoch [28/50], Train Loss: 0.0123, Val Loss: 0.0143\n",
      "Epoch [29/50], Train Loss: 0.0102, Val Loss: 0.0192\n",
      "Epoch [30/50], Train Loss: 0.0079, Val Loss: 0.0265\n",
      "Epoch [31/50], Train Loss: 0.0064, Val Loss: 0.0328\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1409, Val Loss: 0.3302\n",
      "Epoch [2/50], Train Loss: 0.1320, Val Loss: 0.3138\n",
      "Epoch [3/50], Train Loss: 0.1236, Val Loss: 0.2965\n",
      "Epoch [4/50], Train Loss: 0.1143, Val Loss: 0.2756\n",
      "Epoch [5/50], Train Loss: 0.1029, Val Loss: 0.2477\n",
      "Epoch [6/50], Train Loss: 0.0886, Val Loss: 0.2068\n",
      "Epoch [7/50], Train Loss: 0.0692, Val Loss: 0.1452\n",
      "Epoch [8/50], Train Loss: 0.0481, Val Loss: 0.0789\n",
      "Epoch [9/50], Train Loss: 0.0403, Val Loss: 0.0603\n",
      "Epoch [10/50], Train Loss: 0.0403, Val Loss: 0.0631\n",
      "Epoch [11/50], Train Loss: 0.0378, Val Loss: 0.0623\n",
      "Epoch [12/50], Train Loss: 0.0369, Val Loss: 0.0608\n",
      "Epoch [13/50], Train Loss: 0.0366, Val Loss: 0.0592\n",
      "Epoch [14/50], Train Loss: 0.0350, Val Loss: 0.0585\n",
      "Epoch [15/50], Train Loss: 0.0344, Val Loss: 0.0565\n",
      "Epoch [16/50], Train Loss: 0.0335, Val Loss: 0.0532\n",
      "Epoch [17/50], Train Loss: 0.0324, Val Loss: 0.0517\n",
      "Epoch [18/50], Train Loss: 0.0323, Val Loss: 0.0487\n",
      "Epoch [19/50], Train Loss: 0.0316, Val Loss: 0.0474\n",
      "Epoch [20/50], Train Loss: 0.0306, Val Loss: 0.0448\n",
      "Epoch [21/50], Train Loss: 0.0298, Val Loss: 0.0422\n",
      "Epoch [22/50], Train Loss: 0.0299, Val Loss: 0.0406\n",
      "Epoch [23/50], Train Loss: 0.0288, Val Loss: 0.0392\n",
      "Epoch [24/50], Train Loss: 0.0284, Val Loss: 0.0373\n",
      "Epoch [25/50], Train Loss: 0.0279, Val Loss: 0.0359\n",
      "Epoch [26/50], Train Loss: 0.0272, Val Loss: 0.0346\n",
      "Epoch [27/50], Train Loss: 0.0266, Val Loss: 0.0330\n",
      "Epoch [28/50], Train Loss: 0.0261, Val Loss: 0.0314\n",
      "Epoch [29/50], Train Loss: 0.0255, Val Loss: 0.0301\n",
      "Epoch [30/50], Train Loss: 0.0259, Val Loss: 0.0277\n",
      "Epoch [31/50], Train Loss: 0.0257, Val Loss: 0.0274\n",
      "Epoch [32/50], Train Loss: 0.0248, Val Loss: 0.0262\n",
      "Epoch [33/50], Train Loss: 0.0243, Val Loss: 0.0255\n",
      "Epoch [34/50], Train Loss: 0.0242, Val Loss: 0.0240\n",
      "Epoch [35/50], Train Loss: 0.0231, Val Loss: 0.0231\n",
      "Epoch [36/50], Train Loss: 0.0226, Val Loss: 0.0219\n",
      "Epoch [37/50], Train Loss: 0.0223, Val Loss: 0.0206\n",
      "Epoch [38/50], Train Loss: 0.0217, Val Loss: 0.0192\n",
      "Epoch [39/50], Train Loss: 0.0216, Val Loss: 0.0172\n",
      "Epoch [40/50], Train Loss: 0.0199, Val Loss: 0.0149\n",
      "Epoch [41/50], Train Loss: 0.0195, Val Loss: 0.0134\n",
      "Epoch [42/50], Train Loss: 0.0182, Val Loss: 0.0105\n",
      "Epoch [43/50], Train Loss: 0.0167, Val Loss: 0.0081\n",
      "Epoch [44/50], Train Loss: 0.0157, Val Loss: 0.0067\n",
      "Epoch [45/50], Train Loss: 0.0139, Val Loss: 0.0057\n",
      "Epoch [46/50], Train Loss: 0.0135, Val Loss: 0.0064\n",
      "Epoch [47/50], Train Loss: 0.0124, Val Loss: 0.0080\n",
      "Epoch [48/50], Train Loss: 0.0114, Val Loss: 0.0111\n",
      "Epoch [49/50], Train Loss: 0.0116, Val Loss: 0.0111\n",
      "Epoch [50/50], Train Loss: 0.0109, Val Loss: 0.0114\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1294, Val Loss: 0.3615\n",
      "Epoch [2/50], Train Loss: 0.1182, Val Loss: 0.3400\n",
      "Epoch [3/50], Train Loss: 0.1093, Val Loss: 0.3167\n",
      "Epoch [4/50], Train Loss: 0.0990, Val Loss: 0.2890\n",
      "Epoch [5/50], Train Loss: 0.0877, Val Loss: 0.2534\n",
      "Epoch [6/50], Train Loss: 0.0739, Val Loss: 0.2068\n",
      "Epoch [7/50], Train Loss: 0.0604, Val Loss: 0.1535\n",
      "Epoch [8/50], Train Loss: 0.0538, Val Loss: 0.1122\n",
      "Epoch [9/50], Train Loss: 0.0503, Val Loss: 0.0903\n",
      "Epoch [10/50], Train Loss: 0.0508, Val Loss: 0.0808\n",
      "Epoch [11/50], Train Loss: 0.0475, Val Loss: 0.0743\n",
      "Epoch [12/50], Train Loss: 0.0440, Val Loss: 0.0665\n",
      "Epoch [13/50], Train Loss: 0.0435, Val Loss: 0.0598\n",
      "Epoch [14/50], Train Loss: 0.0426, Val Loss: 0.0545\n",
      "Epoch [15/50], Train Loss: 0.0399, Val Loss: 0.0492\n",
      "Epoch [16/50], Train Loss: 0.0407, Val Loss: 0.0425\n",
      "Epoch [17/50], Train Loss: 0.0376, Val Loss: 0.0364\n",
      "Epoch [18/50], Train Loss: 0.0376, Val Loss: 0.0301\n",
      "Epoch [19/50], Train Loss: 0.0355, Val Loss: 0.0255\n",
      "Epoch [20/50], Train Loss: 0.0327, Val Loss: 0.0212\n",
      "Epoch [21/50], Train Loss: 0.0322, Val Loss: 0.0202\n",
      "Epoch [22/50], Train Loss: 0.0305, Val Loss: 0.0205\n",
      "Epoch [23/50], Train Loss: 0.0301, Val Loss: 0.0235\n",
      "Epoch [24/50], Train Loss: 0.0280, Val Loss: 0.0262\n",
      "Epoch [25/50], Train Loss: 0.0274, Val Loss: 0.0292\n",
      "Epoch [26/50], Train Loss: 0.0267, Val Loss: 0.0327\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1264, Val Loss: 0.3453\n",
      "Epoch [2/50], Train Loss: 0.1161, Val Loss: 0.3274\n",
      "Epoch [3/50], Train Loss: 0.1061, Val Loss: 0.3077\n",
      "Epoch [4/50], Train Loss: 0.0949, Val Loss: 0.2834\n",
      "Epoch [5/50], Train Loss: 0.0814, Val Loss: 0.2502\n",
      "Epoch [6/50], Train Loss: 0.0642, Val Loss: 0.2012\n",
      "Epoch [7/50], Train Loss: 0.0456, Val Loss: 0.1380\n",
      "Epoch [8/50], Train Loss: 0.0369, Val Loss: 0.0988\n",
      "Epoch [9/50], Train Loss: 0.0362, Val Loss: 0.0864\n",
      "Epoch [10/50], Train Loss: 0.0352, Val Loss: 0.0795\n",
      "Epoch [11/50], Train Loss: 0.0343, Val Loss: 0.0740\n",
      "Epoch [12/50], Train Loss: 0.0332, Val Loss: 0.0684\n",
      "Epoch [13/50], Train Loss: 0.0320, Val Loss: 0.0620\n",
      "Epoch [14/50], Train Loss: 0.0307, Val Loss: 0.0545\n",
      "Epoch [15/50], Train Loss: 0.0293, Val Loss: 0.0459\n",
      "Epoch [16/50], Train Loss: 0.0277, Val Loss: 0.0369\n",
      "Epoch [17/50], Train Loss: 0.0261, Val Loss: 0.0290\n",
      "Epoch [18/50], Train Loss: 0.0247, Val Loss: 0.0236\n",
      "Epoch [19/50], Train Loss: 0.0235, Val Loss: 0.0204\n",
      "Epoch [20/50], Train Loss: 0.0225, Val Loss: 0.0186\n",
      "Epoch [21/50], Train Loss: 0.0217, Val Loss: 0.0178\n",
      "Epoch [22/50], Train Loss: 0.0211, Val Loss: 0.0175\n",
      "Epoch [23/50], Train Loss: 0.0206, Val Loss: 0.0177\n",
      "Epoch [24/50], Train Loss: 0.0201, Val Loss: 0.0181\n",
      "Epoch [25/50], Train Loss: 0.0196, Val Loss: 0.0187\n",
      "Epoch [26/50], Train Loss: 0.0192, Val Loss: 0.0194\n",
      "Epoch [27/50], Train Loss: 0.0188, Val Loss: 0.0201\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1153, Val Loss: 0.3233\n",
      "Epoch [2/50], Train Loss: 0.1046, Val Loss: 0.3039\n",
      "Epoch [3/50], Train Loss: 0.0941, Val Loss: 0.2826\n",
      "Epoch [4/50], Train Loss: 0.0821, Val Loss: 0.2551\n",
      "Epoch [5/50], Train Loss: 0.0682, Val Loss: 0.2156\n",
      "Epoch [6/50], Train Loss: 0.0521, Val Loss: 0.1667\n",
      "Epoch [7/50], Train Loss: 0.0436, Val Loss: 0.1312\n",
      "Epoch [8/50], Train Loss: 0.0407, Val Loss: 0.1146\n",
      "Epoch [9/50], Train Loss: 0.0399, Val Loss: 0.1042\n",
      "Epoch [10/50], Train Loss: 0.0385, Val Loss: 0.0976\n",
      "Epoch [11/50], Train Loss: 0.0385, Val Loss: 0.0927\n",
      "Epoch [12/50], Train Loss: 0.0377, Val Loss: 0.0873\n",
      "Epoch [13/50], Train Loss: 0.0364, Val Loss: 0.0824\n",
      "Epoch [14/50], Train Loss: 0.0362, Val Loss: 0.0772\n",
      "Epoch [15/50], Train Loss: 0.0343, Val Loss: 0.0717\n",
      "Epoch [16/50], Train Loss: 0.0342, Val Loss: 0.0669\n",
      "Epoch [17/50], Train Loss: 0.0328, Val Loss: 0.0611\n",
      "Epoch [18/50], Train Loss: 0.0312, Val Loss: 0.0556\n",
      "Epoch [19/50], Train Loss: 0.0303, Val Loss: 0.0491\n",
      "Epoch [20/50], Train Loss: 0.0287, Val Loss: 0.0450\n",
      "Epoch [21/50], Train Loss: 0.0280, Val Loss: 0.0403\n",
      "Epoch [22/50], Train Loss: 0.0272, Val Loss: 0.0360\n",
      "Epoch [23/50], Train Loss: 0.0266, Val Loss: 0.0339\n",
      "Epoch [24/50], Train Loss: 0.0262, Val Loss: 0.0308\n",
      "Epoch [25/50], Train Loss: 0.0251, Val Loss: 0.0292\n",
      "Epoch [26/50], Train Loss: 0.0253, Val Loss: 0.0271\n",
      "Epoch [27/50], Train Loss: 0.0248, Val Loss: 0.0265\n",
      "Epoch [28/50], Train Loss: 0.0240, Val Loss: 0.0255\n",
      "Epoch [29/50], Train Loss: 0.0238, Val Loss: 0.0245\n",
      "Epoch [30/50], Train Loss: 0.0226, Val Loss: 0.0229\n",
      "Epoch [31/50], Train Loss: 0.0231, Val Loss: 0.0236\n",
      "Epoch [32/50], Train Loss: 0.0218, Val Loss: 0.0233\n",
      "Epoch [33/50], Train Loss: 0.0217, Val Loss: 0.0225\n",
      "Epoch [34/50], Train Loss: 0.0208, Val Loss: 0.0231\n",
      "Epoch [35/50], Train Loss: 0.0202, Val Loss: 0.0223\n",
      "Epoch [36/50], Train Loss: 0.0188, Val Loss: 0.0224\n",
      "Epoch [37/50], Train Loss: 0.0174, Val Loss: 0.0225\n",
      "Epoch [38/50], Train Loss: 0.0147, Val Loss: 0.0234\n",
      "Epoch [39/50], Train Loss: 0.0131, Val Loss: 0.0227\n",
      "Epoch [40/50], Train Loss: 0.0112, Val Loss: 0.0243\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1541, Val Loss: 0.3788\n",
      "Epoch [2/50], Train Loss: 0.1403, Val Loss: 0.3494\n",
      "Epoch [3/50], Train Loss: 0.1251, Val Loss: 0.3155\n",
      "Epoch [4/50], Train Loss: 0.1043, Val Loss: 0.2716\n",
      "Epoch [5/50], Train Loss: 0.0813, Val Loss: 0.2120\n",
      "Epoch [6/50], Train Loss: 0.0654, Val Loss: 0.1480\n",
      "Epoch [7/50], Train Loss: 0.0543, Val Loss: 0.1177\n",
      "Epoch [8/50], Train Loss: 0.0545, Val Loss: 0.1123\n",
      "Epoch [9/50], Train Loss: 0.0556, Val Loss: 0.1040\n",
      "Epoch [10/50], Train Loss: 0.0532, Val Loss: 0.0976\n",
      "Epoch [11/50], Train Loss: 0.0520, Val Loss: 0.0932\n",
      "Epoch [12/50], Train Loss: 0.0500, Val Loss: 0.0877\n",
      "Epoch [13/50], Train Loss: 0.0498, Val Loss: 0.0821\n",
      "Epoch [14/50], Train Loss: 0.0499, Val Loss: 0.0767\n",
      "Epoch [15/50], Train Loss: 0.0493, Val Loss: 0.0727\n",
      "Epoch [16/50], Train Loss: 0.0454, Val Loss: 0.0644\n",
      "Epoch [17/50], Train Loss: 0.0467, Val Loss: 0.0594\n",
      "Epoch [18/50], Train Loss: 0.0449, Val Loss: 0.0536\n",
      "Epoch [19/50], Train Loss: 0.0426, Val Loss: 0.0476\n",
      "Epoch [20/50], Train Loss: 0.0420, Val Loss: 0.0426\n",
      "Epoch [21/50], Train Loss: 0.0413, Val Loss: 0.0360\n",
      "Epoch [22/50], Train Loss: 0.0396, Val Loss: 0.0324\n",
      "Epoch [23/50], Train Loss: 0.0401, Val Loss: 0.0310\n",
      "Epoch [24/50], Train Loss: 0.0390, Val Loss: 0.0298\n",
      "Epoch [25/50], Train Loss: 0.0372, Val Loss: 0.0255\n",
      "Epoch [26/50], Train Loss: 0.0374, Val Loss: 0.0245\n",
      "Epoch [27/50], Train Loss: 0.0366, Val Loss: 0.0252\n",
      "Epoch [28/50], Train Loss: 0.0362, Val Loss: 0.0230\n",
      "Epoch [29/50], Train Loss: 0.0350, Val Loss: 0.0222\n",
      "Epoch [30/50], Train Loss: 0.0343, Val Loss: 0.0219\n",
      "Epoch [31/50], Train Loss: 0.0353, Val Loss: 0.0206\n",
      "Epoch [32/50], Train Loss: 0.0357, Val Loss: 0.0213\n",
      "Epoch [33/50], Train Loss: 0.0333, Val Loss: 0.0185\n",
      "Epoch [34/50], Train Loss: 0.0325, Val Loss: 0.0195\n",
      "Epoch [35/50], Train Loss: 0.0325, Val Loss: 0.0187\n",
      "Epoch [36/50], Train Loss: 0.0300, Val Loss: 0.0170\n",
      "Epoch [37/50], Train Loss: 0.0297, Val Loss: 0.0174\n",
      "Epoch [38/50], Train Loss: 0.0296, Val Loss: 0.0159\n",
      "Epoch [39/50], Train Loss: 0.0286, Val Loss: 0.0174\n",
      "Epoch [40/50], Train Loss: 0.0272, Val Loss: 0.0188\n",
      "Epoch [41/50], Train Loss: 0.0257, Val Loss: 0.0213\n",
      "Epoch [42/50], Train Loss: 0.0248, Val Loss: 0.0246\n",
      "Epoch [43/50], Train Loss: 0.0234, Val Loss: 0.0266\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1408, Val Loss: 0.3594\n",
      "Epoch [2/50], Train Loss: 0.1237, Val Loss: 0.3250\n",
      "Epoch [3/50], Train Loss: 0.1066, Val Loss: 0.2861\n",
      "Epoch [4/50], Train Loss: 0.0873, Val Loss: 0.2366\n",
      "Epoch [5/50], Train Loss: 0.0639, Val Loss: 0.1678\n",
      "Epoch [6/50], Train Loss: 0.0374, Val Loss: 0.0821\n",
      "Epoch [7/50], Train Loss: 0.0263, Val Loss: 0.0496\n",
      "Epoch [8/50], Train Loss: 0.0255, Val Loss: 0.0436\n",
      "Epoch [9/50], Train Loss: 0.0242, Val Loss: 0.0381\n",
      "Epoch [10/50], Train Loss: 0.0233, Val Loss: 0.0345\n",
      "Epoch [11/50], Train Loss: 0.0224, Val Loss: 0.0313\n",
      "Epoch [12/50], Train Loss: 0.0216, Val Loss: 0.0286\n",
      "Epoch [13/50], Train Loss: 0.0209, Val Loss: 0.0263\n",
      "Epoch [14/50], Train Loss: 0.0202, Val Loss: 0.0243\n",
      "Epoch [15/50], Train Loss: 0.0196, Val Loss: 0.0225\n",
      "Epoch [16/50], Train Loss: 0.0191, Val Loss: 0.0210\n",
      "Epoch [17/50], Train Loss: 0.0186, Val Loss: 0.0198\n",
      "Epoch [18/50], Train Loss: 0.0181, Val Loss: 0.0186\n",
      "Epoch [19/50], Train Loss: 0.0176, Val Loss: 0.0176\n",
      "Epoch [20/50], Train Loss: 0.0172, Val Loss: 0.0166\n",
      "Epoch [21/50], Train Loss: 0.0167, Val Loss: 0.0155\n",
      "Epoch [22/50], Train Loss: 0.0162, Val Loss: 0.0144\n",
      "Epoch [23/50], Train Loss: 0.0156, Val Loss: 0.0132\n",
      "Epoch [24/50], Train Loss: 0.0150, Val Loss: 0.0117\n",
      "Epoch [25/50], Train Loss: 0.0142, Val Loss: 0.0099\n",
      "Epoch [26/50], Train Loss: 0.0133, Val Loss: 0.0077\n",
      "Epoch [27/50], Train Loss: 0.0120, Val Loss: 0.0054\n",
      "Epoch [28/50], Train Loss: 0.0103, Val Loss: 0.0045\n",
      "Epoch [29/50], Train Loss: 0.0085, Val Loss: 0.0064\n",
      "Epoch [30/50], Train Loss: 0.0073, Val Loss: 0.0091\n",
      "Epoch [31/50], Train Loss: 0.0065, Val Loss: 0.0108\n",
      "Epoch [32/50], Train Loss: 0.0058, Val Loss: 0.0118\n",
      "Epoch [33/50], Train Loss: 0.0053, Val Loss: 0.0126\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1122, Val Loss: 0.3145\n",
      "Epoch [2/50], Train Loss: 0.0963, Val Loss: 0.2802\n",
      "Epoch [3/50], Train Loss: 0.0815, Val Loss: 0.2432\n",
      "Epoch [4/50], Train Loss: 0.0661, Val Loss: 0.2006\n",
      "Epoch [5/50], Train Loss: 0.0508, Val Loss: 0.1509\n",
      "Epoch [6/50], Train Loss: 0.0379, Val Loss: 0.1005\n",
      "Epoch [7/50], Train Loss: 0.0312, Val Loss: 0.0680\n",
      "Epoch [8/50], Train Loss: 0.0294, Val Loss: 0.0532\n",
      "Epoch [9/50], Train Loss: 0.0288, Val Loss: 0.0450\n",
      "Epoch [10/50], Train Loss: 0.0269, Val Loss: 0.0377\n",
      "Epoch [11/50], Train Loss: 0.0256, Val Loss: 0.0319\n",
      "Epoch [12/50], Train Loss: 0.0250, Val Loss: 0.0267\n",
      "Epoch [13/50], Train Loss: 0.0246, Val Loss: 0.0240\n",
      "Epoch [14/50], Train Loss: 0.0234, Val Loss: 0.0201\n",
      "Epoch [15/50], Train Loss: 0.0225, Val Loss: 0.0167\n",
      "Epoch [16/50], Train Loss: 0.0219, Val Loss: 0.0148\n",
      "Epoch [17/50], Train Loss: 0.0209, Val Loss: 0.0129\n",
      "Epoch [18/50], Train Loss: 0.0202, Val Loss: 0.0119\n",
      "Epoch [19/50], Train Loss: 0.0196, Val Loss: 0.0114\n",
      "Epoch [20/50], Train Loss: 0.0187, Val Loss: 0.0107\n",
      "Epoch [21/50], Train Loss: 0.0182, Val Loss: 0.0107\n",
      "Epoch [22/50], Train Loss: 0.0177, Val Loss: 0.0099\n",
      "Epoch [23/50], Train Loss: 0.0175, Val Loss: 0.0095\n",
      "Epoch [24/50], Train Loss: 0.0164, Val Loss: 0.0112\n",
      "Epoch [25/50], Train Loss: 0.0159, Val Loss: 0.0092\n",
      "Epoch [26/50], Train Loss: 0.0153, Val Loss: 0.0092\n",
      "Epoch [27/50], Train Loss: 0.0150, Val Loss: 0.0108\n",
      "Epoch [28/50], Train Loss: 0.0141, Val Loss: 0.0092\n",
      "Epoch [29/50], Train Loss: 0.0135, Val Loss: 0.0118\n",
      "Epoch [30/50], Train Loss: 0.0126, Val Loss: 0.0130\n",
      "Epoch [31/50], Train Loss: 0.0114, Val Loss: 0.0157\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1203, Val Loss: 0.3360\n",
      "Epoch [2/50], Train Loss: 0.1068, Val Loss: 0.3052\n",
      "Epoch [3/50], Train Loss: 0.0932, Val Loss: 0.2740\n",
      "Epoch [4/50], Train Loss: 0.0811, Val Loss: 0.2394\n",
      "Epoch [5/50], Train Loss: 0.0679, Val Loss: 0.1984\n",
      "Epoch [6/50], Train Loss: 0.0540, Val Loss: 0.1477\n",
      "Epoch [7/50], Train Loss: 0.0422, Val Loss: 0.0949\n",
      "Epoch [8/50], Train Loss: 0.0400, Val Loss: 0.0715\n",
      "Epoch [9/50], Train Loss: 0.0373, Val Loss: 0.0628\n",
      "Epoch [10/50], Train Loss: 0.0377, Val Loss: 0.0554\n",
      "Epoch [11/50], Train Loss: 0.0362, Val Loss: 0.0485\n",
      "Epoch [12/50], Train Loss: 0.0350, Val Loss: 0.0448\n",
      "Epoch [13/50], Train Loss: 0.0331, Val Loss: 0.0385\n",
      "Epoch [14/50], Train Loss: 0.0320, Val Loss: 0.0332\n",
      "Epoch [15/50], Train Loss: 0.0315, Val Loss: 0.0268\n",
      "Epoch [16/50], Train Loss: 0.0304, Val Loss: 0.0218\n",
      "Epoch [17/50], Train Loss: 0.0290, Val Loss: 0.0166\n",
      "Epoch [18/50], Train Loss: 0.0276, Val Loss: 0.0123\n",
      "Epoch [19/50], Train Loss: 0.0269, Val Loss: 0.0091\n",
      "Epoch [20/50], Train Loss: 0.0261, Val Loss: 0.0077\n",
      "Epoch [21/50], Train Loss: 0.0235, Val Loss: 0.0075\n",
      "Epoch [22/50], Train Loss: 0.0239, Val Loss: 0.0065\n",
      "Epoch [23/50], Train Loss: 0.0214, Val Loss: 0.0101\n",
      "Epoch [24/50], Train Loss: 0.0207, Val Loss: 0.0119\n",
      "Epoch [25/50], Train Loss: 0.0190, Val Loss: 0.0165\n",
      "Epoch [26/50], Train Loss: 0.0183, Val Loss: 0.0217\n",
      "Epoch [27/50], Train Loss: 0.0167, Val Loss: 0.0219\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1342, Val Loss: 0.3471\n",
      "Epoch [2/50], Train Loss: 0.1134, Val Loss: 0.3051\n",
      "Epoch [3/50], Train Loss: 0.0883, Val Loss: 0.2398\n",
      "Epoch [4/50], Train Loss: 0.0515, Val Loss: 0.1216\n",
      "Epoch [5/50], Train Loss: 0.0290, Val Loss: 0.0598\n",
      "Epoch [6/50], Train Loss: 0.0311, Val Loss: 0.0523\n",
      "Epoch [7/50], Train Loss: 0.0290, Val Loss: 0.0460\n",
      "Epoch [8/50], Train Loss: 0.0274, Val Loss: 0.0406\n",
      "Epoch [9/50], Train Loss: 0.0259, Val Loss: 0.0352\n",
      "Epoch [10/50], Train Loss: 0.0245, Val Loss: 0.0303\n",
      "Epoch [11/50], Train Loss: 0.0233, Val Loss: 0.0263\n",
      "Epoch [12/50], Train Loss: 0.0221, Val Loss: 0.0231\n",
      "Epoch [13/50], Train Loss: 0.0212, Val Loss: 0.0209\n",
      "Epoch [14/50], Train Loss: 0.0205, Val Loss: 0.0193\n",
      "Epoch [15/50], Train Loss: 0.0199, Val Loss: 0.0180\n",
      "Epoch [16/50], Train Loss: 0.0193, Val Loss: 0.0168\n",
      "Epoch [17/50], Train Loss: 0.0187, Val Loss: 0.0156\n",
      "Epoch [18/50], Train Loss: 0.0182, Val Loss: 0.0143\n",
      "Epoch [19/50], Train Loss: 0.0176, Val Loss: 0.0130\n",
      "Epoch [20/50], Train Loss: 0.0170, Val Loss: 0.0117\n",
      "Epoch [21/50], Train Loss: 0.0164, Val Loss: 0.0104\n",
      "Epoch [22/50], Train Loss: 0.0156, Val Loss: 0.0092\n",
      "Epoch [23/50], Train Loss: 0.0147, Val Loss: 0.0081\n",
      "Epoch [24/50], Train Loss: 0.0136, Val Loss: 0.0074\n",
      "Epoch [25/50], Train Loss: 0.0122, Val Loss: 0.0082\n",
      "Epoch [26/50], Train Loss: 0.0104, Val Loss: 0.0122\n",
      "Epoch [27/50], Train Loss: 0.0085, Val Loss: 0.0181\n",
      "Epoch [28/50], Train Loss: 0.0069, Val Loss: 0.0218\n",
      "Epoch [29/50], Train Loss: 0.0058, Val Loss: 0.0223\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1333, Val Loss: 0.3486\n",
      "Epoch [2/50], Train Loss: 0.1138, Val Loss: 0.3121\n",
      "Epoch [3/50], Train Loss: 0.0948, Val Loss: 0.2655\n",
      "Epoch [4/50], Train Loss: 0.0700, Val Loss: 0.1914\n",
      "Epoch [5/50], Train Loss: 0.0405, Val Loss: 0.0857\n",
      "Epoch [6/50], Train Loss: 0.0349, Val Loss: 0.0625\n",
      "Epoch [7/50], Train Loss: 0.0352, Val Loss: 0.0588\n",
      "Epoch [8/50], Train Loss: 0.0339, Val Loss: 0.0524\n",
      "Epoch [9/50], Train Loss: 0.0319, Val Loss: 0.0466\n",
      "Epoch [10/50], Train Loss: 0.0310, Val Loss: 0.0407\n",
      "Epoch [11/50], Train Loss: 0.0298, Val Loss: 0.0341\n",
      "Epoch [12/50], Train Loss: 0.0285, Val Loss: 0.0278\n",
      "Epoch [13/50], Train Loss: 0.0267, Val Loss: 0.0216\n",
      "Epoch [14/50], Train Loss: 0.0254, Val Loss: 0.0160\n",
      "Epoch [15/50], Train Loss: 0.0238, Val Loss: 0.0100\n",
      "Epoch [16/50], Train Loss: 0.0214, Val Loss: 0.0065\n",
      "Epoch [17/50], Train Loss: 0.0190, Val Loss: 0.0090\n",
      "Epoch [18/50], Train Loss: 0.0158, Val Loss: 0.0289\n",
      "Epoch [19/50], Train Loss: 0.0124, Val Loss: 0.0368\n",
      "Epoch [20/50], Train Loss: 0.0112, Val Loss: 0.0456\n",
      "Epoch [21/50], Train Loss: 0.0102, Val Loss: 0.0537\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1420, Val Loss: 0.3528\n",
      "Epoch [2/50], Train Loss: 0.1180, Val Loss: 0.3024\n",
      "Epoch [3/50], Train Loss: 0.0910, Val Loss: 0.2325\n",
      "Epoch [4/50], Train Loss: 0.0606, Val Loss: 0.1311\n",
      "Epoch [5/50], Train Loss: 0.0435, Val Loss: 0.0742\n",
      "Epoch [6/50], Train Loss: 0.0413, Val Loss: 0.0679\n",
      "Epoch [7/50], Train Loss: 0.0408, Val Loss: 0.0598\n",
      "Epoch [8/50], Train Loss: 0.0409, Val Loss: 0.0518\n",
      "Epoch [9/50], Train Loss: 0.0379, Val Loss: 0.0440\n",
      "Epoch [10/50], Train Loss: 0.0366, Val Loss: 0.0384\n",
      "Epoch [11/50], Train Loss: 0.0340, Val Loss: 0.0319\n",
      "Epoch [12/50], Train Loss: 0.0335, Val Loss: 0.0282\n",
      "Epoch [13/50], Train Loss: 0.0329, Val Loss: 0.0244\n",
      "Epoch [14/50], Train Loss: 0.0304, Val Loss: 0.0219\n",
      "Epoch [15/50], Train Loss: 0.0300, Val Loss: 0.0206\n",
      "Epoch [16/50], Train Loss: 0.0291, Val Loss: 0.0188\n",
      "Epoch [17/50], Train Loss: 0.0284, Val Loss: 0.0178\n",
      "Epoch [18/50], Train Loss: 0.0294, Val Loss: 0.0171\n",
      "Epoch [19/50], Train Loss: 0.0276, Val Loss: 0.0154\n",
      "Epoch [20/50], Train Loss: 0.0268, Val Loss: 0.0144\n",
      "Epoch [21/50], Train Loss: 0.0266, Val Loss: 0.0124\n",
      "Epoch [22/50], Train Loss: 0.0254, Val Loss: 0.0107\n",
      "Epoch [23/50], Train Loss: 0.0243, Val Loss: 0.0083\n",
      "Epoch [24/50], Train Loss: 0.0229, Val Loss: 0.0058\n",
      "Epoch [25/50], Train Loss: 0.0217, Val Loss: 0.0042\n",
      "Epoch [26/50], Train Loss: 0.0199, Val Loss: 0.0031\n",
      "Epoch [27/50], Train Loss: 0.0183, Val Loss: 0.0044\n",
      "Epoch [28/50], Train Loss: 0.0183, Val Loss: 0.0059\n",
      "Epoch [29/50], Train Loss: 0.0159, Val Loss: 0.0061\n",
      "Epoch [30/50], Train Loss: 0.0155, Val Loss: 0.0097\n",
      "Epoch [31/50], Train Loss: 0.0166, Val Loss: 0.0073\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1198, Val Loss: 0.3050\n",
      "Epoch [2/50], Train Loss: 0.0992, Val Loss: 0.2615\n",
      "Epoch [3/50], Train Loss: 0.0720, Val Loss: 0.1835\n",
      "Epoch [4/50], Train Loss: 0.0401, Val Loss: 0.0839\n",
      "Epoch [5/50], Train Loss: 0.0372, Val Loss: 0.0741\n",
      "Epoch [6/50], Train Loss: 0.0352, Val Loss: 0.0672\n",
      "Epoch [7/50], Train Loss: 0.0341, Val Loss: 0.0623\n",
      "Epoch [8/50], Train Loss: 0.0327, Val Loss: 0.0568\n",
      "Epoch [9/50], Train Loss: 0.0314, Val Loss: 0.0508\n",
      "Epoch [10/50], Train Loss: 0.0299, Val Loss: 0.0444\n",
      "Epoch [11/50], Train Loss: 0.0284, Val Loss: 0.0379\n",
      "Epoch [12/50], Train Loss: 0.0269, Val Loss: 0.0319\n",
      "Epoch [13/50], Train Loss: 0.0253, Val Loss: 0.0268\n",
      "Epoch [14/50], Train Loss: 0.0240, Val Loss: 0.0235\n",
      "Epoch [15/50], Train Loss: 0.0230, Val Loss: 0.0221\n",
      "Epoch [16/50], Train Loss: 0.0223, Val Loss: 0.0221\n",
      "Epoch [17/50], Train Loss: 0.0217, Val Loss: 0.0222\n",
      "Epoch [18/50], Train Loss: 0.0212, Val Loss: 0.0218\n",
      "Epoch [19/50], Train Loss: 0.0207, Val Loss: 0.0210\n",
      "Epoch [20/50], Train Loss: 0.0201, Val Loss: 0.0201\n",
      "Epoch [21/50], Train Loss: 0.0194, Val Loss: 0.0191\n",
      "Epoch [22/50], Train Loss: 0.0184, Val Loss: 0.0184\n",
      "Epoch [23/50], Train Loss: 0.0168, Val Loss: 0.0188\n",
      "Epoch [24/50], Train Loss: 0.0136, Val Loss: 0.0235\n",
      "Epoch [25/50], Train Loss: 0.0079, Val Loss: 0.0306\n",
      "Epoch [26/50], Train Loss: 0.0060, Val Loss: 0.0316\n",
      "Epoch [27/50], Train Loss: 0.0054, Val Loss: 0.0285\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1305, Val Loss: 0.3439\n",
      "Epoch [2/50], Train Loss: 0.1040, Val Loss: 0.2860\n",
      "Epoch [3/50], Train Loss: 0.0697, Val Loss: 0.1880\n",
      "Epoch [4/50], Train Loss: 0.0393, Val Loss: 0.0874\n",
      "Epoch [5/50], Train Loss: 0.0423, Val Loss: 0.0878\n",
      "Epoch [6/50], Train Loss: 0.0383, Val Loss: 0.0755\n",
      "Epoch [7/50], Train Loss: 0.0375, Val Loss: 0.0682\n",
      "Epoch [8/50], Train Loss: 0.0354, Val Loss: 0.0596\n",
      "Epoch [9/50], Train Loss: 0.0341, Val Loss: 0.0517\n",
      "Epoch [10/50], Train Loss: 0.0321, Val Loss: 0.0439\n",
      "Epoch [11/50], Train Loss: 0.0301, Val Loss: 0.0362\n",
      "Epoch [12/50], Train Loss: 0.0285, Val Loss: 0.0309\n",
      "Epoch [13/50], Train Loss: 0.0270, Val Loss: 0.0275\n",
      "Epoch [14/50], Train Loss: 0.0260, Val Loss: 0.0262\n",
      "Epoch [15/50], Train Loss: 0.0249, Val Loss: 0.0257\n",
      "Epoch [16/50], Train Loss: 0.0246, Val Loss: 0.0254\n",
      "Epoch [17/50], Train Loss: 0.0243, Val Loss: 0.0249\n",
      "Epoch [18/50], Train Loss: 0.0243, Val Loss: 0.0244\n",
      "Epoch [19/50], Train Loss: 0.0237, Val Loss: 0.0229\n",
      "Epoch [20/50], Train Loss: 0.0240, Val Loss: 0.0235\n",
      "Epoch [21/50], Train Loss: 0.0236, Val Loss: 0.0236\n",
      "Epoch [22/50], Train Loss: 0.0230, Val Loss: 0.0231\n",
      "Epoch [23/50], Train Loss: 0.0227, Val Loss: 0.0230\n",
      "Epoch [24/50], Train Loss: 0.0227, Val Loss: 0.0222\n",
      "Epoch [25/50], Train Loss: 0.0219, Val Loss: 0.0212\n",
      "Epoch [26/50], Train Loss: 0.0217, Val Loss: 0.0209\n",
      "Epoch [27/50], Train Loss: 0.0218, Val Loss: 0.0214\n",
      "Epoch [28/50], Train Loss: 0.0218, Val Loss: 0.0213\n",
      "Epoch [29/50], Train Loss: 0.0208, Val Loss: 0.0204\n",
      "Epoch [30/50], Train Loss: 0.0204, Val Loss: 0.0198\n",
      "Epoch [31/50], Train Loss: 0.0196, Val Loss: 0.0196\n",
      "Epoch [32/50], Train Loss: 0.0194, Val Loss: 0.0220\n",
      "Epoch [33/50], Train Loss: 0.0179, Val Loss: 0.0216\n",
      "Epoch [34/50], Train Loss: 0.0143, Val Loss: 0.0228\n",
      "Epoch [35/50], Train Loss: 0.0107, Val Loss: 0.0236\n",
      "Epoch [36/50], Train Loss: 0.0096, Val Loss: 0.0240\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adam, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1644, Val Loss: 0.3909\n",
      "Epoch [2/50], Train Loss: 0.1388, Val Loss: 0.3445\n",
      "Epoch [3/50], Train Loss: 0.1095, Val Loss: 0.2664\n",
      "Epoch [4/50], Train Loss: 0.0635, Val Loss: 0.0987\n",
      "Epoch [5/50], Train Loss: 0.0491, Val Loss: 0.0737\n",
      "Epoch [6/50], Train Loss: 0.0487, Val Loss: 0.0759\n",
      "Epoch [7/50], Train Loss: 0.0465, Val Loss: 0.0693\n",
      "Epoch [8/50], Train Loss: 0.0444, Val Loss: 0.0596\n",
      "Epoch [9/50], Train Loss: 0.0418, Val Loss: 0.0562\n",
      "Epoch [10/50], Train Loss: 0.0388, Val Loss: 0.0498\n",
      "Epoch [11/50], Train Loss: 0.0385, Val Loss: 0.0420\n",
      "Epoch [12/50], Train Loss: 0.0371, Val Loss: 0.0348\n",
      "Epoch [13/50], Train Loss: 0.0348, Val Loss: 0.0288\n",
      "Epoch [14/50], Train Loss: 0.0336, Val Loss: 0.0227\n",
      "Epoch [15/50], Train Loss: 0.0319, Val Loss: 0.0216\n",
      "Epoch [16/50], Train Loss: 0.0310, Val Loss: 0.0205\n",
      "Epoch [17/50], Train Loss: 0.0311, Val Loss: 0.0225\n",
      "Epoch [18/50], Train Loss: 0.0303, Val Loss: 0.0190\n",
      "Epoch [19/50], Train Loss: 0.0286, Val Loss: 0.0161\n",
      "Epoch [20/50], Train Loss: 0.0305, Val Loss: 0.0170\n",
      "Epoch [21/50], Train Loss: 0.0270, Val Loss: 0.0108\n",
      "Epoch [22/50], Train Loss: 0.0262, Val Loss: 0.0100\n",
      "Epoch [23/50], Train Loss: 0.0240, Val Loss: 0.0062\n",
      "Epoch [24/50], Train Loss: 0.0217, Val Loss: 0.0039\n",
      "Epoch [25/50], Train Loss: 0.0191, Val Loss: 0.0029\n",
      "Epoch [26/50], Train Loss: 0.0174, Val Loss: 0.0045\n",
      "Epoch [27/50], Train Loss: 0.0167, Val Loss: 0.0050\n",
      "Epoch [28/50], Train Loss: 0.0161, Val Loss: 0.0055\n",
      "Epoch [29/50], Train Loss: 0.0159, Val Loss: 0.0046\n",
      "Epoch [30/50], Train Loss: 0.0159, Val Loss: 0.0086\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1746, Val Loss: 0.4169\n",
      "Epoch [2/50], Train Loss: 0.1741, Val Loss: 0.4162\n",
      "Epoch [3/50], Train Loss: 0.1736, Val Loss: 0.4154\n",
      "Epoch [4/50], Train Loss: 0.1732, Val Loss: 0.4146\n",
      "Epoch [5/50], Train Loss: 0.1727, Val Loss: 0.4139\n",
      "Epoch [6/50], Train Loss: 0.1722, Val Loss: 0.4131\n",
      "Epoch [7/50], Train Loss: 0.1718, Val Loss: 0.4124\n",
      "Epoch [8/50], Train Loss: 0.1713, Val Loss: 0.4116\n",
      "Epoch [9/50], Train Loss: 0.1708, Val Loss: 0.4108\n",
      "Epoch [10/50], Train Loss: 0.1704, Val Loss: 0.4101\n",
      "Epoch [11/50], Train Loss: 0.1699, Val Loss: 0.4093\n",
      "Epoch [12/50], Train Loss: 0.1694, Val Loss: 0.4086\n",
      "Epoch [13/50], Train Loss: 0.1690, Val Loss: 0.4078\n",
      "Epoch [14/50], Train Loss: 0.1685, Val Loss: 0.4071\n",
      "Epoch [15/50], Train Loss: 0.1681, Val Loss: 0.4063\n",
      "Epoch [16/50], Train Loss: 0.1676, Val Loss: 0.4056\n",
      "Epoch [17/50], Train Loss: 0.1672, Val Loss: 0.4049\n",
      "Epoch [18/50], Train Loss: 0.1667, Val Loss: 0.4041\n",
      "Epoch [19/50], Train Loss: 0.1663, Val Loss: 0.4034\n",
      "Epoch [20/50], Train Loss: 0.1658, Val Loss: 0.4027\n",
      "Epoch [21/50], Train Loss: 0.1654, Val Loss: 0.4019\n",
      "Epoch [22/50], Train Loss: 0.1649, Val Loss: 0.4012\n",
      "Epoch [23/50], Train Loss: 0.1645, Val Loss: 0.4005\n",
      "Epoch [24/50], Train Loss: 0.1641, Val Loss: 0.3997\n",
      "Epoch [25/50], Train Loss: 0.1636, Val Loss: 0.3990\n",
      "Epoch [26/50], Train Loss: 0.1632, Val Loss: 0.3983\n",
      "Epoch [27/50], Train Loss: 0.1627, Val Loss: 0.3976\n",
      "Epoch [28/50], Train Loss: 0.1623, Val Loss: 0.3969\n",
      "Epoch [29/50], Train Loss: 0.1619, Val Loss: 0.3961\n",
      "Epoch [30/50], Train Loss: 0.1615, Val Loss: 0.3954\n",
      "Epoch [31/50], Train Loss: 0.1610, Val Loss: 0.3947\n",
      "Epoch [32/50], Train Loss: 0.1606, Val Loss: 0.3940\n",
      "Epoch [33/50], Train Loss: 0.1602, Val Loss: 0.3933\n",
      "Epoch [34/50], Train Loss: 0.1597, Val Loss: 0.3926\n",
      "Epoch [35/50], Train Loss: 0.1593, Val Loss: 0.3919\n",
      "Epoch [36/50], Train Loss: 0.1589, Val Loss: 0.3912\n",
      "Epoch [37/50], Train Loss: 0.1585, Val Loss: 0.3905\n",
      "Epoch [38/50], Train Loss: 0.1581, Val Loss: 0.3898\n",
      "Epoch [39/50], Train Loss: 0.1576, Val Loss: 0.3891\n",
      "Epoch [40/50], Train Loss: 0.1572, Val Loss: 0.3884\n",
      "Epoch [41/50], Train Loss: 0.1568, Val Loss: 0.3877\n",
      "Epoch [42/50], Train Loss: 0.1564, Val Loss: 0.3870\n",
      "Epoch [43/50], Train Loss: 0.1560, Val Loss: 0.3863\n",
      "Epoch [44/50], Train Loss: 0.1556, Val Loss: 0.3857\n",
      "Epoch [45/50], Train Loss: 0.1552, Val Loss: 0.3850\n",
      "Epoch [46/50], Train Loss: 0.1548, Val Loss: 0.3843\n",
      "Epoch [47/50], Train Loss: 0.1543, Val Loss: 0.3836\n",
      "Epoch [48/50], Train Loss: 0.1539, Val Loss: 0.3829\n",
      "Epoch [49/50], Train Loss: 0.1535, Val Loss: 0.3823\n",
      "Epoch [50/50], Train Loss: 0.1531, Val Loss: 0.3816\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1264, Val Loss: 0.3506\n",
      "Epoch [2/50], Train Loss: 0.1265, Val Loss: 0.3500\n",
      "Epoch [3/50], Train Loss: 0.1257, Val Loss: 0.3494\n",
      "Epoch [4/50], Train Loss: 0.1259, Val Loss: 0.3488\n",
      "Epoch [5/50], Train Loss: 0.1257, Val Loss: 0.3482\n",
      "Epoch [6/50], Train Loss: 0.1250, Val Loss: 0.3477\n",
      "Epoch [7/50], Train Loss: 0.1248, Val Loss: 0.3471\n",
      "Epoch [8/50], Train Loss: 0.1241, Val Loss: 0.3465\n",
      "Epoch [9/50], Train Loss: 0.1249, Val Loss: 0.3459\n",
      "Epoch [10/50], Train Loss: 0.1241, Val Loss: 0.3453\n",
      "Epoch [11/50], Train Loss: 0.1235, Val Loss: 0.3448\n",
      "Epoch [12/50], Train Loss: 0.1234, Val Loss: 0.3442\n",
      "Epoch [13/50], Train Loss: 0.1230, Val Loss: 0.3436\n",
      "Epoch [14/50], Train Loss: 0.1222, Val Loss: 0.3430\n",
      "Epoch [15/50], Train Loss: 0.1220, Val Loss: 0.3425\n",
      "Epoch [16/50], Train Loss: 0.1218, Val Loss: 0.3419\n",
      "Epoch [17/50], Train Loss: 0.1214, Val Loss: 0.3413\n",
      "Epoch [18/50], Train Loss: 0.1222, Val Loss: 0.3408\n",
      "Epoch [19/50], Train Loss: 0.1209, Val Loss: 0.3402\n",
      "Epoch [20/50], Train Loss: 0.1212, Val Loss: 0.3396\n",
      "Epoch [21/50], Train Loss: 0.1204, Val Loss: 0.3391\n",
      "Epoch [22/50], Train Loss: 0.1205, Val Loss: 0.3385\n",
      "Epoch [23/50], Train Loss: 0.1200, Val Loss: 0.3380\n",
      "Epoch [24/50], Train Loss: 0.1202, Val Loss: 0.3374\n",
      "Epoch [25/50], Train Loss: 0.1199, Val Loss: 0.3369\n",
      "Epoch [26/50], Train Loss: 0.1190, Val Loss: 0.3363\n",
      "Epoch [27/50], Train Loss: 0.1189, Val Loss: 0.3358\n",
      "Epoch [28/50], Train Loss: 0.1194, Val Loss: 0.3352\n",
      "Epoch [29/50], Train Loss: 0.1181, Val Loss: 0.3346\n",
      "Epoch [30/50], Train Loss: 0.1188, Val Loss: 0.3341\n",
      "Epoch [31/50], Train Loss: 0.1176, Val Loss: 0.3335\n",
      "Epoch [32/50], Train Loss: 0.1179, Val Loss: 0.3330\n",
      "Epoch [33/50], Train Loss: 0.1175, Val Loss: 0.3325\n",
      "Epoch [34/50], Train Loss: 0.1171, Val Loss: 0.3319\n",
      "Epoch [35/50], Train Loss: 0.1175, Val Loss: 0.3314\n",
      "Epoch [36/50], Train Loss: 0.1164, Val Loss: 0.3308\n",
      "Epoch [37/50], Train Loss: 0.1167, Val Loss: 0.3303\n",
      "Epoch [38/50], Train Loss: 0.1157, Val Loss: 0.3298\n",
      "Epoch [39/50], Train Loss: 0.1165, Val Loss: 0.3292\n",
      "Epoch [40/50], Train Loss: 0.1148, Val Loss: 0.3287\n",
      "Epoch [41/50], Train Loss: 0.1140, Val Loss: 0.3282\n",
      "Epoch [42/50], Train Loss: 0.1149, Val Loss: 0.3276\n",
      "Epoch [43/50], Train Loss: 0.1149, Val Loss: 0.3271\n",
      "Epoch [44/50], Train Loss: 0.1148, Val Loss: 0.3265\n",
      "Epoch [45/50], Train Loss: 0.1137, Val Loss: 0.3260\n",
      "Epoch [46/50], Train Loss: 0.1139, Val Loss: 0.3255\n",
      "Epoch [47/50], Train Loss: 0.1128, Val Loss: 0.3250\n",
      "Epoch [48/50], Train Loss: 0.1132, Val Loss: 0.3245\n",
      "Epoch [49/50], Train Loss: 0.1129, Val Loss: 0.3239\n",
      "Epoch [50/50], Train Loss: 0.1130, Val Loss: 0.3234\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1234, Val Loss: 0.3073\n",
      "Epoch [2/50], Train Loss: 0.1230, Val Loss: 0.3069\n",
      "Epoch [3/50], Train Loss: 0.1215, Val Loss: 0.3065\n",
      "Epoch [4/50], Train Loss: 0.1232, Val Loss: 0.3060\n",
      "Epoch [5/50], Train Loss: 0.1205, Val Loss: 0.3056\n",
      "Epoch [6/50], Train Loss: 0.1205, Val Loss: 0.3052\n",
      "Epoch [7/50], Train Loss: 0.1204, Val Loss: 0.3048\n",
      "Epoch [8/50], Train Loss: 0.1211, Val Loss: 0.3044\n",
      "Epoch [9/50], Train Loss: 0.1198, Val Loss: 0.3039\n",
      "Epoch [10/50], Train Loss: 0.1200, Val Loss: 0.3035\n",
      "Epoch [11/50], Train Loss: 0.1177, Val Loss: 0.3031\n",
      "Epoch [12/50], Train Loss: 0.1200, Val Loss: 0.3027\n",
      "Epoch [13/50], Train Loss: 0.1188, Val Loss: 0.3023\n",
      "Epoch [14/50], Train Loss: 0.1202, Val Loss: 0.3019\n",
      "Epoch [15/50], Train Loss: 0.1184, Val Loss: 0.3015\n",
      "Epoch [16/50], Train Loss: 0.1184, Val Loss: 0.3010\n",
      "Epoch [17/50], Train Loss: 0.1189, Val Loss: 0.3006\n",
      "Epoch [18/50], Train Loss: 0.1174, Val Loss: 0.3002\n",
      "Epoch [19/50], Train Loss: 0.1176, Val Loss: 0.2998\n",
      "Epoch [20/50], Train Loss: 0.1166, Val Loss: 0.2994\n",
      "Epoch [21/50], Train Loss: 0.1181, Val Loss: 0.2990\n",
      "Epoch [22/50], Train Loss: 0.1170, Val Loss: 0.2986\n",
      "Epoch [23/50], Train Loss: 0.1174, Val Loss: 0.2982\n",
      "Epoch [24/50], Train Loss: 0.1180, Val Loss: 0.2978\n",
      "Epoch [25/50], Train Loss: 0.1148, Val Loss: 0.2974\n",
      "Epoch [26/50], Train Loss: 0.1175, Val Loss: 0.2970\n",
      "Epoch [27/50], Train Loss: 0.1166, Val Loss: 0.2966\n",
      "Epoch [28/50], Train Loss: 0.1166, Val Loss: 0.2962\n",
      "Epoch [29/50], Train Loss: 0.1168, Val Loss: 0.2958\n",
      "Epoch [30/50], Train Loss: 0.1153, Val Loss: 0.2954\n",
      "Epoch [31/50], Train Loss: 0.1151, Val Loss: 0.2950\n",
      "Epoch [32/50], Train Loss: 0.1149, Val Loss: 0.2946\n",
      "Epoch [33/50], Train Loss: 0.1152, Val Loss: 0.2942\n",
      "Epoch [34/50], Train Loss: 0.1151, Val Loss: 0.2938\n",
      "Epoch [35/50], Train Loss: 0.1163, Val Loss: 0.2934\n",
      "Epoch [36/50], Train Loss: 0.1157, Val Loss: 0.2930\n",
      "Epoch [37/50], Train Loss: 0.1153, Val Loss: 0.2926\n",
      "Epoch [38/50], Train Loss: 0.1137, Val Loss: 0.2922\n",
      "Epoch [39/50], Train Loss: 0.1145, Val Loss: 0.2918\n",
      "Epoch [40/50], Train Loss: 0.1126, Val Loss: 0.2914\n",
      "Epoch [41/50], Train Loss: 0.1133, Val Loss: 0.2910\n",
      "Epoch [42/50], Train Loss: 0.1127, Val Loss: 0.2907\n",
      "Epoch [43/50], Train Loss: 0.1131, Val Loss: 0.2903\n",
      "Epoch [44/50], Train Loss: 0.1132, Val Loss: 0.2899\n",
      "Epoch [45/50], Train Loss: 0.1135, Val Loss: 0.2895\n",
      "Epoch [46/50], Train Loss: 0.1115, Val Loss: 0.2891\n",
      "Epoch [47/50], Train Loss: 0.1123, Val Loss: 0.2887\n",
      "Epoch [48/50], Train Loss: 0.1123, Val Loss: 0.2883\n",
      "Epoch [49/50], Train Loss: 0.1126, Val Loss: 0.2880\n",
      "Epoch [50/50], Train Loss: 0.1103, Val Loss: 0.2876\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1924, Val Loss: 0.4058\n",
      "Epoch [2/50], Train Loss: 0.1919, Val Loss: 0.4052\n",
      "Epoch [3/50], Train Loss: 0.1914, Val Loss: 0.4045\n",
      "Epoch [4/50], Train Loss: 0.1910, Val Loss: 0.4039\n",
      "Epoch [5/50], Train Loss: 0.1905, Val Loss: 0.4032\n",
      "Epoch [6/50], Train Loss: 0.1901, Val Loss: 0.4026\n",
      "Epoch [7/50], Train Loss: 0.1896, Val Loss: 0.4020\n",
      "Epoch [8/50], Train Loss: 0.1892, Val Loss: 0.4013\n",
      "Epoch [9/50], Train Loss: 0.1887, Val Loss: 0.4007\n",
      "Epoch [10/50], Train Loss: 0.1883, Val Loss: 0.4000\n",
      "Epoch [11/50], Train Loss: 0.1878, Val Loss: 0.3994\n",
      "Epoch [12/50], Train Loss: 0.1874, Val Loss: 0.3988\n",
      "Epoch [13/50], Train Loss: 0.1869, Val Loss: 0.3981\n",
      "Epoch [14/50], Train Loss: 0.1865, Val Loss: 0.3975\n",
      "Epoch [15/50], Train Loss: 0.1860, Val Loss: 0.3969\n",
      "Epoch [16/50], Train Loss: 0.1856, Val Loss: 0.3963\n",
      "Epoch [17/50], Train Loss: 0.1851, Val Loss: 0.3956\n",
      "Epoch [18/50], Train Loss: 0.1847, Val Loss: 0.3950\n",
      "Epoch [19/50], Train Loss: 0.1842, Val Loss: 0.3944\n",
      "Epoch [20/50], Train Loss: 0.1838, Val Loss: 0.3938\n",
      "Epoch [21/50], Train Loss: 0.1834, Val Loss: 0.3932\n",
      "Epoch [22/50], Train Loss: 0.1829, Val Loss: 0.3926\n",
      "Epoch [23/50], Train Loss: 0.1825, Val Loss: 0.3919\n",
      "Epoch [24/50], Train Loss: 0.1821, Val Loss: 0.3913\n",
      "Epoch [25/50], Train Loss: 0.1816, Val Loss: 0.3907\n",
      "Epoch [26/50], Train Loss: 0.1812, Val Loss: 0.3901\n",
      "Epoch [27/50], Train Loss: 0.1808, Val Loss: 0.3895\n",
      "Epoch [28/50], Train Loss: 0.1804, Val Loss: 0.3889\n",
      "Epoch [29/50], Train Loss: 0.1799, Val Loss: 0.3883\n",
      "Epoch [30/50], Train Loss: 0.1795, Val Loss: 0.3877\n",
      "Epoch [31/50], Train Loss: 0.1791, Val Loss: 0.3871\n",
      "Epoch [32/50], Train Loss: 0.1787, Val Loss: 0.3865\n",
      "Epoch [33/50], Train Loss: 0.1782, Val Loss: 0.3859\n",
      "Epoch [34/50], Train Loss: 0.1778, Val Loss: 0.3853\n",
      "Epoch [35/50], Train Loss: 0.1774, Val Loss: 0.3847\n",
      "Epoch [36/50], Train Loss: 0.1770, Val Loss: 0.3841\n",
      "Epoch [37/50], Train Loss: 0.1766, Val Loss: 0.3835\n",
      "Epoch [38/50], Train Loss: 0.1762, Val Loss: 0.3829\n",
      "Epoch [39/50], Train Loss: 0.1758, Val Loss: 0.3823\n",
      "Epoch [40/50], Train Loss: 0.1753, Val Loss: 0.3817\n",
      "Epoch [41/50], Train Loss: 0.1749, Val Loss: 0.3811\n",
      "Epoch [42/50], Train Loss: 0.1745, Val Loss: 0.3806\n",
      "Epoch [43/50], Train Loss: 0.1741, Val Loss: 0.3800\n",
      "Epoch [44/50], Train Loss: 0.1737, Val Loss: 0.3794\n",
      "Epoch [45/50], Train Loss: 0.1733, Val Loss: 0.3788\n",
      "Epoch [46/50], Train Loss: 0.1729, Val Loss: 0.3782\n",
      "Epoch [47/50], Train Loss: 0.1725, Val Loss: 0.3777\n",
      "Epoch [48/50], Train Loss: 0.1721, Val Loss: 0.3771\n",
      "Epoch [49/50], Train Loss: 0.1717, Val Loss: 0.3765\n",
      "Epoch [50/50], Train Loss: 0.1713, Val Loss: 0.3760\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1777, Val Loss: 0.4580\n",
      "Epoch [2/50], Train Loss: 0.1774, Val Loss: 0.4573\n",
      "Epoch [3/50], Train Loss: 0.1763, Val Loss: 0.4566\n",
      "Epoch [4/50], Train Loss: 0.1760, Val Loss: 0.4558\n",
      "Epoch [5/50], Train Loss: 0.1759, Val Loss: 0.4551\n",
      "Epoch [6/50], Train Loss: 0.1758, Val Loss: 0.4544\n",
      "Epoch [7/50], Train Loss: 0.1747, Val Loss: 0.4536\n",
      "Epoch [8/50], Train Loss: 0.1746, Val Loss: 0.4529\n",
      "Epoch [9/50], Train Loss: 0.1741, Val Loss: 0.4522\n",
      "Epoch [10/50], Train Loss: 0.1736, Val Loss: 0.4515\n",
      "Epoch [11/50], Train Loss: 0.1732, Val Loss: 0.4507\n",
      "Epoch [12/50], Train Loss: 0.1727, Val Loss: 0.4500\n",
      "Epoch [13/50], Train Loss: 0.1725, Val Loss: 0.4493\n",
      "Epoch [14/50], Train Loss: 0.1714, Val Loss: 0.4486\n",
      "Epoch [15/50], Train Loss: 0.1718, Val Loss: 0.4479\n",
      "Epoch [16/50], Train Loss: 0.1710, Val Loss: 0.4472\n",
      "Epoch [17/50], Train Loss: 0.1705, Val Loss: 0.4465\n",
      "Epoch [18/50], Train Loss: 0.1708, Val Loss: 0.4458\n",
      "Epoch [19/50], Train Loss: 0.1697, Val Loss: 0.4451\n",
      "Epoch [20/50], Train Loss: 0.1701, Val Loss: 0.4444\n",
      "Epoch [21/50], Train Loss: 0.1690, Val Loss: 0.4437\n",
      "Epoch [22/50], Train Loss: 0.1688, Val Loss: 0.4430\n",
      "Epoch [23/50], Train Loss: 0.1683, Val Loss: 0.4423\n",
      "Epoch [24/50], Train Loss: 0.1683, Val Loss: 0.4416\n",
      "Epoch [25/50], Train Loss: 0.1673, Val Loss: 0.4409\n",
      "Epoch [26/50], Train Loss: 0.1670, Val Loss: 0.4402\n",
      "Epoch [27/50], Train Loss: 0.1669, Val Loss: 0.4395\n",
      "Epoch [28/50], Train Loss: 0.1662, Val Loss: 0.4388\n",
      "Epoch [29/50], Train Loss: 0.1661, Val Loss: 0.4381\n",
      "Epoch [30/50], Train Loss: 0.1654, Val Loss: 0.4374\n",
      "Epoch [31/50], Train Loss: 0.1653, Val Loss: 0.4367\n",
      "Epoch [32/50], Train Loss: 0.1643, Val Loss: 0.4360\n",
      "Epoch [33/50], Train Loss: 0.1649, Val Loss: 0.4354\n",
      "Epoch [34/50], Train Loss: 0.1634, Val Loss: 0.4347\n",
      "Epoch [35/50], Train Loss: 0.1634, Val Loss: 0.4340\n",
      "Epoch [36/50], Train Loss: 0.1631, Val Loss: 0.4333\n",
      "Epoch [37/50], Train Loss: 0.1631, Val Loss: 0.4326\n",
      "Epoch [38/50], Train Loss: 0.1628, Val Loss: 0.4320\n",
      "Epoch [39/50], Train Loss: 0.1622, Val Loss: 0.4313\n",
      "Epoch [40/50], Train Loss: 0.1622, Val Loss: 0.4306\n",
      "Epoch [41/50], Train Loss: 0.1615, Val Loss: 0.4300\n",
      "Epoch [42/50], Train Loss: 0.1610, Val Loss: 0.4293\n",
      "Epoch [43/50], Train Loss: 0.1606, Val Loss: 0.4286\n",
      "Epoch [44/50], Train Loss: 0.1604, Val Loss: 0.4280\n",
      "Epoch [45/50], Train Loss: 0.1596, Val Loss: 0.4273\n",
      "Epoch [46/50], Train Loss: 0.1599, Val Loss: 0.4266\n",
      "Epoch [47/50], Train Loss: 0.1595, Val Loss: 0.4260\n",
      "Epoch [48/50], Train Loss: 0.1590, Val Loss: 0.4253\n",
      "Epoch [49/50], Train Loss: 0.1584, Val Loss: 0.4247\n",
      "Epoch [50/50], Train Loss: 0.1580, Val Loss: 0.4240\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1815, Val Loss: 0.4397\n",
      "Epoch [2/50], Train Loss: 0.1821, Val Loss: 0.4390\n",
      "Epoch [3/50], Train Loss: 0.1820, Val Loss: 0.4383\n",
      "Epoch [4/50], Train Loss: 0.1820, Val Loss: 0.4376\n",
      "Epoch [5/50], Train Loss: 0.1817, Val Loss: 0.4369\n",
      "Epoch [6/50], Train Loss: 0.1817, Val Loss: 0.4361\n",
      "Epoch [7/50], Train Loss: 0.1791, Val Loss: 0.4354\n",
      "Epoch [8/50], Train Loss: 0.1784, Val Loss: 0.4347\n",
      "Epoch [9/50], Train Loss: 0.1792, Val Loss: 0.4340\n",
      "Epoch [10/50], Train Loss: 0.1785, Val Loss: 0.4333\n",
      "Epoch [11/50], Train Loss: 0.1794, Val Loss: 0.4326\n",
      "Epoch [12/50], Train Loss: 0.1785, Val Loss: 0.4319\n",
      "Epoch [13/50], Train Loss: 0.1761, Val Loss: 0.4312\n",
      "Epoch [14/50], Train Loss: 0.1764, Val Loss: 0.4305\n",
      "Epoch [15/50], Train Loss: 0.1762, Val Loss: 0.4298\n",
      "Epoch [16/50], Train Loss: 0.1758, Val Loss: 0.4291\n",
      "Epoch [17/50], Train Loss: 0.1755, Val Loss: 0.4284\n",
      "Epoch [18/50], Train Loss: 0.1760, Val Loss: 0.4277\n",
      "Epoch [19/50], Train Loss: 0.1740, Val Loss: 0.4270\n",
      "Epoch [20/50], Train Loss: 0.1752, Val Loss: 0.4263\n",
      "Epoch [21/50], Train Loss: 0.1734, Val Loss: 0.4256\n",
      "Epoch [22/50], Train Loss: 0.1740, Val Loss: 0.4249\n",
      "Epoch [23/50], Train Loss: 0.1722, Val Loss: 0.4242\n",
      "Epoch [24/50], Train Loss: 0.1719, Val Loss: 0.4236\n",
      "Epoch [25/50], Train Loss: 0.1717, Val Loss: 0.4229\n",
      "Epoch [26/50], Train Loss: 0.1717, Val Loss: 0.4222\n",
      "Epoch [27/50], Train Loss: 0.1712, Val Loss: 0.4215\n",
      "Epoch [28/50], Train Loss: 0.1726, Val Loss: 0.4208\n",
      "Epoch [29/50], Train Loss: 0.1714, Val Loss: 0.4201\n",
      "Epoch [30/50], Train Loss: 0.1707, Val Loss: 0.4195\n",
      "Epoch [31/50], Train Loss: 0.1702, Val Loss: 0.4188\n",
      "Epoch [32/50], Train Loss: 0.1706, Val Loss: 0.4181\n",
      "Epoch [33/50], Train Loss: 0.1699, Val Loss: 0.4175\n",
      "Epoch [34/50], Train Loss: 0.1685, Val Loss: 0.4168\n",
      "Epoch [35/50], Train Loss: 0.1678, Val Loss: 0.4161\n",
      "Epoch [36/50], Train Loss: 0.1672, Val Loss: 0.4155\n",
      "Epoch [37/50], Train Loss: 0.1674, Val Loss: 0.4148\n",
      "Epoch [38/50], Train Loss: 0.1669, Val Loss: 0.4142\n",
      "Epoch [39/50], Train Loss: 0.1645, Val Loss: 0.4135\n",
      "Epoch [40/50], Train Loss: 0.1658, Val Loss: 0.4129\n",
      "Epoch [41/50], Train Loss: 0.1664, Val Loss: 0.4122\n",
      "Epoch [42/50], Train Loss: 0.1645, Val Loss: 0.4116\n",
      "Epoch [43/50], Train Loss: 0.1652, Val Loss: 0.4109\n",
      "Epoch [44/50], Train Loss: 0.1647, Val Loss: 0.4102\n",
      "Epoch [45/50], Train Loss: 0.1638, Val Loss: 0.4096\n",
      "Epoch [46/50], Train Loss: 0.1632, Val Loss: 0.4090\n",
      "Epoch [47/50], Train Loss: 0.1634, Val Loss: 0.4083\n",
      "Epoch [48/50], Train Loss: 0.1624, Val Loss: 0.4077\n",
      "Epoch [49/50], Train Loss: 0.1624, Val Loss: 0.4070\n",
      "Epoch [50/50], Train Loss: 0.1637, Val Loss: 0.4064\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0942, Val Loss: 0.2707\n",
      "Epoch [2/50], Train Loss: 0.0940, Val Loss: 0.2704\n",
      "Epoch [3/50], Train Loss: 0.0939, Val Loss: 0.2702\n",
      "Epoch [4/50], Train Loss: 0.0937, Val Loss: 0.2699\n",
      "Epoch [5/50], Train Loss: 0.0935, Val Loss: 0.2696\n",
      "Epoch [6/50], Train Loss: 0.0934, Val Loss: 0.2693\n",
      "Epoch [7/50], Train Loss: 0.0932, Val Loss: 0.2690\n",
      "Epoch [8/50], Train Loss: 0.0931, Val Loss: 0.2687\n",
      "Epoch [9/50], Train Loss: 0.0929, Val Loss: 0.2684\n",
      "Epoch [10/50], Train Loss: 0.0928, Val Loss: 0.2681\n",
      "Epoch [11/50], Train Loss: 0.0926, Val Loss: 0.2678\n",
      "Epoch [12/50], Train Loss: 0.0925, Val Loss: 0.2675\n",
      "Epoch [13/50], Train Loss: 0.0923, Val Loss: 0.2673\n",
      "Epoch [14/50], Train Loss: 0.0922, Val Loss: 0.2670\n",
      "Epoch [15/50], Train Loss: 0.0920, Val Loss: 0.2667\n",
      "Epoch [16/50], Train Loss: 0.0918, Val Loss: 0.2664\n",
      "Epoch [17/50], Train Loss: 0.0917, Val Loss: 0.2661\n",
      "Epoch [18/50], Train Loss: 0.0915, Val Loss: 0.2658\n",
      "Epoch [19/50], Train Loss: 0.0914, Val Loss: 0.2655\n",
      "Epoch [20/50], Train Loss: 0.0912, Val Loss: 0.2653\n",
      "Epoch [21/50], Train Loss: 0.0911, Val Loss: 0.2650\n",
      "Epoch [22/50], Train Loss: 0.0909, Val Loss: 0.2647\n",
      "Epoch [23/50], Train Loss: 0.0908, Val Loss: 0.2644\n",
      "Epoch [24/50], Train Loss: 0.0906, Val Loss: 0.2641\n",
      "Epoch [25/50], Train Loss: 0.0905, Val Loss: 0.2638\n",
      "Epoch [26/50], Train Loss: 0.0904, Val Loss: 0.2636\n",
      "Epoch [27/50], Train Loss: 0.0902, Val Loss: 0.2633\n",
      "Epoch [28/50], Train Loss: 0.0901, Val Loss: 0.2630\n",
      "Epoch [29/50], Train Loss: 0.0899, Val Loss: 0.2627\n",
      "Epoch [30/50], Train Loss: 0.0898, Val Loss: 0.2625\n",
      "Epoch [31/50], Train Loss: 0.0896, Val Loss: 0.2622\n",
      "Epoch [32/50], Train Loss: 0.0895, Val Loss: 0.2619\n",
      "Epoch [33/50], Train Loss: 0.0893, Val Loss: 0.2616\n",
      "Epoch [34/50], Train Loss: 0.0892, Val Loss: 0.2614\n",
      "Epoch [35/50], Train Loss: 0.0890, Val Loss: 0.2611\n",
      "Epoch [36/50], Train Loss: 0.0889, Val Loss: 0.2608\n",
      "Epoch [37/50], Train Loss: 0.0888, Val Loss: 0.2605\n",
      "Epoch [38/50], Train Loss: 0.0886, Val Loss: 0.2603\n",
      "Epoch [39/50], Train Loss: 0.0885, Val Loss: 0.2600\n",
      "Epoch [40/50], Train Loss: 0.0883, Val Loss: 0.2597\n",
      "Epoch [41/50], Train Loss: 0.0882, Val Loss: 0.2594\n",
      "Epoch [42/50], Train Loss: 0.0880, Val Loss: 0.2592\n",
      "Epoch [43/50], Train Loss: 0.0879, Val Loss: 0.2589\n",
      "Epoch [44/50], Train Loss: 0.0878, Val Loss: 0.2586\n",
      "Epoch [45/50], Train Loss: 0.0876, Val Loss: 0.2584\n",
      "Epoch [46/50], Train Loss: 0.0875, Val Loss: 0.2581\n",
      "Epoch [47/50], Train Loss: 0.0873, Val Loss: 0.2578\n",
      "Epoch [48/50], Train Loss: 0.0872, Val Loss: 0.2576\n",
      "Epoch [49/50], Train Loss: 0.0871, Val Loss: 0.2573\n",
      "Epoch [50/50], Train Loss: 0.0869, Val Loss: 0.2570\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.2037, Val Loss: 0.4930\n",
      "Epoch [2/50], Train Loss: 0.2039, Val Loss: 0.4921\n",
      "Epoch [3/50], Train Loss: 0.2034, Val Loss: 0.4912\n",
      "Epoch [4/50], Train Loss: 0.2021, Val Loss: 0.4903\n",
      "Epoch [5/50], Train Loss: 0.2031, Val Loss: 0.4894\n",
      "Epoch [6/50], Train Loss: 0.2008, Val Loss: 0.4885\n",
      "Epoch [7/50], Train Loss: 0.2014, Val Loss: 0.4876\n",
      "Epoch [8/50], Train Loss: 0.1999, Val Loss: 0.4867\n",
      "Epoch [9/50], Train Loss: 0.1998, Val Loss: 0.4858\n",
      "Epoch [10/50], Train Loss: 0.1987, Val Loss: 0.4849\n",
      "Epoch [11/50], Train Loss: 0.1994, Val Loss: 0.4840\n",
      "Epoch [12/50], Train Loss: 0.1982, Val Loss: 0.4831\n",
      "Epoch [13/50], Train Loss: 0.1978, Val Loss: 0.4822\n",
      "Epoch [14/50], Train Loss: 0.1968, Val Loss: 0.4814\n",
      "Epoch [15/50], Train Loss: 0.1964, Val Loss: 0.4805\n",
      "Epoch [16/50], Train Loss: 0.1961, Val Loss: 0.4796\n",
      "Epoch [17/50], Train Loss: 0.1948, Val Loss: 0.4787\n",
      "Epoch [18/50], Train Loss: 0.1948, Val Loss: 0.4779\n",
      "Epoch [19/50], Train Loss: 0.1932, Val Loss: 0.4770\n",
      "Epoch [20/50], Train Loss: 0.1937, Val Loss: 0.4761\n",
      "Epoch [21/50], Train Loss: 0.1933, Val Loss: 0.4753\n",
      "Epoch [22/50], Train Loss: 0.1930, Val Loss: 0.4744\n",
      "Epoch [23/50], Train Loss: 0.1921, Val Loss: 0.4735\n",
      "Epoch [24/50], Train Loss: 0.1919, Val Loss: 0.4727\n",
      "Epoch [25/50], Train Loss: 0.1914, Val Loss: 0.4718\n",
      "Epoch [26/50], Train Loss: 0.1906, Val Loss: 0.4710\n",
      "Epoch [27/50], Train Loss: 0.1907, Val Loss: 0.4701\n",
      "Epoch [28/50], Train Loss: 0.1894, Val Loss: 0.4693\n",
      "Epoch [29/50], Train Loss: 0.1889, Val Loss: 0.4684\n",
      "Epoch [30/50], Train Loss: 0.1881, Val Loss: 0.4676\n",
      "Epoch [31/50], Train Loss: 0.1885, Val Loss: 0.4667\n",
      "Epoch [32/50], Train Loss: 0.1875, Val Loss: 0.4659\n",
      "Epoch [33/50], Train Loss: 0.1870, Val Loss: 0.4650\n",
      "Epoch [34/50], Train Loss: 0.1872, Val Loss: 0.4642\n",
      "Epoch [35/50], Train Loss: 0.1863, Val Loss: 0.4634\n",
      "Epoch [36/50], Train Loss: 0.1853, Val Loss: 0.4625\n",
      "Epoch [37/50], Train Loss: 0.1847, Val Loss: 0.4617\n",
      "Epoch [38/50], Train Loss: 0.1842, Val Loss: 0.4609\n",
      "Epoch [39/50], Train Loss: 0.1842, Val Loss: 0.4600\n",
      "Epoch [40/50], Train Loss: 0.1837, Val Loss: 0.4592\n",
      "Epoch [41/50], Train Loss: 0.1831, Val Loss: 0.4584\n",
      "Epoch [42/50], Train Loss: 0.1828, Val Loss: 0.4576\n",
      "Epoch [43/50], Train Loss: 0.1829, Val Loss: 0.4567\n",
      "Epoch [44/50], Train Loss: 0.1816, Val Loss: 0.4559\n",
      "Epoch [45/50], Train Loss: 0.1801, Val Loss: 0.4551\n",
      "Epoch [46/50], Train Loss: 0.1801, Val Loss: 0.4543\n",
      "Epoch [47/50], Train Loss: 0.1807, Val Loss: 0.4535\n",
      "Epoch [48/50], Train Loss: 0.1797, Val Loss: 0.4526\n",
      "Epoch [49/50], Train Loss: 0.1789, Val Loss: 0.4518\n",
      "Epoch [50/50], Train Loss: 0.1787, Val Loss: 0.4510\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.2290, Val Loss: 0.5033\n",
      "Epoch [2/50], Train Loss: 0.2310, Val Loss: 0.5023\n",
      "Epoch [3/50], Train Loss: 0.2295, Val Loss: 0.5014\n",
      "Epoch [4/50], Train Loss: 0.2287, Val Loss: 0.5005\n",
      "Epoch [5/50], Train Loss: 0.2288, Val Loss: 0.4996\n",
      "Epoch [6/50], Train Loss: 0.2291, Val Loss: 0.4986\n",
      "Epoch [7/50], Train Loss: 0.2275, Val Loss: 0.4977\n",
      "Epoch [8/50], Train Loss: 0.2258, Val Loss: 0.4968\n",
      "Epoch [9/50], Train Loss: 0.2258, Val Loss: 0.4959\n",
      "Epoch [10/50], Train Loss: 0.2266, Val Loss: 0.4950\n",
      "Epoch [11/50], Train Loss: 0.2231, Val Loss: 0.4941\n",
      "Epoch [12/50], Train Loss: 0.2244, Val Loss: 0.4932\n",
      "Epoch [13/50], Train Loss: 0.2236, Val Loss: 0.4923\n",
      "Epoch [14/50], Train Loss: 0.2235, Val Loss: 0.4914\n",
      "Epoch [15/50], Train Loss: 0.2229, Val Loss: 0.4905\n",
      "Epoch [16/50], Train Loss: 0.2225, Val Loss: 0.4896\n",
      "Epoch [17/50], Train Loss: 0.2212, Val Loss: 0.4887\n",
      "Epoch [18/50], Train Loss: 0.2202, Val Loss: 0.4878\n",
      "Epoch [19/50], Train Loss: 0.2204, Val Loss: 0.4869\n",
      "Epoch [20/50], Train Loss: 0.2193, Val Loss: 0.4860\n",
      "Epoch [21/50], Train Loss: 0.2188, Val Loss: 0.4851\n",
      "Epoch [22/50], Train Loss: 0.2183, Val Loss: 0.4842\n",
      "Epoch [23/50], Train Loss: 0.2180, Val Loss: 0.4833\n",
      "Epoch [24/50], Train Loss: 0.2177, Val Loss: 0.4825\n",
      "Epoch [25/50], Train Loss: 0.2171, Val Loss: 0.4816\n",
      "Epoch [26/50], Train Loss: 0.2160, Val Loss: 0.4807\n",
      "Epoch [27/50], Train Loss: 0.2154, Val Loss: 0.4798\n",
      "Epoch [28/50], Train Loss: 0.2165, Val Loss: 0.4790\n",
      "Epoch [29/50], Train Loss: 0.2134, Val Loss: 0.4781\n",
      "Epoch [30/50], Train Loss: 0.2126, Val Loss: 0.4773\n",
      "Epoch [31/50], Train Loss: 0.2124, Val Loss: 0.4764\n",
      "Epoch [32/50], Train Loss: 0.2121, Val Loss: 0.4755\n",
      "Epoch [33/50], Train Loss: 0.2130, Val Loss: 0.4747\n",
      "Epoch [34/50], Train Loss: 0.2117, Val Loss: 0.4738\n",
      "Epoch [35/50], Train Loss: 0.2113, Val Loss: 0.4730\n",
      "Epoch [36/50], Train Loss: 0.2110, Val Loss: 0.4721\n",
      "Epoch [37/50], Train Loss: 0.2105, Val Loss: 0.4713\n",
      "Epoch [38/50], Train Loss: 0.2085, Val Loss: 0.4704\n",
      "Epoch [39/50], Train Loss: 0.2078, Val Loss: 0.4696\n",
      "Epoch [40/50], Train Loss: 0.2078, Val Loss: 0.4688\n",
      "Epoch [41/50], Train Loss: 0.2065, Val Loss: 0.4679\n",
      "Epoch [42/50], Train Loss: 0.2065, Val Loss: 0.4671\n",
      "Epoch [43/50], Train Loss: 0.2056, Val Loss: 0.4663\n",
      "Epoch [44/50], Train Loss: 0.2054, Val Loss: 0.4654\n",
      "Epoch [45/50], Train Loss: 0.2054, Val Loss: 0.4646\n",
      "Epoch [46/50], Train Loss: 0.2045, Val Loss: 0.4638\n",
      "Epoch [47/50], Train Loss: 0.2034, Val Loss: 0.4629\n",
      "Epoch [48/50], Train Loss: 0.2040, Val Loss: 0.4621\n",
      "Epoch [49/50], Train Loss: 0.2054, Val Loss: 0.4613\n",
      "Epoch [50/50], Train Loss: 0.2032, Val Loss: 0.4605\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1143, Val Loss: 0.3492\n",
      "Epoch [2/50], Train Loss: 0.1140, Val Loss: 0.3487\n",
      "Epoch [3/50], Train Loss: 0.1138, Val Loss: 0.3482\n",
      "Epoch [4/50], Train Loss: 0.1136, Val Loss: 0.3477\n",
      "Epoch [5/50], Train Loss: 0.1133, Val Loss: 0.3473\n",
      "Epoch [6/50], Train Loss: 0.1131, Val Loss: 0.3468\n",
      "Epoch [7/50], Train Loss: 0.1129, Val Loss: 0.3463\n",
      "Epoch [8/50], Train Loss: 0.1126, Val Loss: 0.3458\n",
      "Epoch [9/50], Train Loss: 0.1124, Val Loss: 0.3453\n",
      "Epoch [10/50], Train Loss: 0.1122, Val Loss: 0.3448\n",
      "Epoch [11/50], Train Loss: 0.1119, Val Loss: 0.3443\n",
      "Epoch [12/50], Train Loss: 0.1117, Val Loss: 0.3438\n",
      "Epoch [13/50], Train Loss: 0.1115, Val Loss: 0.3433\n",
      "Epoch [14/50], Train Loss: 0.1113, Val Loss: 0.3429\n",
      "Epoch [15/50], Train Loss: 0.1110, Val Loss: 0.3424\n",
      "Epoch [16/50], Train Loss: 0.1108, Val Loss: 0.3419\n",
      "Epoch [17/50], Train Loss: 0.1106, Val Loss: 0.3414\n",
      "Epoch [18/50], Train Loss: 0.1104, Val Loss: 0.3409\n",
      "Epoch [19/50], Train Loss: 0.1101, Val Loss: 0.3404\n",
      "Epoch [20/50], Train Loss: 0.1099, Val Loss: 0.3400\n",
      "Epoch [21/50], Train Loss: 0.1097, Val Loss: 0.3395\n",
      "Epoch [22/50], Train Loss: 0.1095, Val Loss: 0.3390\n",
      "Epoch [23/50], Train Loss: 0.1093, Val Loss: 0.3385\n",
      "Epoch [24/50], Train Loss: 0.1090, Val Loss: 0.3381\n",
      "Epoch [25/50], Train Loss: 0.1088, Val Loss: 0.3376\n",
      "Epoch [26/50], Train Loss: 0.1086, Val Loss: 0.3371\n",
      "Epoch [27/50], Train Loss: 0.1084, Val Loss: 0.3367\n",
      "Epoch [28/50], Train Loss: 0.1082, Val Loss: 0.3362\n",
      "Epoch [29/50], Train Loss: 0.1080, Val Loss: 0.3357\n",
      "Epoch [30/50], Train Loss: 0.1077, Val Loss: 0.3352\n",
      "Epoch [31/50], Train Loss: 0.1075, Val Loss: 0.3348\n",
      "Epoch [32/50], Train Loss: 0.1073, Val Loss: 0.3343\n",
      "Epoch [33/50], Train Loss: 0.1071, Val Loss: 0.3339\n",
      "Epoch [34/50], Train Loss: 0.1069, Val Loss: 0.3334\n",
      "Epoch [35/50], Train Loss: 0.1067, Val Loss: 0.3329\n",
      "Epoch [36/50], Train Loss: 0.1065, Val Loss: 0.3325\n",
      "Epoch [37/50], Train Loss: 0.1062, Val Loss: 0.3320\n",
      "Epoch [38/50], Train Loss: 0.1060, Val Loss: 0.3315\n",
      "Epoch [39/50], Train Loss: 0.1058, Val Loss: 0.3311\n",
      "Epoch [40/50], Train Loss: 0.1056, Val Loss: 0.3306\n",
      "Epoch [41/50], Train Loss: 0.1054, Val Loss: 0.3302\n",
      "Epoch [42/50], Train Loss: 0.1052, Val Loss: 0.3297\n",
      "Epoch [43/50], Train Loss: 0.1050, Val Loss: 0.3293\n",
      "Epoch [44/50], Train Loss: 0.1048, Val Loss: 0.3288\n",
      "Epoch [45/50], Train Loss: 0.1046, Val Loss: 0.3283\n",
      "Epoch [46/50], Train Loss: 0.1044, Val Loss: 0.3279\n",
      "Epoch [47/50], Train Loss: 0.1042, Val Loss: 0.3275\n",
      "Epoch [48/50], Train Loss: 0.1040, Val Loss: 0.3270\n",
      "Epoch [49/50], Train Loss: 0.1038, Val Loss: 0.3265\n",
      "Epoch [50/50], Train Loss: 0.1036, Val Loss: 0.3261\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1726, Val Loss: 0.4119\n",
      "Epoch [2/50], Train Loss: 0.1719, Val Loss: 0.4112\n",
      "Epoch [3/50], Train Loss: 0.1722, Val Loss: 0.4104\n",
      "Epoch [4/50], Train Loss: 0.1716, Val Loss: 0.4097\n",
      "Epoch [5/50], Train Loss: 0.1716, Val Loss: 0.4089\n",
      "Epoch [6/50], Train Loss: 0.1712, Val Loss: 0.4081\n",
      "Epoch [7/50], Train Loss: 0.1696, Val Loss: 0.4074\n",
      "Epoch [8/50], Train Loss: 0.1701, Val Loss: 0.4066\n",
      "Epoch [9/50], Train Loss: 0.1694, Val Loss: 0.4059\n",
      "Epoch [10/50], Train Loss: 0.1688, Val Loss: 0.4051\n",
      "Epoch [11/50], Train Loss: 0.1686, Val Loss: 0.4044\n",
      "Epoch [12/50], Train Loss: 0.1679, Val Loss: 0.4036\n",
      "Epoch [13/50], Train Loss: 0.1677, Val Loss: 0.4029\n",
      "Epoch [14/50], Train Loss: 0.1667, Val Loss: 0.4022\n",
      "Epoch [15/50], Train Loss: 0.1670, Val Loss: 0.4014\n",
      "Epoch [16/50], Train Loss: 0.1666, Val Loss: 0.4007\n",
      "Epoch [17/50], Train Loss: 0.1651, Val Loss: 0.4000\n",
      "Epoch [18/50], Train Loss: 0.1648, Val Loss: 0.3992\n",
      "Epoch [19/50], Train Loss: 0.1649, Val Loss: 0.3985\n",
      "Epoch [20/50], Train Loss: 0.1647, Val Loss: 0.3978\n",
      "Epoch [21/50], Train Loss: 0.1646, Val Loss: 0.3971\n",
      "Epoch [22/50], Train Loss: 0.1647, Val Loss: 0.3963\n",
      "Epoch [23/50], Train Loss: 0.1637, Val Loss: 0.3956\n",
      "Epoch [24/50], Train Loss: 0.1636, Val Loss: 0.3949\n",
      "Epoch [25/50], Train Loss: 0.1622, Val Loss: 0.3942\n",
      "Epoch [26/50], Train Loss: 0.1628, Val Loss: 0.3935\n",
      "Epoch [27/50], Train Loss: 0.1620, Val Loss: 0.3928\n",
      "Epoch [28/50], Train Loss: 0.1616, Val Loss: 0.3920\n",
      "Epoch [29/50], Train Loss: 0.1600, Val Loss: 0.3913\n",
      "Epoch [30/50], Train Loss: 0.1599, Val Loss: 0.3906\n",
      "Epoch [31/50], Train Loss: 0.1602, Val Loss: 0.3899\n",
      "Epoch [32/50], Train Loss: 0.1601, Val Loss: 0.3892\n",
      "Epoch [33/50], Train Loss: 0.1589, Val Loss: 0.3885\n",
      "Epoch [34/50], Train Loss: 0.1593, Val Loss: 0.3878\n",
      "Epoch [35/50], Train Loss: 0.1583, Val Loss: 0.3871\n",
      "Epoch [36/50], Train Loss: 0.1579, Val Loss: 0.3864\n",
      "Epoch [37/50], Train Loss: 0.1578, Val Loss: 0.3857\n",
      "Epoch [38/50], Train Loss: 0.1577, Val Loss: 0.3850\n",
      "Epoch [39/50], Train Loss: 0.1565, Val Loss: 0.3844\n",
      "Epoch [40/50], Train Loss: 0.1560, Val Loss: 0.3837\n",
      "Epoch [41/50], Train Loss: 0.1556, Val Loss: 0.3830\n",
      "Epoch [42/50], Train Loss: 0.1559, Val Loss: 0.3823\n",
      "Epoch [43/50], Train Loss: 0.1556, Val Loss: 0.3816\n",
      "Epoch [44/50], Train Loss: 0.1552, Val Loss: 0.3809\n",
      "Epoch [45/50], Train Loss: 0.1546, Val Loss: 0.3803\n",
      "Epoch [46/50], Train Loss: 0.1540, Val Loss: 0.3796\n",
      "Epoch [47/50], Train Loss: 0.1543, Val Loss: 0.3789\n",
      "Epoch [48/50], Train Loss: 0.1532, Val Loss: 0.3782\n",
      "Epoch [49/50], Train Loss: 0.1526, Val Loss: 0.3776\n",
      "Epoch [50/50], Train Loss: 0.1519, Val Loss: 0.3769\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1615, Val Loss: 0.4076\n",
      "Epoch [2/50], Train Loss: 0.1611, Val Loss: 0.4069\n",
      "Epoch [3/50], Train Loss: 0.1611, Val Loss: 0.4062\n",
      "Epoch [4/50], Train Loss: 0.1605, Val Loss: 0.4055\n",
      "Epoch [5/50], Train Loss: 0.1602, Val Loss: 0.4048\n",
      "Epoch [6/50], Train Loss: 0.1599, Val Loss: 0.4041\n",
      "Epoch [7/50], Train Loss: 0.1600, Val Loss: 0.4035\n",
      "Epoch [8/50], Train Loss: 0.1594, Val Loss: 0.4028\n",
      "Epoch [9/50], Train Loss: 0.1583, Val Loss: 0.4021\n",
      "Epoch [10/50], Train Loss: 0.1586, Val Loss: 0.4014\n",
      "Epoch [11/50], Train Loss: 0.1582, Val Loss: 0.4007\n",
      "Epoch [12/50], Train Loss: 0.1577, Val Loss: 0.4001\n",
      "Epoch [13/50], Train Loss: 0.1574, Val Loss: 0.3994\n",
      "Epoch [14/50], Train Loss: 0.1569, Val Loss: 0.3987\n",
      "Epoch [15/50], Train Loss: 0.1572, Val Loss: 0.3981\n",
      "Epoch [16/50], Train Loss: 0.1564, Val Loss: 0.3974\n",
      "Epoch [17/50], Train Loss: 0.1567, Val Loss: 0.3968\n",
      "Epoch [18/50], Train Loss: 0.1553, Val Loss: 0.3961\n",
      "Epoch [19/50], Train Loss: 0.1555, Val Loss: 0.3954\n",
      "Epoch [20/50], Train Loss: 0.1542, Val Loss: 0.3948\n",
      "Epoch [21/50], Train Loss: 0.1538, Val Loss: 0.3941\n",
      "Epoch [22/50], Train Loss: 0.1543, Val Loss: 0.3935\n",
      "Epoch [23/50], Train Loss: 0.1528, Val Loss: 0.3928\n",
      "Epoch [24/50], Train Loss: 0.1523, Val Loss: 0.3922\n",
      "Epoch [25/50], Train Loss: 0.1523, Val Loss: 0.3915\n",
      "Epoch [26/50], Train Loss: 0.1519, Val Loss: 0.3909\n",
      "Epoch [27/50], Train Loss: 0.1518, Val Loss: 0.3902\n",
      "Epoch [28/50], Train Loss: 0.1512, Val Loss: 0.3896\n",
      "Epoch [29/50], Train Loss: 0.1513, Val Loss: 0.3889\n",
      "Epoch [30/50], Train Loss: 0.1517, Val Loss: 0.3883\n",
      "Epoch [31/50], Train Loss: 0.1512, Val Loss: 0.3877\n",
      "Epoch [32/50], Train Loss: 0.1493, Val Loss: 0.3870\n",
      "Epoch [33/50], Train Loss: 0.1498, Val Loss: 0.3864\n",
      "Epoch [34/50], Train Loss: 0.1503, Val Loss: 0.3858\n",
      "Epoch [35/50], Train Loss: 0.1487, Val Loss: 0.3851\n",
      "Epoch [36/50], Train Loss: 0.1486, Val Loss: 0.3845\n",
      "Epoch [37/50], Train Loss: 0.1483, Val Loss: 0.3839\n",
      "Epoch [38/50], Train Loss: 0.1490, Val Loss: 0.3832\n",
      "Epoch [39/50], Train Loss: 0.1473, Val Loss: 0.3826\n",
      "Epoch [40/50], Train Loss: 0.1468, Val Loss: 0.3820\n",
      "Epoch [41/50], Train Loss: 0.1477, Val Loss: 0.3814\n",
      "Epoch [42/50], Train Loss: 0.1461, Val Loss: 0.3808\n",
      "Epoch [43/50], Train Loss: 0.1463, Val Loss: 0.3801\n",
      "Epoch [44/50], Train Loss: 0.1457, Val Loss: 0.3795\n",
      "Epoch [45/50], Train Loss: 0.1453, Val Loss: 0.3789\n",
      "Epoch [46/50], Train Loss: 0.1453, Val Loss: 0.3783\n",
      "Epoch [47/50], Train Loss: 0.1446, Val Loss: 0.3777\n",
      "Epoch [48/50], Train Loss: 0.1448, Val Loss: 0.3771\n",
      "Epoch [49/50], Train Loss: 0.1450, Val Loss: 0.3765\n",
      "Epoch [50/50], Train Loss: 0.1436, Val Loss: 0.3759\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1691, Val Loss: 0.4558\n",
      "Epoch [2/50], Train Loss: 0.1686, Val Loss: 0.4550\n",
      "Epoch [3/50], Train Loss: 0.1682, Val Loss: 0.4542\n",
      "Epoch [4/50], Train Loss: 0.1677, Val Loss: 0.4534\n",
      "Epoch [5/50], Train Loss: 0.1673, Val Loss: 0.4526\n",
      "Epoch [6/50], Train Loss: 0.1669, Val Loss: 0.4518\n",
      "Epoch [7/50], Train Loss: 0.1664, Val Loss: 0.4510\n",
      "Epoch [8/50], Train Loss: 0.1660, Val Loss: 0.4502\n",
      "Epoch [9/50], Train Loss: 0.1656, Val Loss: 0.4495\n",
      "Epoch [10/50], Train Loss: 0.1651, Val Loss: 0.4487\n",
      "Epoch [11/50], Train Loss: 0.1647, Val Loss: 0.4479\n",
      "Epoch [12/50], Train Loss: 0.1643, Val Loss: 0.4471\n",
      "Epoch [13/50], Train Loss: 0.1639, Val Loss: 0.4463\n",
      "Epoch [14/50], Train Loss: 0.1634, Val Loss: 0.4455\n",
      "Epoch [15/50], Train Loss: 0.1630, Val Loss: 0.4448\n",
      "Epoch [16/50], Train Loss: 0.1626, Val Loss: 0.4440\n",
      "Epoch [17/50], Train Loss: 0.1622, Val Loss: 0.4432\n",
      "Epoch [18/50], Train Loss: 0.1618, Val Loss: 0.4425\n",
      "Epoch [19/50], Train Loss: 0.1613, Val Loss: 0.4417\n",
      "Epoch [20/50], Train Loss: 0.1609, Val Loss: 0.4409\n",
      "Epoch [21/50], Train Loss: 0.1605, Val Loss: 0.4402\n",
      "Epoch [22/50], Train Loss: 0.1601, Val Loss: 0.4394\n",
      "Epoch [23/50], Train Loss: 0.1597, Val Loss: 0.4387\n",
      "Epoch [24/50], Train Loss: 0.1593, Val Loss: 0.4379\n",
      "Epoch [25/50], Train Loss: 0.1589, Val Loss: 0.4371\n",
      "Epoch [26/50], Train Loss: 0.1585, Val Loss: 0.4364\n",
      "Epoch [27/50], Train Loss: 0.1581, Val Loss: 0.4357\n",
      "Epoch [28/50], Train Loss: 0.1577, Val Loss: 0.4349\n",
      "Epoch [29/50], Train Loss: 0.1573, Val Loss: 0.4341\n",
      "Epoch [30/50], Train Loss: 0.1569, Val Loss: 0.4334\n",
      "Epoch [31/50], Train Loss: 0.1565, Val Loss: 0.4327\n",
      "Epoch [32/50], Train Loss: 0.1561, Val Loss: 0.4319\n",
      "Epoch [33/50], Train Loss: 0.1557, Val Loss: 0.4312\n",
      "Epoch [34/50], Train Loss: 0.1553, Val Loss: 0.4304\n",
      "Epoch [35/50], Train Loss: 0.1549, Val Loss: 0.4297\n",
      "Epoch [36/50], Train Loss: 0.1545, Val Loss: 0.4290\n",
      "Epoch [37/50], Train Loss: 0.1541, Val Loss: 0.4283\n",
      "Epoch [38/50], Train Loss: 0.1537, Val Loss: 0.4275\n",
      "Epoch [39/50], Train Loss: 0.1533, Val Loss: 0.4268\n",
      "Epoch [40/50], Train Loss: 0.1529, Val Loss: 0.4261\n",
      "Epoch [41/50], Train Loss: 0.1525, Val Loss: 0.4253\n",
      "Epoch [42/50], Train Loss: 0.1521, Val Loss: 0.4246\n",
      "Epoch [43/50], Train Loss: 0.1518, Val Loss: 0.4239\n",
      "Epoch [44/50], Train Loss: 0.1514, Val Loss: 0.4232\n",
      "Epoch [45/50], Train Loss: 0.1510, Val Loss: 0.4225\n",
      "Epoch [46/50], Train Loss: 0.1506, Val Loss: 0.4218\n",
      "Epoch [47/50], Train Loss: 0.1502, Val Loss: 0.4210\n",
      "Epoch [48/50], Train Loss: 0.1499, Val Loss: 0.4203\n",
      "Epoch [49/50], Train Loss: 0.1495, Val Loss: 0.4196\n",
      "Epoch [50/50], Train Loss: 0.1491, Val Loss: 0.4189\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1780, Val Loss: 0.4394\n",
      "Epoch [2/50], Train Loss: 0.1773, Val Loss: 0.4387\n",
      "Epoch [3/50], Train Loss: 0.1771, Val Loss: 0.4380\n",
      "Epoch [4/50], Train Loss: 0.1764, Val Loss: 0.4373\n",
      "Epoch [5/50], Train Loss: 0.1764, Val Loss: 0.4366\n",
      "Epoch [6/50], Train Loss: 0.1759, Val Loss: 0.4359\n",
      "Epoch [7/50], Train Loss: 0.1755, Val Loss: 0.4352\n",
      "Epoch [8/50], Train Loss: 0.1752, Val Loss: 0.4345\n",
      "Epoch [9/50], Train Loss: 0.1745, Val Loss: 0.4338\n",
      "Epoch [10/50], Train Loss: 0.1742, Val Loss: 0.4331\n",
      "Epoch [11/50], Train Loss: 0.1739, Val Loss: 0.4324\n",
      "Epoch [12/50], Train Loss: 0.1727, Val Loss: 0.4317\n",
      "Epoch [13/50], Train Loss: 0.1729, Val Loss: 0.4310\n",
      "Epoch [14/50], Train Loss: 0.1726, Val Loss: 0.4303\n",
      "Epoch [15/50], Train Loss: 0.1722, Val Loss: 0.4297\n",
      "Epoch [16/50], Train Loss: 0.1718, Val Loss: 0.4290\n",
      "Epoch [17/50], Train Loss: 0.1711, Val Loss: 0.4283\n",
      "Epoch [18/50], Train Loss: 0.1706, Val Loss: 0.4276\n",
      "Epoch [19/50], Train Loss: 0.1701, Val Loss: 0.4269\n",
      "Epoch [20/50], Train Loss: 0.1699, Val Loss: 0.4262\n",
      "Epoch [21/50], Train Loss: 0.1695, Val Loss: 0.4256\n",
      "Epoch [22/50], Train Loss: 0.1689, Val Loss: 0.4249\n",
      "Epoch [23/50], Train Loss: 0.1687, Val Loss: 0.4242\n",
      "Epoch [24/50], Train Loss: 0.1683, Val Loss: 0.4235\n",
      "Epoch [25/50], Train Loss: 0.1682, Val Loss: 0.4229\n",
      "Epoch [26/50], Train Loss: 0.1673, Val Loss: 0.4222\n",
      "Epoch [27/50], Train Loss: 0.1671, Val Loss: 0.4215\n",
      "Epoch [28/50], Train Loss: 0.1668, Val Loss: 0.4209\n",
      "Epoch [29/50], Train Loss: 0.1660, Val Loss: 0.4202\n",
      "Epoch [30/50], Train Loss: 0.1658, Val Loss: 0.4196\n",
      "Epoch [31/50], Train Loss: 0.1653, Val Loss: 0.4189\n",
      "Epoch [32/50], Train Loss: 0.1652, Val Loss: 0.4182\n",
      "Epoch [33/50], Train Loss: 0.1648, Val Loss: 0.4176\n",
      "Epoch [34/50], Train Loss: 0.1644, Val Loss: 0.4169\n",
      "Epoch [35/50], Train Loss: 0.1633, Val Loss: 0.4163\n",
      "Epoch [36/50], Train Loss: 0.1635, Val Loss: 0.4156\n",
      "Epoch [37/50], Train Loss: 0.1633, Val Loss: 0.4150\n",
      "Epoch [38/50], Train Loss: 0.1628, Val Loss: 0.4143\n",
      "Epoch [39/50], Train Loss: 0.1624, Val Loss: 0.4137\n",
      "Epoch [40/50], Train Loss: 0.1620, Val Loss: 0.4130\n",
      "Epoch [41/50], Train Loss: 0.1615, Val Loss: 0.4124\n",
      "Epoch [42/50], Train Loss: 0.1615, Val Loss: 0.4117\n",
      "Epoch [43/50], Train Loss: 0.1608, Val Loss: 0.4111\n",
      "Epoch [44/50], Train Loss: 0.1598, Val Loss: 0.4104\n",
      "Epoch [45/50], Train Loss: 0.1596, Val Loss: 0.4098\n",
      "Epoch [46/50], Train Loss: 0.1597, Val Loss: 0.4092\n",
      "Epoch [47/50], Train Loss: 0.1595, Val Loss: 0.4085\n",
      "Epoch [48/50], Train Loss: 0.1591, Val Loss: 0.4079\n",
      "Epoch [49/50], Train Loss: 0.1592, Val Loss: 0.4073\n",
      "Epoch [50/50], Train Loss: 0.1583, Val Loss: 0.4066\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1077, Val Loss: 0.2947\n",
      "Epoch [2/50], Train Loss: 0.1068, Val Loss: 0.2943\n",
      "Epoch [3/50], Train Loss: 0.1077, Val Loss: 0.2939\n",
      "Epoch [4/50], Train Loss: 0.1080, Val Loss: 0.2935\n",
      "Epoch [5/50], Train Loss: 0.1068, Val Loss: 0.2931\n",
      "Epoch [6/50], Train Loss: 0.1070, Val Loss: 0.2927\n",
      "Epoch [7/50], Train Loss: 0.1065, Val Loss: 0.2923\n",
      "Epoch [8/50], Train Loss: 0.1068, Val Loss: 0.2919\n",
      "Epoch [9/50], Train Loss: 0.1055, Val Loss: 0.2916\n",
      "Epoch [10/50], Train Loss: 0.1067, Val Loss: 0.2912\n",
      "Epoch [11/50], Train Loss: 0.1059, Val Loss: 0.2908\n",
      "Epoch [12/50], Train Loss: 0.1062, Val Loss: 0.2904\n",
      "Epoch [13/50], Train Loss: 0.1057, Val Loss: 0.2900\n",
      "Epoch [14/50], Train Loss: 0.1060, Val Loss: 0.2896\n",
      "Epoch [15/50], Train Loss: 0.1042, Val Loss: 0.2892\n",
      "Epoch [16/50], Train Loss: 0.1043, Val Loss: 0.2888\n",
      "Epoch [17/50], Train Loss: 0.1042, Val Loss: 0.2884\n",
      "Epoch [18/50], Train Loss: 0.1051, Val Loss: 0.2880\n",
      "Epoch [19/50], Train Loss: 0.1038, Val Loss: 0.2876\n",
      "Epoch [20/50], Train Loss: 0.1046, Val Loss: 0.2873\n",
      "Epoch [21/50], Train Loss: 0.1037, Val Loss: 0.2869\n",
      "Epoch [22/50], Train Loss: 0.1035, Val Loss: 0.2865\n",
      "Epoch [23/50], Train Loss: 0.1028, Val Loss: 0.2861\n",
      "Epoch [24/50], Train Loss: 0.1025, Val Loss: 0.2857\n",
      "Epoch [25/50], Train Loss: 0.1031, Val Loss: 0.2853\n",
      "Epoch [26/50], Train Loss: 0.1029, Val Loss: 0.2850\n",
      "Epoch [27/50], Train Loss: 0.1029, Val Loss: 0.2846\n",
      "Epoch [28/50], Train Loss: 0.1023, Val Loss: 0.2842\n",
      "Epoch [29/50], Train Loss: 0.1022, Val Loss: 0.2838\n",
      "Epoch [30/50], Train Loss: 0.1024, Val Loss: 0.2835\n",
      "Epoch [31/50], Train Loss: 0.1020, Val Loss: 0.2831\n",
      "Epoch [32/50], Train Loss: 0.1019, Val Loss: 0.2827\n",
      "Epoch [33/50], Train Loss: 0.1020, Val Loss: 0.2823\n",
      "Epoch [34/50], Train Loss: 0.1016, Val Loss: 0.2819\n",
      "Epoch [35/50], Train Loss: 0.1005, Val Loss: 0.2816\n",
      "Epoch [36/50], Train Loss: 0.1021, Val Loss: 0.2812\n",
      "Epoch [37/50], Train Loss: 0.1000, Val Loss: 0.2808\n",
      "Epoch [38/50], Train Loss: 0.1007, Val Loss: 0.2805\n",
      "Epoch [39/50], Train Loss: 0.1007, Val Loss: 0.2801\n",
      "Epoch [40/50], Train Loss: 0.0999, Val Loss: 0.2797\n",
      "Epoch [41/50], Train Loss: 0.0996, Val Loss: 0.2794\n",
      "Epoch [42/50], Train Loss: 0.0998, Val Loss: 0.2790\n",
      "Epoch [43/50], Train Loss: 0.0997, Val Loss: 0.2786\n",
      "Epoch [44/50], Train Loss: 0.0994, Val Loss: 0.2783\n",
      "Epoch [45/50], Train Loss: 0.0997, Val Loss: 0.2779\n",
      "Epoch [46/50], Train Loss: 0.0990, Val Loss: 0.2775\n",
      "Epoch [47/50], Train Loss: 0.0989, Val Loss: 0.2772\n",
      "Epoch [48/50], Train Loss: 0.0990, Val Loss: 0.2768\n",
      "Epoch [49/50], Train Loss: 0.0983, Val Loss: 0.2765\n",
      "Epoch [50/50], Train Loss: 0.0985, Val Loss: 0.2761\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.2091, Val Loss: 0.4866\n",
      "Epoch [2/50], Train Loss: 0.2085, Val Loss: 0.4856\n",
      "Epoch [3/50], Train Loss: 0.2078, Val Loss: 0.4846\n",
      "Epoch [4/50], Train Loss: 0.2072, Val Loss: 0.4836\n",
      "Epoch [5/50], Train Loss: 0.2066, Val Loss: 0.4826\n",
      "Epoch [6/50], Train Loss: 0.2060, Val Loss: 0.4817\n",
      "Epoch [7/50], Train Loss: 0.2054, Val Loss: 0.4807\n",
      "Epoch [8/50], Train Loss: 0.2047, Val Loss: 0.4797\n",
      "Epoch [9/50], Train Loss: 0.2041, Val Loss: 0.4787\n",
      "Epoch [10/50], Train Loss: 0.2035, Val Loss: 0.4778\n",
      "Epoch [11/50], Train Loss: 0.2029, Val Loss: 0.4768\n",
      "Epoch [12/50], Train Loss: 0.2023, Val Loss: 0.4759\n",
      "Epoch [13/50], Train Loss: 0.2017, Val Loss: 0.4749\n",
      "Epoch [14/50], Train Loss: 0.2011, Val Loss: 0.4739\n",
      "Epoch [15/50], Train Loss: 0.2005, Val Loss: 0.4730\n",
      "Epoch [16/50], Train Loss: 0.1999, Val Loss: 0.4721\n",
      "Epoch [17/50], Train Loss: 0.1993, Val Loss: 0.4711\n",
      "Epoch [18/50], Train Loss: 0.1987, Val Loss: 0.4702\n",
      "Epoch [19/50], Train Loss: 0.1981, Val Loss: 0.4692\n",
      "Epoch [20/50], Train Loss: 0.1975, Val Loss: 0.4683\n",
      "Epoch [21/50], Train Loss: 0.1969, Val Loss: 0.4674\n",
      "Epoch [22/50], Train Loss: 0.1964, Val Loss: 0.4664\n",
      "Epoch [23/50], Train Loss: 0.1958, Val Loss: 0.4655\n",
      "Epoch [24/50], Train Loss: 0.1952, Val Loss: 0.4646\n",
      "Epoch [25/50], Train Loss: 0.1946, Val Loss: 0.4637\n",
      "Epoch [26/50], Train Loss: 0.1941, Val Loss: 0.4628\n",
      "Epoch [27/50], Train Loss: 0.1935, Val Loss: 0.4618\n",
      "Epoch [28/50], Train Loss: 0.1929, Val Loss: 0.4609\n",
      "Epoch [29/50], Train Loss: 0.1923, Val Loss: 0.4600\n",
      "Epoch [30/50], Train Loss: 0.1918, Val Loss: 0.4591\n",
      "Epoch [31/50], Train Loss: 0.1912, Val Loss: 0.4582\n",
      "Epoch [32/50], Train Loss: 0.1907, Val Loss: 0.4573\n",
      "Epoch [33/50], Train Loss: 0.1901, Val Loss: 0.4564\n",
      "Epoch [34/50], Train Loss: 0.1895, Val Loss: 0.4555\n",
      "Epoch [35/50], Train Loss: 0.1890, Val Loss: 0.4546\n",
      "Epoch [36/50], Train Loss: 0.1884, Val Loss: 0.4537\n",
      "Epoch [37/50], Train Loss: 0.1879, Val Loss: 0.4529\n",
      "Epoch [38/50], Train Loss: 0.1873, Val Loss: 0.4520\n",
      "Epoch [39/50], Train Loss: 0.1868, Val Loss: 0.4511\n",
      "Epoch [40/50], Train Loss: 0.1862, Val Loss: 0.4502\n",
      "Epoch [41/50], Train Loss: 0.1857, Val Loss: 0.4493\n",
      "Epoch [42/50], Train Loss: 0.1852, Val Loss: 0.4485\n",
      "Epoch [43/50], Train Loss: 0.1846, Val Loss: 0.4476\n",
      "Epoch [44/50], Train Loss: 0.1841, Val Loss: 0.4467\n",
      "Epoch [45/50], Train Loss: 0.1835, Val Loss: 0.4459\n",
      "Epoch [46/50], Train Loss: 0.1830, Val Loss: 0.4450\n",
      "Epoch [47/50], Train Loss: 0.1825, Val Loss: 0.4441\n",
      "Epoch [48/50], Train Loss: 0.1820, Val Loss: 0.4433\n",
      "Epoch [49/50], Train Loss: 0.1814, Val Loss: 0.4424\n",
      "Epoch [50/50], Train Loss: 0.1809, Val Loss: 0.4416\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1366, Val Loss: 0.3629\n",
      "Epoch [2/50], Train Loss: 0.1362, Val Loss: 0.3623\n",
      "Epoch [3/50], Train Loss: 0.1359, Val Loss: 0.3618\n",
      "Epoch [4/50], Train Loss: 0.1353, Val Loss: 0.3612\n",
      "Epoch [5/50], Train Loss: 0.1357, Val Loss: 0.3607\n",
      "Epoch [6/50], Train Loss: 0.1348, Val Loss: 0.3602\n",
      "Epoch [7/50], Train Loss: 0.1349, Val Loss: 0.3596\n",
      "Epoch [8/50], Train Loss: 0.1346, Val Loss: 0.3591\n",
      "Epoch [9/50], Train Loss: 0.1344, Val Loss: 0.3586\n",
      "Epoch [10/50], Train Loss: 0.1337, Val Loss: 0.3581\n",
      "Epoch [11/50], Train Loss: 0.1335, Val Loss: 0.3575\n",
      "Epoch [12/50], Train Loss: 0.1333, Val Loss: 0.3570\n",
      "Epoch [13/50], Train Loss: 0.1327, Val Loss: 0.3565\n",
      "Epoch [14/50], Train Loss: 0.1327, Val Loss: 0.3560\n",
      "Epoch [15/50], Train Loss: 0.1326, Val Loss: 0.3555\n",
      "Epoch [16/50], Train Loss: 0.1317, Val Loss: 0.3549\n",
      "Epoch [17/50], Train Loss: 0.1320, Val Loss: 0.3544\n",
      "Epoch [18/50], Train Loss: 0.1315, Val Loss: 0.3539\n",
      "Epoch [19/50], Train Loss: 0.1317, Val Loss: 0.3534\n",
      "Epoch [20/50], Train Loss: 0.1303, Val Loss: 0.3529\n",
      "Epoch [21/50], Train Loss: 0.1304, Val Loss: 0.3524\n",
      "Epoch [22/50], Train Loss: 0.1301, Val Loss: 0.3518\n",
      "Epoch [23/50], Train Loss: 0.1301, Val Loss: 0.3513\n",
      "Epoch [24/50], Train Loss: 0.1299, Val Loss: 0.3508\n",
      "Epoch [25/50], Train Loss: 0.1295, Val Loss: 0.3503\n",
      "Epoch [26/50], Train Loss: 0.1293, Val Loss: 0.3498\n",
      "Epoch [27/50], Train Loss: 0.1289, Val Loss: 0.3493\n",
      "Epoch [28/50], Train Loss: 0.1288, Val Loss: 0.3488\n",
      "Epoch [29/50], Train Loss: 0.1286, Val Loss: 0.3483\n",
      "Epoch [30/50], Train Loss: 0.1282, Val Loss: 0.3478\n",
      "Epoch [31/50], Train Loss: 0.1283, Val Loss: 0.3473\n",
      "Epoch [32/50], Train Loss: 0.1275, Val Loss: 0.3468\n",
      "Epoch [33/50], Train Loss: 0.1275, Val Loss: 0.3463\n",
      "Epoch [34/50], Train Loss: 0.1268, Val Loss: 0.3458\n",
      "Epoch [35/50], Train Loss: 0.1269, Val Loss: 0.3453\n",
      "Epoch [36/50], Train Loss: 0.1260, Val Loss: 0.3448\n",
      "Epoch [37/50], Train Loss: 0.1259, Val Loss: 0.3443\n",
      "Epoch [38/50], Train Loss: 0.1262, Val Loss: 0.3438\n",
      "Epoch [39/50], Train Loss: 0.1255, Val Loss: 0.3433\n",
      "Epoch [40/50], Train Loss: 0.1255, Val Loss: 0.3428\n",
      "Epoch [41/50], Train Loss: 0.1251, Val Loss: 0.3424\n",
      "Epoch [42/50], Train Loss: 0.1248, Val Loss: 0.3419\n",
      "Epoch [43/50], Train Loss: 0.1245, Val Loss: 0.3414\n",
      "Epoch [44/50], Train Loss: 0.1243, Val Loss: 0.3409\n",
      "Epoch [45/50], Train Loss: 0.1242, Val Loss: 0.3404\n",
      "Epoch [46/50], Train Loss: 0.1240, Val Loss: 0.3399\n",
      "Epoch [47/50], Train Loss: 0.1235, Val Loss: 0.3394\n",
      "Epoch [48/50], Train Loss: 0.1232, Val Loss: 0.3390\n",
      "Epoch [49/50], Train Loss: 0.1229, Val Loss: 0.3385\n",
      "Epoch [50/50], Train Loss: 0.1226, Val Loss: 0.3380\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1227, Val Loss: 0.3475\n",
      "Epoch [2/50], Train Loss: 0.1227, Val Loss: 0.3470\n",
      "Epoch [3/50], Train Loss: 0.1223, Val Loss: 0.3465\n",
      "Epoch [4/50], Train Loss: 0.1219, Val Loss: 0.3460\n",
      "Epoch [5/50], Train Loss: 0.1219, Val Loss: 0.3455\n",
      "Epoch [6/50], Train Loss: 0.1216, Val Loss: 0.3450\n",
      "Epoch [7/50], Train Loss: 0.1223, Val Loss: 0.3446\n",
      "Epoch [8/50], Train Loss: 0.1211, Val Loss: 0.3441\n",
      "Epoch [9/50], Train Loss: 0.1205, Val Loss: 0.3436\n",
      "Epoch [10/50], Train Loss: 0.1201, Val Loss: 0.3431\n",
      "Epoch [11/50], Train Loss: 0.1198, Val Loss: 0.3427\n",
      "Epoch [12/50], Train Loss: 0.1212, Val Loss: 0.3422\n",
      "Epoch [13/50], Train Loss: 0.1198, Val Loss: 0.3417\n",
      "Epoch [14/50], Train Loss: 0.1194, Val Loss: 0.3413\n",
      "Epoch [15/50], Train Loss: 0.1192, Val Loss: 0.3408\n",
      "Epoch [16/50], Train Loss: 0.1192, Val Loss: 0.3403\n",
      "Epoch [17/50], Train Loss: 0.1187, Val Loss: 0.3398\n",
      "Epoch [18/50], Train Loss: 0.1189, Val Loss: 0.3394\n",
      "Epoch [19/50], Train Loss: 0.1183, Val Loss: 0.3389\n",
      "Epoch [20/50], Train Loss: 0.1187, Val Loss: 0.3384\n",
      "Epoch [21/50], Train Loss: 0.1177, Val Loss: 0.3380\n",
      "Epoch [22/50], Train Loss: 0.1175, Val Loss: 0.3375\n",
      "Epoch [23/50], Train Loss: 0.1178, Val Loss: 0.3371\n",
      "Epoch [24/50], Train Loss: 0.1170, Val Loss: 0.3366\n",
      "Epoch [25/50], Train Loss: 0.1169, Val Loss: 0.3361\n",
      "Epoch [26/50], Train Loss: 0.1166, Val Loss: 0.3357\n",
      "Epoch [27/50], Train Loss: 0.1165, Val Loss: 0.3352\n",
      "Epoch [28/50], Train Loss: 0.1159, Val Loss: 0.3348\n",
      "Epoch [29/50], Train Loss: 0.1161, Val Loss: 0.3343\n",
      "Epoch [30/50], Train Loss: 0.1154, Val Loss: 0.3339\n",
      "Epoch [31/50], Train Loss: 0.1152, Val Loss: 0.3334\n",
      "Epoch [32/50], Train Loss: 0.1146, Val Loss: 0.3330\n",
      "Epoch [33/50], Train Loss: 0.1148, Val Loss: 0.3325\n",
      "Epoch [34/50], Train Loss: 0.1146, Val Loss: 0.3321\n",
      "Epoch [35/50], Train Loss: 0.1143, Val Loss: 0.3316\n",
      "Epoch [36/50], Train Loss: 0.1147, Val Loss: 0.3312\n",
      "Epoch [37/50], Train Loss: 0.1133, Val Loss: 0.3307\n",
      "Epoch [38/50], Train Loss: 0.1142, Val Loss: 0.3303\n",
      "Epoch [39/50], Train Loss: 0.1132, Val Loss: 0.3298\n",
      "Epoch [40/50], Train Loss: 0.1130, Val Loss: 0.3294\n",
      "Epoch [41/50], Train Loss: 0.1127, Val Loss: 0.3289\n",
      "Epoch [42/50], Train Loss: 0.1129, Val Loss: 0.3285\n",
      "Epoch [43/50], Train Loss: 0.1123, Val Loss: 0.3281\n",
      "Epoch [44/50], Train Loss: 0.1122, Val Loss: 0.3276\n",
      "Epoch [45/50], Train Loss: 0.1125, Val Loss: 0.3272\n",
      "Epoch [46/50], Train Loss: 0.1127, Val Loss: 0.3267\n",
      "Epoch [47/50], Train Loss: 0.1118, Val Loss: 0.3263\n",
      "Epoch [48/50], Train Loss: 0.1117, Val Loss: 0.3259\n",
      "Epoch [49/50], Train Loss: 0.1115, Val Loss: 0.3254\n",
      "Epoch [50/50], Train Loss: 0.1106, Val Loss: 0.3250\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1247, Val Loss: 0.3444\n",
      "Epoch [2/50], Train Loss: 0.1244, Val Loss: 0.3439\n",
      "Epoch [3/50], Train Loss: 0.1241, Val Loss: 0.3433\n",
      "Epoch [4/50], Train Loss: 0.1238, Val Loss: 0.3427\n",
      "Epoch [5/50], Train Loss: 0.1235, Val Loss: 0.3421\n",
      "Epoch [6/50], Train Loss: 0.1232, Val Loss: 0.3415\n",
      "Epoch [7/50], Train Loss: 0.1229, Val Loss: 0.3410\n",
      "Epoch [8/50], Train Loss: 0.1226, Val Loss: 0.3404\n",
      "Epoch [9/50], Train Loss: 0.1223, Val Loss: 0.3398\n",
      "Epoch [10/50], Train Loss: 0.1220, Val Loss: 0.3392\n",
      "Epoch [11/50], Train Loss: 0.1217, Val Loss: 0.3387\n",
      "Epoch [12/50], Train Loss: 0.1214, Val Loss: 0.3381\n",
      "Epoch [13/50], Train Loss: 0.1211, Val Loss: 0.3375\n",
      "Epoch [14/50], Train Loss: 0.1208, Val Loss: 0.3370\n",
      "Epoch [15/50], Train Loss: 0.1205, Val Loss: 0.3364\n",
      "Epoch [16/50], Train Loss: 0.1202, Val Loss: 0.3358\n",
      "Epoch [17/50], Train Loss: 0.1199, Val Loss: 0.3353\n",
      "Epoch [18/50], Train Loss: 0.1196, Val Loss: 0.3347\n",
      "Epoch [19/50], Train Loss: 0.1193, Val Loss: 0.3342\n",
      "Epoch [20/50], Train Loss: 0.1191, Val Loss: 0.3336\n",
      "Epoch [21/50], Train Loss: 0.1188, Val Loss: 0.3330\n",
      "Epoch [22/50], Train Loss: 0.1185, Val Loss: 0.3325\n",
      "Epoch [23/50], Train Loss: 0.1182, Val Loss: 0.3319\n",
      "Epoch [24/50], Train Loss: 0.1179, Val Loss: 0.3314\n",
      "Epoch [25/50], Train Loss: 0.1176, Val Loss: 0.3308\n",
      "Epoch [26/50], Train Loss: 0.1173, Val Loss: 0.3303\n",
      "Epoch [27/50], Train Loss: 0.1171, Val Loss: 0.3297\n",
      "Epoch [28/50], Train Loss: 0.1168, Val Loss: 0.3292\n",
      "Epoch [29/50], Train Loss: 0.1165, Val Loss: 0.3286\n",
      "Epoch [30/50], Train Loss: 0.1162, Val Loss: 0.3281\n",
      "Epoch [31/50], Train Loss: 0.1160, Val Loss: 0.3276\n",
      "Epoch [32/50], Train Loss: 0.1157, Val Loss: 0.3270\n",
      "Epoch [33/50], Train Loss: 0.1154, Val Loss: 0.3265\n",
      "Epoch [34/50], Train Loss: 0.1151, Val Loss: 0.3259\n",
      "Epoch [35/50], Train Loss: 0.1149, Val Loss: 0.3254\n",
      "Epoch [36/50], Train Loss: 0.1146, Val Loss: 0.3249\n",
      "Epoch [37/50], Train Loss: 0.1143, Val Loss: 0.3243\n",
      "Epoch [38/50], Train Loss: 0.1140, Val Loss: 0.3238\n",
      "Epoch [39/50], Train Loss: 0.1138, Val Loss: 0.3233\n",
      "Epoch [40/50], Train Loss: 0.1135, Val Loss: 0.3227\n",
      "Epoch [41/50], Train Loss: 0.1132, Val Loss: 0.3222\n",
      "Epoch [42/50], Train Loss: 0.1130, Val Loss: 0.3217\n",
      "Epoch [43/50], Train Loss: 0.1127, Val Loss: 0.3212\n",
      "Epoch [44/50], Train Loss: 0.1124, Val Loss: 0.3206\n",
      "Epoch [45/50], Train Loss: 0.1122, Val Loss: 0.3201\n",
      "Epoch [46/50], Train Loss: 0.1119, Val Loss: 0.3196\n",
      "Epoch [47/50], Train Loss: 0.1116, Val Loss: 0.3191\n",
      "Epoch [48/50], Train Loss: 0.1114, Val Loss: 0.3186\n",
      "Epoch [49/50], Train Loss: 0.1111, Val Loss: 0.3180\n",
      "Epoch [50/50], Train Loss: 0.1109, Val Loss: 0.3175\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1190, Val Loss: 0.3736\n",
      "Epoch [2/50], Train Loss: 0.1188, Val Loss: 0.3729\n",
      "Epoch [3/50], Train Loss: 0.1181, Val Loss: 0.3723\n",
      "Epoch [4/50], Train Loss: 0.1177, Val Loss: 0.3716\n",
      "Epoch [5/50], Train Loss: 0.1177, Val Loss: 0.3710\n",
      "Epoch [6/50], Train Loss: 0.1169, Val Loss: 0.3704\n",
      "Epoch [7/50], Train Loss: 0.1165, Val Loss: 0.3697\n",
      "Epoch [8/50], Train Loss: 0.1172, Val Loss: 0.3691\n",
      "Epoch [9/50], Train Loss: 0.1161, Val Loss: 0.3685\n",
      "Epoch [10/50], Train Loss: 0.1161, Val Loss: 0.3678\n",
      "Epoch [11/50], Train Loss: 0.1157, Val Loss: 0.3672\n",
      "Epoch [12/50], Train Loss: 0.1158, Val Loss: 0.3666\n",
      "Epoch [13/50], Train Loss: 0.1150, Val Loss: 0.3659\n",
      "Epoch [14/50], Train Loss: 0.1144, Val Loss: 0.3653\n",
      "Epoch [15/50], Train Loss: 0.1148, Val Loss: 0.3647\n",
      "Epoch [16/50], Train Loss: 0.1143, Val Loss: 0.3641\n",
      "Epoch [17/50], Train Loss: 0.1134, Val Loss: 0.3635\n",
      "Epoch [18/50], Train Loss: 0.1136, Val Loss: 0.3628\n",
      "Epoch [19/50], Train Loss: 0.1135, Val Loss: 0.3622\n",
      "Epoch [20/50], Train Loss: 0.1128, Val Loss: 0.3616\n",
      "Epoch [21/50], Train Loss: 0.1127, Val Loss: 0.3610\n",
      "Epoch [22/50], Train Loss: 0.1125, Val Loss: 0.3604\n",
      "Epoch [23/50], Train Loss: 0.1119, Val Loss: 0.3598\n",
      "Epoch [24/50], Train Loss: 0.1116, Val Loss: 0.3591\n",
      "Epoch [25/50], Train Loss: 0.1116, Val Loss: 0.3585\n",
      "Epoch [26/50], Train Loss: 0.1118, Val Loss: 0.3579\n",
      "Epoch [27/50], Train Loss: 0.1114, Val Loss: 0.3573\n",
      "Epoch [28/50], Train Loss: 0.1108, Val Loss: 0.3567\n",
      "Epoch [29/50], Train Loss: 0.1111, Val Loss: 0.3561\n",
      "Epoch [30/50], Train Loss: 0.1107, Val Loss: 0.3555\n",
      "Epoch [31/50], Train Loss: 0.1104, Val Loss: 0.3549\n",
      "Epoch [32/50], Train Loss: 0.1093, Val Loss: 0.3543\n",
      "Epoch [33/50], Train Loss: 0.1093, Val Loss: 0.3537\n",
      "Epoch [34/50], Train Loss: 0.1095, Val Loss: 0.3531\n",
      "Epoch [35/50], Train Loss: 0.1092, Val Loss: 0.3526\n",
      "Epoch [36/50], Train Loss: 0.1088, Val Loss: 0.3520\n",
      "Epoch [37/50], Train Loss: 0.1085, Val Loss: 0.3514\n",
      "Epoch [38/50], Train Loss: 0.1081, Val Loss: 0.3508\n",
      "Epoch [39/50], Train Loss: 0.1078, Val Loss: 0.3502\n",
      "Epoch [40/50], Train Loss: 0.1079, Val Loss: 0.3496\n",
      "Epoch [41/50], Train Loss: 0.1077, Val Loss: 0.3490\n",
      "Epoch [42/50], Train Loss: 0.1074, Val Loss: 0.3485\n",
      "Epoch [43/50], Train Loss: 0.1068, Val Loss: 0.3479\n",
      "Epoch [44/50], Train Loss: 0.1072, Val Loss: 0.3473\n",
      "Epoch [45/50], Train Loss: 0.1067, Val Loss: 0.3467\n",
      "Epoch [46/50], Train Loss: 0.1064, Val Loss: 0.3462\n",
      "Epoch [47/50], Train Loss: 0.1058, Val Loss: 0.3456\n",
      "Epoch [48/50], Train Loss: 0.1063, Val Loss: 0.3450\n",
      "Epoch [49/50], Train Loss: 0.1058, Val Loss: 0.3444\n",
      "Epoch [50/50], Train Loss: 0.1055, Val Loss: 0.3439\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1880, Val Loss: 0.4599\n",
      "Epoch [2/50], Train Loss: 0.1867, Val Loss: 0.4591\n",
      "Epoch [3/50], Train Loss: 0.1856, Val Loss: 0.4583\n",
      "Epoch [4/50], Train Loss: 0.1861, Val Loss: 0.4574\n",
      "Epoch [5/50], Train Loss: 0.1859, Val Loss: 0.4566\n",
      "Epoch [6/50], Train Loss: 0.1843, Val Loss: 0.4558\n",
      "Epoch [7/50], Train Loss: 0.1848, Val Loss: 0.4550\n",
      "Epoch [8/50], Train Loss: 0.1845, Val Loss: 0.4541\n",
      "Epoch [9/50], Train Loss: 0.1842, Val Loss: 0.4533\n",
      "Epoch [10/50], Train Loss: 0.1839, Val Loss: 0.4525\n",
      "Epoch [11/50], Train Loss: 0.1832, Val Loss: 0.4517\n",
      "Epoch [12/50], Train Loss: 0.1822, Val Loss: 0.4509\n",
      "Epoch [13/50], Train Loss: 0.1822, Val Loss: 0.4500\n",
      "Epoch [14/50], Train Loss: 0.1816, Val Loss: 0.4492\n",
      "Epoch [15/50], Train Loss: 0.1807, Val Loss: 0.4484\n",
      "Epoch [16/50], Train Loss: 0.1801, Val Loss: 0.4476\n",
      "Epoch [17/50], Train Loss: 0.1805, Val Loss: 0.4468\n",
      "Epoch [18/50], Train Loss: 0.1799, Val Loss: 0.4460\n",
      "Epoch [19/50], Train Loss: 0.1789, Val Loss: 0.4452\n",
      "Epoch [20/50], Train Loss: 0.1785, Val Loss: 0.4444\n",
      "Epoch [21/50], Train Loss: 0.1784, Val Loss: 0.4436\n",
      "Epoch [22/50], Train Loss: 0.1787, Val Loss: 0.4428\n",
      "Epoch [23/50], Train Loss: 0.1782, Val Loss: 0.4420\n",
      "Epoch [24/50], Train Loss: 0.1776, Val Loss: 0.4412\n",
      "Epoch [25/50], Train Loss: 0.1759, Val Loss: 0.4404\n",
      "Epoch [26/50], Train Loss: 0.1758, Val Loss: 0.4397\n",
      "Epoch [27/50], Train Loss: 0.1754, Val Loss: 0.4389\n",
      "Epoch [28/50], Train Loss: 0.1751, Val Loss: 0.4381\n",
      "Epoch [29/50], Train Loss: 0.1754, Val Loss: 0.4373\n",
      "Epoch [30/50], Train Loss: 0.1747, Val Loss: 0.4365\n",
      "Epoch [31/50], Train Loss: 0.1735, Val Loss: 0.4358\n",
      "Epoch [32/50], Train Loss: 0.1732, Val Loss: 0.4350\n",
      "Epoch [33/50], Train Loss: 0.1744, Val Loss: 0.4342\n",
      "Epoch [34/50], Train Loss: 0.1727, Val Loss: 0.4335\n",
      "Epoch [35/50], Train Loss: 0.1725, Val Loss: 0.4327\n",
      "Epoch [36/50], Train Loss: 0.1721, Val Loss: 0.4319\n",
      "Epoch [37/50], Train Loss: 0.1707, Val Loss: 0.4312\n",
      "Epoch [38/50], Train Loss: 0.1704, Val Loss: 0.4304\n",
      "Epoch [39/50], Train Loss: 0.1700, Val Loss: 0.4296\n",
      "Epoch [40/50], Train Loss: 0.1701, Val Loss: 0.4289\n",
      "Epoch [41/50], Train Loss: 0.1696, Val Loss: 0.4281\n",
      "Epoch [42/50], Train Loss: 0.1691, Val Loss: 0.4274\n",
      "Epoch [43/50], Train Loss: 0.1687, Val Loss: 0.4266\n",
      "Epoch [44/50], Train Loss: 0.1694, Val Loss: 0.4259\n",
      "Epoch [45/50], Train Loss: 0.1674, Val Loss: 0.4251\n",
      "Epoch [46/50], Train Loss: 0.1680, Val Loss: 0.4244\n",
      "Epoch [47/50], Train Loss: 0.1669, Val Loss: 0.4236\n",
      "Epoch [48/50], Train Loss: 0.1666, Val Loss: 0.4229\n",
      "Epoch [49/50], Train Loss: 0.1663, Val Loss: 0.4222\n",
      "Epoch [50/50], Train Loss: 0.1655, Val Loss: 0.4214\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1589, Val Loss: 0.4093\n",
      "Epoch [2/50], Train Loss: 0.1585, Val Loss: 0.4087\n",
      "Epoch [3/50], Train Loss: 0.1581, Val Loss: 0.4081\n",
      "Epoch [4/50], Train Loss: 0.1578, Val Loss: 0.4074\n",
      "Epoch [5/50], Train Loss: 0.1574, Val Loss: 0.4068\n",
      "Epoch [6/50], Train Loss: 0.1570, Val Loss: 0.4062\n",
      "Epoch [7/50], Train Loss: 0.1567, Val Loss: 0.4055\n",
      "Epoch [8/50], Train Loss: 0.1563, Val Loss: 0.4049\n",
      "Epoch [9/50], Train Loss: 0.1559, Val Loss: 0.4043\n",
      "Epoch [10/50], Train Loss: 0.1556, Val Loss: 0.4037\n",
      "Epoch [11/50], Train Loss: 0.1552, Val Loss: 0.4030\n",
      "Epoch [12/50], Train Loss: 0.1549, Val Loss: 0.4024\n",
      "Epoch [13/50], Train Loss: 0.1545, Val Loss: 0.4018\n",
      "Epoch [14/50], Train Loss: 0.1541, Val Loss: 0.4012\n",
      "Epoch [15/50], Train Loss: 0.1538, Val Loss: 0.4006\n",
      "Epoch [16/50], Train Loss: 0.1534, Val Loss: 0.4000\n",
      "Epoch [17/50], Train Loss: 0.1531, Val Loss: 0.3993\n",
      "Epoch [18/50], Train Loss: 0.1527, Val Loss: 0.3987\n",
      "Epoch [19/50], Train Loss: 0.1524, Val Loss: 0.3981\n",
      "Epoch [20/50], Train Loss: 0.1520, Val Loss: 0.3975\n",
      "Epoch [21/50], Train Loss: 0.1517, Val Loss: 0.3969\n",
      "Epoch [22/50], Train Loss: 0.1513, Val Loss: 0.3963\n",
      "Epoch [23/50], Train Loss: 0.1510, Val Loss: 0.3957\n",
      "Epoch [24/50], Train Loss: 0.1506, Val Loss: 0.3951\n",
      "Epoch [25/50], Train Loss: 0.1503, Val Loss: 0.3945\n",
      "Epoch [26/50], Train Loss: 0.1499, Val Loss: 0.3939\n",
      "Epoch [27/50], Train Loss: 0.1496, Val Loss: 0.3933\n",
      "Epoch [28/50], Train Loss: 0.1493, Val Loss: 0.3927\n",
      "Epoch [29/50], Train Loss: 0.1489, Val Loss: 0.3921\n",
      "Epoch [30/50], Train Loss: 0.1486, Val Loss: 0.3915\n",
      "Epoch [31/50], Train Loss: 0.1482, Val Loss: 0.3909\n",
      "Epoch [32/50], Train Loss: 0.1479, Val Loss: 0.3903\n",
      "Epoch [33/50], Train Loss: 0.1476, Val Loss: 0.3897\n",
      "Epoch [34/50], Train Loss: 0.1472, Val Loss: 0.3892\n",
      "Epoch [35/50], Train Loss: 0.1469, Val Loss: 0.3886\n",
      "Epoch [36/50], Train Loss: 0.1466, Val Loss: 0.3880\n",
      "Epoch [37/50], Train Loss: 0.1462, Val Loss: 0.3874\n",
      "Epoch [38/50], Train Loss: 0.1459, Val Loss: 0.3868\n",
      "Epoch [39/50], Train Loss: 0.1456, Val Loss: 0.3862\n",
      "Epoch [40/50], Train Loss: 0.1452, Val Loss: 0.3857\n",
      "Epoch [41/50], Train Loss: 0.1449, Val Loss: 0.3851\n",
      "Epoch [42/50], Train Loss: 0.1446, Val Loss: 0.3845\n",
      "Epoch [43/50], Train Loss: 0.1443, Val Loss: 0.3839\n",
      "Epoch [44/50], Train Loss: 0.1439, Val Loss: 0.3833\n",
      "Epoch [45/50], Train Loss: 0.1436, Val Loss: 0.3828\n",
      "Epoch [46/50], Train Loss: 0.1433, Val Loss: 0.3822\n",
      "Epoch [47/50], Train Loss: 0.1430, Val Loss: 0.3816\n",
      "Epoch [48/50], Train Loss: 0.1426, Val Loss: 0.3811\n",
      "Epoch [49/50], Train Loss: 0.1423, Val Loss: 0.3805\n",
      "Epoch [50/50], Train Loss: 0.1420, Val Loss: 0.3799\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1190, Val Loss: 0.3251\n",
      "Epoch [2/50], Train Loss: 0.1191, Val Loss: 0.3246\n",
      "Epoch [3/50], Train Loss: 0.1188, Val Loss: 0.3242\n",
      "Epoch [4/50], Train Loss: 0.1185, Val Loss: 0.3238\n",
      "Epoch [5/50], Train Loss: 0.1182, Val Loss: 0.3233\n",
      "Epoch [6/50], Train Loss: 0.1177, Val Loss: 0.3229\n",
      "Epoch [7/50], Train Loss: 0.1178, Val Loss: 0.3224\n",
      "Epoch [8/50], Train Loss: 0.1174, Val Loss: 0.3220\n",
      "Epoch [9/50], Train Loss: 0.1172, Val Loss: 0.3216\n",
      "Epoch [10/50], Train Loss: 0.1170, Val Loss: 0.3211\n",
      "Epoch [11/50], Train Loss: 0.1168, Val Loss: 0.3207\n",
      "Epoch [12/50], Train Loss: 0.1163, Val Loss: 0.3203\n",
      "Epoch [13/50], Train Loss: 0.1165, Val Loss: 0.3198\n",
      "Epoch [14/50], Train Loss: 0.1163, Val Loss: 0.3194\n",
      "Epoch [15/50], Train Loss: 0.1158, Val Loss: 0.3190\n",
      "Epoch [16/50], Train Loss: 0.1156, Val Loss: 0.3186\n",
      "Epoch [17/50], Train Loss: 0.1154, Val Loss: 0.3181\n",
      "Epoch [18/50], Train Loss: 0.1151, Val Loss: 0.3177\n",
      "Epoch [19/50], Train Loss: 0.1150, Val Loss: 0.3173\n",
      "Epoch [20/50], Train Loss: 0.1144, Val Loss: 0.3169\n",
      "Epoch [21/50], Train Loss: 0.1144, Val Loss: 0.3164\n",
      "Epoch [22/50], Train Loss: 0.1141, Val Loss: 0.3160\n",
      "Epoch [23/50], Train Loss: 0.1137, Val Loss: 0.3156\n",
      "Epoch [24/50], Train Loss: 0.1138, Val Loss: 0.3152\n",
      "Epoch [25/50], Train Loss: 0.1134, Val Loss: 0.3148\n",
      "Epoch [26/50], Train Loss: 0.1131, Val Loss: 0.3143\n",
      "Epoch [27/50], Train Loss: 0.1131, Val Loss: 0.3139\n",
      "Epoch [28/50], Train Loss: 0.1129, Val Loss: 0.3135\n",
      "Epoch [29/50], Train Loss: 0.1125, Val Loss: 0.3131\n",
      "Epoch [30/50], Train Loss: 0.1120, Val Loss: 0.3127\n",
      "Epoch [31/50], Train Loss: 0.1122, Val Loss: 0.3123\n",
      "Epoch [32/50], Train Loss: 0.1118, Val Loss: 0.3119\n",
      "Epoch [33/50], Train Loss: 0.1118, Val Loss: 0.3115\n",
      "Epoch [34/50], Train Loss: 0.1116, Val Loss: 0.3110\n",
      "Epoch [35/50], Train Loss: 0.1111, Val Loss: 0.3106\n",
      "Epoch [36/50], Train Loss: 0.1108, Val Loss: 0.3102\n",
      "Epoch [37/50], Train Loss: 0.1103, Val Loss: 0.3098\n",
      "Epoch [38/50], Train Loss: 0.1104, Val Loss: 0.3094\n",
      "Epoch [39/50], Train Loss: 0.1104, Val Loss: 0.3090\n",
      "Epoch [40/50], Train Loss: 0.1099, Val Loss: 0.3086\n",
      "Epoch [41/50], Train Loss: 0.1098, Val Loss: 0.3082\n",
      "Epoch [42/50], Train Loss: 0.1096, Val Loss: 0.3078\n",
      "Epoch [43/50], Train Loss: 0.1094, Val Loss: 0.3074\n",
      "Epoch [44/50], Train Loss: 0.1094, Val Loss: 0.3070\n",
      "Epoch [45/50], Train Loss: 0.1088, Val Loss: 0.3066\n",
      "Epoch [46/50], Train Loss: 0.1083, Val Loss: 0.3062\n",
      "Epoch [47/50], Train Loss: 0.1085, Val Loss: 0.3058\n",
      "Epoch [48/50], Train Loss: 0.1081, Val Loss: 0.3054\n",
      "Epoch [49/50], Train Loss: 0.1082, Val Loss: 0.3050\n",
      "Epoch [50/50], Train Loss: 0.1080, Val Loss: 0.3046\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1315, Val Loss: 0.3604\n",
      "Epoch [2/50], Train Loss: 0.1315, Val Loss: 0.3599\n",
      "Epoch [3/50], Train Loss: 0.1315, Val Loss: 0.3594\n",
      "Epoch [4/50], Train Loss: 0.1311, Val Loss: 0.3588\n",
      "Epoch [5/50], Train Loss: 0.1309, Val Loss: 0.3583\n",
      "Epoch [6/50], Train Loss: 0.1308, Val Loss: 0.3578\n",
      "Epoch [7/50], Train Loss: 0.1306, Val Loss: 0.3573\n",
      "Epoch [8/50], Train Loss: 0.1292, Val Loss: 0.3567\n",
      "Epoch [9/50], Train Loss: 0.1299, Val Loss: 0.3562\n",
      "Epoch [10/50], Train Loss: 0.1298, Val Loss: 0.3557\n",
      "Epoch [11/50], Train Loss: 0.1291, Val Loss: 0.3552\n",
      "Epoch [12/50], Train Loss: 0.1285, Val Loss: 0.3547\n",
      "Epoch [13/50], Train Loss: 0.1285, Val Loss: 0.3542\n",
      "Epoch [14/50], Train Loss: 0.1280, Val Loss: 0.3536\n",
      "Epoch [15/50], Train Loss: 0.1278, Val Loss: 0.3531\n",
      "Epoch [16/50], Train Loss: 0.1283, Val Loss: 0.3526\n",
      "Epoch [17/50], Train Loss: 0.1275, Val Loss: 0.3521\n",
      "Epoch [18/50], Train Loss: 0.1267, Val Loss: 0.3516\n",
      "Epoch [19/50], Train Loss: 0.1260, Val Loss: 0.3511\n",
      "Epoch [20/50], Train Loss: 0.1267, Val Loss: 0.3506\n",
      "Epoch [21/50], Train Loss: 0.1262, Val Loss: 0.3501\n",
      "Epoch [22/50], Train Loss: 0.1261, Val Loss: 0.3496\n",
      "Epoch [23/50], Train Loss: 0.1258, Val Loss: 0.3490\n",
      "Epoch [24/50], Train Loss: 0.1258, Val Loss: 0.3485\n",
      "Epoch [25/50], Train Loss: 0.1258, Val Loss: 0.3480\n",
      "Epoch [26/50], Train Loss: 0.1245, Val Loss: 0.3475\n",
      "Epoch [27/50], Train Loss: 0.1245, Val Loss: 0.3470\n",
      "Epoch [28/50], Train Loss: 0.1248, Val Loss: 0.3465\n",
      "Epoch [29/50], Train Loss: 0.1243, Val Loss: 0.3460\n",
      "Epoch [30/50], Train Loss: 0.1243, Val Loss: 0.3455\n",
      "Epoch [31/50], Train Loss: 0.1241, Val Loss: 0.3450\n",
      "Epoch [32/50], Train Loss: 0.1232, Val Loss: 0.3445\n",
      "Epoch [33/50], Train Loss: 0.1231, Val Loss: 0.3441\n",
      "Epoch [34/50], Train Loss: 0.1231, Val Loss: 0.3436\n",
      "Epoch [35/50], Train Loss: 0.1225, Val Loss: 0.3431\n",
      "Epoch [36/50], Train Loss: 0.1226, Val Loss: 0.3426\n",
      "Epoch [37/50], Train Loss: 0.1220, Val Loss: 0.3421\n",
      "Epoch [38/50], Train Loss: 0.1221, Val Loss: 0.3416\n",
      "Epoch [39/50], Train Loss: 0.1216, Val Loss: 0.3411\n",
      "Epoch [40/50], Train Loss: 0.1210, Val Loss: 0.3406\n",
      "Epoch [41/50], Train Loss: 0.1216, Val Loss: 0.3401\n",
      "Epoch [42/50], Train Loss: 0.1206, Val Loss: 0.3397\n",
      "Epoch [43/50], Train Loss: 0.1209, Val Loss: 0.3392\n",
      "Epoch [44/50], Train Loss: 0.1200, Val Loss: 0.3387\n",
      "Epoch [45/50], Train Loss: 0.1201, Val Loss: 0.3382\n",
      "Epoch [46/50], Train Loss: 0.1199, Val Loss: 0.3377\n",
      "Epoch [47/50], Train Loss: 0.1196, Val Loss: 0.3372\n",
      "Epoch [48/50], Train Loss: 0.1188, Val Loss: 0.3368\n",
      "Epoch [49/50], Train Loss: 0.1192, Val Loss: 0.3363\n",
      "Epoch [50/50], Train Loss: 0.1192, Val Loss: 0.3358\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1103, Val Loss: 0.3109\n",
      "Epoch [2/50], Train Loss: 0.1101, Val Loss: 0.3105\n",
      "Epoch [3/50], Train Loss: 0.1098, Val Loss: 0.3100\n",
      "Epoch [4/50], Train Loss: 0.1096, Val Loss: 0.3096\n",
      "Epoch [5/50], Train Loss: 0.1093, Val Loss: 0.3091\n",
      "Epoch [6/50], Train Loss: 0.1091, Val Loss: 0.3087\n",
      "Epoch [7/50], Train Loss: 0.1088, Val Loss: 0.3082\n",
      "Epoch [8/50], Train Loss: 0.1086, Val Loss: 0.3078\n",
      "Epoch [9/50], Train Loss: 0.1084, Val Loss: 0.3074\n",
      "Epoch [10/50], Train Loss: 0.1081, Val Loss: 0.3069\n",
      "Epoch [11/50], Train Loss: 0.1079, Val Loss: 0.3065\n",
      "Epoch [12/50], Train Loss: 0.1076, Val Loss: 0.3060\n",
      "Epoch [13/50], Train Loss: 0.1074, Val Loss: 0.3056\n",
      "Epoch [14/50], Train Loss: 0.1072, Val Loss: 0.3051\n",
      "Epoch [15/50], Train Loss: 0.1069, Val Loss: 0.3047\n",
      "Epoch [16/50], Train Loss: 0.1067, Val Loss: 0.3043\n",
      "Epoch [17/50], Train Loss: 0.1065, Val Loss: 0.3038\n",
      "Epoch [18/50], Train Loss: 0.1062, Val Loss: 0.3034\n",
      "Epoch [19/50], Train Loss: 0.1060, Val Loss: 0.3030\n",
      "Epoch [20/50], Train Loss: 0.1058, Val Loss: 0.3025\n",
      "Epoch [21/50], Train Loss: 0.1055, Val Loss: 0.3021\n",
      "Epoch [22/50], Train Loss: 0.1053, Val Loss: 0.3017\n",
      "Epoch [23/50], Train Loss: 0.1051, Val Loss: 0.3012\n",
      "Epoch [24/50], Train Loss: 0.1048, Val Loss: 0.3008\n",
      "Epoch [25/50], Train Loss: 0.1046, Val Loss: 0.3004\n",
      "Epoch [26/50], Train Loss: 0.1044, Val Loss: 0.2999\n",
      "Epoch [27/50], Train Loss: 0.1042, Val Loss: 0.2995\n",
      "Epoch [28/50], Train Loss: 0.1039, Val Loss: 0.2991\n",
      "Epoch [29/50], Train Loss: 0.1037, Val Loss: 0.2987\n",
      "Epoch [30/50], Train Loss: 0.1035, Val Loss: 0.2983\n",
      "Epoch [31/50], Train Loss: 0.1033, Val Loss: 0.2978\n",
      "Epoch [32/50], Train Loss: 0.1030, Val Loss: 0.2974\n",
      "Epoch [33/50], Train Loss: 0.1028, Val Loss: 0.2970\n",
      "Epoch [34/50], Train Loss: 0.1026, Val Loss: 0.2966\n",
      "Epoch [35/50], Train Loss: 0.1024, Val Loss: 0.2962\n",
      "Epoch [36/50], Train Loss: 0.1021, Val Loss: 0.2957\n",
      "Epoch [37/50], Train Loss: 0.1019, Val Loss: 0.2953\n",
      "Epoch [38/50], Train Loss: 0.1017, Val Loss: 0.2949\n",
      "Epoch [39/50], Train Loss: 0.1015, Val Loss: 0.2945\n",
      "Epoch [40/50], Train Loss: 0.1013, Val Loss: 0.2941\n",
      "Epoch [41/50], Train Loss: 0.1011, Val Loss: 0.2937\n",
      "Epoch [42/50], Train Loss: 0.1008, Val Loss: 0.2933\n",
      "Epoch [43/50], Train Loss: 0.1006, Val Loss: 0.2928\n",
      "Epoch [44/50], Train Loss: 0.1004, Val Loss: 0.2924\n",
      "Epoch [45/50], Train Loss: 0.1002, Val Loss: 0.2920\n",
      "Epoch [46/50], Train Loss: 0.1000, Val Loss: 0.2916\n",
      "Epoch [47/50], Train Loss: 0.0998, Val Loss: 0.2912\n",
      "Epoch [48/50], Train Loss: 0.0996, Val Loss: 0.2908\n",
      "Epoch [49/50], Train Loss: 0.0994, Val Loss: 0.2904\n",
      "Epoch [50/50], Train Loss: 0.0991, Val Loss: 0.2900\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1728, Val Loss: 0.4586\n",
      "Epoch [2/50], Train Loss: 0.1722, Val Loss: 0.4578\n",
      "Epoch [3/50], Train Loss: 0.1718, Val Loss: 0.4571\n",
      "Epoch [4/50], Train Loss: 0.1712, Val Loss: 0.4563\n",
      "Epoch [5/50], Train Loss: 0.1712, Val Loss: 0.4555\n",
      "Epoch [6/50], Train Loss: 0.1703, Val Loss: 0.4548\n",
      "Epoch [7/50], Train Loss: 0.1699, Val Loss: 0.4540\n",
      "Epoch [8/50], Train Loss: 0.1696, Val Loss: 0.4533\n",
      "Epoch [9/50], Train Loss: 0.1696, Val Loss: 0.4525\n",
      "Epoch [10/50], Train Loss: 0.1685, Val Loss: 0.4518\n",
      "Epoch [11/50], Train Loss: 0.1685, Val Loss: 0.4510\n",
      "Epoch [12/50], Train Loss: 0.1680, Val Loss: 0.4503\n",
      "Epoch [13/50], Train Loss: 0.1678, Val Loss: 0.4496\n",
      "Epoch [14/50], Train Loss: 0.1671, Val Loss: 0.4488\n",
      "Epoch [15/50], Train Loss: 0.1668, Val Loss: 0.4481\n",
      "Epoch [16/50], Train Loss: 0.1664, Val Loss: 0.4473\n",
      "Epoch [17/50], Train Loss: 0.1661, Val Loss: 0.4466\n",
      "Epoch [18/50], Train Loss: 0.1653, Val Loss: 0.4459\n",
      "Epoch [19/50], Train Loss: 0.1653, Val Loss: 0.4451\n",
      "Epoch [20/50], Train Loss: 0.1650, Val Loss: 0.4444\n",
      "Epoch [21/50], Train Loss: 0.1643, Val Loss: 0.4437\n",
      "Epoch [22/50], Train Loss: 0.1642, Val Loss: 0.4430\n",
      "Epoch [23/50], Train Loss: 0.1633, Val Loss: 0.4422\n",
      "Epoch [24/50], Train Loss: 0.1627, Val Loss: 0.4415\n",
      "Epoch [25/50], Train Loss: 0.1628, Val Loss: 0.4408\n",
      "Epoch [26/50], Train Loss: 0.1621, Val Loss: 0.4401\n",
      "Epoch [27/50], Train Loss: 0.1617, Val Loss: 0.4394\n",
      "Epoch [28/50], Train Loss: 0.1614, Val Loss: 0.4387\n",
      "Epoch [29/50], Train Loss: 0.1611, Val Loss: 0.4379\n",
      "Epoch [30/50], Train Loss: 0.1611, Val Loss: 0.4372\n",
      "Epoch [31/50], Train Loss: 0.1604, Val Loss: 0.4365\n",
      "Epoch [32/50], Train Loss: 0.1600, Val Loss: 0.4358\n",
      "Epoch [33/50], Train Loss: 0.1597, Val Loss: 0.4351\n",
      "Epoch [34/50], Train Loss: 0.1596, Val Loss: 0.4344\n",
      "Epoch [35/50], Train Loss: 0.1590, Val Loss: 0.4337\n",
      "Epoch [36/50], Train Loss: 0.1585, Val Loss: 0.4330\n",
      "Epoch [37/50], Train Loss: 0.1584, Val Loss: 0.4323\n",
      "Epoch [38/50], Train Loss: 0.1577, Val Loss: 0.4316\n",
      "Epoch [39/50], Train Loss: 0.1570, Val Loss: 0.4309\n",
      "Epoch [40/50], Train Loss: 0.1570, Val Loss: 0.4302\n",
      "Epoch [41/50], Train Loss: 0.1566, Val Loss: 0.4295\n",
      "Epoch [42/50], Train Loss: 0.1558, Val Loss: 0.4288\n",
      "Epoch [43/50], Train Loss: 0.1556, Val Loss: 0.4281\n",
      "Epoch [44/50], Train Loss: 0.1553, Val Loss: 0.4275\n",
      "Epoch [45/50], Train Loss: 0.1547, Val Loss: 0.4268\n",
      "Epoch [46/50], Train Loss: 0.1548, Val Loss: 0.4261\n",
      "Epoch [47/50], Train Loss: 0.1544, Val Loss: 0.4254\n",
      "Epoch [48/50], Train Loss: 0.1538, Val Loss: 0.4247\n",
      "Epoch [49/50], Train Loss: 0.1532, Val Loss: 0.4240\n",
      "Epoch [50/50], Train Loss: 0.1532, Val Loss: 0.4234\n",
      "Testing parameters: lr=0.0001, optimizer=sgd, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1758, Val Loss: 0.4328\n",
      "Epoch [2/50], Train Loss: 0.1748, Val Loss: 0.4321\n",
      "Epoch [3/50], Train Loss: 0.1753, Val Loss: 0.4314\n",
      "Epoch [4/50], Train Loss: 0.1749, Val Loss: 0.4306\n",
      "Epoch [5/50], Train Loss: 0.1737, Val Loss: 0.4299\n",
      "Epoch [6/50], Train Loss: 0.1743, Val Loss: 0.4292\n",
      "Epoch [7/50], Train Loss: 0.1736, Val Loss: 0.4284\n",
      "Epoch [8/50], Train Loss: 0.1731, Val Loss: 0.4277\n",
      "Epoch [9/50], Train Loss: 0.1722, Val Loss: 0.4270\n",
      "Epoch [10/50], Train Loss: 0.1717, Val Loss: 0.4263\n",
      "Epoch [11/50], Train Loss: 0.1718, Val Loss: 0.4255\n",
      "Epoch [12/50], Train Loss: 0.1707, Val Loss: 0.4248\n",
      "Epoch [13/50], Train Loss: 0.1711, Val Loss: 0.4241\n",
      "Epoch [14/50], Train Loss: 0.1700, Val Loss: 0.4234\n",
      "Epoch [15/50], Train Loss: 0.1695, Val Loss: 0.4227\n",
      "Epoch [16/50], Train Loss: 0.1702, Val Loss: 0.4220\n",
      "Epoch [17/50], Train Loss: 0.1688, Val Loss: 0.4213\n",
      "Epoch [18/50], Train Loss: 0.1683, Val Loss: 0.4206\n",
      "Epoch [19/50], Train Loss: 0.1677, Val Loss: 0.4199\n",
      "Epoch [20/50], Train Loss: 0.1676, Val Loss: 0.4192\n",
      "Epoch [21/50], Train Loss: 0.1674, Val Loss: 0.4185\n",
      "Epoch [22/50], Train Loss: 0.1671, Val Loss: 0.4178\n",
      "Epoch [23/50], Train Loss: 0.1674, Val Loss: 0.4171\n",
      "Epoch [24/50], Train Loss: 0.1664, Val Loss: 0.4164\n",
      "Epoch [25/50], Train Loss: 0.1658, Val Loss: 0.4157\n",
      "Epoch [26/50], Train Loss: 0.1649, Val Loss: 0.4150\n",
      "Epoch [27/50], Train Loss: 0.1651, Val Loss: 0.4143\n",
      "Epoch [28/50], Train Loss: 0.1643, Val Loss: 0.4136\n",
      "Epoch [29/50], Train Loss: 0.1646, Val Loss: 0.4129\n",
      "Epoch [30/50], Train Loss: 0.1638, Val Loss: 0.4122\n",
      "Epoch [31/50], Train Loss: 0.1629, Val Loss: 0.4115\n",
      "Epoch [32/50], Train Loss: 0.1635, Val Loss: 0.4109\n",
      "Epoch [33/50], Train Loss: 0.1623, Val Loss: 0.4102\n",
      "Epoch [34/50], Train Loss: 0.1622, Val Loss: 0.4095\n",
      "Epoch [35/50], Train Loss: 0.1616, Val Loss: 0.4088\n",
      "Epoch [36/50], Train Loss: 0.1610, Val Loss: 0.4082\n",
      "Epoch [37/50], Train Loss: 0.1611, Val Loss: 0.4075\n",
      "Epoch [38/50], Train Loss: 0.1607, Val Loss: 0.4068\n",
      "Epoch [39/50], Train Loss: 0.1599, Val Loss: 0.4061\n",
      "Epoch [40/50], Train Loss: 0.1602, Val Loss: 0.4055\n",
      "Epoch [41/50], Train Loss: 0.1594, Val Loss: 0.4048\n",
      "Epoch [42/50], Train Loss: 0.1589, Val Loss: 0.4042\n",
      "Epoch [43/50], Train Loss: 0.1585, Val Loss: 0.4035\n",
      "Epoch [44/50], Train Loss: 0.1580, Val Loss: 0.4028\n",
      "Epoch [45/50], Train Loss: 0.1585, Val Loss: 0.4022\n",
      "Epoch [46/50], Train Loss: 0.1573, Val Loss: 0.4015\n",
      "Epoch [47/50], Train Loss: 0.1565, Val Loss: 0.4009\n",
      "Epoch [48/50], Train Loss: 0.1572, Val Loss: 0.4002\n",
      "Epoch [49/50], Train Loss: 0.1562, Val Loss: 0.3996\n",
      "Epoch [50/50], Train Loss: 0.1559, Val Loss: 0.3989\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1396, Val Loss: 0.3552\n",
      "Epoch [2/50], Train Loss: 0.1310, Val Loss: 0.3365\n",
      "Epoch [3/50], Train Loss: 0.1229, Val Loss: 0.3180\n",
      "Epoch [4/50], Train Loss: 0.1150, Val Loss: 0.2994\n",
      "Epoch [5/50], Train Loss: 0.1070, Val Loss: 0.2802\n",
      "Epoch [6/50], Train Loss: 0.0988, Val Loss: 0.2602\n",
      "Epoch [7/50], Train Loss: 0.0905, Val Loss: 0.2395\n",
      "Epoch [8/50], Train Loss: 0.0821, Val Loss: 0.2181\n",
      "Epoch [9/50], Train Loss: 0.0737, Val Loss: 0.1960\n",
      "Epoch [10/50], Train Loss: 0.0653, Val Loss: 0.1736\n",
      "Epoch [11/50], Train Loss: 0.0572, Val Loss: 0.1517\n",
      "Epoch [12/50], Train Loss: 0.0497, Val Loss: 0.1310\n",
      "Epoch [13/50], Train Loss: 0.0432, Val Loss: 0.1125\n",
      "Epoch [14/50], Train Loss: 0.0378, Val Loss: 0.0968\n",
      "Epoch [15/50], Train Loss: 0.0336, Val Loss: 0.0843\n",
      "Epoch [16/50], Train Loss: 0.0305, Val Loss: 0.0745\n",
      "Epoch [17/50], Train Loss: 0.0283, Val Loss: 0.0669\n",
      "Epoch [18/50], Train Loss: 0.0266, Val Loss: 0.0610\n",
      "Epoch [19/50], Train Loss: 0.0252, Val Loss: 0.0561\n",
      "Epoch [20/50], Train Loss: 0.0240, Val Loss: 0.0520\n",
      "Epoch [21/50], Train Loss: 0.0230, Val Loss: 0.0484\n",
      "Epoch [22/50], Train Loss: 0.0221, Val Loss: 0.0450\n",
      "Epoch [23/50], Train Loss: 0.0213, Val Loss: 0.0420\n",
      "Epoch [24/50], Train Loss: 0.0206, Val Loss: 0.0391\n",
      "Epoch [25/50], Train Loss: 0.0199, Val Loss: 0.0364\n",
      "Epoch [26/50], Train Loss: 0.0193, Val Loss: 0.0338\n",
      "Epoch [27/50], Train Loss: 0.0187, Val Loss: 0.0313\n",
      "Epoch [28/50], Train Loss: 0.0181, Val Loss: 0.0290\n",
      "Epoch [29/50], Train Loss: 0.0175, Val Loss: 0.0268\n",
      "Epoch [30/50], Train Loss: 0.0170, Val Loss: 0.0247\n",
      "Epoch [31/50], Train Loss: 0.0164, Val Loss: 0.0227\n",
      "Epoch [32/50], Train Loss: 0.0159, Val Loss: 0.0209\n",
      "Epoch [33/50], Train Loss: 0.0154, Val Loss: 0.0192\n",
      "Epoch [34/50], Train Loss: 0.0149, Val Loss: 0.0176\n",
      "Epoch [35/50], Train Loss: 0.0144, Val Loss: 0.0162\n",
      "Epoch [36/50], Train Loss: 0.0140, Val Loss: 0.0149\n",
      "Epoch [37/50], Train Loss: 0.0135, Val Loss: 0.0138\n",
      "Epoch [38/50], Train Loss: 0.0130, Val Loss: 0.0129\n",
      "Epoch [39/50], Train Loss: 0.0126, Val Loss: 0.0121\n",
      "Epoch [40/50], Train Loss: 0.0121, Val Loss: 0.0114\n",
      "Epoch [41/50], Train Loss: 0.0117, Val Loss: 0.0109\n",
      "Epoch [42/50], Train Loss: 0.0113, Val Loss: 0.0105\n",
      "Epoch [43/50], Train Loss: 0.0108, Val Loss: 0.0102\n",
      "Epoch [44/50], Train Loss: 0.0104, Val Loss: 0.0099\n",
      "Epoch [45/50], Train Loss: 0.0100, Val Loss: 0.0098\n",
      "Epoch [46/50], Train Loss: 0.0096, Val Loss: 0.0097\n",
      "Epoch [47/50], Train Loss: 0.0092, Val Loss: 0.0096\n",
      "Epoch [48/50], Train Loss: 0.0088, Val Loss: 0.0096\n",
      "Epoch [49/50], Train Loss: 0.0084, Val Loss: 0.0096\n",
      "Epoch [50/50], Train Loss: 0.0080, Val Loss: 0.0097\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.2146, Val Loss: 0.5342\n",
      "Epoch [2/50], Train Loss: 0.2040, Val Loss: 0.5136\n",
      "Epoch [3/50], Train Loss: 0.1953, Val Loss: 0.4935\n",
      "Epoch [4/50], Train Loss: 0.1853, Val Loss: 0.4737\n",
      "Epoch [5/50], Train Loss: 0.1766, Val Loss: 0.4536\n",
      "Epoch [6/50], Train Loss: 0.1671, Val Loss: 0.4330\n",
      "Epoch [7/50], Train Loss: 0.1582, Val Loss: 0.4118\n",
      "Epoch [8/50], Train Loss: 0.1481, Val Loss: 0.3898\n",
      "Epoch [9/50], Train Loss: 0.1385, Val Loss: 0.3669\n",
      "Epoch [10/50], Train Loss: 0.1278, Val Loss: 0.3429\n",
      "Epoch [11/50], Train Loss: 0.1180, Val Loss: 0.3181\n",
      "Epoch [12/50], Train Loss: 0.1080, Val Loss: 0.2923\n",
      "Epoch [13/50], Train Loss: 0.0976, Val Loss: 0.2659\n",
      "Epoch [14/50], Train Loss: 0.0879, Val Loss: 0.2397\n",
      "Epoch [15/50], Train Loss: 0.0784, Val Loss: 0.2141\n",
      "Epoch [16/50], Train Loss: 0.0686, Val Loss: 0.1900\n",
      "Epoch [17/50], Train Loss: 0.0622, Val Loss: 0.1684\n",
      "Epoch [18/50], Train Loss: 0.0568, Val Loss: 0.1500\n",
      "Epoch [19/50], Train Loss: 0.0529, Val Loss: 0.1347\n",
      "Epoch [20/50], Train Loss: 0.0494, Val Loss: 0.1221\n",
      "Epoch [21/50], Train Loss: 0.0457, Val Loss: 0.1120\n",
      "Epoch [22/50], Train Loss: 0.0441, Val Loss: 0.1033\n",
      "Epoch [23/50], Train Loss: 0.0422, Val Loss: 0.0961\n",
      "Epoch [24/50], Train Loss: 0.0402, Val Loss: 0.0901\n",
      "Epoch [25/50], Train Loss: 0.0396, Val Loss: 0.0847\n",
      "Epoch [26/50], Train Loss: 0.0373, Val Loss: 0.0801\n",
      "Epoch [27/50], Train Loss: 0.0365, Val Loss: 0.0759\n",
      "Epoch [28/50], Train Loss: 0.0359, Val Loss: 0.0722\n",
      "Epoch [29/50], Train Loss: 0.0360, Val Loss: 0.0687\n",
      "Epoch [30/50], Train Loss: 0.0351, Val Loss: 0.0652\n",
      "Epoch [31/50], Train Loss: 0.0334, Val Loss: 0.0624\n",
      "Epoch [32/50], Train Loss: 0.0326, Val Loss: 0.0599\n",
      "Epoch [33/50], Train Loss: 0.0322, Val Loss: 0.0573\n",
      "Epoch [34/50], Train Loss: 0.0329, Val Loss: 0.0548\n",
      "Epoch [35/50], Train Loss: 0.0321, Val Loss: 0.0521\n",
      "Epoch [36/50], Train Loss: 0.0310, Val Loss: 0.0496\n",
      "Epoch [37/50], Train Loss: 0.0310, Val Loss: 0.0476\n",
      "Epoch [38/50], Train Loss: 0.0302, Val Loss: 0.0459\n",
      "Epoch [39/50], Train Loss: 0.0304, Val Loss: 0.0444\n",
      "Epoch [40/50], Train Loss: 0.0301, Val Loss: 0.0429\n",
      "Epoch [41/50], Train Loss: 0.0291, Val Loss: 0.0412\n",
      "Epoch [42/50], Train Loss: 0.0294, Val Loss: 0.0393\n",
      "Epoch [43/50], Train Loss: 0.0280, Val Loss: 0.0378\n",
      "Epoch [44/50], Train Loss: 0.0287, Val Loss: 0.0364\n",
      "Epoch [45/50], Train Loss: 0.0275, Val Loss: 0.0348\n",
      "Epoch [46/50], Train Loss: 0.0270, Val Loss: 0.0334\n",
      "Epoch [47/50], Train Loss: 0.0276, Val Loss: 0.0325\n",
      "Epoch [48/50], Train Loss: 0.0275, Val Loss: 0.0311\n",
      "Epoch [49/50], Train Loss: 0.0277, Val Loss: 0.0298\n",
      "Epoch [50/50], Train Loss: 0.0268, Val Loss: 0.0287\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.2173, Val Loss: 0.5446\n",
      "Epoch [2/50], Train Loss: 0.2090, Val Loss: 0.5281\n",
      "Epoch [3/50], Train Loss: 0.2013, Val Loss: 0.5127\n",
      "Epoch [4/50], Train Loss: 0.1945, Val Loss: 0.4977\n",
      "Epoch [5/50], Train Loss: 0.1882, Val Loss: 0.4829\n",
      "Epoch [6/50], Train Loss: 0.1800, Val Loss: 0.4680\n",
      "Epoch [7/50], Train Loss: 0.1732, Val Loss: 0.4528\n",
      "Epoch [8/50], Train Loss: 0.1669, Val Loss: 0.4367\n",
      "Epoch [9/50], Train Loss: 0.1587, Val Loss: 0.4199\n",
      "Epoch [10/50], Train Loss: 0.1514, Val Loss: 0.4020\n",
      "Epoch [11/50], Train Loss: 0.1427, Val Loss: 0.3825\n",
      "Epoch [12/50], Train Loss: 0.1351, Val Loss: 0.3618\n",
      "Epoch [13/50], Train Loss: 0.1264, Val Loss: 0.3397\n",
      "Epoch [14/50], Train Loss: 0.1179, Val Loss: 0.3158\n",
      "Epoch [15/50], Train Loss: 0.1097, Val Loss: 0.2906\n",
      "Epoch [16/50], Train Loss: 0.1018, Val Loss: 0.2644\n",
      "Epoch [17/50], Train Loss: 0.0903, Val Loss: 0.2377\n",
      "Epoch [18/50], Train Loss: 0.0831, Val Loss: 0.2110\n",
      "Epoch [19/50], Train Loss: 0.0780, Val Loss: 0.1856\n",
      "Epoch [20/50], Train Loss: 0.0738, Val Loss: 0.1638\n",
      "Epoch [21/50], Train Loss: 0.0677, Val Loss: 0.1453\n",
      "Epoch [22/50], Train Loss: 0.0649, Val Loss: 0.1296\n",
      "Epoch [23/50], Train Loss: 0.0657, Val Loss: 0.1200\n",
      "Epoch [24/50], Train Loss: 0.0611, Val Loss: 0.1135\n",
      "Epoch [25/50], Train Loss: 0.0590, Val Loss: 0.1064\n",
      "Epoch [26/50], Train Loss: 0.0579, Val Loss: 0.0999\n",
      "Epoch [27/50], Train Loss: 0.0570, Val Loss: 0.0945\n",
      "Epoch [28/50], Train Loss: 0.0586, Val Loss: 0.0901\n",
      "Epoch [29/50], Train Loss: 0.0561, Val Loss: 0.0866\n",
      "Epoch [30/50], Train Loss: 0.0547, Val Loss: 0.0845\n",
      "Epoch [31/50], Train Loss: 0.0554, Val Loss: 0.0820\n",
      "Epoch [32/50], Train Loss: 0.0528, Val Loss: 0.0777\n",
      "Epoch [33/50], Train Loss: 0.0503, Val Loss: 0.0749\n",
      "Epoch [34/50], Train Loss: 0.0487, Val Loss: 0.0722\n",
      "Epoch [35/50], Train Loss: 0.0511, Val Loss: 0.0700\n",
      "Epoch [36/50], Train Loss: 0.0515, Val Loss: 0.0674\n",
      "Epoch [37/50], Train Loss: 0.0509, Val Loss: 0.0637\n",
      "Epoch [38/50], Train Loss: 0.0483, Val Loss: 0.0614\n",
      "Epoch [39/50], Train Loss: 0.0494, Val Loss: 0.0590\n",
      "Epoch [40/50], Train Loss: 0.0475, Val Loss: 0.0565\n",
      "Epoch [41/50], Train Loss: 0.0449, Val Loss: 0.0539\n",
      "Epoch [42/50], Train Loss: 0.0461, Val Loss: 0.0507\n",
      "Epoch [43/50], Train Loss: 0.0430, Val Loss: 0.0487\n",
      "Epoch [44/50], Train Loss: 0.0456, Val Loss: 0.0469\n",
      "Epoch [45/50], Train Loss: 0.0436, Val Loss: 0.0434\n",
      "Epoch [46/50], Train Loss: 0.0431, Val Loss: 0.0411\n",
      "Epoch [47/50], Train Loss: 0.0420, Val Loss: 0.0386\n",
      "Epoch [48/50], Train Loss: 0.0414, Val Loss: 0.0343\n",
      "Epoch [49/50], Train Loss: 0.0408, Val Loss: 0.0330\n",
      "Epoch [50/50], Train Loss: 0.0392, Val Loss: 0.0319\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1290, Val Loss: 0.2852\n",
      "Epoch [2/50], Train Loss: 0.1210, Val Loss: 0.2731\n",
      "Epoch [3/50], Train Loss: 0.1142, Val Loss: 0.2618\n",
      "Epoch [4/50], Train Loss: 0.1080, Val Loss: 0.2511\n",
      "Epoch [5/50], Train Loss: 0.1022, Val Loss: 0.2407\n",
      "Epoch [6/50], Train Loss: 0.0967, Val Loss: 0.2303\n",
      "Epoch [7/50], Train Loss: 0.0914, Val Loss: 0.2197\n",
      "Epoch [8/50], Train Loss: 0.0861, Val Loss: 0.2088\n",
      "Epoch [9/50], Train Loss: 0.0810, Val Loss: 0.1975\n",
      "Epoch [10/50], Train Loss: 0.0757, Val Loss: 0.1854\n",
      "Epoch [11/50], Train Loss: 0.0704, Val Loss: 0.1725\n",
      "Epoch [12/50], Train Loss: 0.0649, Val Loss: 0.1587\n",
      "Epoch [13/50], Train Loss: 0.0594, Val Loss: 0.1439\n",
      "Epoch [14/50], Train Loss: 0.0538, Val Loss: 0.1285\n",
      "Epoch [15/50], Train Loss: 0.0485, Val Loss: 0.1129\n",
      "Epoch [16/50], Train Loss: 0.0437, Val Loss: 0.0982\n",
      "Epoch [17/50], Train Loss: 0.0398, Val Loss: 0.0855\n",
      "Epoch [18/50], Train Loss: 0.0369, Val Loss: 0.0758\n",
      "Epoch [19/50], Train Loss: 0.0349, Val Loss: 0.0693\n",
      "Epoch [20/50], Train Loss: 0.0336, Val Loss: 0.0654\n",
      "Epoch [21/50], Train Loss: 0.0327, Val Loss: 0.0632\n",
      "Epoch [22/50], Train Loss: 0.0319, Val Loss: 0.0618\n",
      "Epoch [23/50], Train Loss: 0.0313, Val Loss: 0.0607\n",
      "Epoch [24/50], Train Loss: 0.0307, Val Loss: 0.0597\n",
      "Epoch [25/50], Train Loss: 0.0301, Val Loss: 0.0586\n",
      "Epoch [26/50], Train Loss: 0.0296, Val Loss: 0.0574\n",
      "Epoch [27/50], Train Loss: 0.0291, Val Loss: 0.0560\n",
      "Epoch [28/50], Train Loss: 0.0286, Val Loss: 0.0545\n",
      "Epoch [29/50], Train Loss: 0.0281, Val Loss: 0.0530\n",
      "Epoch [30/50], Train Loss: 0.0276, Val Loss: 0.0514\n",
      "Epoch [31/50], Train Loss: 0.0271, Val Loss: 0.0497\n",
      "Epoch [32/50], Train Loss: 0.0266, Val Loss: 0.0480\n",
      "Epoch [33/50], Train Loss: 0.0260, Val Loss: 0.0463\n",
      "Epoch [34/50], Train Loss: 0.0255, Val Loss: 0.0446\n",
      "Epoch [35/50], Train Loss: 0.0249, Val Loss: 0.0429\n",
      "Epoch [36/50], Train Loss: 0.0244, Val Loss: 0.0413\n",
      "Epoch [37/50], Train Loss: 0.0238, Val Loss: 0.0397\n",
      "Epoch [38/50], Train Loss: 0.0232, Val Loss: 0.0381\n",
      "Epoch [39/50], Train Loss: 0.0226, Val Loss: 0.0366\n",
      "Epoch [40/50], Train Loss: 0.0220, Val Loss: 0.0352\n",
      "Epoch [41/50], Train Loss: 0.0213, Val Loss: 0.0339\n",
      "Epoch [42/50], Train Loss: 0.0207, Val Loss: 0.0327\n",
      "Epoch [43/50], Train Loss: 0.0200, Val Loss: 0.0316\n",
      "Epoch [44/50], Train Loss: 0.0193, Val Loss: 0.0307\n",
      "Epoch [45/50], Train Loss: 0.0186, Val Loss: 0.0299\n",
      "Epoch [46/50], Train Loss: 0.0179, Val Loss: 0.0293\n",
      "Epoch [47/50], Train Loss: 0.0171, Val Loss: 0.0289\n",
      "Epoch [48/50], Train Loss: 0.0164, Val Loss: 0.0286\n",
      "Epoch [49/50], Train Loss: 0.0156, Val Loss: 0.0285\n",
      "Epoch [50/50], Train Loss: 0.0149, Val Loss: 0.0284\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1315, Val Loss: 0.3166\n",
      "Epoch [2/50], Train Loss: 0.1216, Val Loss: 0.2989\n",
      "Epoch [3/50], Train Loss: 0.1124, Val Loss: 0.2814\n",
      "Epoch [4/50], Train Loss: 0.1035, Val Loss: 0.2635\n",
      "Epoch [5/50], Train Loss: 0.0936, Val Loss: 0.2448\n",
      "Epoch [6/50], Train Loss: 0.0850, Val Loss: 0.2255\n",
      "Epoch [7/50], Train Loss: 0.0776, Val Loss: 0.2059\n",
      "Epoch [8/50], Train Loss: 0.0683, Val Loss: 0.1864\n",
      "Epoch [9/50], Train Loss: 0.0611, Val Loss: 0.1678\n",
      "Epoch [10/50], Train Loss: 0.0556, Val Loss: 0.1509\n",
      "Epoch [11/50], Train Loss: 0.0513, Val Loss: 0.1361\n",
      "Epoch [12/50], Train Loss: 0.0483, Val Loss: 0.1244\n",
      "Epoch [13/50], Train Loss: 0.0464, Val Loss: 0.1160\n",
      "Epoch [14/50], Train Loss: 0.0460, Val Loss: 0.1101\n",
      "Epoch [15/50], Train Loss: 0.0443, Val Loss: 0.1059\n",
      "Epoch [16/50], Train Loss: 0.0439, Val Loss: 0.1032\n",
      "Epoch [17/50], Train Loss: 0.0440, Val Loss: 0.1013\n",
      "Epoch [18/50], Train Loss: 0.0433, Val Loss: 0.0993\n",
      "Epoch [19/50], Train Loss: 0.0430, Val Loss: 0.0974\n",
      "Epoch [20/50], Train Loss: 0.0431, Val Loss: 0.0953\n",
      "Epoch [21/50], Train Loss: 0.0433, Val Loss: 0.0937\n",
      "Epoch [22/50], Train Loss: 0.0418, Val Loss: 0.0922\n",
      "Epoch [23/50], Train Loss: 0.0415, Val Loss: 0.0905\n",
      "Epoch [24/50], Train Loss: 0.0411, Val Loss: 0.0887\n",
      "Epoch [25/50], Train Loss: 0.0407, Val Loss: 0.0872\n",
      "Epoch [26/50], Train Loss: 0.0419, Val Loss: 0.0854\n",
      "Epoch [27/50], Train Loss: 0.0393, Val Loss: 0.0828\n",
      "Epoch [28/50], Train Loss: 0.0392, Val Loss: 0.0804\n",
      "Epoch [29/50], Train Loss: 0.0388, Val Loss: 0.0785\n",
      "Epoch [30/50], Train Loss: 0.0379, Val Loss: 0.0762\n",
      "Epoch [31/50], Train Loss: 0.0374, Val Loss: 0.0738\n",
      "Epoch [32/50], Train Loss: 0.0375, Val Loss: 0.0713\n",
      "Epoch [33/50], Train Loss: 0.0351, Val Loss: 0.0684\n",
      "Epoch [34/50], Train Loss: 0.0348, Val Loss: 0.0649\n",
      "Epoch [35/50], Train Loss: 0.0354, Val Loss: 0.0617\n",
      "Epoch [36/50], Train Loss: 0.0345, Val Loss: 0.0579\n",
      "Epoch [37/50], Train Loss: 0.0327, Val Loss: 0.0539\n",
      "Epoch [38/50], Train Loss: 0.0325, Val Loss: 0.0505\n",
      "Epoch [39/50], Train Loss: 0.0326, Val Loss: 0.0467\n",
      "Epoch [40/50], Train Loss: 0.0315, Val Loss: 0.0430\n",
      "Epoch [41/50], Train Loss: 0.0311, Val Loss: 0.0392\n",
      "Epoch [42/50], Train Loss: 0.0304, Val Loss: 0.0361\n",
      "Epoch [43/50], Train Loss: 0.0281, Val Loss: 0.0323\n",
      "Epoch [44/50], Train Loss: 0.0292, Val Loss: 0.0289\n",
      "Epoch [45/50], Train Loss: 0.0283, Val Loss: 0.0270\n",
      "Epoch [46/50], Train Loss: 0.0272, Val Loss: 0.0247\n",
      "Epoch [47/50], Train Loss: 0.0270, Val Loss: 0.0235\n",
      "Epoch [48/50], Train Loss: 0.0258, Val Loss: 0.0217\n",
      "Epoch [49/50], Train Loss: 0.0263, Val Loss: 0.0202\n",
      "Epoch [50/50], Train Loss: 0.0252, Val Loss: 0.0196\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.0813, Val Loss: 0.2580\n",
      "Epoch [2/50], Train Loss: 0.0781, Val Loss: 0.2487\n",
      "Epoch [3/50], Train Loss: 0.0742, Val Loss: 0.2403\n",
      "Epoch [4/50], Train Loss: 0.0703, Val Loss: 0.2324\n",
      "Epoch [5/50], Train Loss: 0.0673, Val Loss: 0.2249\n",
      "Epoch [6/50], Train Loss: 0.0640, Val Loss: 0.2174\n",
      "Epoch [7/50], Train Loss: 0.0625, Val Loss: 0.2102\n",
      "Epoch [8/50], Train Loss: 0.0595, Val Loss: 0.2029\n",
      "Epoch [9/50], Train Loss: 0.0564, Val Loss: 0.1959\n",
      "Epoch [10/50], Train Loss: 0.0561, Val Loss: 0.1890\n",
      "Epoch [11/50], Train Loss: 0.0549, Val Loss: 0.1822\n",
      "Epoch [12/50], Train Loss: 0.0520, Val Loss: 0.1754\n",
      "Epoch [13/50], Train Loss: 0.0503, Val Loss: 0.1689\n",
      "Epoch [14/50], Train Loss: 0.0491, Val Loss: 0.1627\n",
      "Epoch [15/50], Train Loss: 0.0477, Val Loss: 0.1567\n",
      "Epoch [16/50], Train Loss: 0.0480, Val Loss: 0.1510\n",
      "Epoch [17/50], Train Loss: 0.0455, Val Loss: 0.1453\n",
      "Epoch [18/50], Train Loss: 0.0458, Val Loss: 0.1401\n",
      "Epoch [19/50], Train Loss: 0.0450, Val Loss: 0.1353\n",
      "Epoch [20/50], Train Loss: 0.0436, Val Loss: 0.1304\n",
      "Epoch [21/50], Train Loss: 0.0432, Val Loss: 0.1263\n",
      "Epoch [22/50], Train Loss: 0.0428, Val Loss: 0.1223\n",
      "Epoch [23/50], Train Loss: 0.0413, Val Loss: 0.1188\n",
      "Epoch [24/50], Train Loss: 0.0418, Val Loss: 0.1157\n",
      "Epoch [25/50], Train Loss: 0.0410, Val Loss: 0.1125\n",
      "Epoch [26/50], Train Loss: 0.0404, Val Loss: 0.1090\n",
      "Epoch [27/50], Train Loss: 0.0396, Val Loss: 0.1058\n",
      "Epoch [28/50], Train Loss: 0.0398, Val Loss: 0.1025\n",
      "Epoch [29/50], Train Loss: 0.0388, Val Loss: 0.0997\n",
      "Epoch [30/50], Train Loss: 0.0384, Val Loss: 0.0967\n",
      "Epoch [31/50], Train Loss: 0.0384, Val Loss: 0.0942\n",
      "Epoch [32/50], Train Loss: 0.0382, Val Loss: 0.0913\n",
      "Epoch [33/50], Train Loss: 0.0386, Val Loss: 0.0891\n",
      "Epoch [34/50], Train Loss: 0.0377, Val Loss: 0.0864\n",
      "Epoch [35/50], Train Loss: 0.0351, Val Loss: 0.0830\n",
      "Epoch [36/50], Train Loss: 0.0350, Val Loss: 0.0802\n",
      "Epoch [37/50], Train Loss: 0.0353, Val Loss: 0.0769\n",
      "Epoch [38/50], Train Loss: 0.0340, Val Loss: 0.0731\n",
      "Epoch [39/50], Train Loss: 0.0337, Val Loss: 0.0695\n",
      "Epoch [40/50], Train Loss: 0.0324, Val Loss: 0.0654\n",
      "Epoch [41/50], Train Loss: 0.0316, Val Loss: 0.0620\n",
      "Epoch [42/50], Train Loss: 0.0313, Val Loss: 0.0591\n",
      "Epoch [43/50], Train Loss: 0.0284, Val Loss: 0.0570\n",
      "Epoch [44/50], Train Loss: 0.0277, Val Loss: 0.0558\n",
      "Epoch [45/50], Train Loss: 0.0275, Val Loss: 0.0543\n",
      "Epoch [46/50], Train Loss: 0.0257, Val Loss: 0.0531\n",
      "Epoch [47/50], Train Loss: 0.0249, Val Loss: 0.0517\n",
      "Epoch [48/50], Train Loss: 0.0259, Val Loss: 0.0501\n",
      "Epoch [49/50], Train Loss: 0.0249, Val Loss: 0.0485\n",
      "Epoch [50/50], Train Loss: 0.0251, Val Loss: 0.0483\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0702, Val Loss: 0.2076\n",
      "Epoch [2/50], Train Loss: 0.0651, Val Loss: 0.1977\n",
      "Epoch [3/50], Train Loss: 0.0607, Val Loss: 0.1883\n",
      "Epoch [4/50], Train Loss: 0.0567, Val Loss: 0.1792\n",
      "Epoch [5/50], Train Loss: 0.0529, Val Loss: 0.1701\n",
      "Epoch [6/50], Train Loss: 0.0494, Val Loss: 0.1610\n",
      "Epoch [7/50], Train Loss: 0.0463, Val Loss: 0.1521\n",
      "Epoch [8/50], Train Loss: 0.0435, Val Loss: 0.1434\n",
      "Epoch [9/50], Train Loss: 0.0411, Val Loss: 0.1351\n",
      "Epoch [10/50], Train Loss: 0.0393, Val Loss: 0.1275\n",
      "Epoch [11/50], Train Loss: 0.0380, Val Loss: 0.1210\n",
      "Epoch [12/50], Train Loss: 0.0371, Val Loss: 0.1155\n",
      "Epoch [13/50], Train Loss: 0.0365, Val Loss: 0.1110\n",
      "Epoch [14/50], Train Loss: 0.0361, Val Loss: 0.1075\n",
      "Epoch [15/50], Train Loss: 0.0358, Val Loss: 0.1046\n",
      "Epoch [16/50], Train Loss: 0.0356, Val Loss: 0.1021\n",
      "Epoch [17/50], Train Loss: 0.0353, Val Loss: 0.0999\n",
      "Epoch [18/50], Train Loss: 0.0350, Val Loss: 0.0979\n",
      "Epoch [19/50], Train Loss: 0.0347, Val Loss: 0.0958\n",
      "Epoch [20/50], Train Loss: 0.0344, Val Loss: 0.0937\n",
      "Epoch [21/50], Train Loss: 0.0340, Val Loss: 0.0915\n",
      "Epoch [22/50], Train Loss: 0.0336, Val Loss: 0.0892\n",
      "Epoch [23/50], Train Loss: 0.0330, Val Loss: 0.0867\n",
      "Epoch [24/50], Train Loss: 0.0324, Val Loss: 0.0840\n",
      "Epoch [25/50], Train Loss: 0.0317, Val Loss: 0.0813\n",
      "Epoch [26/50], Train Loss: 0.0309, Val Loss: 0.0785\n",
      "Epoch [27/50], Train Loss: 0.0299, Val Loss: 0.0757\n",
      "Epoch [28/50], Train Loss: 0.0287, Val Loss: 0.0732\n",
      "Epoch [29/50], Train Loss: 0.0274, Val Loss: 0.0712\n",
      "Epoch [30/50], Train Loss: 0.0260, Val Loss: 0.0696\n",
      "Epoch [31/50], Train Loss: 0.0245, Val Loss: 0.0684\n",
      "Epoch [32/50], Train Loss: 0.0231, Val Loss: 0.0668\n",
      "Epoch [33/50], Train Loss: 0.0218, Val Loss: 0.0647\n",
      "Epoch [34/50], Train Loss: 0.0206, Val Loss: 0.0620\n",
      "Epoch [35/50], Train Loss: 0.0193, Val Loss: 0.0588\n",
      "Epoch [36/50], Train Loss: 0.0181, Val Loss: 0.0556\n",
      "Epoch [37/50], Train Loss: 0.0169, Val Loss: 0.0524\n",
      "Epoch [38/50], Train Loss: 0.0157, Val Loss: 0.0493\n",
      "Epoch [39/50], Train Loss: 0.0146, Val Loss: 0.0466\n",
      "Epoch [40/50], Train Loss: 0.0135, Val Loss: 0.0443\n",
      "Epoch [41/50], Train Loss: 0.0125, Val Loss: 0.0426\n",
      "Epoch [42/50], Train Loss: 0.0116, Val Loss: 0.0416\n",
      "Epoch [43/50], Train Loss: 0.0107, Val Loss: 0.0411\n",
      "Epoch [44/50], Train Loss: 0.0099, Val Loss: 0.0410\n",
      "Epoch [45/50], Train Loss: 0.0092, Val Loss: 0.0412\n",
      "Epoch [46/50], Train Loss: 0.0086, Val Loss: 0.0415\n",
      "Epoch [47/50], Train Loss: 0.0080, Val Loss: 0.0418\n",
      "Epoch [48/50], Train Loss: 0.0076, Val Loss: 0.0421\n",
      "Epoch [49/50], Train Loss: 0.0071, Val Loss: 0.0424\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1541, Val Loss: 0.3902\n",
      "Epoch [2/50], Train Loss: 0.1437, Val Loss: 0.3759\n",
      "Epoch [3/50], Train Loss: 0.1359, Val Loss: 0.3622\n",
      "Epoch [4/50], Train Loss: 0.1269, Val Loss: 0.3487\n",
      "Epoch [5/50], Train Loss: 0.1197, Val Loss: 0.3347\n",
      "Epoch [6/50], Train Loss: 0.1119, Val Loss: 0.3201\n",
      "Epoch [7/50], Train Loss: 0.1031, Val Loss: 0.3041\n",
      "Epoch [8/50], Train Loss: 0.0946, Val Loss: 0.2864\n",
      "Epoch [9/50], Train Loss: 0.0852, Val Loss: 0.2661\n",
      "Epoch [10/50], Train Loss: 0.0759, Val Loss: 0.2426\n",
      "Epoch [11/50], Train Loss: 0.0671, Val Loss: 0.2168\n",
      "Epoch [12/50], Train Loss: 0.0593, Val Loss: 0.1913\n",
      "Epoch [13/50], Train Loss: 0.0535, Val Loss: 0.1707\n",
      "Epoch [14/50], Train Loss: 0.0509, Val Loss: 0.1562\n",
      "Epoch [15/50], Train Loss: 0.0489, Val Loss: 0.1460\n",
      "Epoch [16/50], Train Loss: 0.0469, Val Loss: 0.1389\n",
      "Epoch [17/50], Train Loss: 0.0466, Val Loss: 0.1329\n",
      "Epoch [18/50], Train Loss: 0.0450, Val Loss: 0.1280\n",
      "Epoch [19/50], Train Loss: 0.0454, Val Loss: 0.1242\n",
      "Epoch [20/50], Train Loss: 0.0439, Val Loss: 0.1209\n",
      "Epoch [21/50], Train Loss: 0.0444, Val Loss: 0.1176\n",
      "Epoch [22/50], Train Loss: 0.0435, Val Loss: 0.1144\n",
      "Epoch [23/50], Train Loss: 0.0421, Val Loss: 0.1118\n",
      "Epoch [24/50], Train Loss: 0.0432, Val Loss: 0.1090\n",
      "Epoch [25/50], Train Loss: 0.0411, Val Loss: 0.1064\n",
      "Epoch [26/50], Train Loss: 0.0416, Val Loss: 0.1042\n",
      "Epoch [27/50], Train Loss: 0.0405, Val Loss: 0.1015\n",
      "Epoch [28/50], Train Loss: 0.0398, Val Loss: 0.0985\n",
      "Epoch [29/50], Train Loss: 0.0389, Val Loss: 0.0952\n",
      "Epoch [30/50], Train Loss: 0.0410, Val Loss: 0.0930\n",
      "Epoch [31/50], Train Loss: 0.0379, Val Loss: 0.0904\n",
      "Epoch [32/50], Train Loss: 0.0368, Val Loss: 0.0871\n",
      "Epoch [33/50], Train Loss: 0.0359, Val Loss: 0.0837\n",
      "Epoch [34/50], Train Loss: 0.0359, Val Loss: 0.0808\n",
      "Epoch [35/50], Train Loss: 0.0341, Val Loss: 0.0779\n",
      "Epoch [36/50], Train Loss: 0.0340, Val Loss: 0.0743\n",
      "Epoch [37/50], Train Loss: 0.0339, Val Loss: 0.0709\n",
      "Epoch [38/50], Train Loss: 0.0334, Val Loss: 0.0679\n",
      "Epoch [39/50], Train Loss: 0.0316, Val Loss: 0.0653\n",
      "Epoch [40/50], Train Loss: 0.0323, Val Loss: 0.0625\n",
      "Epoch [41/50], Train Loss: 0.0315, Val Loss: 0.0597\n",
      "Epoch [42/50], Train Loss: 0.0297, Val Loss: 0.0577\n",
      "Epoch [43/50], Train Loss: 0.0304, Val Loss: 0.0552\n",
      "Epoch [44/50], Train Loss: 0.0298, Val Loss: 0.0535\n",
      "Epoch [45/50], Train Loss: 0.0288, Val Loss: 0.0517\n",
      "Epoch [46/50], Train Loss: 0.0295, Val Loss: 0.0503\n",
      "Epoch [47/50], Train Loss: 0.0292, Val Loss: 0.0489\n",
      "Epoch [48/50], Train Loss: 0.0290, Val Loss: 0.0477\n",
      "Epoch [49/50], Train Loss: 0.0285, Val Loss: 0.0465\n",
      "Epoch [50/50], Train Loss: 0.0281, Val Loss: 0.0455\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=16, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1373, Val Loss: 0.3594\n",
      "Epoch [2/50], Train Loss: 0.1281, Val Loss: 0.3433\n",
      "Epoch [3/50], Train Loss: 0.1195, Val Loss: 0.3275\n",
      "Epoch [4/50], Train Loss: 0.1133, Val Loss: 0.3114\n",
      "Epoch [5/50], Train Loss: 0.1056, Val Loss: 0.2948\n",
      "Epoch [6/50], Train Loss: 0.1000, Val Loss: 0.2773\n",
      "Epoch [7/50], Train Loss: 0.0921, Val Loss: 0.2587\n",
      "Epoch [8/50], Train Loss: 0.0869, Val Loss: 0.2387\n",
      "Epoch [9/50], Train Loss: 0.0780, Val Loss: 0.2175\n",
      "Epoch [10/50], Train Loss: 0.0725, Val Loss: 0.1954\n",
      "Epoch [11/50], Train Loss: 0.0668, Val Loss: 0.1763\n",
      "Epoch [12/50], Train Loss: 0.0648, Val Loss: 0.1611\n",
      "Epoch [13/50], Train Loss: 0.0622, Val Loss: 0.1491\n",
      "Epoch [14/50], Train Loss: 0.0593, Val Loss: 0.1399\n",
      "Epoch [15/50], Train Loss: 0.0577, Val Loss: 0.1351\n",
      "Epoch [16/50], Train Loss: 0.0556, Val Loss: 0.1295\n",
      "Epoch [17/50], Train Loss: 0.0543, Val Loss: 0.1260\n",
      "Epoch [18/50], Train Loss: 0.0548, Val Loss: 0.1234\n",
      "Epoch [19/50], Train Loss: 0.0566, Val Loss: 0.1225\n",
      "Epoch [20/50], Train Loss: 0.0558, Val Loss: 0.1213\n",
      "Epoch [21/50], Train Loss: 0.0545, Val Loss: 0.1193\n",
      "Epoch [22/50], Train Loss: 0.0512, Val Loss: 0.1161\n",
      "Epoch [23/50], Train Loss: 0.0522, Val Loss: 0.1146\n",
      "Epoch [24/50], Train Loss: 0.0503, Val Loss: 0.1131\n",
      "Epoch [25/50], Train Loss: 0.0499, Val Loss: 0.1106\n",
      "Epoch [26/50], Train Loss: 0.0506, Val Loss: 0.1084\n",
      "Epoch [27/50], Train Loss: 0.0498, Val Loss: 0.1069\n",
      "Epoch [28/50], Train Loss: 0.0488, Val Loss: 0.1037\n",
      "Epoch [29/50], Train Loss: 0.0506, Val Loss: 0.1022\n",
      "Epoch [30/50], Train Loss: 0.0481, Val Loss: 0.0998\n",
      "Epoch [31/50], Train Loss: 0.0470, Val Loss: 0.0977\n",
      "Epoch [32/50], Train Loss: 0.0465, Val Loss: 0.0967\n",
      "Epoch [33/50], Train Loss: 0.0469, Val Loss: 0.0936\n",
      "Epoch [34/50], Train Loss: 0.0469, Val Loss: 0.0914\n",
      "Epoch [35/50], Train Loss: 0.0456, Val Loss: 0.0874\n",
      "Epoch [36/50], Train Loss: 0.0451, Val Loss: 0.0838\n",
      "Epoch [37/50], Train Loss: 0.0440, Val Loss: 0.0810\n",
      "Epoch [38/50], Train Loss: 0.0447, Val Loss: 0.0793\n",
      "Epoch [39/50], Train Loss: 0.0430, Val Loss: 0.0753\n",
      "Epoch [40/50], Train Loss: 0.0414, Val Loss: 0.0705\n",
      "Epoch [41/50], Train Loss: 0.0422, Val Loss: 0.0687\n",
      "Epoch [42/50], Train Loss: 0.0413, Val Loss: 0.0649\n",
      "Epoch [43/50], Train Loss: 0.0409, Val Loss: 0.0612\n",
      "Epoch [44/50], Train Loss: 0.0396, Val Loss: 0.0585\n",
      "Epoch [45/50], Train Loss: 0.0399, Val Loss: 0.0546\n",
      "Epoch [46/50], Train Loss: 0.0377, Val Loss: 0.0515\n",
      "Epoch [47/50], Train Loss: 0.0382, Val Loss: 0.0482\n",
      "Epoch [48/50], Train Loss: 0.0365, Val Loss: 0.0460\n",
      "Epoch [49/50], Train Loss: 0.0357, Val Loss: 0.0439\n",
      "Epoch [50/50], Train Loss: 0.0349, Val Loss: 0.0429\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1307, Val Loss: 0.3291\n",
      "Epoch [2/50], Train Loss: 0.1207, Val Loss: 0.3091\n",
      "Epoch [3/50], Train Loss: 0.1117, Val Loss: 0.2894\n",
      "Epoch [4/50], Train Loss: 0.1028, Val Loss: 0.2692\n",
      "Epoch [5/50], Train Loss: 0.0939, Val Loss: 0.2478\n",
      "Epoch [6/50], Train Loss: 0.0846, Val Loss: 0.2244\n",
      "Epoch [7/50], Train Loss: 0.0749, Val Loss: 0.1984\n",
      "Epoch [8/50], Train Loss: 0.0646, Val Loss: 0.1695\n",
      "Epoch [9/50], Train Loss: 0.0540, Val Loss: 0.1378\n",
      "Epoch [10/50], Train Loss: 0.0438, Val Loss: 0.1059\n",
      "Epoch [11/50], Train Loss: 0.0356, Val Loss: 0.0793\n",
      "Epoch [12/50], Train Loss: 0.0307, Val Loss: 0.0631\n",
      "Epoch [13/50], Train Loss: 0.0284, Val Loss: 0.0556\n",
      "Epoch [14/50], Train Loss: 0.0269, Val Loss: 0.0517\n",
      "Epoch [15/50], Train Loss: 0.0257, Val Loss: 0.0490\n",
      "Epoch [16/50], Train Loss: 0.0248, Val Loss: 0.0467\n",
      "Epoch [17/50], Train Loss: 0.0240, Val Loss: 0.0447\n",
      "Epoch [18/50], Train Loss: 0.0234, Val Loss: 0.0427\n",
      "Epoch [19/50], Train Loss: 0.0227, Val Loss: 0.0408\n",
      "Epoch [20/50], Train Loss: 0.0221, Val Loss: 0.0390\n",
      "Epoch [21/50], Train Loss: 0.0215, Val Loss: 0.0372\n",
      "Epoch [22/50], Train Loss: 0.0210, Val Loss: 0.0354\n",
      "Epoch [23/50], Train Loss: 0.0204, Val Loss: 0.0337\n",
      "Epoch [24/50], Train Loss: 0.0199, Val Loss: 0.0320\n",
      "Epoch [25/50], Train Loss: 0.0193, Val Loss: 0.0304\n",
      "Epoch [26/50], Train Loss: 0.0188, Val Loss: 0.0288\n",
      "Epoch [27/50], Train Loss: 0.0183, Val Loss: 0.0273\n",
      "Epoch [28/50], Train Loss: 0.0177, Val Loss: 0.0259\n",
      "Epoch [29/50], Train Loss: 0.0172, Val Loss: 0.0245\n",
      "Epoch [30/50], Train Loss: 0.0166, Val Loss: 0.0231\n",
      "Epoch [31/50], Train Loss: 0.0161, Val Loss: 0.0217\n",
      "Epoch [32/50], Train Loss: 0.0155, Val Loss: 0.0204\n",
      "Epoch [33/50], Train Loss: 0.0149, Val Loss: 0.0191\n",
      "Epoch [34/50], Train Loss: 0.0143, Val Loss: 0.0178\n",
      "Epoch [35/50], Train Loss: 0.0137, Val Loss: 0.0165\n",
      "Epoch [36/50], Train Loss: 0.0130, Val Loss: 0.0152\n",
      "Epoch [37/50], Train Loss: 0.0122, Val Loss: 0.0139\n",
      "Epoch [38/50], Train Loss: 0.0115, Val Loss: 0.0128\n",
      "Epoch [39/50], Train Loss: 0.0106, Val Loss: 0.0119\n",
      "Epoch [40/50], Train Loss: 0.0097, Val Loss: 0.0114\n",
      "Epoch [41/50], Train Loss: 0.0087, Val Loss: 0.0115\n",
      "Epoch [42/50], Train Loss: 0.0077, Val Loss: 0.0125\n",
      "Epoch [43/50], Train Loss: 0.0068, Val Loss: 0.0143\n",
      "Epoch [44/50], Train Loss: 0.0060, Val Loss: 0.0167\n",
      "Epoch [45/50], Train Loss: 0.0054, Val Loss: 0.0190\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1857, Val Loss: 0.4391\n",
      "Epoch [2/50], Train Loss: 0.1724, Val Loss: 0.4136\n",
      "Epoch [3/50], Train Loss: 0.1601, Val Loss: 0.3888\n",
      "Epoch [4/50], Train Loss: 0.1478, Val Loss: 0.3632\n",
      "Epoch [5/50], Train Loss: 0.1354, Val Loss: 0.3360\n",
      "Epoch [6/50], Train Loss: 0.1231, Val Loss: 0.3059\n",
      "Epoch [7/50], Train Loss: 0.1089, Val Loss: 0.2721\n",
      "Epoch [8/50], Train Loss: 0.0935, Val Loss: 0.2327\n",
      "Epoch [9/50], Train Loss: 0.0775, Val Loss: 0.1878\n",
      "Epoch [10/50], Train Loss: 0.0605, Val Loss: 0.1393\n",
      "Epoch [11/50], Train Loss: 0.0479, Val Loss: 0.0957\n",
      "Epoch [12/50], Train Loss: 0.0386, Val Loss: 0.0681\n",
      "Epoch [13/50], Train Loss: 0.0360, Val Loss: 0.0563\n",
      "Epoch [14/50], Train Loss: 0.0352, Val Loss: 0.0507\n",
      "Epoch [15/50], Train Loss: 0.0337, Val Loss: 0.0468\n",
      "Epoch [16/50], Train Loss: 0.0329, Val Loss: 0.0436\n",
      "Epoch [17/50], Train Loss: 0.0325, Val Loss: 0.0421\n",
      "Epoch [18/50], Train Loss: 0.0316, Val Loss: 0.0397\n",
      "Epoch [19/50], Train Loss: 0.0316, Val Loss: 0.0378\n",
      "Epoch [20/50], Train Loss: 0.0302, Val Loss: 0.0359\n",
      "Epoch [21/50], Train Loss: 0.0291, Val Loss: 0.0340\n",
      "Epoch [22/50], Train Loss: 0.0297, Val Loss: 0.0321\n",
      "Epoch [23/50], Train Loss: 0.0286, Val Loss: 0.0308\n",
      "Epoch [24/50], Train Loss: 0.0273, Val Loss: 0.0284\n",
      "Epoch [25/50], Train Loss: 0.0270, Val Loss: 0.0255\n",
      "Epoch [26/50], Train Loss: 0.0264, Val Loss: 0.0240\n",
      "Epoch [27/50], Train Loss: 0.0267, Val Loss: 0.0216\n",
      "Epoch [28/50], Train Loss: 0.0248, Val Loss: 0.0201\n",
      "Epoch [29/50], Train Loss: 0.0246, Val Loss: 0.0179\n",
      "Epoch [30/50], Train Loss: 0.0243, Val Loss: 0.0160\n",
      "Epoch [31/50], Train Loss: 0.0233, Val Loss: 0.0144\n",
      "Epoch [32/50], Train Loss: 0.0232, Val Loss: 0.0127\n",
      "Epoch [33/50], Train Loss: 0.0225, Val Loss: 0.0111\n",
      "Epoch [34/50], Train Loss: 0.0218, Val Loss: 0.0092\n",
      "Epoch [35/50], Train Loss: 0.0211, Val Loss: 0.0076\n",
      "Epoch [36/50], Train Loss: 0.0202, Val Loss: 0.0067\n",
      "Epoch [37/50], Train Loss: 0.0191, Val Loss: 0.0063\n",
      "Epoch [38/50], Train Loss: 0.0184, Val Loss: 0.0058\n",
      "Epoch [39/50], Train Loss: 0.0181, Val Loss: 0.0068\n",
      "Epoch [40/50], Train Loss: 0.0171, Val Loss: 0.0077\n",
      "Epoch [41/50], Train Loss: 0.0154, Val Loss: 0.0099\n",
      "Epoch [42/50], Train Loss: 0.0144, Val Loss: 0.0121\n",
      "Epoch [43/50], Train Loss: 0.0139, Val Loss: 0.0145\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1452, Val Loss: 0.3781\n",
      "Epoch [2/50], Train Loss: 0.1356, Val Loss: 0.3589\n",
      "Epoch [3/50], Train Loss: 0.1278, Val Loss: 0.3390\n",
      "Epoch [4/50], Train Loss: 0.1179, Val Loss: 0.3178\n",
      "Epoch [5/50], Train Loss: 0.1096, Val Loss: 0.2945\n",
      "Epoch [6/50], Train Loss: 0.1004, Val Loss: 0.2685\n",
      "Epoch [7/50], Train Loss: 0.0898, Val Loss: 0.2388\n",
      "Epoch [8/50], Train Loss: 0.0805, Val Loss: 0.2057\n",
      "Epoch [9/50], Train Loss: 0.0696, Val Loss: 0.1689\n",
      "Epoch [10/50], Train Loss: 0.0611, Val Loss: 0.1321\n",
      "Epoch [11/50], Train Loss: 0.0524, Val Loss: 0.1000\n",
      "Epoch [12/50], Train Loss: 0.0484, Val Loss: 0.0814\n",
      "Epoch [13/50], Train Loss: 0.0464, Val Loss: 0.0715\n",
      "Epoch [14/50], Train Loss: 0.0457, Val Loss: 0.0667\n",
      "Epoch [15/50], Train Loss: 0.0426, Val Loss: 0.0614\n",
      "Epoch [16/50], Train Loss: 0.0416, Val Loss: 0.0605\n",
      "Epoch [17/50], Train Loss: 0.0406, Val Loss: 0.0544\n",
      "Epoch [18/50], Train Loss: 0.0397, Val Loss: 0.0520\n",
      "Epoch [19/50], Train Loss: 0.0382, Val Loss: 0.0503\n",
      "Epoch [20/50], Train Loss: 0.0381, Val Loss: 0.0477\n",
      "Epoch [21/50], Train Loss: 0.0363, Val Loss: 0.0457\n",
      "Epoch [22/50], Train Loss: 0.0347, Val Loss: 0.0420\n",
      "Epoch [23/50], Train Loss: 0.0344, Val Loss: 0.0379\n",
      "Epoch [24/50], Train Loss: 0.0329, Val Loss: 0.0364\n",
      "Epoch [25/50], Train Loss: 0.0337, Val Loss: 0.0352\n",
      "Epoch [26/50], Train Loss: 0.0321, Val Loss: 0.0322\n",
      "Epoch [27/50], Train Loss: 0.0331, Val Loss: 0.0309\n",
      "Epoch [28/50], Train Loss: 0.0319, Val Loss: 0.0290\n",
      "Epoch [29/50], Train Loss: 0.0302, Val Loss: 0.0260\n",
      "Epoch [30/50], Train Loss: 0.0307, Val Loss: 0.0262\n",
      "Epoch [31/50], Train Loss: 0.0302, Val Loss: 0.0259\n",
      "Epoch [32/50], Train Loss: 0.0287, Val Loss: 0.0245\n",
      "Epoch [33/50], Train Loss: 0.0277, Val Loss: 0.0229\n",
      "Epoch [34/50], Train Loss: 0.0290, Val Loss: 0.0227\n",
      "Epoch [35/50], Train Loss: 0.0278, Val Loss: 0.0213\n",
      "Epoch [36/50], Train Loss: 0.0279, Val Loss: 0.0200\n",
      "Epoch [37/50], Train Loss: 0.0267, Val Loss: 0.0202\n",
      "Epoch [38/50], Train Loss: 0.0269, Val Loss: 0.0192\n",
      "Epoch [39/50], Train Loss: 0.0261, Val Loss: 0.0186\n",
      "Epoch [40/50], Train Loss: 0.0271, Val Loss: 0.0186\n",
      "Epoch [41/50], Train Loss: 0.0253, Val Loss: 0.0175\n",
      "Epoch [42/50], Train Loss: 0.0266, Val Loss: 0.0170\n",
      "Epoch [43/50], Train Loss: 0.0262, Val Loss: 0.0163\n",
      "Epoch [44/50], Train Loss: 0.0239, Val Loss: 0.0160\n",
      "Epoch [45/50], Train Loss: 0.0245, Val Loss: 0.0155\n",
      "Epoch [46/50], Train Loss: 0.0237, Val Loss: 0.0149\n",
      "Epoch [47/50], Train Loss: 0.0239, Val Loss: 0.0143\n",
      "Epoch [48/50], Train Loss: 0.0237, Val Loss: 0.0136\n",
      "Epoch [49/50], Train Loss: 0.0227, Val Loss: 0.0131\n",
      "Epoch [50/50], Train Loss: 0.0235, Val Loss: 0.0124\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1262, Val Loss: 0.3180\n",
      "Epoch [2/50], Train Loss: 0.1167, Val Loss: 0.3015\n",
      "Epoch [3/50], Train Loss: 0.1074, Val Loss: 0.2833\n",
      "Epoch [4/50], Train Loss: 0.0971, Val Loss: 0.2609\n",
      "Epoch [5/50], Train Loss: 0.0844, Val Loss: 0.2299\n",
      "Epoch [6/50], Train Loss: 0.0677, Val Loss: 0.1831\n",
      "Epoch [7/50], Train Loss: 0.0478, Val Loss: 0.1196\n",
      "Epoch [8/50], Train Loss: 0.0357, Val Loss: 0.0794\n",
      "Epoch [9/50], Train Loss: 0.0328, Val Loss: 0.0684\n",
      "Epoch [10/50], Train Loss: 0.0309, Val Loss: 0.0628\n",
      "Epoch [11/50], Train Loss: 0.0298, Val Loss: 0.0595\n",
      "Epoch [12/50], Train Loss: 0.0288, Val Loss: 0.0570\n",
      "Epoch [13/50], Train Loss: 0.0279, Val Loss: 0.0547\n",
      "Epoch [14/50], Train Loss: 0.0271, Val Loss: 0.0525\n",
      "Epoch [15/50], Train Loss: 0.0264, Val Loss: 0.0503\n",
      "Epoch [16/50], Train Loss: 0.0257, Val Loss: 0.0481\n",
      "Epoch [17/50], Train Loss: 0.0250, Val Loss: 0.0460\n",
      "Epoch [18/50], Train Loss: 0.0244, Val Loss: 0.0440\n",
      "Epoch [19/50], Train Loss: 0.0238, Val Loss: 0.0422\n",
      "Epoch [20/50], Train Loss: 0.0233, Val Loss: 0.0404\n",
      "Epoch [21/50], Train Loss: 0.0228, Val Loss: 0.0389\n",
      "Epoch [22/50], Train Loss: 0.0224, Val Loss: 0.0375\n",
      "Epoch [23/50], Train Loss: 0.0220, Val Loss: 0.0364\n",
      "Epoch [24/50], Train Loss: 0.0217, Val Loss: 0.0354\n",
      "Epoch [25/50], Train Loss: 0.0214, Val Loss: 0.0346\n",
      "Epoch [26/50], Train Loss: 0.0211, Val Loss: 0.0339\n",
      "Epoch [27/50], Train Loss: 0.0208, Val Loss: 0.0334\n",
      "Epoch [28/50], Train Loss: 0.0206, Val Loss: 0.0329\n",
      "Epoch [29/50], Train Loss: 0.0204, Val Loss: 0.0325\n",
      "Epoch [30/50], Train Loss: 0.0201, Val Loss: 0.0321\n",
      "Epoch [31/50], Train Loss: 0.0199, Val Loss: 0.0318\n",
      "Epoch [32/50], Train Loss: 0.0197, Val Loss: 0.0314\n",
      "Epoch [33/50], Train Loss: 0.0195, Val Loss: 0.0311\n",
      "Epoch [34/50], Train Loss: 0.0193, Val Loss: 0.0308\n",
      "Epoch [35/50], Train Loss: 0.0191, Val Loss: 0.0305\n",
      "Epoch [36/50], Train Loss: 0.0189, Val Loss: 0.0302\n",
      "Epoch [37/50], Train Loss: 0.0187, Val Loss: 0.0299\n",
      "Epoch [38/50], Train Loss: 0.0184, Val Loss: 0.0296\n",
      "Epoch [39/50], Train Loss: 0.0182, Val Loss: 0.0292\n",
      "Epoch [40/50], Train Loss: 0.0180, Val Loss: 0.0289\n",
      "Epoch [41/50], Train Loss: 0.0177, Val Loss: 0.0286\n",
      "Epoch [42/50], Train Loss: 0.0175, Val Loss: 0.0282\n",
      "Epoch [43/50], Train Loss: 0.0172, Val Loss: 0.0278\n",
      "Epoch [44/50], Train Loss: 0.0170, Val Loss: 0.0274\n",
      "Epoch [45/50], Train Loss: 0.0167, Val Loss: 0.0270\n",
      "Epoch [46/50], Train Loss: 0.0164, Val Loss: 0.0265\n",
      "Epoch [47/50], Train Loss: 0.0160, Val Loss: 0.0260\n",
      "Epoch [48/50], Train Loss: 0.0157, Val Loss: 0.0254\n",
      "Epoch [49/50], Train Loss: 0.0153, Val Loss: 0.0248\n",
      "Epoch [50/50], Train Loss: 0.0148, Val Loss: 0.0241\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1292, Val Loss: 0.3742\n",
      "Epoch [2/50], Train Loss: 0.1162, Val Loss: 0.3470\n",
      "Epoch [3/50], Train Loss: 0.1043, Val Loss: 0.3196\n",
      "Epoch [4/50], Train Loss: 0.0926, Val Loss: 0.2896\n",
      "Epoch [5/50], Train Loss: 0.0802, Val Loss: 0.2540\n",
      "Epoch [6/50], Train Loss: 0.0657, Val Loss: 0.2101\n",
      "Epoch [7/50], Train Loss: 0.0518, Val Loss: 0.1564\n",
      "Epoch [8/50], Train Loss: 0.0394, Val Loss: 0.1031\n",
      "Epoch [9/50], Train Loss: 0.0346, Val Loss: 0.0709\n",
      "Epoch [10/50], Train Loss: 0.0336, Val Loss: 0.0583\n",
      "Epoch [11/50], Train Loss: 0.0336, Val Loss: 0.0502\n",
      "Epoch [12/50], Train Loss: 0.0320, Val Loss: 0.0415\n",
      "Epoch [13/50], Train Loss: 0.0305, Val Loss: 0.0340\n",
      "Epoch [14/50], Train Loss: 0.0286, Val Loss: 0.0286\n",
      "Epoch [15/50], Train Loss: 0.0277, Val Loss: 0.0228\n",
      "Epoch [16/50], Train Loss: 0.0256, Val Loss: 0.0175\n",
      "Epoch [17/50], Train Loss: 0.0246, Val Loss: 0.0152\n",
      "Epoch [18/50], Train Loss: 0.0237, Val Loss: 0.0124\n",
      "Epoch [19/50], Train Loss: 0.0236, Val Loss: 0.0105\n",
      "Epoch [20/50], Train Loss: 0.0229, Val Loss: 0.0085\n",
      "Epoch [21/50], Train Loss: 0.0228, Val Loss: 0.0077\n",
      "Epoch [22/50], Train Loss: 0.0225, Val Loss: 0.0077\n",
      "Epoch [23/50], Train Loss: 0.0216, Val Loss: 0.0068\n",
      "Epoch [24/50], Train Loss: 0.0215, Val Loss: 0.0069\n",
      "Epoch [25/50], Train Loss: 0.0205, Val Loss: 0.0055\n",
      "Epoch [26/50], Train Loss: 0.0214, Val Loss: 0.0061\n",
      "Epoch [27/50], Train Loss: 0.0209, Val Loss: 0.0050\n",
      "Epoch [28/50], Train Loss: 0.0205, Val Loss: 0.0055\n",
      "Epoch [29/50], Train Loss: 0.0208, Val Loss: 0.0047\n",
      "Epoch [30/50], Train Loss: 0.0199, Val Loss: 0.0056\n",
      "Epoch [31/50], Train Loss: 0.0203, Val Loss: 0.0048\n",
      "Epoch [32/50], Train Loss: 0.0196, Val Loss: 0.0050\n",
      "Epoch [33/50], Train Loss: 0.0190, Val Loss: 0.0048\n",
      "Epoch [34/50], Train Loss: 0.0192, Val Loss: 0.0049\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1952, Val Loss: 0.4655\n",
      "Epoch [2/50], Train Loss: 0.1793, Val Loss: 0.4390\n",
      "Epoch [3/50], Train Loss: 0.1636, Val Loss: 0.4117\n",
      "Epoch [4/50], Train Loss: 0.1500, Val Loss: 0.3819\n",
      "Epoch [5/50], Train Loss: 0.1334, Val Loss: 0.3471\n",
      "Epoch [6/50], Train Loss: 0.1138, Val Loss: 0.3045\n",
      "Epoch [7/50], Train Loss: 0.0958, Val Loss: 0.2530\n",
      "Epoch [8/50], Train Loss: 0.0764, Val Loss: 0.1969\n",
      "Epoch [9/50], Train Loss: 0.0660, Val Loss: 0.1515\n",
      "Epoch [10/50], Train Loss: 0.0614, Val Loss: 0.1261\n",
      "Epoch [11/50], Train Loss: 0.0601, Val Loss: 0.1148\n",
      "Epoch [12/50], Train Loss: 0.0569, Val Loss: 0.1044\n",
      "Epoch [13/50], Train Loss: 0.0567, Val Loss: 0.0970\n",
      "Epoch [14/50], Train Loss: 0.0511, Val Loss: 0.0907\n",
      "Epoch [15/50], Train Loss: 0.0527, Val Loss: 0.0849\n",
      "Epoch [16/50], Train Loss: 0.0480, Val Loss: 0.0801\n",
      "Epoch [17/50], Train Loss: 0.0496, Val Loss: 0.0732\n",
      "Epoch [18/50], Train Loss: 0.0463, Val Loss: 0.0681\n",
      "Epoch [19/50], Train Loss: 0.0447, Val Loss: 0.0634\n",
      "Epoch [20/50], Train Loss: 0.0436, Val Loss: 0.0561\n",
      "Epoch [21/50], Train Loss: 0.0419, Val Loss: 0.0530\n",
      "Epoch [22/50], Train Loss: 0.0430, Val Loss: 0.0463\n",
      "Epoch [23/50], Train Loss: 0.0407, Val Loss: 0.0415\n",
      "Epoch [24/50], Train Loss: 0.0387, Val Loss: 0.0396\n",
      "Epoch [25/50], Train Loss: 0.0384, Val Loss: 0.0371\n",
      "Epoch [26/50], Train Loss: 0.0357, Val Loss: 0.0328\n",
      "Epoch [27/50], Train Loss: 0.0350, Val Loss: 0.0294\n",
      "Epoch [28/50], Train Loss: 0.0338, Val Loss: 0.0270\n",
      "Epoch [29/50], Train Loss: 0.0337, Val Loss: 0.0250\n",
      "Epoch [30/50], Train Loss: 0.0325, Val Loss: 0.0209\n",
      "Epoch [31/50], Train Loss: 0.0309, Val Loss: 0.0211\n",
      "Epoch [32/50], Train Loss: 0.0300, Val Loss: 0.0178\n",
      "Epoch [33/50], Train Loss: 0.0289, Val Loss: 0.0144\n",
      "Epoch [34/50], Train Loss: 0.0284, Val Loss: 0.0129\n",
      "Epoch [35/50], Train Loss: 0.0279, Val Loss: 0.0101\n",
      "Epoch [36/50], Train Loss: 0.0257, Val Loss: 0.0096\n",
      "Epoch [37/50], Train Loss: 0.0272, Val Loss: 0.0080\n",
      "Epoch [38/50], Train Loss: 0.0252, Val Loss: 0.0069\n",
      "Epoch [39/50], Train Loss: 0.0247, Val Loss: 0.0060\n",
      "Epoch [40/50], Train Loss: 0.0228, Val Loss: 0.0085\n",
      "Epoch [41/50], Train Loss: 0.0228, Val Loss: 0.0075\n",
      "Epoch [42/50], Train Loss: 0.0257, Val Loss: 0.0086\n",
      "Epoch [43/50], Train Loss: 0.0228, Val Loss: 0.0105\n",
      "Epoch [44/50], Train Loss: 0.0226, Val Loss: 0.0087\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1309, Val Loss: 0.3520\n",
      "Epoch [2/50], Train Loss: 0.1154, Val Loss: 0.3217\n",
      "Epoch [3/50], Train Loss: 0.0998, Val Loss: 0.2874\n",
      "Epoch [4/50], Train Loss: 0.0827, Val Loss: 0.2449\n",
      "Epoch [5/50], Train Loss: 0.0635, Val Loss: 0.1900\n",
      "Epoch [6/50], Train Loss: 0.0449, Val Loss: 0.1265\n",
      "Epoch [7/50], Train Loss: 0.0355, Val Loss: 0.0858\n",
      "Epoch [8/50], Train Loss: 0.0349, Val Loss: 0.0746\n",
      "Epoch [9/50], Train Loss: 0.0339, Val Loss: 0.0693\n",
      "Epoch [10/50], Train Loss: 0.0328, Val Loss: 0.0643\n",
      "Epoch [11/50], Train Loss: 0.0318, Val Loss: 0.0597\n",
      "Epoch [12/50], Train Loss: 0.0308, Val Loss: 0.0553\n",
      "Epoch [13/50], Train Loss: 0.0298, Val Loss: 0.0509\n",
      "Epoch [14/50], Train Loss: 0.0287, Val Loss: 0.0465\n",
      "Epoch [15/50], Train Loss: 0.0276, Val Loss: 0.0422\n",
      "Epoch [16/50], Train Loss: 0.0265, Val Loss: 0.0380\n",
      "Epoch [17/50], Train Loss: 0.0254, Val Loss: 0.0342\n",
      "Epoch [18/50], Train Loss: 0.0243, Val Loss: 0.0308\n",
      "Epoch [19/50], Train Loss: 0.0233, Val Loss: 0.0278\n",
      "Epoch [20/50], Train Loss: 0.0224, Val Loss: 0.0254\n",
      "Epoch [21/50], Train Loss: 0.0217, Val Loss: 0.0235\n",
      "Epoch [22/50], Train Loss: 0.0211, Val Loss: 0.0221\n",
      "Epoch [23/50], Train Loss: 0.0206, Val Loss: 0.0211\n",
      "Epoch [24/50], Train Loss: 0.0202, Val Loss: 0.0205\n",
      "Epoch [25/50], Train Loss: 0.0199, Val Loss: 0.0201\n",
      "Epoch [26/50], Train Loss: 0.0197, Val Loss: 0.0200\n",
      "Epoch [27/50], Train Loss: 0.0195, Val Loss: 0.0200\n",
      "Epoch [28/50], Train Loss: 0.0193, Val Loss: 0.0200\n",
      "Epoch [29/50], Train Loss: 0.0190, Val Loss: 0.0202\n",
      "Epoch [30/50], Train Loss: 0.0188, Val Loss: 0.0204\n",
      "Epoch [31/50], Train Loss: 0.0186, Val Loss: 0.0206\n",
      "Epoch [32/50], Train Loss: 0.0184, Val Loss: 0.0209\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1196, Val Loss: 0.3271\n",
      "Epoch [2/50], Train Loss: 0.1061, Val Loss: 0.2996\n",
      "Epoch [3/50], Train Loss: 0.0923, Val Loss: 0.2683\n",
      "Epoch [4/50], Train Loss: 0.0770, Val Loss: 0.2288\n",
      "Epoch [5/50], Train Loss: 0.0593, Val Loss: 0.1769\n",
      "Epoch [6/50], Train Loss: 0.0445, Val Loss: 0.1213\n",
      "Epoch [7/50], Train Loss: 0.0405, Val Loss: 0.0950\n",
      "Epoch [8/50], Train Loss: 0.0411, Val Loss: 0.0856\n",
      "Epoch [9/50], Train Loss: 0.0394, Val Loss: 0.0798\n",
      "Epoch [10/50], Train Loss: 0.0385, Val Loss: 0.0738\n",
      "Epoch [11/50], Train Loss: 0.0372, Val Loss: 0.0660\n",
      "Epoch [12/50], Train Loss: 0.0351, Val Loss: 0.0590\n",
      "Epoch [13/50], Train Loss: 0.0347, Val Loss: 0.0525\n",
      "Epoch [14/50], Train Loss: 0.0328, Val Loss: 0.0437\n",
      "Epoch [15/50], Train Loss: 0.0323, Val Loss: 0.0381\n",
      "Epoch [16/50], Train Loss: 0.0299, Val Loss: 0.0325\n",
      "Epoch [17/50], Train Loss: 0.0289, Val Loss: 0.0287\n",
      "Epoch [18/50], Train Loss: 0.0278, Val Loss: 0.0267\n",
      "Epoch [19/50], Train Loss: 0.0275, Val Loss: 0.0251\n",
      "Epoch [20/50], Train Loss: 0.0261, Val Loss: 0.0246\n",
      "Epoch [21/50], Train Loss: 0.0254, Val Loss: 0.0228\n",
      "Epoch [22/50], Train Loss: 0.0257, Val Loss: 0.0233\n",
      "Epoch [23/50], Train Loss: 0.0254, Val Loss: 0.0221\n",
      "Epoch [24/50], Train Loss: 0.0249, Val Loss: 0.0222\n",
      "Epoch [25/50], Train Loss: 0.0246, Val Loss: 0.0217\n",
      "Epoch [26/50], Train Loss: 0.0251, Val Loss: 0.0218\n",
      "Epoch [27/50], Train Loss: 0.0241, Val Loss: 0.0228\n",
      "Epoch [28/50], Train Loss: 0.0238, Val Loss: 0.0220\n",
      "Epoch [29/50], Train Loss: 0.0241, Val Loss: 0.0222\n",
      "Epoch [30/50], Train Loss: 0.0234, Val Loss: 0.0225\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=32, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1207, Val Loss: 0.2925\n",
      "Epoch [2/50], Train Loss: 0.1095, Val Loss: 0.2729\n",
      "Epoch [3/50], Train Loss: 0.0999, Val Loss: 0.2532\n",
      "Epoch [4/50], Train Loss: 0.0894, Val Loss: 0.2309\n",
      "Epoch [5/50], Train Loss: 0.0807, Val Loss: 0.2034\n",
      "Epoch [6/50], Train Loss: 0.0691, Val Loss: 0.1681\n",
      "Epoch [7/50], Train Loss: 0.0552, Val Loss: 0.1260\n",
      "Epoch [8/50], Train Loss: 0.0510, Val Loss: 0.0998\n",
      "Epoch [9/50], Train Loss: 0.0479, Val Loss: 0.0932\n",
      "Epoch [10/50], Train Loss: 0.0467, Val Loss: 0.0894\n",
      "Epoch [11/50], Train Loss: 0.0459, Val Loss: 0.0881\n",
      "Epoch [12/50], Train Loss: 0.0450, Val Loss: 0.0848\n",
      "Epoch [13/50], Train Loss: 0.0434, Val Loss: 0.0833\n",
      "Epoch [14/50], Train Loss: 0.0416, Val Loss: 0.0783\n",
      "Epoch [15/50], Train Loss: 0.0427, Val Loss: 0.0746\n",
      "Epoch [16/50], Train Loss: 0.0417, Val Loss: 0.0692\n",
      "Epoch [17/50], Train Loss: 0.0395, Val Loss: 0.0652\n",
      "Epoch [18/50], Train Loss: 0.0400, Val Loss: 0.0617\n",
      "Epoch [19/50], Train Loss: 0.0392, Val Loss: 0.0599\n",
      "Epoch [20/50], Train Loss: 0.0365, Val Loss: 0.0541\n",
      "Epoch [21/50], Train Loss: 0.0371, Val Loss: 0.0537\n",
      "Epoch [22/50], Train Loss: 0.0364, Val Loss: 0.0487\n",
      "Epoch [23/50], Train Loss: 0.0354, Val Loss: 0.0455\n",
      "Epoch [24/50], Train Loss: 0.0350, Val Loss: 0.0471\n",
      "Epoch [25/50], Train Loss: 0.0358, Val Loss: 0.0423\n",
      "Epoch [26/50], Train Loss: 0.0362, Val Loss: 0.0456\n",
      "Epoch [27/50], Train Loss: 0.0342, Val Loss: 0.0407\n",
      "Epoch [28/50], Train Loss: 0.0351, Val Loss: 0.0409\n",
      "Epoch [29/50], Train Loss: 0.0335, Val Loss: 0.0385\n",
      "Epoch [30/50], Train Loss: 0.0332, Val Loss: 0.0403\n",
      "Epoch [31/50], Train Loss: 0.0333, Val Loss: 0.0385\n",
      "Epoch [32/50], Train Loss: 0.0331, Val Loss: 0.0373\n",
      "Epoch [33/50], Train Loss: 0.0333, Val Loss: 0.0398\n",
      "Epoch [34/50], Train Loss: 0.0327, Val Loss: 0.0362\n",
      "Epoch [35/50], Train Loss: 0.0317, Val Loss: 0.0366\n",
      "Epoch [36/50], Train Loss: 0.0311, Val Loss: 0.0336\n",
      "Epoch [37/50], Train Loss: 0.0311, Val Loss: 0.0334\n",
      "Epoch [38/50], Train Loss: 0.0306, Val Loss: 0.0337\n",
      "Epoch [39/50], Train Loss: 0.0304, Val Loss: 0.0341\n",
      "Epoch [40/50], Train Loss: 0.0289, Val Loss: 0.0316\n",
      "Epoch [41/50], Train Loss: 0.0295, Val Loss: 0.0322\n",
      "Epoch [42/50], Train Loss: 0.0298, Val Loss: 0.0317\n",
      "Epoch [43/50], Train Loss: 0.0287, Val Loss: 0.0317\n",
      "Epoch [44/50], Train Loss: 0.0280, Val Loss: 0.0295\n",
      "Epoch [45/50], Train Loss: 0.0284, Val Loss: 0.0321\n",
      "Epoch [46/50], Train Loss: 0.0286, Val Loss: 0.0300\n",
      "Epoch [47/50], Train Loss: 0.0269, Val Loss: 0.0295\n",
      "Epoch [48/50], Train Loss: 0.0259, Val Loss: 0.0301\n",
      "Epoch [49/50], Train Loss: 0.0257, Val Loss: 0.0291\n",
      "Epoch [50/50], Train Loss: 0.0244, Val Loss: 0.0278\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1695, Val Loss: 0.4289\n",
      "Epoch [2/50], Train Loss: 0.1522, Val Loss: 0.3940\n",
      "Epoch [3/50], Train Loss: 0.1359, Val Loss: 0.3569\n",
      "Epoch [4/50], Train Loss: 0.1180, Val Loss: 0.3118\n",
      "Epoch [5/50], Train Loss: 0.0957, Val Loss: 0.2477\n",
      "Epoch [6/50], Train Loss: 0.0641, Val Loss: 0.1351\n",
      "Epoch [7/50], Train Loss: 0.0285, Val Loss: 0.0294\n",
      "Epoch [8/50], Train Loss: 0.0280, Val Loss: 0.0276\n",
      "Epoch [9/50], Train Loss: 0.0255, Val Loss: 0.0227\n",
      "Epoch [10/50], Train Loss: 0.0243, Val Loss: 0.0198\n",
      "Epoch [11/50], Train Loss: 0.0232, Val Loss: 0.0174\n",
      "Epoch [12/50], Train Loss: 0.0222, Val Loss: 0.0154\n",
      "Epoch [13/50], Train Loss: 0.0213, Val Loss: 0.0136\n",
      "Epoch [14/50], Train Loss: 0.0204, Val Loss: 0.0121\n",
      "Epoch [15/50], Train Loss: 0.0196, Val Loss: 0.0108\n",
      "Epoch [16/50], Train Loss: 0.0189, Val Loss: 0.0096\n",
      "Epoch [17/50], Train Loss: 0.0182, Val Loss: 0.0085\n",
      "Epoch [18/50], Train Loss: 0.0175, Val Loss: 0.0075\n",
      "Epoch [19/50], Train Loss: 0.0168, Val Loss: 0.0065\n",
      "Epoch [20/50], Train Loss: 0.0161, Val Loss: 0.0055\n",
      "Epoch [21/50], Train Loss: 0.0153, Val Loss: 0.0045\n",
      "Epoch [22/50], Train Loss: 0.0144, Val Loss: 0.0037\n",
      "Epoch [23/50], Train Loss: 0.0133, Val Loss: 0.0038\n",
      "Epoch [24/50], Train Loss: 0.0118, Val Loss: 0.0062\n",
      "Epoch [25/50], Train Loss: 0.0098, Val Loss: 0.0140\n",
      "Epoch [26/50], Train Loss: 0.0076, Val Loss: 0.0268\n",
      "Epoch [27/50], Train Loss: 0.0063, Val Loss: 0.0350\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1319, Val Loss: 0.3670\n",
      "Epoch [2/50], Train Loss: 0.1185, Val Loss: 0.3379\n",
      "Epoch [3/50], Train Loss: 0.1054, Val Loss: 0.3074\n",
      "Epoch [4/50], Train Loss: 0.0909, Val Loss: 0.2713\n",
      "Epoch [5/50], Train Loss: 0.0743, Val Loss: 0.2228\n",
      "Epoch [6/50], Train Loss: 0.0538, Val Loss: 0.1500\n",
      "Epoch [7/50], Train Loss: 0.0346, Val Loss: 0.0747\n",
      "Epoch [8/50], Train Loss: 0.0328, Val Loss: 0.0616\n",
      "Epoch [9/50], Train Loss: 0.0305, Val Loss: 0.0541\n",
      "Epoch [10/50], Train Loss: 0.0296, Val Loss: 0.0489\n",
      "Epoch [11/50], Train Loss: 0.0281, Val Loss: 0.0455\n",
      "Epoch [12/50], Train Loss: 0.0269, Val Loss: 0.0406\n",
      "Epoch [13/50], Train Loss: 0.0261, Val Loss: 0.0377\n",
      "Epoch [14/50], Train Loss: 0.0253, Val Loss: 0.0342\n",
      "Epoch [15/50], Train Loss: 0.0245, Val Loss: 0.0312\n",
      "Epoch [16/50], Train Loss: 0.0237, Val Loss: 0.0291\n",
      "Epoch [17/50], Train Loss: 0.0236, Val Loss: 0.0275\n",
      "Epoch [18/50], Train Loss: 0.0224, Val Loss: 0.0259\n",
      "Epoch [19/50], Train Loss: 0.0220, Val Loss: 0.0243\n",
      "Epoch [20/50], Train Loss: 0.0211, Val Loss: 0.0236\n",
      "Epoch [21/50], Train Loss: 0.0206, Val Loss: 0.0227\n",
      "Epoch [22/50], Train Loss: 0.0204, Val Loss: 0.0219\n",
      "Epoch [23/50], Train Loss: 0.0193, Val Loss: 0.0209\n",
      "Epoch [24/50], Train Loss: 0.0190, Val Loss: 0.0201\n",
      "Epoch [25/50], Train Loss: 0.0185, Val Loss: 0.0192\n",
      "Epoch [26/50], Train Loss: 0.0179, Val Loss: 0.0179\n",
      "Epoch [27/50], Train Loss: 0.0175, Val Loss: 0.0166\n",
      "Epoch [28/50], Train Loss: 0.0169, Val Loss: 0.0156\n",
      "Epoch [29/50], Train Loss: 0.0170, Val Loss: 0.0146\n",
      "Epoch [30/50], Train Loss: 0.0165, Val Loss: 0.0137\n",
      "Epoch [31/50], Train Loss: 0.0155, Val Loss: 0.0127\n",
      "Epoch [32/50], Train Loss: 0.0152, Val Loss: 0.0114\n",
      "Epoch [33/50], Train Loss: 0.0140, Val Loss: 0.0100\n",
      "Epoch [34/50], Train Loss: 0.0133, Val Loss: 0.0086\n",
      "Epoch [35/50], Train Loss: 0.0119, Val Loss: 0.0082\n",
      "Epoch [36/50], Train Loss: 0.0111, Val Loss: 0.0099\n",
      "Epoch [37/50], Train Loss: 0.0093, Val Loss: 0.0164\n",
      "Epoch [38/50], Train Loss: 0.0084, Val Loss: 0.0305\n",
      "Epoch [39/50], Train Loss: 0.0080, Val Loss: 0.0286\n",
      "Epoch [40/50], Train Loss: 0.0073, Val Loss: 0.0366\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=1, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1003, Val Loss: 0.2881\n",
      "Epoch [2/50], Train Loss: 0.0866, Val Loss: 0.2597\n",
      "Epoch [3/50], Train Loss: 0.0773, Val Loss: 0.2321\n",
      "Epoch [4/50], Train Loss: 0.0670, Val Loss: 0.2034\n",
      "Epoch [5/50], Train Loss: 0.0576, Val Loss: 0.1722\n",
      "Epoch [6/50], Train Loss: 0.0469, Val Loss: 0.1375\n",
      "Epoch [7/50], Train Loss: 0.0392, Val Loss: 0.1006\n",
      "Epoch [8/50], Train Loss: 0.0333, Val Loss: 0.0683\n",
      "Epoch [9/50], Train Loss: 0.0315, Val Loss: 0.0513\n",
      "Epoch [10/50], Train Loss: 0.0299, Val Loss: 0.0438\n",
      "Epoch [11/50], Train Loss: 0.0291, Val Loss: 0.0393\n",
      "Epoch [12/50], Train Loss: 0.0282, Val Loss: 0.0351\n",
      "Epoch [13/50], Train Loss: 0.0268, Val Loss: 0.0287\n",
      "Epoch [14/50], Train Loss: 0.0259, Val Loss: 0.0249\n",
      "Epoch [15/50], Train Loss: 0.0244, Val Loss: 0.0209\n",
      "Epoch [16/50], Train Loss: 0.0233, Val Loss: 0.0162\n",
      "Epoch [17/50], Train Loss: 0.0226, Val Loss: 0.0143\n",
      "Epoch [18/50], Train Loss: 0.0212, Val Loss: 0.0093\n",
      "Epoch [19/50], Train Loss: 0.0196, Val Loss: 0.0075\n",
      "Epoch [20/50], Train Loss: 0.0186, Val Loss: 0.0055\n",
      "Epoch [21/50], Train Loss: 0.0178, Val Loss: 0.0064\n",
      "Epoch [22/50], Train Loss: 0.0159, Val Loss: 0.0065\n",
      "Epoch [23/50], Train Loss: 0.0149, Val Loss: 0.0130\n",
      "Epoch [24/50], Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [25/50], Train Loss: 0.0129, Val Loss: 0.0205\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.0967, Val Loss: 0.2819\n",
      "Epoch [2/50], Train Loss: 0.0810, Val Loss: 0.2443\n",
      "Epoch [3/50], Train Loss: 0.0641, Val Loss: 0.1932\n",
      "Epoch [4/50], Train Loss: 0.0447, Val Loss: 0.1200\n",
      "Epoch [5/50], Train Loss: 0.0330, Val Loss: 0.0659\n",
      "Epoch [6/50], Train Loss: 0.0331, Val Loss: 0.0570\n",
      "Epoch [7/50], Train Loss: 0.0314, Val Loss: 0.0492\n",
      "Epoch [8/50], Train Loss: 0.0301, Val Loss: 0.0425\n",
      "Epoch [9/50], Train Loss: 0.0288, Val Loss: 0.0363\n",
      "Epoch [10/50], Train Loss: 0.0276, Val Loss: 0.0303\n",
      "Epoch [11/50], Train Loss: 0.0263, Val Loss: 0.0248\n",
      "Epoch [12/50], Train Loss: 0.0250, Val Loss: 0.0200\n",
      "Epoch [13/50], Train Loss: 0.0237, Val Loss: 0.0161\n",
      "Epoch [14/50], Train Loss: 0.0224, Val Loss: 0.0135\n",
      "Epoch [15/50], Train Loss: 0.0213, Val Loss: 0.0118\n",
      "Epoch [16/50], Train Loss: 0.0202, Val Loss: 0.0108\n",
      "Epoch [17/50], Train Loss: 0.0192, Val Loss: 0.0098\n",
      "Epoch [18/50], Train Loss: 0.0181, Val Loss: 0.0086\n",
      "Epoch [19/50], Train Loss: 0.0167, Val Loss: 0.0073\n",
      "Epoch [20/50], Train Loss: 0.0148, Val Loss: 0.0078\n",
      "Epoch [21/50], Train Loss: 0.0119, Val Loss: 0.0163\n",
      "Epoch [22/50], Train Loss: 0.0088, Val Loss: 0.0268\n",
      "Epoch [23/50], Train Loss: 0.0071, Val Loss: 0.0366\n",
      "Epoch [24/50], Train Loss: 0.0066, Val Loss: 0.0386\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1148, Val Loss: 0.3205\n",
      "Epoch [2/50], Train Loss: 0.0970, Val Loss: 0.2823\n",
      "Epoch [3/50], Train Loss: 0.0787, Val Loss: 0.2312\n",
      "Epoch [4/50], Train Loss: 0.0547, Val Loss: 0.1457\n",
      "Epoch [5/50], Train Loss: 0.0345, Val Loss: 0.0616\n",
      "Epoch [6/50], Train Loss: 0.0369, Val Loss: 0.0593\n",
      "Epoch [7/50], Train Loss: 0.0341, Val Loss: 0.0526\n",
      "Epoch [8/50], Train Loss: 0.0332, Val Loss: 0.0475\n",
      "Epoch [9/50], Train Loss: 0.0318, Val Loss: 0.0418\n",
      "Epoch [10/50], Train Loss: 0.0307, Val Loss: 0.0360\n",
      "Epoch [11/50], Train Loss: 0.0293, Val Loss: 0.0314\n",
      "Epoch [12/50], Train Loss: 0.0278, Val Loss: 0.0270\n",
      "Epoch [13/50], Train Loss: 0.0272, Val Loss: 0.0231\n",
      "Epoch [14/50], Train Loss: 0.0264, Val Loss: 0.0186\n",
      "Epoch [15/50], Train Loss: 0.0253, Val Loss: 0.0170\n",
      "Epoch [16/50], Train Loss: 0.0239, Val Loss: 0.0145\n",
      "Epoch [17/50], Train Loss: 0.0232, Val Loss: 0.0139\n",
      "Epoch [18/50], Train Loss: 0.0223, Val Loss: 0.0135\n",
      "Epoch [19/50], Train Loss: 0.0224, Val Loss: 0.0133\n",
      "Epoch [20/50], Train Loss: 0.0214, Val Loss: 0.0131\n",
      "Epoch [21/50], Train Loss: 0.0203, Val Loss: 0.0126\n",
      "Epoch [22/50], Train Loss: 0.0201, Val Loss: 0.0118\n",
      "Epoch [23/50], Train Loss: 0.0195, Val Loss: 0.0105\n",
      "Epoch [24/50], Train Loss: 0.0185, Val Loss: 0.0094\n",
      "Epoch [25/50], Train Loss: 0.0180, Val Loss: 0.0071\n",
      "Epoch [26/50], Train Loss: 0.0166, Val Loss: 0.0055\n",
      "Epoch [27/50], Train Loss: 0.0146, Val Loss: 0.0077\n",
      "Epoch [28/50], Train Loss: 0.0127, Val Loss: 0.0123\n",
      "Epoch [29/50], Train Loss: 0.0098, Val Loss: 0.0213\n",
      "Epoch [30/50], Train Loss: 0.0089, Val Loss: 0.0259\n",
      "Epoch [31/50], Train Loss: 0.0086, Val Loss: 0.0253\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=2, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1227, Val Loss: 0.3219\n",
      "Epoch [2/50], Train Loss: 0.1037, Val Loss: 0.2809\n",
      "Epoch [3/50], Train Loss: 0.0815, Val Loss: 0.2201\n",
      "Epoch [4/50], Train Loss: 0.0545, Val Loss: 0.1253\n",
      "Epoch [5/50], Train Loss: 0.0434, Val Loss: 0.0804\n",
      "Epoch [6/50], Train Loss: 0.0466, Val Loss: 0.0841\n",
      "Epoch [7/50], Train Loss: 0.0435, Val Loss: 0.0797\n",
      "Epoch [8/50], Train Loss: 0.0415, Val Loss: 0.0730\n",
      "Epoch [9/50], Train Loss: 0.0401, Val Loss: 0.0680\n",
      "Epoch [10/50], Train Loss: 0.0390, Val Loss: 0.0641\n",
      "Epoch [11/50], Train Loss: 0.0373, Val Loss: 0.0573\n",
      "Epoch [12/50], Train Loss: 0.0372, Val Loss: 0.0531\n",
      "Epoch [13/50], Train Loss: 0.0364, Val Loss: 0.0494\n",
      "Epoch [14/50], Train Loss: 0.0349, Val Loss: 0.0437\n",
      "Epoch [15/50], Train Loss: 0.0340, Val Loss: 0.0395\n",
      "Epoch [16/50], Train Loss: 0.0323, Val Loss: 0.0346\n",
      "Epoch [17/50], Train Loss: 0.0311, Val Loss: 0.0288\n",
      "Epoch [18/50], Train Loss: 0.0298, Val Loss: 0.0258\n",
      "Epoch [19/50], Train Loss: 0.0282, Val Loss: 0.0211\n",
      "Epoch [20/50], Train Loss: 0.0263, Val Loss: 0.0183\n",
      "Epoch [21/50], Train Loss: 0.0254, Val Loss: 0.0159\n",
      "Epoch [22/50], Train Loss: 0.0245, Val Loss: 0.0125\n",
      "Epoch [23/50], Train Loss: 0.0226, Val Loss: 0.0077\n",
      "Epoch [24/50], Train Loss: 0.0205, Val Loss: 0.0043\n",
      "Epoch [25/50], Train Loss: 0.0184, Val Loss: 0.0058\n",
      "Epoch [26/50], Train Loss: 0.0167, Val Loss: 0.0096\n",
      "Epoch [27/50], Train Loss: 0.0160, Val Loss: 0.0088\n",
      "Epoch [28/50], Train Loss: 0.0163, Val Loss: 0.0084\n",
      "Epoch [29/50], Train Loss: 0.0147, Val Loss: 0.0120\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.0\n",
      "Epoch [1/50], Train Loss: 0.1469, Val Loss: 0.3406\n",
      "Epoch [2/50], Train Loss: 0.1188, Val Loss: 0.2868\n",
      "Epoch [3/50], Train Loss: 0.0857, Val Loss: 0.2008\n",
      "Epoch [4/50], Train Loss: 0.0436, Val Loss: 0.0729\n",
      "Epoch [5/50], Train Loss: 0.0403, Val Loss: 0.0738\n",
      "Epoch [6/50], Train Loss: 0.0375, Val Loss: 0.0731\n",
      "Epoch [7/50], Train Loss: 0.0356, Val Loss: 0.0695\n",
      "Epoch [8/50], Train Loss: 0.0343, Val Loss: 0.0659\n",
      "Epoch [9/50], Train Loss: 0.0330, Val Loss: 0.0614\n",
      "Epoch [10/50], Train Loss: 0.0316, Val Loss: 0.0565\n",
      "Epoch [11/50], Train Loss: 0.0301, Val Loss: 0.0513\n",
      "Epoch [12/50], Train Loss: 0.0285, Val Loss: 0.0463\n",
      "Epoch [13/50], Train Loss: 0.0269, Val Loss: 0.0419\n",
      "Epoch [14/50], Train Loss: 0.0252, Val Loss: 0.0389\n",
      "Epoch [15/50], Train Loss: 0.0238, Val Loss: 0.0374\n",
      "Epoch [16/50], Train Loss: 0.0228, Val Loss: 0.0369\n",
      "Epoch [17/50], Train Loss: 0.0223, Val Loss: 0.0368\n",
      "Epoch [18/50], Train Loss: 0.0219, Val Loss: 0.0365\n",
      "Epoch [19/50], Train Loss: 0.0215, Val Loss: 0.0359\n",
      "Epoch [20/50], Train Loss: 0.0212, Val Loss: 0.0351\n",
      "Epoch [21/50], Train Loss: 0.0210, Val Loss: 0.0344\n",
      "Epoch [22/50], Train Loss: 0.0207, Val Loss: 0.0338\n",
      "Epoch [23/50], Train Loss: 0.0205, Val Loss: 0.0331\n",
      "Epoch [24/50], Train Loss: 0.0202, Val Loss: 0.0324\n",
      "Epoch [25/50], Train Loss: 0.0200, Val Loss: 0.0317\n",
      "Epoch [26/50], Train Loss: 0.0197, Val Loss: 0.0309\n",
      "Epoch [27/50], Train Loss: 0.0195, Val Loss: 0.0300\n",
      "Epoch [28/50], Train Loss: 0.0192, Val Loss: 0.0290\n",
      "Epoch [29/50], Train Loss: 0.0188, Val Loss: 0.0279\n",
      "Epoch [30/50], Train Loss: 0.0185, Val Loss: 0.0265\n",
      "Epoch [31/50], Train Loss: 0.0180, Val Loss: 0.0249\n",
      "Epoch [32/50], Train Loss: 0.0175, Val Loss: 0.0227\n",
      "Epoch [33/50], Train Loss: 0.0168, Val Loss: 0.0200\n",
      "Epoch [34/50], Train Loss: 0.0159, Val Loss: 0.0166\n",
      "Epoch [35/50], Train Loss: 0.0146, Val Loss: 0.0132\n",
      "Epoch [36/50], Train Loss: 0.0125, Val Loss: 0.0128\n",
      "Epoch [37/50], Train Loss: 0.0094, Val Loss: 0.0178\n",
      "Epoch [38/50], Train Loss: 0.0067, Val Loss: 0.0224\n",
      "Epoch [39/50], Train Loss: 0.0049, Val Loss: 0.0241\n",
      "Epoch [40/50], Train Loss: 0.0041, Val Loss: 0.0231\n",
      "Epoch [41/50], Train Loss: 0.0041, Val Loss: 0.0225\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.2\n",
      "Epoch [1/50], Train Loss: 0.1045, Val Loss: 0.3031\n",
      "Epoch [2/50], Train Loss: 0.0905, Val Loss: 0.2730\n",
      "Epoch [3/50], Train Loss: 0.0742, Val Loss: 0.2275\n",
      "Epoch [4/50], Train Loss: 0.0516, Val Loss: 0.1370\n",
      "Epoch [5/50], Train Loss: 0.0374, Val Loss: 0.0769\n",
      "Epoch [6/50], Train Loss: 0.0402, Val Loss: 0.0778\n",
      "Epoch [7/50], Train Loss: 0.0371, Val Loss: 0.0689\n",
      "Epoch [8/50], Train Loss: 0.0361, Val Loss: 0.0619\n",
      "Epoch [9/50], Train Loss: 0.0346, Val Loss: 0.0544\n",
      "Epoch [10/50], Train Loss: 0.0327, Val Loss: 0.0461\n",
      "Epoch [11/50], Train Loss: 0.0324, Val Loss: 0.0387\n",
      "Epoch [12/50], Train Loss: 0.0301, Val Loss: 0.0298\n",
      "Epoch [13/50], Train Loss: 0.0282, Val Loss: 0.0230\n",
      "Epoch [14/50], Train Loss: 0.0268, Val Loss: 0.0177\n",
      "Epoch [15/50], Train Loss: 0.0251, Val Loss: 0.0139\n",
      "Epoch [16/50], Train Loss: 0.0245, Val Loss: 0.0126\n",
      "Epoch [17/50], Train Loss: 0.0238, Val Loss: 0.0128\n",
      "Epoch [18/50], Train Loss: 0.0227, Val Loss: 0.0141\n",
      "Epoch [19/50], Train Loss: 0.0224, Val Loss: 0.0141\n",
      "Epoch [20/50], Train Loss: 0.0224, Val Loss: 0.0138\n",
      "Epoch [21/50], Train Loss: 0.0216, Val Loss: 0.0138\n",
      "Early stopping triggered.\n",
      "Testing parameters: lr=0.0001, optimizer=adamw, hidden_size=64, num_layers=3, dropout=0.5\n",
      "Epoch [1/50], Train Loss: 0.1001, Val Loss: 0.2822\n",
      "Epoch [2/50], Train Loss: 0.0840, Val Loss: 0.2457\n",
      "Epoch [3/50], Train Loss: 0.0670, Val Loss: 0.1950\n",
      "Epoch [4/50], Train Loss: 0.0501, Val Loss: 0.1286\n",
      "Epoch [5/50], Train Loss: 0.0446, Val Loss: 0.0962\n",
      "Epoch [6/50], Train Loss: 0.0461, Val Loss: 0.0934\n",
      "Epoch [7/50], Train Loss: 0.0444, Val Loss: 0.0873\n",
      "Epoch [8/50], Train Loss: 0.0436, Val Loss: 0.0790\n",
      "Epoch [9/50], Train Loss: 0.0416, Val Loss: 0.0717\n",
      "Epoch [10/50], Train Loss: 0.0392, Val Loss: 0.0616\n",
      "Epoch [11/50], Train Loss: 0.0382, Val Loss: 0.0514\n",
      "Epoch [12/50], Train Loss: 0.0364, Val Loss: 0.0388\n",
      "Epoch [13/50], Train Loss: 0.0354, Val Loss: 0.0257\n",
      "Epoch [14/50], Train Loss: 0.0324, Val Loss: 0.0123\n",
      "Epoch [15/50], Train Loss: 0.0303, Val Loss: 0.0085\n",
      "Epoch [16/50], Train Loss: 0.0270, Val Loss: 0.0066\n",
      "Epoch [17/50], Train Loss: 0.0238, Val Loss: 0.0116\n",
      "Epoch [18/50], Train Loss: 0.0199, Val Loss: 0.0275\n",
      "Epoch [19/50], Train Loss: 0.0165, Val Loss: 0.0302\n",
      "Epoch [20/50], Train Loss: 0.0162, Val Loss: 0.0272\n",
      "Epoch [21/50], Train Loss: 0.0158, Val Loss: 0.0310\n",
      "Early stopping triggered.\n",
      "Best Parameters: (0.0005, 'adam', 64, 1, 0.5), Best Validation Loss: 0.0017\n",
      "Best model loaded.\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transform to PyTorch Tensor\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "# LSTM Model with Dropout\n",
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
    "        super(MyLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out[:, -1, :])  # Dropout on the last hidden state\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.005, 0.001, 0.0005, 0.0001],\n",
    "    \"optimizer\": [\"adam\", \"sgd\", \"adamw\"],\n",
    "    \"hidden_size\": [16, 32, 64, 128],\n",
    "    \"num_layers\": [1, 2, 3],\n",
    "    \"dropout\": [0.0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Generate all combinations of hyperparameters\n",
    "param_combinations = list(product(*param_grid.values()))\n",
    "best_val_loss = float(\"inf\")\n",
    "best_params = None\n",
    "\n",
    "# Grid Search\n",
    "for params in param_combinations:\n",
    "    learning_rate, optimizer_name, hidden_size, num_layers, dropout = params\n",
    "\n",
    "    print(f\"Testing parameters: lr={learning_rate}, optimizer={optimizer_name}, hidden_size={hidden_size}, num_layers={num_layers}, dropout={dropout}\")\n",
    "\n",
    "    # Initialize model\n",
    "    model = MyLSTM(input_size=5, hidden_size=hidden_size, num_layers=num_layers, output_size=5, dropout=dropout).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Initialize optimizer\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Early Stopping\n",
    "    patience = 5\n",
    "    early_stop_counter = 0\n",
    "    best_model_val_loss = float(\"inf\")\n",
    "\n",
    "    # Training Loop\n",
    "    for epoch in range(50):  # Max epochs\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i in range(0, len(X_train), 32):  # Batch size = 32\n",
    "            x_batch = X_train[i:i+32]\n",
    "            y_batch = y_train[i:i+32]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss /= len(X_train) / 32  # Average train loss\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val).item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/50], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if val_loss < best_model_val_loss:\n",
    "            best_model_val_loss = val_loss\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # Update best parameters if current combination is better\n",
    "    if best_model_val_loss < best_val_loss:\n",
    "        best_val_loss = best_model_val_loss\n",
    "        best_params = params\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "print(f\"Best Parameters: {best_params}, Best Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "# Load Best Model\n",
    "model = MyLSTM(\n",
    "    input_size=5,\n",
    "    hidden_size=best_params[2],\n",
    "    num_layers=best_params[3],\n",
    "    output_size=5,\n",
    "    dropout=best_params[4]\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "print(\"Best model loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the best parameters is: Best Parameters: (lr = 0.0005, optimizer = 'adam', hidden_size:64, num_layers = 1, best_dropout = 0.5) with the Validation Loss: 0.0017\n",
    "\n",
    "Next step, I will used this best model to assess the model performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open - MSE: 0.0013, MAE: 0.0317, R²: 0.7000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/IAAAIjCAYAAACgdyAGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADsN0lEQVR4nOzdd3gUVRcG8HfTQxISSoDQQkINvQkCUqUjUkTqJ01AEJCOgHRUQAFBQECRrnREEAQBQXpv0kPovSeQQNrO98dxstlkk+wm25K8v+fZZyazszN3N5vNnrnnnqtRFEUBEREREREREaULDrZuABEREREREREZj4E8ERERERERUTrCQJ6IiIiIiIgoHWEgT0RERERERJSOMJAnIiIiIiIiSkcYyBMRERERERGlIwzkiYiIiIiIiNIRBvJERERERERE6QgDeSIiIiIiIqJ0hIE8ERGRhRQqVAhdu3aN+3nPnj3QaDTYs2ePzdqUUMI2EhERkf1jIE9ERBnSkiVLoNFo4m5ubm4oVqwY+vXrh4cPH9q6eSbZunUrxo8fb+tmWESdOnX0fk9J3ezl+R84cACtWrVC7ty54erqikKFCuGTTz7BrVu3bN00IiLKRJxs3QAiIiJLmjhxIgICAvDmzRvs378f8+bNw9atW3Hu3DlkyZLFqm2pVasWXr9+DRcXF5Met3XrVsydO9dugllz+uKLL9CjR4+4n48dO4bvv/8eo0aNQlBQUNz2smXL2qJ5embPno0BAwYgMDAQ/fv3h5+fHy5evIiFCxdi9erV2Lp1K6pXr27rZhIRUSbAQJ6IiDK0Jk2aoHLlygCAHj16IEeOHJgxYwZ+//13dOjQweBjwsPD4eHhYfa2ODg4wM3NzezHTc8aNGig97Obmxu+//57NGjQAHXq1EnycZb6HSXlwIEDGDhwIN555x1s27ZN7yJQnz59UKNGDbRp0wbnz59HtmzZrNYuIiLKnJhaT0REmUq9evUAANevXwcAdO3aFZ6enggJCUHTpk3h5eWFTp06AQC0Wi1mzpyJUqVKwc3NDblz58Ynn3yC58+f6x1TURR8+eWXyJ8/P7JkyYK6devi/Pnzic6d1Bj5I0eOoGnTpsiWLRs8PDxQtmxZzJo1K659c+fOBQC9VHOVuduYUHR0NLJnz45u3bolui8sLAxubm4YOnRo3LbZs2ejVKlSyJIlC7Jly4bKlSvj119/TfE8yRk/fjw0Gg0uXLiAjh07Ilu2bHjnnXcASGq+oYC/a9euKFSokN42Y18rQyZNmgSNRoOlS5cmyuQoXLgwvvnmG9y/fx8LFizQa4OnpyeuXbuGRo0awcPDA3nz5sXEiROhKEqq2laoUCG899572L9/P6pUqQI3NzcEBgZi2bJlKT4HIiLKOBjIExFRphISEgIAyJEjR9y2mJgYNGrUCLly5cK0adPwwQcfAAA++eQTDBs2DDVq1MCsWbPQrVs3/PLLL2jUqBGio6PjHj927FiMGTMG5cqVw7fffovAwEA0bNgQ4eHhKbZnx44dqFWrFi5cuIABAwZg+vTpqFu3Lv7444+4Nqi91suXL4+7qSzdRmdnZ7Rq1QobN25EVFSU3n0bN25EZGQk2rdvDwD46aef8Nlnn6FkyZKYOXMmJkyYgPLly+PIkSMpvg7G+PDDDxEREYGvv/4aPXv2NPnxxr5WCUVERGDXrl2oWbMmAgICDO7Trl07uLq6xv3eVLGxsWjcuDFy586Nb775BpUqVcK4ceMwbty4VLft6tWraNOmDRo0aIDp06cjW7Zs6Nq1q1EXZoiIKINQiIiIMqDFixcrAJSdO3cqjx8/Vm7fvq2sWrVKyZEjh+Lu7q7cuXNHURRF6dKliwJAGTFihN7j9+3bpwBQfvnlF73t27Zt09v+6NEjxcXFRWnWrJmi1Wrj9hs1apQCQOnSpUvctt27dysAlN27dyuKoigxMTFKQECA4u/vrzx//lzvPPGP1bdvX8XQv2xLtNGQ7du3KwCUzZs3621v2rSpEhgYGPdzixYtlFKlSiV7rJSsXbtW7zVSFEUZN26cAkDp0KFDov1r166t1K5dO9H2Ll26KP7+/nE/G/taGXL69GkFgDJgwIBk2162bFkle/bsem0AoPTv3z9um1arVZo1a6a4uLgojx8/Nrlt/v7+CgBl7969cdsePXqkuLq6KkOGDEm2fURElHGwR56IiDK0+vXrw9fXFwUKFED79u3h6emJ3377Dfny5dPbr0+fPno/r127Ft7e3mjQoAGePHkSd6tUqRI8PT2xe/duAMDOnTsRFRWF/v3766W8Dxw4MMW2nTp1CtevX8fAgQPh4+Ojd1/8YyXFGm0EZDhCzpw5sXr16rhtz58/x44dO9CuXbu4bT4+Prhz5w6OHTtm1HFN1bt371Q/1tjXypCXL18CALy8vJI9h5eXF8LCwhJt79evX9y6RqNBv379EBUVhZ07d6aqbSVLlkTNmjXjfvb19UXx4sVx7dq1lF8IIiLKEFjsjoiIMrS5c+eiWLFicHJyQu7cuVG8eHE4OOhfx3ZyckL+/Pn1tgUHByM0NBS5cuUyeNxHjx4BAG7evAkAKFq0qN79vr6+KRY9U9P8S5cubfwTsnIbAXl9PvjgA/z666+IjIyEq6srNmzYgOjoaL1A/vPPP8fOnTtRpUoVFClSBA0bNkTHjh1Ro0aNVD2/hJJKazeGsa+VIWoArwb0SXn58mWiYN/BwQGBgYF624oVKwYAuHHjRqraVrBgwUT7ZMuWzaix/kRElDEwkCciogytSpUqcVXrk+Lq6poouNdqtciVKxd++eUXg4/x9fU1WxtTy5ptbN++PRYsWIA///wTLVu2xJo1a1CiRAmUK1cubp+goCBcvnwZf/zxB7Zt24b169fjhx9+wNixYzFhwoQ0t8Hd3T3RNo1Gk6hwHCBj0+NLy2tVpEgRODk54ezZs0nuExkZicuXL6f4XjPE1LY5Ojoa3M/Q60BERBkTA3kiIiIDChcujJ07d6JGjRoGA0iVv78/AOlVjd/z+vjx4xR7SAsXLgwAOHfuHOrXr5/kfkml2VujjapatWrBz88Pq1evxjvvvIO///4bX3zxRaL9PDw80K5dO7Rr1w5RUVFo3bo1vvrqK4wcOdIiU+9ly5bNYEq5moWgMva1MsTDwwN169bF33//jZs3b8a9nvGtWbMGkZGReO+99/S2a7VaXLt2La4XHgCuXLkCAHFV9dPSNiIiypw4Rp6IiMiAtm3bIjY2FpMmTUp0X0xMDF68eAFAxuA7Oztj9uzZej2iM2fOTPEcFStWREBAAGbOnBl3PFX8Y6nzpSfcxxptVDk4OKBNmzbYvHkzli9fjpiYGL20egB4+vSp3s8uLi4oWbIkFEVJtip8WhQuXBiXLl3C48eP47adOXMGBw4c0NvP2NcqKaNHj4aiKOjatStev36td9/169cxfPhw+Pn54ZNPPkn02Dlz5sStK4qCOXPmwNnZGe+++65Z2kZERJkPe+SJiIgMqF27Nj755BNMnjwZp0+fRsOGDeHs7Izg4GCsXbsWs2bNQps2beDr64uhQ4di8uTJeO+999C0aVOcOnUKf/75J3LmzJnsORwcHDBv3jw0b94c5cuXR7du3eDn54dLly7h/Pnz2L59OwCgUqVKAIDPPvsMjRo1gqOjI9q3b2+VNsbXrl07zJ49G+PGjUOZMmUQFBSkd3/Dhg2RJ08e1KhRA7lz58bFixcxZ84cNGvWLMVCcanVvXt3zJgxA40aNcLHH3+MR48eYf78+ShVqpRe4TljX6uk1KpVC9OmTcPgwYNRtmxZdO3aNe539dNPP0Gr1WLr1q2Jag64ublh27Zt6NKlC6pWrYo///wTW7ZswahRo+JS5tPaNiIiyoRsVzCfiIjIctTp544dO5bsfl26dFE8PDySvP/HH39UKlWqpLi7uyteXl5KmTJllOHDhyv37t2L2yc2NlaZMGGC4ufnp7i7uyt16tRRzp07p/j7+yc7/Zxq//79SoMGDRQvLy/Fw8NDKVu2rDJ79uy4+2NiYpT+/fsrvr6+ikajSTQVnTnbmBytVqsUKFBAAaB8+eWXie5fsGCBUqtWLSVHjhyKq6urUrhwYWXYsGFKaGioUcdXlOSnn1Ona0toxYoVSmBgoOLi4qKUL19e2b59e6Lp51TGvFbJ2bt3r9KiRQslZ86cirOzs1KwYEGlZ8+eyo0bNxLtq763QkJClIYNGypZsmRRcufOrYwbN06JjY1NVdv8/f2VZs2aJXpsUtPwERFRxqRRFFZGISIiIjK3rl27Yt26dXj16pWtm0JERBkMx8gTERERERERpSMM5ImIiIiIiIjSEQbyREREREREROkIx8gTERERERERpSPskSciIiIiIiJKRxjIExEREREREaUjTrZugD3SarW4d+8evLy8oNFobN0cIiIiIiIiyuAURcHLly+RN29eODgk3+fOQN6Ae/fuoUCBArZuBhEREREREWUyt2/fRv78+ZPdh4G8AV5eXgDkBcyaNauNW0NEREREREQZXVhYGAoUKBAXjyaHgbwBajp91qxZGcgTERERERGR1RgzvJvF7oiIiIiIiIjSEQbyREREREREROkIA3kiIiIiIiKidIRj5FNJURTExMQgNjbW1k2hDMzR0RFOTk6cBpGIiIiIiOIwkE+FqKgo3L9/HxEREbZuCmUCWbJkgZ+fH1xcXGzdFCIiIiIisgMM5E2k1Wpx/fp1ODo6Im/evHBxcWFvKVmEoiiIiorC48ePcf36dRQtWhQODhwNQ0RERESU2TGQN1FUVBS0Wi0KFCiALFmy2Lo5lMG5u7vD2dkZN2/eRFRUFNzc3GzdJCIiIiIisjF276USe0bJWvheIyIiIiKi+BghEBEREREREaUjDOSJiIiIiIiI0hEG8kRERERERETpCAP5TECj0SR7Gz9+vFXbc/78ebRt2xa+vr5wdXVFsWLFMHbsWE7nR0REREREZARWrc8E7t+/H7e+evVqjB07FpcvX47b5unpGbeuKApiY2Ph5GSZt8bhw4dRv3591K9fH1u2bEHu3Llx9OhRDBkyBLt27cLu3bs5XzoREREREVEy2CNvBooChIdb/6YoxrUvT548cTdvb29oNJq4ny9dugQvLy/8+eefqFSpElxdXbF//3507doVLVu21DvOwIEDUadOnbiftVotJk+ejICAALi7u6NcuXJYt25dMq+Tgo8//hhBQUHYsGEDqlSpAn9/f3z44YfYvHkzDh06hO+++y5uf41Gg3nz5qFJkyZwd3dHYGBgouPfvn0bbdu2hY+PD7Jnz44WLVrgxo0bcferz2PatGnw8/NDjhw50LdvX0RHRxv34hEREREREdkZmwbye/fuRfPmzZE3b15oNBps3Lgxxcfs2bMHFStWhKurK4oUKYIlS5Yk2mfu3LkoVKgQ3NzcULVqVRw9etT8jY8nIgLw9LT+zZyZ6CNGjMCUKVNw8eJFlC1b1qjHTJ48GcuWLcP8+fNx/vx5DBo0CP/73//wzz//GNz/9OnTuHDhAgYPHpxoSrVy5cqhfv36WLlypd72MWPG4IMPPsCZM2fQqVMntG/fHhcvXgQAREdHo1GjRvDy8sK+fftw4MABeHp6onHjxoiKioo7xu7duxESEoLdu3dj6dKlWLJkicH3DRERERERUXpg00A+PDwc5cqVw9y5c43a//r162jWrBnq1q2L06dPY+DAgejRowe2b98et8/q1asxePBgjBs3DidPnkS5cuXQqFEjPHr0yFJPI0OYOHEiGjRogMKFCyN79uwp7h8ZGYmvv/4aixYtQqNGjRAYGIiuXbvif//7HxYsWGDwMVeuXAEABAUFGbw/KCgobh/Vhx9+iB49eqBYsWKYNGkSKleujNmzZwOQ37VWq8XChQtRpkwZBAUFYfHixbh16xb27NkTd4xs2bJhzpw5KFGiBN577z00a9YMu3btMuZlISIiIiIisjs2HSPfpEkTNGnSxOj958+fj4CAAEyfPh2ABH779+/Hd999h0aNGgEAZsyYgZ49e6Jbt25xj9myZQsWLVqEESNGmP9JAMiSBXj1yiKHTvG85lK5cmWT9r969SoiIiLQoEEDve1RUVGoUKFCso9VjB0TAKBatWqJfj59+jQA4MyZM7h69Sq8vLz09nnz5g1CQkLifi5VqhQcHR3jfvbz88O///5rdBuIiIiIiMj2Hj8GHj4ESpe2dUtsL10Vuzt06BDq16+vt61Ro0YYOHAgAAkiT5w4gZEjR8bd7+DggPr16+PQoUNJHjcyMhKRkZFxP4eFhZnULo0G8PAw6SF2xyPBE3BwcEgUcMcfV/7qvysXW7ZsQb58+fT2c3V1NXiOYsWKAQAuXrxoMNi/ePFi3D7GePXqFSpVqoRffvkl0X2+vr5x687Oznr3aTQaaLVao89DRERERES216oVcPAg8NdfQIKwMNNJV8XuHjx4gNy5c+tty507N8LCwvD69Ws8efIEsbGxBvd58OBBksedPHkyvL29424FChSwSPvTE19fX71q9wDiesIBoGTJknB1dcWtW7dQpEgRvVtSr1/58uVRokQJfPfdd4kC6TNnzmDnzp3o0KGD3vbDhw8n+llNza9YsSKCg4ORK1euRG3w9vZO7VMnIiIiIiI7ExoqQbyiAAMGADExtm6RbaWrQN5SRo4cidDQ0Ljb7du3bd0km6tXrx6OHz+OZcuWITg4GOPGjcO5c+fi7vfy8sLQoUMxaNAgLF26FCEhITh58iRmz56NpUuXGjymRqPBzz//jAsXLuCDDz7A0aNHcevWLaxduxbNmzdHtWrV4rIrVGvXrsWiRYtw5coVjBs3DkePHkW/fv0AAJ06dULOnDnRokUL7Nu3D9evX8eePXvw2Wef4c6dOxZ7bYiIiIiIyLqOHdPN2nXhAjBvnm3bY2vpKpDPkycPHj58qLft4cOHyJo1K9zd3ZEzZ044Ojoa3CdPnjxJHtfV1RVZs2bVu2V2jRo1wpgxYzB8+HC89dZbePnyJTp37qy3z6RJkzBmzBhMnjwZQUFBaNy4MbZs2YKAgIAkj1u9enUcPnwYjo6OaNKkCYoUKYKRI0eiS5cu2LFjR6K0/AkTJmDVqlUoW7Ysli1bhpUrV6JkyZIAgCxZsmDv3r0oWLAgWrdujaCgIHz88cd48+YNf4dERERERBmImqir1uUeOxZ48sR27bE1jWJK5TEL0mg0+O233xLNXR7f559/jq1bt+oVKuvYsSOePXuGbdu2AQCqVq2KKlWqxFU212q1KFiwIPr162d0sbuwsDB4e3sjNDQ0UUD45s0bXL9+HQEBAXBzczPxWZIpjHlPZAZ8zxERERFRZvfee8CWLcB33wGLFwNnzwKffgoYOQFaupBcHJqQTXvkX716hdOnT8eNvb5+/TpOnz6NW7duAZCU9/i9wL1798a1a9cwfPhwXLp0CT/88APWrFmDQYMGxe0zePBg/PTTT1i6dCkuXryIPn36IDw8PK6KPREREREREaUfiqLrka9RA5g5U9bnzwcy62RUNq1af/z4cdStWzfu58GDBwMAunTpgiVLluD+/ftxQT0ABAQEYMuWLRg0aBBmzZqF/PnzY+HChXFTzwFAu3bt8PjxY4wdOxYPHjxA+fLlsW3btkQF8IiIiIiIiMj+hYQAT58Crq5AuXKAiwvwwQfA+vVS+G7XLplJLDOxm9R6e8LUerInfM8RERERUWa2fDnQuTNQvTpw4IBsu3EDKFECiIyUgL51a5s20SzSTWo9ERERERERUXLUtPq339ZtK1QIGDpU1n/4wepNsjkG8kRERERERGS3DAXyAFC/viwz48zTDOSJiIiIiIjILkVEAGfOyHq1avr3qWXQEsw+nikwkCciIiIiIiK7dOIEEBsL5MsH5M+vf58ayL94IWPlMxMG8kRERERERGSXkkqrB4Bs2QBnZ1l/9Mh6bbIHDOSJiIiIiIjILiUXyGs0QK5csp7Z0usZyJPZde3aFS1btoz7uU6dOhg4cKDV27Fnzx5oNBq8ePHC6ucmIiIiIqK0URTg0CFZNxTIA5l3nDwD+Uyia9eu0Gg00Gg0cHFxQZEiRTBx4kTExMRY/NwbNmzApEmTjNrXFsH3wYMH0bRpU2TLlg1ubm4oU6YMZsyYgdjYWKu1gYiIiIiI9N2+Ddy/Dzg5ARUrGt6HPfKU4TVu3Bj3799HcHAwhgwZgvHjx+Pbb781uG9UVJTZzps9e3Z4eXmZ7Xjm9Ntvv6F27drInz8/du/ejUuXLmHAgAH48ssv0b59eyiKYusmEhERERFlSmpafblyQJYshvdhjzylnqIA4eHWv5kYZLq6uiJPnjzw9/dHnz59UL9+fWzatAmALh3+q6++Qt68eVG8eHEAwO3bt9G2bVv4+Pgge/bsaNGiBW7cuBF3zNjYWAwePBg+Pj7IkSMHhg8fnij4TZhaHxkZic8//xwFChSAq6srihQpgp9//hk3btxA3bp1AQDZsmWDRqNB165dAQBarRaTJ09GQEAA3N3dUa5cOaxbt07vPFu3bkWxYsXg7u6OunXr6rXTkPDwcPTs2RPvv/8+fvzxR5QvXx6FChVCjx49sHTpUqxbtw5r1qwBANy4cQMajQarVq1C9erV4ebmhtKlS+Off/7RO+a5c+fQpEkTeHp6Infu3Pjoo4/w5MkTvdfis88+w/Dhw5E9e3bkyZMH48ePT7adRERERESZkRrIJ5x2Lj4G8pR6ERGAp6f1bxERaWq2u7u7Xs/7rl27cPnyZezYsQN//PEHoqOj0ahRI3h5eWHfvn04cOAAPD090bhx47jHTZ8+HUuWLMGiRYuwf/9+PHv2DL/99luy5+3cuTNWrlyJ77//HhcvXsSCBQvg6emJAgUKYP369QCAy5cv4/79+5g1axYAYPLkyVi2bBnmz5+P8+fPY9CgQfjf//4XF0jfvn0brVu3RvPmzXH69Gn06NEDI0aMSLYdf/31F54+fYqhQ4cmuq958+YoVqwYVq5cqbd92LBhGDJkCE6dOoVq1aqhefPmePr0KQDgxYsXqFevHipUqIDjx49j27ZtePjwIdq2bat3jKVLl8LDwwNHjhzBN998g4kTJ2LHjh3JtpWIiIiIKLNJrtCdKrMG8k62bgBZn6Io2LVrF7Zv347+/fvHbffw8MDChQvh4uICAFixYgW0Wi0WLlwIjUYDAFi8eDF8fHywZ88eNGzYEDNnzsTIkSPRunVrAMD8+fOxffv2JM995coVrFmzBjt27ED9+vUBAIGBgXH3Z8+eHQCQK1cu+Pj4AJAe/K+//ho7d+5Etf8uxwUGBmL//v1YsGABateujXnz5qFw4cKYPn06AKB48eL4999/MXXq1GTbAgBBQUEG7y9RokTcPqp+/frhgw8+AADMmzcP27Ztw88//4zhw4djzpw5qFChAr7++uu4/RctWoQCBQrgypUrKFasGACgbNmyGDduHACgaNGimDNnDnbt2oUGDRok2VYiIiIioswkMhI4eVLWGcgnxkDeHLJkAV69ss15TfDHH3/A09MT0dHR0Gq16Nixo15ad5kyZeKCeAA4c+YMrl69mmh8+5s3bxASEoLQ0FDcv38fVatWjbvPyckJlStXTnJs+enTp+Ho6IjatWsb3e6rV68iIiIiUaAbFRWFChUqAAAuXryo1w4AcUF/SkwZBx//mOpzvXjxIgB5vXbv3g1PT89EjwsJCdEL5OPz8/PDo8w28SURERERUTLOnJFgPmdOIF6/XyIM5Cn1NBrAw8PWrUhR3bp1MW/ePLi4uCBv3rxwctL/9XskeA6vXr1CpUqV8MsvvyQ6lq+vb6ra4O7ubvJjXv13kWTLli3Ily+f3n2urq6pageAuMD64sWLqF69eqL7L168iJIlS5rUzubNmxvMAvDz84tbd3Z21rtPo9FAq9UafR4iIiIioozuwAFZvv22hFtJUQP5zNYvxjHymYiHhweKFCmCggULJgriDalYsSKCg4ORK1cuFClSRO/m7e0Nb29v+Pn54ciRI3GPiYmJwYkTJ5I8ZpkyZaDVahMViVOpGQHxp34rWbIkXF1dcevWrUTtKFCgAABJjz969KjesQ6rg2qS0LBhQ2TPnj0uHT++TZs2ITg4GB06dEjymOpzVVPzK1asiPPnz6NQoUKJ2pnwIgkRERERESVNDRdq1Up+PzWQf/oUsMLM2naDgTwlqVOnTsiZMydatGiBffv24fr169izZw8+++wz3LlzBwAwYMAATJkyBRs3bsSlS5fw6aefJjsHfKFChdClSxd0794dGzdujDumWh3e398fGo0Gf/zxBx4/foxXr17By8sLQ4cOxaBBg7B06VKEhITg5MmTmD17NpYuXQoA6N27N4KDgzFs2DBcvnwZv/76K5YsWZLs8/Pw8MCCBQvw+++/o1evXjh79ixu3LiBn3/+GV27dkWbNm0SFaqbO3cufvvtN1y6dAl9+/bF8+fP0b17dwBA37598ezZM3To0AHHjh1DSEgItm/fjm7dunFOeiIiIiIiI2m1wL59sp7SiNwcOQAHB5nQ6/Fjy7fNXjCQpyRlyZIFe/fuRcGCBdG6dWsEBQXh448/xps3b5A1a1YAwJAhQ/DRRx+hS5cuqFatGry8vNCqVatkjztv3jy0adMGn376KUqUKIGePXsiPDwcAJAvXz5MmDABI0aMQO7cudGvXz8AwKRJkzBmzBhMnjwZQUFBaNy4MbZs2YKAgAAAQMGCBbF+/Xps3LgR5cqVw/z58/WKziWlTZs22L17N27duoWaNWuiePHi+O677/DFF19g1apVcUX+VFOmTMGUKVNQrlw57N+/H5s2bULOnDkBAHnz5sWBAwcQGxuLhg0bokyZMhg4cCB8fHzg4MA/NSIiIiIiY5w7Bzx7JqOXK1ZMfl9HR0Ad9ZuZxslrFFMqfWUSYWFh8Pb2RmhoaFzAqnrz5g2uX7+OgIAAuLm52aiFZG03btxAQEAATp06hfLly1v13HzPEREREVFmMns28NlnQMOGQDITYsUpVw44exbYtg1o1Mjy7bOU5OLQhNhNSERERERERHZDHR9v7ERXmbFyPQN5IiIiIiIisguKAuzdK+vGBvK5cskyMwXynH6OyAiFChUyab55IiIiIiIy3aVLUrTOzQ146y3jHsMeeSIiIiIiIiIbUdPqq1UD/puZOkUM5Mlo7J0la+F7jYiIiIgyC1PHxwMM5MkIzs7OAICIiAgbt4QyC/W9pr73iIiIiIgyIkVhIG8sjpE3kaOjI3x8fPDo0SMAMtd6wrnGicxBURRERETg0aNH8PHxgaOjo62bRERERERkMSEhwP37klJftarxj2MgT0bJkycPAMQF80SW5OPjE/eeIyIiIiLKqNTe+KpVAXd34x+nBvKPHwOxsUBm6P9iIJ8KGo0Gfn5+yJUrF6Kjo23dHMrAnJ2d2RNPRERERJmCGsjXqmXa43x9ZanVAs+e6X7OyBjIp4GjoyODLCIiIiIiIjNIzfh4AHB2BnLkAJ4+lfT6zBDIs9gdERERERER2dSNG8CtW4CTE1C9uumPz2zj5BnIExERERERkU2pvfGVKwMeHqY/noE8ERERERERkRXt3StLU8fHqxjIExEREREREVnR/v2yNHV8vIqBPBEREREREZGVxMYC167JetmyqTtGrlyyZCBPREREREREZGH37wMxMVLozs8vdcdgjzwRERERERGRldy8Kcv8+YHUzu7NQJ6IiIiIiIjISm7dkmXBgqk/BgN5IiIiIiIiIitRe+T9/VN/DDWQf/QIUJS0t8neMZAnIiIiIiIimzFHj7xa7C46Gnj+PO1tsncM5ImIiIiIiMhmzNEj7+YGeHvLemZIr2cgT0RERERERDZjjh55QD+9PqNjIE9EREREREQ2oSjm6ZEHMlfBOwbyREREREREZBMvXgAvX8p6gQJpOxYDeSIiIiIiIiILU9Pqc+YEPDzSdiwG8kREREREREQWZq60eoCBPBERERGRUSIibN0CIkrPzFXoDmAgT0RERESUogkTgKxZgf37bd0SIkqvzNkjr84lz0CeiIiIiCgJW7YAsbHAtm22bgkRpVfskU8dBvJEREREZDJFAS5flvV//7VtW4go/bLUGHlFSfvx7BkDeSIiIiIy2cOHQFiYrJ87Z9u2EFH6ZYke+TdvdFPaZVQM5ImIiIjIZGpvPABcuwa8emW7thBR+hQZCdy/L+vm6JH38NBNYZfR0+sZyBMRERGRyeIH8gBw4YJt2kFE6dedO7J0d5d55M0hs4yTZyBPRERERCZLGMhznDwRmUodH1+wIKDRmOeYfn6yfPDAPMezVwzkiYiIiMhkaiCfNassOU6eiExlzvHxKjWQv3fPfMe0RwzkiYiIiMhkaiDfvLksGcgTkanMWbFelTevLNWx9xkVA3kiIiIiMklUFHD9uqx/8IEsmVpPRKaKn1pvLmogzx55IiIiIqJ4QkKA2FjA0xNo0EC2PXwIPH5s23YRUfqiptZbokeegTwRERERUTxqWn2xYhLMBwbKz0yvJyJTsEc+9RjIExEREZFJ1EC+eHFZli4tSwbyRGQsrRa4fVvW2SNvOgbyRERERGSShIF8mTKy5Dh5IjLWo0dAZKRMO5c/v/mOq1atf/ECeP3afMe1NzYP5OfOnYtChQrBzc0NVatWxdGjR5PcNzo6GhMnTkThwoXh5uaGcuXKYdu2bXr7jB8/HhqNRu9WokQJSz8NIiIiokyDPfJElFbq+Pi8eQFnZ/Md19sbcHeX9Yxcud6mgfzq1asxePBgjBs3DidPnkS5cuXQqFEjPHr0yOD+o0ePxoIFCzB79mxcuHABvXv3RqtWrXDq1Cm9/UqVKoX79+/H3fbv32+Np0NERESUKVy5IsuEPfLnzgGKYps2EVH6Yomp5wDp4c8M6fU2DeRnzJiBnj17olu3bihZsiTmz5+PLFmyYNGiRQb3X758OUaNGoWmTZsiMDAQffr0QdOmTTF9+nS9/ZycnJAnT564W86cOa3xdIiIiIgyvGfPgCdPZL1YMd3S2Rl4+VLXy0ZElBz1s8Kche5UDOQtKCoqCidOnED9+vV1jXFwQP369XHo0CGDj4mMjISbm5veNnd390Q97sHBwcibNy8CAwPRqVMn3ErhP0pkZCTCwsL0bkRERESUmJpWnz8/4OEh687OgDqSkePkicgYluqRBxjIW9STJ08QGxuL3Llz623PnTs3Hjx4YPAxjRo1wowZMxAcHAytVosdO3Zgw4YNuB9v8EPVqlWxZMkSbNu2DfPmzcP169dRs2ZNvHz5Msm2TJ48Gd7e3nG3AgUKmOdJEhEREWUwCcfHqzhOnohMwR75tLF5sTtTzJo1C0WLFkWJEiXg4uKCfv36oVu3bnBw0D2NJk2a4MMPP0TZsmXRqFEjbN26FS9evMCaNWuSPO7IkSMRGhoad7utzoNARERERHqSCuTjj5MnIkqJJXvk1cr1DOQtIGfOnHB0dMTDhw/1tj98+BB58uQx+BhfX19s3LgR4eHhuHnzJi5dugRPT08EBgYmeR4fHx8UK1YMV69eTXIfV1dXZM2aVe9GRERERIml1CNvTGp9ZCQQG2vedhFR+mKNHnlWrbcAFxcXVKpUCbt27YrbptVqsWvXLlSrVi3Zx7q5uSFfvnyIiYnB+vXr0aJFiyT3ffXqFUJCQuCnXpYhIiIiolRLqUf+0iUgOjrpx4eFSXG82rUt0z4isn+vXknhTIBj5FPLpqn1gwcPxk8//YSlS5fi4sWL6NOnD8LDw9GtWzcAQOfOnTFy5Mi4/Y8cOYINGzbg2rVr2LdvHxo3bgytVovhw4fH7TN06FD8888/uHHjBg4ePIhWrVrB0dERHTp0sPrzIyIiIspIYmMBNckxYSBfsCDg6QlERQHBwUkf459/pCfuwAEgNNRybSUioSjAnDlApUrAvn22bo1Q0+q9vQFLJENnhkDeyZYnb9euHR4/foyxY8fiwYMHKF++PLZt2xZXAO/WrVt649/fvHmD0aNH49q1a/D09ETTpk2xfPly+Pj4xO1z584ddOjQAU+fPoWvry/eeecdHD58GL6+vtZ+ekREREQZyo0bEqi7uSVOh3VwAEqVAo4ckXHyJUsaPsbevbr1q1cluCAiy3jzBujTB1iyRH7+6CPg/HndjBMJ3b0LnDgBnDoFnD4tNwCoWhWoXh2oVg0oVw5wcUl9m6KjgcOHZd0SvfGALpAPC5Pef09Py5zHljSKoii2boS9CQsLg7e3N0JDQzlenoiIiOg/W7cCzZpJGv3Zs4nv79kTWLgQGD0amDTJ8DGqVAGOHZP1VauAdu0s116izOzePaB1a7m45uAAZMsGPH0KDBkCTJuWeP+pU4GRI6UHPzlZsgDDhsnfuZOR3cK7dgG//ioXCM6flwuCAPD++8Dvv5v2vIzl5SVB/JUrQNGiljmHuZkSh9q0R56IiIiI0o+kxserUpqC7uVL4ORJ3c/J1CImojQ4cgRo1UqKvWXLBqxeLT3hzZoBM2cCnToBFSro9l+zBhgxQtbLlpX7ypeXZUwMcOiQ3A4flrHtEyYA27YBK1YARYok35YVK4DOnfUvEHh7y7HVc1qCn58M87l/P/0E8qZgIE9ERERERkkpkFcL3p05Y/j+gwf1q9UzkCcyv5cvgcaNgRcvZLjL778DhQvLfW3bStDeq5cE5Y6OkiHTpYvcP2gQMGNG4mO++64sFUUuCvTuLRcLypcHZs0CuncHNJrEj1u+XI6tKHLudu0kgC9UyPD+5pQ3rwTyGXWcfLqaR56IiIiIbCelQL5SJcDZGbh+HbhwIfH9//wjS7W8EQN5IvM7e1aC+Dx5pBddDeIBCbq9vYHjx4G5c4E7d4AWLWQsfbNmwLffJn9sjQZo317OUbs2EB4O9OgBvPce8Ndf+hfqli3TBfGffAKsXCmp/gEBlg/igYxf8I6BPBEREREZJaVA3tsbaNRI1teuTXy/WuiuY0dZMpAnMj/1Ilq5cjJOPL48eWQsPAB88QXQtKmknpcuLWPYHR2NO0fBgjLufcoUuXi3dav87QcGAuPGyQWDrl0liO/dG/jhBxmnb00M5ImIiIgo0wsLky/8QNKBPCDps4Ck78YXEQEcPSrr3bvL8sEDKUZFROZz8aIsg4IM39+zp1Sgf/UK+PdfwNcX2LzZ9GngHB2Bzz+XyvZ9+0qmza1bwMSJwMCBEsT36SM9/9YO4gEG8kREREREcb3xuXNLz3tS3n9fpqa6cEGqU6uOHJFiW3nzAhUrAjlzyvaQEMu1mSgzUgP5pKaAdHAAFiyQnnQXF+C332TMemqVLCnz1N+/L+nz9etL6vxnn8l2WwTxAAN5IiIiIqK46ebUgnZJ8faWQluAfq+8Oj6+dm35kq9Wug4ONm87iTK7lHrkAUmlP3ZMxsrXqGGe87q5yfj5HTuAyEhJr7dVEA/oAnk1kyijYSBPRERERClSK9GXLZvyvvHT69Upp9Tx8bVqyVIN5DlOnsh8Xr0Cbt6U9eQCeUDG0Kd0YS61nJ0tc1xT+PnJkj3yRERERJRh7dol1eaTovbIlyuX8rGaNwdcXYFLl2RO+chIqZ4NSI88wECeyBLUITC+vkCOHLZti62pgfyrVzIlX0bDQJ6IiIgok9u9W8a1fvih4fsVxbQe+axZgSZNZH3NGknfffNGgosSJWQ7A3ki80tpfHxm4umpK+CXEXvlGcgTERERZXJLlsjyxAmZfzqhO3dku5NTyum6qvjp9er4+Fq1dPNHFy0qSwbyROajTj1n7N9pRpeRC94xkCciIiLKxCIigA0bdD8fO5Z4H7U3vkQJSZk3xnvvSfGrK1eAH3+UbWpaPaDrkb97V9pARGlnTKG7zISBPBERERFlSJs368/lfuRI4n3U8fHGpNWrvLyApk1lXS2+pRa6A4Ds2YFs2WT92jXjj0tESWMgry8jV65nIE9ERESUif3yiyzz5JGloUBe7ZE3ptBdfGp6PQD4+CSukM1x8kTmExWl+1viGHmRkSvXM5AnIiIiyqSePgX+/FPWv/5alocP66aMU6WmRx4AmjUD3N1lvWbNxHNKcy55IvMJDgZiYyUbRu2JzpSWLgXatQNu32ZqPRERERFlPOvWATExQPnyQMeOgIsL8OSJ/jR0r1/LOHfA9B55T0+gZUtZb9Qo8f3skSdLev3a1i2wrvhp9WpRyUzn1Cng44+lymadOijicgsAA3kiIiIiykDUtPqOHaWIXfny8vPhw7p9zp8HtFogZ05d+r0pfvgBWLUK+OSTxPcxkCdL+eMPwNsbmDjR1i2xnkw/Pj4mBujZU9ISNBrg2jXU/7IOCuAWA3kiIiIiyhhu3gT27ZPvux06yLa335Zl/HHyalp9uXKp6+Xz8ZEsVyenxPcxkCdLiIgA+vYFoqOB33+3dWusJ9PPIf/99zKHpre3fIgVLgy3+9exB3XgeOdmoiFD6R0DeSIiIqJMaOVKWdauDeTPL+tVq8oyfiCvFrozdXy8MdRA/vZt4M0b8x+fMqdvvgFuSUY1zp+XjtrMIFPPIX/9OjBmjKxPmwa89RawZw+0hYsgENexLbIOXv57w6ZNNDcG8kRERESZ0K+/yrJTJ902tUf+1CkgMlLW4/fIm5uvL5A1qxTXiz8unyi1btwApk7V/RwZmTkyPmJjgcuXZT3TBfKKAvTpI6kYtWvLGHkAyJ8fDv/swVWHogjADbg1qQOEhdm0qebEQJ6IiIgok/n3X7m5uABt2ui2BwTIWPioKOD0afl+bMkeeY2G6fVkXkOHSnZHnTpAlSqy7d9/bdokq7h5U563q6v8HWcqv/4KbN8uT/7HH/XHAOXLh56Fd+MyiuFms75y5TCDYCBPRERElMmoRe6aNZMx7CqNRpdef/gwcPcu8Pw54OhouV4+BvJkLrt2AevXy/v1+++BMmVke2YI5NW0+uLF5flnGk+fAgMHyvqYMUCxYol2cfLPh4o4icM1h1m3bRbGQJ6IiIgok9m+XZZt2ya+L37BO7U3vkQJwM3NMm1hIE/mEB0NfPaZrH/6qQTxmSmQz7QV62fPljkzS5UChhkO1PPmBSLgkeEq1xuoH0pEREREGVVMjO5Lv5p6HF/8gndqIGSJtHqVGsgHB1vuHJSxvHgBfPutjH93cwPc3YGQEOmVzpEDmDBB9mMgn8FFRgLz5sn6mDEyVsiAvHllef++ldplJQzkiYiIiDKRq1fl+6+HB1CoUOL7q1SJm4IZO3fKNksUulOxR55MNWIEsGCB4fu+/hrIlk3W1UD+2jXg1SvA09M67bOFTDn13KpVwKNHQL58QOvWSe6mBvLskSciIiKidOvcOVmWKgU4GBhk6e0tqfQXLwJ//y3brNEjf/OmFNlLolONCIDMbvDzz7L+ySeAs7MUeXv9GggM1BUsB2RWhDx5gAcPZBo6Ndsk/rGaN5de7HHjgNKlrfc8zElRMuHUc4oCzJol6/36yRshCX5+smQgT0RERETplhrIJxe0vP22rocPsGyPfJ48QJYsMnPUjRsGa1URxZk0SYaH1K8PzJ+f8v5lykgg/++/iQP5n3+WAP/8eSmS164dMH68FIxLT+7fl1nVHByAokVt3Ror2bdP5sl0dwd69kx21/z5JZjPkcNKbbMSFrsjIiIiykSMCeTjBzw5cuh6tCyBU9CRsa5cAZYtk/VJk4x7THLj5P/6S7ePokimdsmSQK9ekh2SXqgX3QoXlhnYMgW1N/5//0sxQn/7bemN//13K7TLihjIExEREWUiakCjBjiGqJXrAUmrjz8tsyWovYgM5Ck5EyYAsbEybWL892hykgrknz4Fjh+X9W3bpHO3eXNAqwV++sm43n57kenGx9+4AWzcKOsDBtiyJTbFQJ6IiIgok3j9WhcsJ9cjX6qUpLsDlk2rV7FHnlJy/jywcqWsT5xo/OPiB/KKotu+c6f8XKaMFEMrXx7YtElmMwOkaF54uFmabnGZbnz8nDlyxaV+ffmwyqQYyBMRERFlEpcuyfffHDmA3LmT3s/JCaheXdYrV7Z8uxjIU0rGj5fAu3VroGJF4x9XsqSMHX/yBHj4ULddTatv2FB//08+kaJ5Dx8Cc+emudlWcfq0LJPLsskwXr0CFi6U9YEDbdoUW2MgT0RERJRJxB8fn1K6/Lx5Esi0b2/5dnEueUrO6dPAunXynlXniDeWu7vu/aWm1ytK0oG8s7NUsAeAqVOliJw9i43VBfKVKtm0KdaxdCkQGirjcZo0sXVrbIqBPBEREVEmoQYyxkyzVaQI8OmngKOjZduknguQoa/R0ZY/H6UvamDdvn3qpohTp088e1aWFy8Cd+4Abm5AzZqJ9+/USaZgfPYMmDkzVU1GZKR1LkxdvixDZjw9M0HF+thYXZG7zz4zPH9mJpK5nz0RERFRJqL2yNtbCm7evBJUxcQAt27ZujVkT8LDgT/+kPUxY1J3jIQF79Te+Fq1pMc+IUdHXc//9OkS0JtCUYD33pOpFI8cSV2bjXXypCzLl88Ece2mTXJ1xMcH6NLF1q2xuYz+6yYiIiKi/xgz9ZwtODjI1FkAx8mTvlOnpK5DvnypL+aWVCCfMK0+vjZtpCc/LAyYNs20861cKcX0AGD3btMeayo1kDelbkC6pf4i+vQBvLxs2xY7wECeiIiIKBMIDQVu35Z1eyz0zIJ3ZMiJE7JMS9FFNZC/cEF6+PfskZ+TC+QdHHRz1c+aBTx6ZNy5Xr4Ehg7V/Wxo/npzyjSB/MGDcnNxAfr3t3Vr7AIDeSIiIqJMQO2Nz59fMlPtDQN5MkSd6z0thdwCA2U6xTdvpFba69eAn1/KmSnNmwNvvQVERACDB8vQj5RMnAjcvy9F8wDd350laLWSsQBkgkD+229l+dFH8ssjBvJEREREmYG9ptWr1EJdDOQpPjWQT0uPvIODLgvlu+9k2bBhyjM3aDTAlCmy/ssvUiQ9ufHyFy/qiuOp57l0yXIFHK9dk9R/N7cMPof8lSvA77/L+pAhtm2LHWEgT0RERJQJ2GuhOxV75CmhsDCpyg6kfWo19X2vvr+SS6uPr149mfrOw0PGvb/1FnD+fOL9FEUKqcfESE9+nz5SST4qynLV69VhB2XLAk5OljmHXZgxQ1dBMENfsTANA3kiIiKiTMCUqedsQQ3kr12TWaZs6dIlCdjUTkCyjVOnJH4rWBDIlSttx0p4Aat+feMf+8EHMjy7UCF5f779NrBqFfD8ubQPADZskEDf1VV64x0cdH9rlkqvzxTj4x89ApYskfVhw2zaFHvDQJ6IiIgog1MU+0+tz59f6lhFRemK8tnKqlWS0r18uW3bkdmZI61epc4lDwAVKph+YaBsWeDYMaBuXeDVK6BDByB7dsDbW+7r1Uv2Gz5cNwMDA3kzmDsXiIwEqlQBata0dWvsCgN5IiIiogzu4UPg6VPpJbTXzFRHRylKBtg+vf7iRVm+fGnbdmR25gzk4/fIN2qUumPkzAls3y7Buq+vbHv5UrJdnj2TzIERI3T7q4G8JSrXK0omCOQjIiSQB6Q3PqWiBpkMA3kiIiKiDE7tESxSBHB3t21bkmMv4+TVQD4szLbtyOzMGcj7+krWBwA0bpz64zg7A1OnSsZ3eLhMaffnn8DChcDff0t1fJV68cASPfK3bsnFAycn+82ySbOZM+UKZGAg0KqVrVtjdzJyWQQiIiIigv2Pj1fZQyAfGytFsgH2yNvS8+e690FaC92pVq6U+ge1apnneFmySIZLUlku6t9bSIh0LscP8tNK7Y0vXVrG5Wc4168DkybJ+oQJkrJDetgjT0RERJTB2fv4eJU9BPLXr8uQXICBvC2pgWpAgIxFN4d33gF69LBehnauXJIJoCjSc29OGTqtXlGA/v2BN2+kKEGnTrZukV1iIE9ERESUwTGQN56aVg8wtd6W1KnVzJFWb0uWSq9XA3lzZSvYlY0bgS1bZBzDDz9wbHwSGMgTERERZWBarW7ea3sP5IsWlWVIiLTbFuIH8i9f6qYXI+sy5/h4W0pr5fq//pLp0+O/L4EM3CP/6hXw2WeyPmwYUKKEbdtjxxjIExEREWVgN25IUS4XF12gbK8KFpTiXW/eAPfu2aYNly7p1mNjpS1kfRktkE9t5fqpU6VzukUL4MUL2Xb/PvDggcxCEX9avQxhwgTgzh2gUCHgiy9s3Rq7xkCeiIiIKAM7c0aWQUESJNszJycZEw0AwcG2aUPCnk+Ok7e+p0+lVgGQ/nuc05JaryjA6dOyHhwMdO4smSpqb3xQkHkL6Nncv/8C330n63PmZLAnZ34M5ImIiIgysEOHZFmlim3bYSxbjpNXlMSBPMfJW586Pr5oUcDHx6ZNSbOSJWV5755MF2eKO3fkMY6OUpl+82bg668zaFr9tWtAx46SBtOqFdCsma1bZPcYyBMREVG6cvaszKGc0Rw5AqxYYf4x2WogX62aeY9rKbYM5B88AEJDJWU5Rw7Zxh5568soafUAkDUr4O8v66b2yqu98aVKAfPmyfrYscDixbKeYQL5336TJ3PuHJAzJzBrlq1blC4wkCciIqJ04+ZN4K23gKpVZdx3RqEoQOvWwEcfAcuXm++4UVG6oIiBfMrU3vjChRnI21JGCuSB1KfXq4F8+fJAt25A797yWZFRhh0gKgoYOFA+/EJD5UPqxAmgQAFbtyxdYCBPRERE6cbWrfLd78EDYNEiW7fGfG7f1hV3GzJExgibw5kzUqwtWzagWDHzHNPS7CGQDwqSnlSAqfW2oAbyGWVqtdRWrj91Spbly8ty5kzg7bd196vb0w1FkQ+67duBadOAGjV0ve9DhwL//CMVL8koqS55EhUVhevXr6Nw4cJwsvfKKURERJQh7NihW58+XXqonJ1t1x5zUQMXAHjyBBgxAvjpp7QfV02rf/ttSRdPD+IH8opi3Smk4wfyak88e+St6+FDubCl0QAVKti6NeaR2sr18XvkARknv24d0LChVKtXLzbZJUWRQf7Hjulup04lLhSQLRuwdCnQvLlt2pmOmRyBR0REoH///li6dCkA4MqVKwgMDET//v2RL18+jBgxwuyNJCKizOXRI10KNZEqJgbYtUvWXV3lPbJmDdCpk23bZQ5qca/y5eXL+8KFQJcuwDvvpO246W18PCCzTjk4ABERknnh52e9c8cP5NV1BvLWpf4tFC9u54GqCeL3yBt7cerFC10Kfblyuu358gHnz5u9ieZx6xawc6fcdu+WP+CEHBwkPahMGbka0aULU+lTyeRrsyNHjsSZM2ewZ88euLm5xW2vX78+Vq9ebdbGERFR5qIoUuyraFGpsL1hg61bRPbk6FFJc86eXTe98NSp5i8OZwtq8NKrF/Dxx7LeuzcQHZ2246qBfPXqaTuONbm46IqDWTu9Xg3eS5QAvLxknYG8de3bJ8uMMj4ekPeTo6ME5+oQmpScPStLf3/5zLNbN28Cw4ZJcO7vLx9gK1dKEO/oKFchevQAFiyQ1KNXr+QPbc0aYPRoBvFpYHIgv3HjRsyZMwfvvPMONPEuJ5UqVQohISFmbRwREWUez54B7dpJsS91TOro0TITDREA/PWXLOvXB/r1Azw9JVX1zz9t2660UhT9McFTp0rh5vPngRkzUn/c+/flO7aDQ/qZek5VtKgsrRnIh4bKawZI4MUx8tan1UoMCADvvWfbtpiTq6uuRoWx6fUJ0+rtzqFDQNu2QGCgjHcPDpbAvVo1YMwYYM8e+eM5fVrGCfXqJR9w7u62bnmGYXIg//jxY+TKlSvR9vDwcL3AnoiIyFh//SWph2vXAk5O8h0gWza5aK9+qUsoJkbGUVLmoQbyDRrI++OTT+TnqVNt1yZzuHVLits5OUmmaY4c8r0YACZMAG7cSN1x1d740qV1vct2KyxMUnH/u3KnjpMPDrZeE9Te+Lx5AW9v9sjbwsGDcvHJyyvjDZk2teCd3Qby589LsF69uvzT1mrl6ur69XJF/uBBYOJEoHZtIEsWW7c2QzM5kK9cuTK2bNkS97MavC9cuBDV0tMALCIisgtbtgCNG0tPWPHiEnxMnCiZeoAEMgnTi6Oj5TH+/sC2bdZvM1nfixeSWg9IIA8AgwZJobu9e3VBa3qkptWXLg2ooxY7d5bvwa9fS0eWVmv6cdPF+HitVibFLlYMqFdPUnK0WotWrtdqJdZI+LkSf3w8wEDeFn75RZatW2e8GNDUKejsMpA/fx6oWxc4fFjGwHTvLmMAduyQX1pGKWqQTpgcyH/99dcYNWoU+vTpg5iYGMyaNQsNGzbE4sWL8dVXX1mijURElEE9fSpD5xRFCpadPKkbF9m/P+DrK1/kly3Tf9ywYVL0TFGAzz9PXZBD6YvaWVu8uG78dL58EvcB6btX3tBUWxqNDCl1c5PvyLNnm37cgwdlabeB/MGDkvPfvbuUKgckBWfsWIsG8osXy6xXvXvrb2cgb1tRUTJsGsgYBSwTUnvkV68G2reXzuxXrwzvGxWlC/jtJpC/eFEutj1+LBPY37wJ/Pyz7goFWZ3Jgfw777yD06dPIyYmBmXKlMFff/2FXLly4dChQ6iUiske586di0KFCsHNzQ1Vq1bFUfVyuwHR0dGYOHEiChcuDDc3N5QrVw7bDHTFmHJMIiKynf79pR5OUJBU6Y7fA+PpKVNwAcCkSfLFBgCWL9dNO+vuLp0B6pc/yrjUtPqGDfW3DxsmQe/vvwMXLli/Xeag9sgnLO5VvLguxf7zz02buioqSndcmwfy+/YBffrIVZd27YCWLSXdoEYNaWTWrPJEFyyQ/b/6CpVPLwQgqfXmrpOxc6csFy/Wf88kDOQ5Rt66tm+XzOw8eSRezGjq1JHEkzdvJJhv21YuVnfoIPUZ4rt4UTJGvL11Fy5t6vJl+aU8eiRXFnbskF8U2ZZiQ6tWrVJcXFyURYsWKefPn1d69uyp+Pj4KA8fPjS4//Dhw5W8efMqW7ZsUUJCQpQffvhBcXNzU06ePJnqYxoSGhqqAFBCQ0PT/ByJiMiwtWsVBVAUR0dFOXrU8D4REYri5yf7/fCDopw4oShubvLzmDGKMnGirBcrpijR0dZtP1lXYKD8rjdtSnxfixZy36hRVm9Wmmm1ipIjh7Tf0N+BVqsoTZvK/WXKKMrr18Yd9/BheUyOHHIMm7h1S1Hat5eGGLppNIrSo4eiPHige8yYMYoCKFpHR6WVx3YFUJS//jJvs4oW1TWhTRvd9sKFZdvff8vP6mfUO++Y9/xkWNu28noPGmTrllhObKyiHDmiKMOH695vgKIMHaq/35Ilsr12bZs0U9+VK7p/xGXLKsqTJ7ZuUYZmShxqciB/8+bNZG+mqFKlitK3b9+4n2NjY5W8efMqkydPNri/n5+fMmfOHL1trVu3Vjp16pTqYyqKorx580YJDQ2Nu92+fZuBPBGRGTx/Ll/OvvhC/3//gweKkjOnfC8YPTr5Y8yZI/vlzasoBQvKerNm8oUoLEx3nJ9/tuhTIRu6elV+x05O8jtP6Oef5f4aNazftrS6fl333JIK0h88UBRfX9OCnO++0/2tWN3r14ry5ZeKkiWLLmDv1k1Rvv1WUb7/XlEWLJBI5dy5xI/VahXlo48UBVAinL2UsjittG9vvqY9f65/HQFQlJMnpckODvLz/fuy77Zt8nO5cuY7PxkWGqq7SHv8uK1bYx1araL8+qs8Zy8vRXnxQnffwIGyfcAAmzVPnD0r/3wBRSlVSlEePbJxgzI+iwbyGo1GcXBwSPJmrMjISMXR0VH57bff9LZ37txZef/99w0+Jnv27MrChQv1tnXq1Enx9/dP9TEVRVHGjRunAEh0YyBPRJQ233+v+9Ls6Sk9pk+eKErLlrovyJGRyR/jzRtFKVBAd5yiReXLuGraNNlesKDsSxnPvHnyO65Vy/D9ISFyv7OzooSHG3/cM2cMx5LWtG6dtL1CheT327xZ9zewbZuinD6tKLNnK8qHH0q2whdf6Pe8q72bX35p2fYn8uKFopQsqWtsjRoSKZsiMlJR6tZVFEC5gYKKj0u48vSpeZq3a5c0q1AhRenYUdabNpV4BVAUHx/d63jwoGwLCDDPuSlpag908eI2zCCxgdhYRQkKkuf+7be67XXqyLbFi23WNEXZs0dRvL11QXz8zBmyGFMCeZPHyJ86dQonT56Mux05cgTz589HsWLFsHbtWqOP8+TJE8TGxiJ37tx623Pnzo0HDx4YfEyjRo0wY8YMBAcHQ6vVYseOHdiwYQPu/zfpZ2qOCQAjR45EaGho3O025zMiIjKLw4dl6eUlRX2+/hrInx/YuFGqjS9dKoVvk+PqCowdK+uenvJYHx/d/Z9+KtNF3bolU9VSxpPU+HhVQIC8r6Kjja9ef+0a8NZbMn78xQuzNDNV1HHsKZUZeu89XXG2xo1lmGr//lIw69o14KuvgFGjJHoGdK9D9eoWaXbSpk2Tgee5cgErVsj4+AoVTDuGiwuwfj0Uf3/44xZ6R81KchpKU8WvRzBhgkx7vXWr1OwCZHy8Opsyi91Zj1qtvlMn3eufGTg4AEOHyvrMmVLbQlHsoGL92rXygRsaCrzzjkwNkiC+ItszOZAvV66c3q1y5cro2bMnpk2bhu+//94SbYwza9YsFC1aFCVKlICLiwv69euHbt26wcHB5Kehx9XVFVmzZtW7ERFR2qmB/Lp1wG+/AeXKSaEfABg3Tn42RvfuwNy5UqSqZEn9+9zdZd55APjySyA83DxtJ/sQEyMzFAC6aecS0mikkBQA/POPccf96iv50vzypbw3bUWtWJ+w0J0h06fr3v+envI9e9IkCUgBYMoUmbrx7l3g9m0JEt56yzLtNujhQ+C772R93ry0RWXZskHz32xIIzAFG358YpYmxn+9ixQBunWTn9UCmmqhO4CBvLXcv6/7G8+I1epT0qkT4Ocnf7erVslF6Rcv5GJ3wv93VvH991KUMipKppT76y8ge3YbNIRSkrYIOJ7ixYvj2LFjRu+fM2dOODo64qE63ch/Hj58iDxJVEH09fXFxo0bER4ejps3b+LSpUvw9PREYGBgqo9JRESW8eiR9BRqNEDVqlKo+uRJqS7+ww9ShdtYDg7S8161quH7u3eXXtmHD4E5c8zSfLITR49K1fBs2ZLvta5dW5Z79qR8zGvXJBtE9euvaWpiqimK8T3ygMzqcOiQzNTw/LlU+R49WjJW1Ph5/Higa1dZL1tWAn6r+fpruZL21ltAq1ZpP16HDogpUx7eCMN7Z7+K66VMi4RT/Y0Zo58VVKKEbl0N5CMjdbNmkPmtWiVTiFarBvz3lT5TcXUFPvtM1qdNk/+TAFCqVMoZa2Y3ZQowYIB8OH36qUwJ4+5u5UaQsUwO5MPCwvRuoaGhuHTpEkaPHo2iRYsafRwXFxdUqlQJu9RLcAC0Wi127dqFainMk+Lm5oZ8+fIhJiYG69evR4sWLdJ8TCIiMq8jR2QZFCRT6AASkL//vsxE5eRkvnO5uEgAAwCTJ+umpE4oIkKCfrX3LSO7dw/44APJbk7P1LT6+vUlDTopao/8kSPA69fJH/Orr2RKMzXj+++/pVfQ2m7elOm2nJ2Nn4o5a1bZN+Hfz8CB8h0c0E2vZtWvPjduSC88IH+E5siPdnCA07SpAIC+mIvfZ15P0+GeP5eLOIAukC9YUH8+eUM98gB75S0pflp9ZvXJJ4CHh0wxqU45afW0+mXLgJEjZX3SJLkqntyHLtmeqQPwDRW702g0SsGCBZWDBw+adKxVq1Yprq6uypIlS5QLFy4ovXr1Unx8fJQH/xVT+Oijj5QRI0bE7X/48GFl/fr1SkhIiLJ3716lXr16SkBAgPI8XtWjlI5pDE4/R0SUdqNGSY2c7t2tc76YGEWpVEnO2aWL4X0GDdJVCM/oxXfHjdPVG+vdO/0WAqxZU57DggXJ76fV6oorq9OHGRISIlMeAlLMrFo1WZ85M23tTKpA14sXirJwoRSvql1bUeLPhqtOb1axYtrOHd/48brf+7Jl5jtuirp0kZO++655j6vVKo/Lv6sogLLGpVOa3sc7dkgTCxfW3/7ggaJ4eMj74tYt/fvUSurXr6f+vJS0Bw90Mwhk9M/klKiV6tVbWj+TTPLXX/KPEVCUYcOseGJKyJQ41OT+kN27d+v97ODgAF9fXxQpUgROJnavtGvXDo8fP8bYsWPx4MEDlC9fHtu2bYsrVnfr1i298e9v3rzB6NGjce3aNXh6eqJp06ZYvnw5fOJVPUrpmEREZB3q+Pi337bO+RwdJWX/7bclbbpHD6nRo9q/X4oJATLues0aoG9f67TNFrZv163Pnw+cOiW1CvLnt12bTPX6tS6zQ+1xT4o6Tv7XX2WcfN26hvdTe+MbNZIe644dJV39118lo9RUMTGSLXD0qIxnLV1aeszz5gU2bZLijGpdCEAK1e3ZIz3rpqTVG2vsWOnZ++cfGc5iFRcuAMuXy/rkyeY9tkaDbAumAlUr48OoX/DXzCFo+LmJxfP+kzCtXpU7t9TyevYMKFBA/z4vL/n9sUfeMvbtk2XZsoCvr23bYmsDBwKzZ8vnE2DFHvnTpyV9KyYG6NBBl9pD9s8KFxbSHfbIExGlTUyMTDcHyLRO1tSzp5y3TBlFiY6WbeHhilKkiGz385Pl229bt13W9OyZbk7sH3+UKbUARcmVS1F277Z164y3Z4+0O08e46akWrBA9q9d2/D9CXvjFUV6BNVtwcGmt/Gnn/R70QzdgoIUZcIEef3V9r1+rSgNGhiXbWD3WrWSJ9K6tcVOcbpUB0UBlOM5Gqb6GG3aSDO/+cb4xxQuLI/Zvz/Vp6Vk9O8vr2+/frZuiX3o0EH3uRF/mlWLuXFDPmABmfIxvaZuZSBm75HftGmT0RcG3n///VReUiAiooziwgWZbs7T0/pVdydPBtavl7GGc+dKL+sXXwBXrwL58kl15JIlJWPg6lWpXJ3R/P23FI8KCgJ69gTq1ZMOlzNnpEc4ODhxz6M9UivQ165t3JBrtdf+8GHpRXVz078/YW88IL2x774rY/FXrtTNgGCM8HDd1IhjxkgP2rlzcrt+XaZ+69wZqFhR2t+8ubTxn3+A9u0t0yNvdUeOSNl/BweZNsJCvL//ElHvrkOlp3/h0cpdyNXhXZOPYcoMASpWrrcstUe+Zk3btsNeDB8umVNlyuhPs2oRr18DTZsCDx5IKtGGDVJ5j9IPY64MaDQao24ODg5pvgphD9gjT0SUNj/+KBf469Wz7fm9vGQcskYjP2/dKvc3bCg/T5hgm/ZZWq9e8vwGDNBtCw+XLAVAUZYutVnTTFKvnrR37lzj9tdqdZ1Le/bo32eoN161ZIlsL17cuJ5/1cSJ8riAAOM7svbsURRXV12vm7NzOu8EU39J3bpZ/FTr8/ZTFEC5WryJyY998kT3mr94Yfzj1BoNa9aYfEpKwYsXus/me/ds3Rr7cemSfi0Nixk+XJfylLA4BNmMKXGoUVXrtVqtUbdYdVAHERFlatYeH5/Qxx8DVapIL9qHH8rX9+7dgSZN5P7//U+WK1bIfRmJoujGxzdsqNueJYuM5QZkPLe9i4qSseuAbmq5lCQ1n7xWC/Tvn7g3XtWqlXREXb4Mo6c4e/gQ+OYbWf/6a+M7smrXBlavlg5sQMYGp9tOsJ07Jf0j/rQRFvT0f1LEIODyNkl5MIGa/VC0qG4WDWOwR95yDh6Uz6vChWUedRLFiwO5cln4JCdO6Mrj//hj+kjRokTMNo88ERGRytaBvIODpNWr6dj58gHTp+vub9VKAtvgYODYMdu00VKCg2VaMxeXxAFwlSqyTA+B/PHjkvmZM6dpwzMMzSc/dSqwdauk2qvBd3xZs0raO2D8nPITJ8rwkcqVgbZtjW8fALRoASxaJO0x9bF2Q1F0U1X16SPzuFlY3lpF8BcawAGKBB8mSE1aPSDvDQAICzPtcZQyptXbSHS0XO3WaoF27XQffpTupCqQDw8Px9atWzF//nx8//33ejciIsrcXryQMfIAULWq7dpRuTLw+ecSLC1erD/e0NNTV9E7vc+znpA67/o770j18vjU38fp00BkpFWbZbK9e2VZs6ZpU5KrPfKHDslz3L0bGD1ats2ZIz3ghnTsKMuVK+X7bXIuXwYWLJD1b7/V9a6boksXCQ6HDzf9sXZhwwaJjj08gFGjrHLKkiWBeegDAFB+/lnSNoyU2kCePfKWw0DeRqZNk4Ip2bMDjN3SNZOnnzt16hSaNm2KiIgIhIeHI3v27Hjy5AmyZMmCXLly4bPPPrNEO4mIKJ1Qe7gDA62QHpiCyZOlwJmhQKtTJ+l9XbVKeuudna3fPktQA/n4afWqQoWkh/vJE/kep/bQ26P4he5MUby4FLB7+FCmf+vfXwLzrl1leEVSmjSRlOu7d+UiQnLT3Y0aJWn6772X8rR4yUm377mYGN3VkSFDrPaH7u8P7HRrjrtv8iLf43tyMaF9e6Mem9rCggzkLePNG11mEAN5K7p8GZgwQdZnzrT9P2lKE5OvIQ8aNAjNmzfH8+fP4e7ujsOHD+PmzZuoVKkSpqljLYiIKNOydVp9Qkn1ljZoIPMWP34sQ30zgqgo6YEGDAfyGo0ueFfnZ7dHMTHA/v2ybmogr9EAtWrJ+kcfSUBfpoz+UAtD3Nyksj8g8zknFbjt3i3xo4NDJp5uefly4NIlIEcOCeStxMEBKFbSCT+hp2yYP9+oxz16BNy6Jb//CiZOQa8G8kytN6+jR+XzKnfujDlziF3SaoEePSRVqVEjXbEYSrdMDuRPnz6NIUOGwMHBAY6OjoiMjESBAgXwzTffYJSVUquIiMh+2VsgnxRnZ11nXkrp9eHhwObNEmDas8OHZdy2ry9QrpzhfdLDOPnTp+V5eHtLEG4qtZc8MlICsXXrpCZCSsaOlcDizBkZOprw933woIxvB2SIaalSprct3XvzBhg3TtZHjtQNIreSkiWBhegBrYOjpG2o43iSofbGFy9uenPV/dkjb17x0+pNGTpjE4oixUeOH5eUsyNHZOzOmTPy95Be/PSTXCH18JCxQXb/wlNKTE6td3Z2hsN/3Ru5cuXCrVu3EBQUBG9vb9y+fdvsDSQiovRDUXQ9vfYeyAPSITF7NrBxo27e+4SioqTz4sABKZQ2bJjVm2k0tVp9gwZJZyKkh0BeTauvWRNwdDT98XXr6tZ//hkoVsy4x/n7ywWb2rWBP/8EPvtM15N/4ADQuLG8T+rUAb77zvR2ZQjz5wO3bwP58wOffmr105csCaxAfpzM1xyVb2+U9qQwzlcdH29qWj3A1HpLUQN5NXvG7sTESCN//13G6CQ1S4Kjo3zAlC0rVx2zZpVicjExsnR2lit+5cpJ1VVbBc9hYcCYMbL+1VfyYUfpnsmBfIUKFXDs2DEULVoUtWvXxtixY/HkyRMsX74cpUuXtkQbiYgonQgJAZ4+lem0kuoRtidvvSVpnVevApMmSap0/O9ZigL06ydBHCBB4dCh9tuRkdz4eNVbb8nyyhXg+XMgWzbLt8tUaqG71H7JDwoCZs2SCzMffmjaY996S2ontG4NzJsnU2NVqSJj6MPDgXr1JNg3poc/w7l5U+baA6RX3t3d6k1QZzBY4toblbERWLZMimEkrOwYj9ojb2qhO4CBvCXExkp2C2CH4+Ojo2UqxXnz5ANS5eoq48kdHOSm0Uhl12fPgIsX5bZ6dfLHzp5dAv4ePaRIizVNnSrjyIoVs8kFOLIMjaIYN4NubGwsHB0dcfz4cbx8+RJ169bFo0eP0LlzZxw8eBBFixbFokWLUC49fHNLQVhYGLy9vREaGoqsVk4ZIyJKz1askHHJ1avrgl97t3ixrgja0KHS664G6vPmyXcejUY6VqKiJOPAHovEPXki3zMVBbh3L/l5mQsXBq5dk8C/QQPrtdEYWq0U5Hv+3Lav9XffAYMHy7q7u0yFV7++dNBlyiB+3z65uvHkiVwpOXsWcDK5PyjNgoMlFsnipsWrvEWhuXYNWLhQxjokIX9+KWK4b5/M5mCKrVuBZs2AihV1FwQobU6elOyIrFklDk5N1o1F3L4tY2oOHZKfc+aUipYtWsgHZcKLRYoC3L8vfwtnzgDnzsk/CWdnuTk5ydW/s2elpkRsrO6xkyYBX3xhnavCd+4ARYvKMIDfftNN2UJ2yZQ41OhP4Hz58qFr167o3r07Kv93STNXrlzYtm1b2lpLREQZRnoZHx9ft26SLv3ZZzIrz+vXkqm7b59sA6Sn/uxZ4JdfpAPQHgP5Xbvke2WZMskH8YBMQ3ftmqTX21sg/++/EsR7eEjwZCsDB0qGydy58p5o0ECCeBt0QtveTz/JFa2YGPmlbNxokyAeAAICpHM04o0Dnn/4CbJP/VyuuCURyEdGShAP6HrzTcEeefNT0+pr1LCjIH7rVrkK/eyZFOdYsABo0yb5Bmo0QN68cmvcOPnjR0ZKPYdffpFpUsaMkfS16dNTN3+lKcaMkSD+nXd0RT4oQzD6ndO3b1+sW7cOQUFBqFmzJpYsWYKIiAhLto2IiNKRu3eBP/6Q9fQUyAMyRdmPP8r3srlzZex8mzYSt3ToIOPiO3eWfVetMmn6aqtQFGDLFllPLq1eZc+V69W0+ho1bBYrApD3wsyZUpS9b99MGsRHR8sfR69e8sfQtq1EYQUK2KxJTk5StA4ATpTtJj2fJ04A588b3P/pU1k6OqZuGAkDefOzq/njw8OBzz+XtItnz2T8xcmT0jNvzqsMrq4yZcK0afLBAsiyWzfLVlE9cwZYulTWp02z33FhlCpGB/JjxozB1atXsWvXLgQGBqJfv37w8/NDz549ccQevwkQEZHVnD0rwfvNm0CePJKCnN707CnfdxwcgJUrJYO4YkXJ2tVogHfflZ7up0+lEJqtXb4sFx3atpV2LV8u200J5I8elYsA9iS188dbgpOTfPedMycTBvGA9HLPmSPrX34pV7HsYFyB2rN++q6vric0ifHJaiCfPXvqYhgG8ualKHYSyD97Junt/v4yngqQFKz9+4HAQMuee8AA+Wfj6CgpXh98YLnq98OHy4vetq2kYlGGYnIuR506dbB06VI8ePAA06dPx8WLF1GtWjWUKlUKM2bMsEQbiYjIjCIjJTM2NNQ8x/vrL8nYu3MHKFFCihjZYwE1Y3z0kcQqTk5yQWLjRl3c4uioq0+0bJnNmggAWL9egpl+/YC1a2WudFdX+T4Yv2J7UipUkOfz8KEMC7UXiqLrkbeHQD5T27xZrg45OAAbNlhvPK8R1ED+wgXo5pBctcrgVSk1kM+RI3XnUoeohofrD3G2hSdP0tdsZ4ZcuQI8eiSfV2rhTat69EiKofj7y3yTT59K0ZANG6RCpqurddrRubOc09VVquJ3727+q6p//SU3Z2cpCEkZTqoHZXh6eqJHjx7Yv38/Nm/ejAcPHmCYPc/JQ0REAKS4W6tWwIQJaT/WokWSkfjypQReBw/KGNb07MMPJbPg4sXEGcRqev3mzdKhYwuxscCoUVIUrmpV6VTau1cuzKxbJ9/ZUuLuLsWTAetNQ/fmjWSwbtiQ9D4nTkhhZTe31FUYJzMJDQX69JH1wYPlA8OO6AXyzZvLGyY4GDh9OtG+T57IMmfO1J1L7ZEHpJaGrVy9KkX7TJ2Fwd6ovfFVqlgvZo7z8iVQrZqMS3/1Sj4EV66UQnS2eI+//76MR3NyknaMH2++Y0dH6+ZK7dvX8lkGZBOpDuQjIiKwZMkS1K5dG++//z5y5MiBr776ypxtIyIiC1Cnw01rBeZt2yTzNiZGxpRv355+e+ITypsX8PFJvL1MGaB8efmOlNJMQ5ayfr30amXLBuzYAYweLSmqpn4ptvZ88mPHSgbr//4nhZ4NUTuNWre2wZd80hkxQopeFC5snit+ZhY/kFc8vaSyOCC98gmktUfe1VVXq8GW6fW7d0s21R9/SFCfXp08Kctq1Wxw8kGDpMpngQLyQp4+LRkdtizGUb++FNYDgIkTdWOk0urzz2XMm4+P/JOgDMnkQP7gwYPo0aMH/Pz80LdvXxQqVAi7d+/GlStXMGLECEu0kYiIzEjtSb50KW3HUb97dO0qqeaZJfBSe+VtkV6vKLppvD/7TL+30FTWDOQPHpSx5oBUgP/yy8T7nDsnvfUajWRxk43s3QvMny/rP/1kF2PiEypSRGKvV69kSE9cev3q1YnSk9MayGs0uvT6sLDUHcMczp7Vra9YkbZjbd+ufzxrUv/vlCpl5RNv3gz8/LP8Qpcvl1QyOxkqgu7d5eIZIFfH1fFFqbVmjcyfCUjaXGrf/GT3jA7kv/nmm7iK9f/++y++/fZbPHjwAEuXLkWtWrUs2UYiIjIjNZB/9Eim+UqN589lth5AMm/t5fuQNXToIOPLDx+WbF5r+vNPKULs4aGbGi+11LpHx49bduxvRIRc7FEU3Tl//FE6xuJTg/s2bVI3TRiZwevXQI8est6zp3EFF2zA2Vnmkgf+S69v2hTw9JQxMQkKMKc1tR6wfMG74GDpJE6u4zR+4L1sWeqHU1+9KvUBK1WSWfusXexSDeRLlLDiSR8/1r2vBw+2zwIcX30lH37R0ZLmn9p/LhcvyoUBQHrl7WxYDJmX0YH8t99+i8aNG+PMmTM4cuQIevXqBa+0dAUQEZFNxB/bffly6o6xbp1MwVamjNwykzx5dJXhzZUFaQxFke96gAxfzp49bccrUUJin/Dw/4IhC/niC/lOmjevDMdo2FCGY8QfDnrpknQiAcwCtamJE+WX5eenq+Rtp/TGybu76+bHTpBen9YeecDygfx330lmwcKFhgNrRdEF8hqNDI86cCB15zp1SpYxMcCnnwK9e1tvOs3QUN2wGnUKQYtTFHmSjx5JGoChdCB74OAgV2iqVJF/0rVqmT49ysuXMi4pPFwuwtnrcyWzMTqQv3fvHr777juULl3aku0hIiILix/Ipza9/pdfZKlWcc9s4qfXW3IK4Pj27pUUdVdX6VRKK0dHXUE5S6XX790rhaABCVJ8fHQXI1askHR6QLYpCtCypa4IH1nZv/8C334r6/PmGS4SYUf0AnlAl16/Zo1eiom9B/KvXulS5R8+lNIECd25A7x4IcMJ1KeZ2qE96sVbf3+5KPDjj0C9enJuS1PP7ecHeHtb/nwA5MXdsEHSOJYvl8KI9srdXSrYlywJPHggmSZ9+hhXZVFRpCf+0iUgXz7d9CuUoRkdyDsbUwaXiIjsXlp75G/f1s313aGDedqU3rRoIYHBzZvAr79a55zq2Pju3eWLsDmo4+QTZCObRXg40K2bfL/8+GOgSRPZXrmyTJOnKMCYMdIBrL6G7I23oWHDJABu3VrXu23HEgXyDRvKxYf792Uu8P+YI5C35Bj5lSv1LxAcP554H7U3vkQJGfEAyPWK1ExFp1687d1b6r1lzSq9+5UrG76IYE5WT6u/fVvm6AQkBahCBSudOA1y55Y3wcCB8vP8+VJhde9eCejjXzm+e1fS44YMkXFL6rQl69YBuXLZovVkZamuWk9EROlTWnvkV66UZe3aQMGC5mlTeuPurpvZZ9Iky/fKHz8u0wE7OurOaw4VK8ry/HnzHVM1fryuQPSMGfr3TZokmaQbN0p2g1YrtacqVTJ/O8gI27fLzdnZ7lPqVXqV6xUALi5yEQLQS6+39zHyatFQDw9ZHjuWeB81kC9bVj53CxSQNPXNm00/X/xgumlTycYpXFh6/S09VMjqgfzYsXL15e23geHDrXRSM3B3l/EWu3bJLzskRH7xXl7yN+roKPuo8xHOmCFvHI0GmD1bni9lCgzkiYgykTdvpPiYKjU98moaaGZNq1f17SvBwdWruqEGCcXGSu0iQ65fl0ruNWrIdMLxfy8JqenoHTsCAQFpa3d8hQrJ8tYt8x0TkMBKfU2+/17Xo6kKCtINTzh8WJZjxpi3DWSk2Fjd1aF+/SSqSweKFZOLQS9eSBYyAF3e+bp1cVfX7Dm1/sQJubm46IqWJ9cjX7asPOePPpKfTU2vV5TEwXTx4rq/RUtPa2fVQP7SJd0LNGtW+kwzr1dPhrx07SrBu0qrlX/mDg7SW9+njzzXa9eATz6xVWvJBhjIExFlIgmr1F+9ajjQVBSZ7zdh6ua//8rNxUUK7GZmnp7J98rfvStfkt3dJTZq3Bjo3186iSpXBgID5fEHD0rPWp8+hgtd/fyz9FxrNLov++aiZlTcu5f0BYfUuHRJMpzd3OR5GzJ+vHQuAZIVrVa0JytbskT+qLNlS1djG1xdZRo6IF56fd26gK+vdMP//TdiYyXQB+wztV7tjf/gA93Qk+PHE38OxA/kAV0g/+efUsPNWHfvypAXJyf96zXq62jpQP7iRVlaJZAfP14C3vff140hSo+8vYHFi4HISPnlPX0qH9jXrklaxqlTwA8/yJtCvTJLmUaqAnmtVosrV65g//792Lt3r96NiIjsl5pWny2bTA8dHS09wwmtWiVpzm+/rd9bq/ayNm0qx8jsPv1UeuVDQvTndn7xQgLYkBDp8Lx2TTKX58yRoP/ECelMqVtXYie1YPFPP+kf//BhOQcgBcXNPS1b7txyUUar/W8+bjPZtUuW77yTdG0pf39g3DgZyjl5svnOTSZ49UqXCjFmTNqnQrCyROPknZx0VxhXr8bz57qgOC1PzRI98mFhutoQvXvL7B8uLvIZHf8zOTJSlzmlBvIlSgBvvSWfLepQJ2OoPeKBgbqLaIB1AvnoaN3xLR7InzkDrF4t65MmWfhkVuLoKP+0s2eXIikBAXI1mTI1kwP5w4cPo0iRIggKCkKtWrVQp06duFtdO51vlIiIhNojnzOnbh5mQ+n16hzxZ85IZ8aRIxLsqV88M3tavcrTUzf08ssvpVf+zRupvn7unHzfOn4c2LNHgvThwyWNdcEC6bH++2/5nqkGsv3768bI3r8vPXVRUTIV8KhR5m+/g4OuV96c6fVqIP/uu8nv98UXUi1bHatPVjZ9urzRAgN1V4zSkUSBPKAL5H//HU8eSJqMj0/aMqstEcj/8ot0sAYFATVrShBfrpzcF3+c/MWLErBnzy5TOKrUdHhTxrWrn/UJA2k1kL97N/khPmlx7Zp8PmbJIkO7LWrsWFm2a8dpMChDMzmQ7927NypXroxz587h2bNneP78edztWfwKSkREZHfUj+ns2XVf5gwVvNu3T5a5ckmgVbu2pIHfvi1ppu+9Z532pgeffirZvCEhwNKlkuH4zz/yOv35p2Q21K4N9OgBTJ0q+/TqpV9UeNgwCf6joiQOuX9flvfuSbCydKkE3Zbg7y/LmzfNc7zYWLlwAaQcyJMN3b+vK2w3darkqqczBgP5WrUkj/7pU8Tslg+ytKTVA+YP5BVFl1bfq5cMmwF000HGHyevptWXKaPbD5ByAE5Okt2jTuOYkqTGqGfPrsuwunbN+OdhCvXcxYtb7rMMgFTv27RJTjJ+vAVPRGR7Jv8pBQcH4+uvv0ZQUBB8fHzg7e2tdyMiIvtlKJBP2CN/+7YEdY6OwOnTErRHRuoqj7dpY99T8Vqbh4euV753b6mz5eIi49rVHraUaDQyVLlIEekZL1VKxs57e8tx1EDCEtQeeXMF8idPytACHx/2tNstRZEpqyIigGrVJPUjHTIYyDs5xU2f57FtPYC0B/LmHiN/5IhkO7m56XrWAUmXBwwH8gk7lnPmlOHfgPFDU5IrNmfp9Hr13EFBljl+HLXOQ+fOViyPT2QbJgfyVatWxVVLV8MgIiKLiD9GvnhxWU/YI69OwVyhgqSGb9wo3/lVTKtPrE8f6ZWPiZGgfPlyGf9uCm9vYP16KY73/Lkc59dfgaJFLdNmlbl75NW0+jp19Astkx2ZNk0GVzs4yBW6+F296Yj6GfbkSYJCnv9dmMh18DdooE3T1HOA+Xvkf/xRlm3b6o/dV3vkT5yQoUxA0oE8oItZV640rlfeHgJ5i8bW//wD7NghF3PU9HqiDMzkQL5///4YMmQIlixZghMnTuDs2bN6NyIisl/G9Mirgfw778jS0VG+969bJ1PbshxKYh4ewJQpkp08e7Z8QU+NsmWlZz5PHmDmTCkqaGlqIG+uMfLGjo8nG9m0Cfj8c1mfOTNdzzmdJYuut12vWOO77wJZs8LjxT1UxRG7S63fuVOWXbrobw8Kkuf08iVw5YpsSy6Qr1BBMqQUJeW49eVL3WukXgCJL0ME8uPGybJHD/PO00lkp0wu/fHBf1c5u3fvHrdNo9FAURRoNBrExsaar3VERGRW8QN5taf3yRO5qb1W6vj4mjX1H5tOs2+tpnt3me43reM/27YFPvzQep2k5kytf/NGdyGIgbwdOnsW6NhRIr/evWXe+HQuf36ZkevuXRlHDkCuqL33HvDrr/gA63E3R7U0ncOcgXx4uAxfAhIPvXFykuD8wAEpeJctm9Qo0WhkuI0hEyZIJs9vv0lKvtqrn5B6YSBXLsMV/C0ZyBuav97szpyRHnknJ6miSZQJmPx14/r164lu165di1sSEZH9ih/Ie3jogji1V/75c12KZo0a1m9femeuIk7WzHSO3yNvaB57Uxw6JMG8nx+Hp9qdhw+B5s0lknz3XeD779NtSn18agX0RNMntm4tC2xAjuxpe2Obc4y8GlDnyGF47H78cfL//ivrRYrI57UhJUsC//ufrKszCRqSVMV6lRrIBwcnfYzUevRI6mZoNBYcKjRvnixbt7ZCWXwi+2Byj7y/+h+fiIjSnfiBPCAplrduyZe8GjWkwJqiyJet3Llt185UefxYxvu+eCGRpHorUEC+7cafOJni5M8vX7DfvJGXMH41fVPFT6vPADGi/Xn6VMZwHD0qf6B58+puLi7yx6veoqOlC/nlS4lAt26VP/ZixYC1azPM30OSgXzjxoh0dEdg7HUUf3MaQIVUn0PtkX/1Sl7atLy31YDaUHo7oOtRP3ZMd5EtpRnUxo2TcfLbtklGjDosKr74VeMNUQP527fls8CcBU3VcwcEWKhQ6suXMp8fIJkmRJlEqmbVXL58OebPn4/r16/j0KFD8Pf3x8yZMxEQEIAW/1UKJSIi+5MwkC9RQmoDqV+01LTohGn1dk1RpLrc4MES6Bji7i5dXdWqyc3fXwIfFxcJaLy9pcx6JuTqKmPy79+X9HpzBfJkRm/eAHPmAF9+CYSGpv442bIBf/yhm2ssA8iXT5aJAnkPDxz2aYLaTzeg1KUNMEcgr9VKof+keseNkVIgr/bInzoFBAbKekqBfOHCMrTnxx8lq3zPnsQXG1JKbff1lef58iVw/XrqqstHR0uhvqpV9c9v8bT6FSvkKkuJElJlkyiTMDmQnzdvHsaOHYuBAwfiq6++ihsT7+Pjg5kzZzKQJyKyY4Z65AHdl0t1fLyhHh27FBIiPTBq9aiyZWVOpgcPJDK9f1/2CQ0F9u6VW1Jat5bc1PLlrdJ0e+Lvrwvk1UBCFRkpwUHz5kDt2kkfIzRUOooBBvJmoyjAqlXAyJG6IgZlywKffSYp8vfuyeDw+/clinJwkAhKo5Gxwl5ekhfu5SUXqzp2tPw0CFam9sjfvZv4vi1urVEbG+B/fD2ASak+h4eHvKSKIskN5gjkk0txz5pVzrNpk2xLKZAHpIL9kiXyEbdzJ9Cggf79KQXTatr7yZMyTj41gfyUKVJ0b/x4Xd05Y86dJoqiS6vv3ZupQJSpmBzIz549Gz/99BNatmyJKVOmxG2vXLkyhg4datbGERGRealTNMXvkQfki9abN5LOCaSDHvmYGEmjHz8eeP1a8jXHj5de+YQpw1qtfHs+dEhuR45Idb+oKLlFR8uT37BBbs2bS0CfMKLNwPz9gcOHDVeuX7sWmD4dWLMGuHEj6ToA//wjL3XRojKagdIoOhr45BNg8WL5OV8+6ZH/6CPO6xdPkqn1ADZEvocv4QyPWxeBixdTPYm5RiPXQsLCpMfazy/17U0pxd3BQdLr//5bV1zPmEC+QAGZBnPWLAmi4wfysbG6sfnJBdNFiugC+dTYuFGWM2YAAwbokpwsGsgfPCjFBNzdZe54okwkVcXuKlRInJ7k6uqK8PBwszSKiIjMLzZWho8DiQP5a9fk+1BUlAy9LVzYJk00zvHjEmR//rkE8fXqyRe5zz83PO7XwUG+wHfvDvz0k1TuvndPgvmwMDnGuXNAhw7yjX3zZqBKFaBFC8PRQQaU3FzyJ07I8vZtSdlNCtPqzSg0VOYeXLxY3r/jx0sk1rUrg/gEkkqtVxTg5gtv7ER92bBhg3EHVEus//CDzA/Xty/w1Vf42GExGmI73oQY6Po3kqLoAuqkAnlAv/K8pydQqJBxxx8xQkYLHTqkuygLyN91ZKQMo0mu1FVaKtc/eybDAQD5WJ07V3efRQP5+fNl2b59hhoyQmQMkwP5gIAAnD59OtH2bdu2ISiVVzqJiMjy1CAe0H3fyZtXvijGxABLl8q2mjXtNDvx1Svpca9aFTh9Wq5GLF4seaTqN9DUKlUK+PVX6bXr3FmCpU2bZPuPP6a9nLudS24KOvXLOQAsW5b0MdJ9IK8oMoXVrFkShSxbJsHfjh26+cKs4fZtGduyc6fkcG/aJF2sWbJYrw3piNoj/+KFjDZQhYXJ59p6/Ddv5tq1cjXTEEWR2gEffSQHDAqSAH7ZMgnoR4/GjBfdsR2NUaplEUlNSYW7d6WNjo668e+GxE8GKl3a+Nkw8uSRqSsB/UBaTecvViz560BpCeT37pWX0em/XN/vvpPnGhGh+1wxeyD/5ImkCgGSjkCUyZgcyA8ePBh9+/bF6tWroSgKjh49iq+++gojR47E8OHDLdFGIiIyA3V8fNasui9bGo2uZ2jtWlna5fj4W7ckv/S77yR/u2NHCbq7djXvVYfixeWKxtmzcsEgLEzSm999V9IWMqj4U9DFpyhyzUS1bp1+sKR68AA4f15+FXXrWqyZlnHpkkzGXbKk1EcYOFDmV+/SBfjgA6BhQ+kS7dxZFxFZypEj8r47d06isr17gWbNLHvOdE4tAQDoj5NX617udH9fotczZyTT5sAB/QNcuCC/4+bNpWjavXvSdV2vnlxAGT0a6N4dB70b4yFywTHqjVzcSwX17VO4sPScJyV+j7wxafXx9esny1WrZBYKwPge8bQE8n//LcuPP5bn9/QpsGCBTGenKHLdNWdO04+brMWLJY2sUqVMNRSKKI6SCitWrFCKFCmiaDQaRaPRKPny5VMWLlyYmkPZpdDQUAWAEhoaauumEBGZzeHDMi9VoUL62zt2jD9nlaKcOGGb9iUpMlJRqlaVxhUsqChbt1rnvDExijJjhqK4u8u53d0VpU8fRTl1yjrnt6KzZ+UpZs+uvz0kRLa7uChKYKCsL1uW+PHjxsl9lSpZpblp8/ixoqxbpyj9+ilKyZL6b35XV0Vp1kxRPvhAURo1UpTq1RUlKEh3v0ajKO3bK8q5c+ZrT0yMomzcqCh16+rOU6qUoty8ab5zZHAlSsjLtmuXbtuRI7qPDGXJEkXJmlX3+nbqJL/DAQMUxdFR97sfOFAO8vp1onO8+66itMY62Td3bkWJijK5nXPmyMObN09+P61WUXLmlH3nzDHtHFqt/B0CijJ5smzr1Ut+HjMm+cfeuyf7OTjIx64pSpeWx65bpyg//STrfn7y0gPyp2RWsbGKUriwHDwDxSBEpsShqQrkVeHh4crDhw/Tcgi7xECeiDKirVvlO0+FCvrbJ07Ufb/19FSU6GjbtC9JAwdK43x8FOXaNeuf/+pV/SALUJS33pIvj69eWb89FvDihe6pvXyp2752rS5AV98n9evrP/bePUXx8JD71q61bruN9uSJokydqihly+r/HgFFcXJSlKZN5QpFUv/3jx1TlBYt9B8XEKAoLVsqytixirJ+vaL8+aeizJqlKJ9+Ki9SYKCi5MkjV0c8PeVqSNas0oYWLRRl0CB5rHqFBJCgsmNHRXn+3IovTvpXv768fEuX6rYl+rx78EBRPv5YLsYkfA+0bClXrZLRsqWiOCFKCc+aWxexmqh/f3no0KEp7ztggLxtUmiWQYsX6y5iREcrSq1a8vOKFck/TqtVlCxZZN8rV4w/38OHupfy8WO5CJA/v+7PBFCU7t1Nfx7J2r5dDuztnWE+h4kUxUqB/MOHD5W9e/cqe/fuVR49epTaw9glBvJElBGtWCHfe959V3/76tW6L2ENGtimbUnasEHXuN9/t107tFpF2blTUdq2VRRnZ12b8uRRlC1bbNcuM/L2lqcUv7N51CjZ1qOHXENRO6Vv39bto/b2Va0qL5NdOX5cUbp2VRQ3N/3ArXRp6ZFft05Rnj41/ninTklvvaFgMC23bNkU5fPPFeXWLYu9FBlZ167yMn79tW7b8uWGLzwpx49L9zAg2RZ//WXUOTp3loccrDsy1R+WDRvKQ3/6KeV90/K3FBGhKDlyyLl++01RcuWS9ePHU36seq3LlMQn9X9I2bK6bd9/r/8W/+Ybk59G8v73Pzlw375mPjCRbZkSh5o8/dzLly/x6aefYuXKldBqtQAAR0dHtGvXDnPnzoW3t7cZE/+JiMhcEs4hr4o/btKupp0LCQG6dZP1oUNlfnhb0WhknPy77wKPHsk4+nnzgOvXZQxzz54yR5s6WDcd8veX0gC3bkmNP0BX6K5CBSAgAKhVS4Ztr1ghFbIvXgQWLpR9pk2zoyKJZ8/KYOF9+3TbKlaUAmbvvQfkypW645YvL4UCnj2TMddnz+qWb95INbHixWWpTgju4qK7vXol7xn19uCBvKj/+x+L2aWBoSnonjyRZaJx2ZUqAfv3y5u3aFHDM10YoP5pHyzZE9X2TJEiiCEhJk3xoY6RT65ivSotf0vu7kCPHsDUqcBXX8lHlrHnLVJE3s6mjJNXx8fXq6fb1qOHzJaontushe4iInRz3XXqZMYDE6UvJgfyPXr0wKlTp7BlyxZUq1YNAHDo0CEMGDAAn3zyCVatWmX2RhIRUdolFcgXLSpfGhXFjgrdvXkDtG0r03BVrw58/bWtW6STKxcwbJgEil98AcycKdPa7dwpAb5dXQ0xnhrIx69cHz+QB6T+2969Usz7888lmNdqgZYt7eS9ExEBTJwoF1ViYiRIa9tWfldVq5rvSkP27FLVLzWV/TjDj9kZmoJOLXaXI4eBB2g0UtzQBGogf9spQIrjbd8uV7EmTzbq8RERumKSFpmGLYHevYFvv5XZOgG52OHpmfLj1IJ3wcHGn2v3blnG/3Nwd5dJRkaMkJ/N+py3bpWLYv7+wNtvm/HAROmLyVXr//jjDyxatAiNGjVC1qxZkTVrVjRq1Ag//fQTNm/ebIk2EhGRGSQVyLu7AwMGSNHmGjWs3y6Dhg0DTp6Ub+GrVxvda2ZV7u7AjBnSHeXvLz2stWsD33wjV0XSmYRT0N2/Lx3GGo2ucnabNvK0L16UCQQ2bZKC4EbGMpb1118yV9fUqRLEf/CBzDSwYoV82bebdAEyN7VH3lDVeoOBfCqogfzLlwB69ZIfFi2SqulGUKu3Z8tmgertBhQqJJ/pKmMDaVMr19+9C1y5IlPk1aqlf1+fPpLJU6yYLM1m5UpZtm/Pv2vK1EwO5HPkyGEwfd7b2xvZ1ImJiYjI7iQVyAO6oCy5KZGsZudOYM4cWV++XPct3V7VqSNd2d26yTf1zz+XKcz+G36WXiScgk7tjS9RQqYzByRTvFUrWR8yRJY9e1qnhzFZ06cDjRrJxZQCBeTNvG6d/b93yCwMpdabO5DPmlWWYWGQCDlPHskb//13ox4fP63eWrGnOhUdYLlAXu2Nr1gR8PHRvy9rVplJ8d9/dVOepllYGLBli6x36GCmgxKlTyYH8qNHj8bgwYPx4MGDuG0PHjzAsGHDMGbMGLM2joiIzOf5c1kaCuTtRmgo0L27rPftCzRpYtv2GCtrVumdmzFDfv7+e/mSGRlp23aZQA3k1R75hGn1qs6ddeseHjLVtk0FB8sQB0DeM+fP63dFUoanptY/fKjrIE9yjHwq6fXIOzvLhOmA0XPKmzI+3lzefVd3PmNHEqiB/PXrktiSEkPj4+PLksXMF4g3bpTP1RIldKlCRJmUyYH8vHnzcPjwYRQsWBBFihRBkSJFULBgQRw8eBALFixAxYoV425ERGQ/kuuRtxuDBgG3b0sBqalTbd0a0w0aJGmfzs7AmjVA48ZyccIexcbKYPeqVYEhQxDgLW+QlAL5+vUBPz9ZHzZMOiZtRlGATz+VL/aNGgGzZ6frgoOUOjlz6oLFe/dkadHUekCquWk0kkFkRPe1GshbM3tFowF++UWGTsW/AJecfPkANzcJ4tXsnOQYGh9vUWpafYcOTKunTM/kRJeWLVtaoBlERGRpdh/I//EHsHixfDlbskSXz53etG8P+PpKDvqePZJzOmSIfJM2ptqUpSmKvNajRkneKwAcPYpKixZjAMZi/t1PER3tkmQg7+gow8537QKGD7du0xNZuVICKVdXYO5cfrHPpDQaSa+/dk3GbBcqZLlAPizsvw2FCsnFo23bpNhlChcebdEjD0iR/kqVjN/fwUGuo54/L9cnAgOT3vf6deDGDUmbt0qxyydPZLYAQD5niTI5kwP5cTbPoSMiotSw60D+6VMZbA1IqWO7KIGeBu++K+XdmzaV6KJvX0n/7tlTBq6qleWs7dgxyRo4cEB+9vGRilSbN8Ph3DnMxCD0Vebizg/Tce2aTPeXMJAHJI02qVRaq3n+XJ4LAIwebdI0YJTx5Msnf2rqOHlLjZGP65EHpFd+2zZg1SpgypQkLyQpCnDpkqxbO5BPjSJFdIF8w4ZJ76f2xlepYqVrlOvWSSZRxYpSQY8okzM5tf7169fYtGkTpk2bhmnTpmHz5s14/fq1JdpGRERmoih2Hsj37y8l0oOCZPLhjKB8eemG+/57CTJfvJD5oAICZO75tWtlmj1rWbZMpiU4cEBKz48YIZHP119LHv2PP+KxY24UxVUEDGyBj7AMBQva6fsFkAsjjx5JrvKwYbZuDdlY/IJ3ERGA+tXUImPkVU2bSubQrVu6ed4MuH9fZktTe7vtnbEF71IaH2926hTXLHJHBMDEQH7Tpk3w9/dHy5YtMXz4cAwfPhwtWrSAv78/p54jIrJjL19KRwYg0x/ZlS1bJEXa0VHmYXdzs3WLzMfLSy5SXLkCbN4sPfVarcyD3LatDDbv0wf45x/LBfVarfRYd+kCREfLpO9Xr8qcceqbwckJ6NkT3WoEYx56AwB+RC98GJB0cGJTR44A8+fL+rx5klpPmVr8QF7tjXd2Nl9PcfxAPm52SXd3uSgHAOvXJ/lYNa0+ICB9vFWNCeQVRRfIW2V8/N27kuUEyGcnERkfyB88eBBt2rRBrVq1cODAATx79gzPnj3D/v37UbNmTbRp0waHDx+2ZFuJiCiV1N54d3e52Y3oaGDoUFkfNAh46y3btsdSHByA996T8dyXLsn49Pz5pZd+/nyZws7HRyZi/uILYPt2eW3SKiICaNcO+Oor+XnUKAk48uY1uHuuwl7oi7nYhOZwQyTGnGolvd72JDoa+OQTiSQ6d5bXjjI9tXL93bv6afXmKpugptZHRyeYjKJNG1muWxcvwtdni0J3aWFMIH/njmQaODkB1apZoVGrV8vr+847thuaRGRnjA7kv/zyS3Tr1g3r1q1DtWrV4OPjAx8fH1SvXh3r169H165dMXHiREu2lYiIUkkN5O2uN/6nnySwzZlTeo0zg+LFJbC+cUMKN330EZA7t0QH+/ZJqnvjxjIGdMGC1E9hd+mSBLnr1knX5NKlcl6HpP/1+/sDChzwEZbjEorDO+wO8OGH5rmoYC7TpgFnzsibedo0W7eG7ET8HnlzTz0H6Pfs66XXN2kiWUQhIfK+NCA9jY8HdIF8SIgukyshNcgPCLDSxWG1Wj2L3BHFMTqQP3z4MPr165fk/X379sWhQ4fM0igiIjIvuxwfHxqqm4R8/HjA29umzbE6R0eZy23ZMunaunwZWLhQepl9fSXQ791bBtV+/730rhvj0SMprle6tBS3y5FDSswbMf+U2tEVBm+0xEZoPb0knXXIkNQ/T3O6cEHeKwAwc6a8TkQwnFpvrkJ3gPy5Zski6yEh8e7w9JRgHkgyvd5WFetTq0ABufYXFSUZDoaogbxVxvwfPy43Z2e5sEhEAEwI5F+/fo2sal6RAd7e3nhjzaI9RERkNLsM5KdMka6z4sWBXr1s3Rrb0mikB/7jj6Xn/OZNCd7z5ZNv0gMGyHrnzsBvvxkO6sPCZNx7kSLADz9IV1qLFhLM16xpVDP8/XXrT3OWgGbFCvlh9my5yGBLsbFA9+4SXTRtKpkMRP9RA/n794HHj2XdnIE8oEvfr1lTrrHFBblqev3atQbT69NbIO/oqJt2LjjY8D7qxQyrBPKzZsmyXTsgVy4rnJAofTA6kC9atCj+VqtaGLBr1y4ULVrULI0iIiLzev5clnYTyN+8CXz3nax/+630tJCOu7sUyQsJkfT6QoVkPP3y5UDr1pIz3Ly5FNoqW1bSzL29ZQz8y5cycfSePcDGjZL7aqT4gXzFioCmxfu6rImePYE5c8z4JE00c6YUucuaVV4TzhlP8eTOLaNGYmIkcQMwfyD/22/S+R4TI2/BIkWkxMfL2u8BLi4Ssasn/8+bN5JcA6SfMfJAyuPkrRbI37sn4+MBYOBAC5+MKH0xOpDv1q0bhg4diq1btya6b8uWLRg+fDi6du1qzrYREZGZ2F2P/KhRMva7Th0pAkeGubpKtsLVq5LiPmiQBPWvXwN//CHV7//9V4J8QLrRVqwAjh4Fatc2+XRqryYQb/74sWPlogIgywkTkizqZTHBwboaCtOn6zeUCFJ0zc9P1k+flqU5x8gDQKlS8ie3d6/UXHvzRt6Og8dn1U24niC9/upV+XPx9k5fncl2E8jPmyc1Ot55Ry5QElEcowP5AQMGoF69enjvvfcQFBSE1q1bo1WrVihRogTef/991K5dGwNTcaVs7ty5KFSoENzc3FC1alUcPXo02f1nzpyJ4sWLw93dHQUKFMCgQYP0UvrHjx8PjUajdyuRni6BEhFZgF0F8kePAr/+Kj2q06ezZ9UYjo6Szztjhsz9fvKkvHY//QRs2wacPy+p9SEhQKdOyRa0S46rqy4YigvkHRwktXXCBPl5/HhJ9ddq0/y0jKLVypCDN2+kpsDHH1vnvJTuqNd3/v1XlubukVfVrCnBvDraZPt26Fevj0ftoC9ePH191CUXyCuKlQL5169100yyN54oESdjd3RwcMDatWuxevVqrFy5Epf+K8FZokQJjB8/Hu1TUUVy9erVGDx4MObPn4+qVati5syZaNSoES5fvoxcBi5b/vrrrxgxYgQWLVqE6tWr48qVK+jatSs0Gg1mzJgRt1+pUqWwc+dO3ZN0MvppEhFlSHYTyCsKMGyYrH/0keRvk2k0Gomy4yJt8+rVC9i0SdfBGHfOsWPlDdS/v4yZf/YMWLRIUoot5flzmY5v3z7Aw0MuXKSnaIisSh3D/uqVLC0VyAPyNmzbVkac3L4NPKz6PnI7OclVhCtXpOYFpEQFYLE/V4tJLpB/+lSuGwK6sfQW8euvUkfF31/qfRCRHpMv2bdr1w4bN27EhQsXcOHCBWzcuDFVQTwAzJgxAz179kS3bt1QsmRJzJ8/H1myZMGiRYsM7n/w4EHUqFEDHTt2RKFChdCwYUN06NAhUS++k5MT8uTJE3fLae7cKiKidMZuAvlt26Qry9UV+PJLGzeGDBk/Xjr8DU5V2K8f8Msvksf8yy9AvXrAgwfmb0R4uEzDFxAgqbWAZCAUKmT+c1GGkXDEhaW//nl5AUFBsn40OBvw7rvyQ7z0+sOHZfn225Zti7mpZa9CQhIn36i98XnzWnDqOUWRuhiAXDxkpxxRIqnLvTODqKgonDhxAvXr19c1xsEB9evXT3Iau+rVq+PEiRNxgfu1a9ewdetWNG3aVG+/4OBg5M2bF4GBgejUqRNu3bqVbFsiIyMRFhamdyMiykjsIpDXaoGRI2W9Xz+Z44jSn44dZXy+tzdw4ICMWz1yJO3HjY2VebinTZN83S++kCkKy5QBNm8GPvkk7eegDC1hIG/JHnnVW2/J8tgxJEqvj44GTpyQTektkPf3l9j59WuZCSA+q6TV//03cO6cZOJwOA2RQTYL5J88eYLY2Fjkzp1bb3vu3LnxIImr+x07dsTEiRPxzjvvwNnZGYULF0adOnUwatSouH2qVq2KJUuWYNu2bZg3bx6uX7+OmjVr4uXLl0m2ZfLkyfD29o67FeCXSyLKYOwikF+zRgI1Ly9gxAgbNoTSrFEjiVyCgqSqdK1akmZvirAwYMcOSQFo2FBSAMqXl6EXDx/qCvedPs2CiGQUNbVeZfVAvmVLqWdx8iRw+TL+/VcCYR+fuEz7dMPJSZcAkzC93iqBvNob362bvIBElIjNAvnU2LNnD77++mv88MMPOHnyJDZs2IAtW7Zg0qRJcfs0adIEH374IcqWLYtGjRph69atePHiBdasWZPkcUeOHInQ0NC42+3bt63xdIiIrMbmgXx0NDBmjKwPG2b5nFeyvKJFpSe+ZUuZ2/3jj2UWggkTgF27dAOVtVrgzh0Z575kCfDpp0C5cvLlvGFD2X/HDpk2z8sLaNBA0ukvXkxT4T7KfGzdI6/kyAmoWaJTpsSl1Vetmj7fxkmNk7d4IB8cLFk/APDZZxY6CVH6Z7MBJzlz5oSjoyMePnyot/3hw4fIkyePwceMGTMGH330EXr06AEAKFOmDMLDw9GrVy988cUXcDDwKenj44NixYrhalLzZwBwdXWFq6trGp4NEZF9s3kgv3ixfBv09WX14YzEy0vGA3/1lcw3/88/cgOkZ7JgQeDuXQn0DQkIAKpXB2rUkGXp0vI4olSIH8g7OFinI7dcOcDZWQrA3bgBBIwZI0NBli/HtedfAChi/2n1//wjn9GKIvVLXFwAFxc0d26IbWhs/UD+u+9k2ayZbrA+ESVis0DexcUFlSpVwq5du9CyZUsAgFarxa5du9CvXz+Dj4mIiEgUrDv+9w9fSWJO21evXiEkJAQfffSR+RpPRJSOvH4tM3cBSRQws0YD1KnLvvhCgj/KOBwcJNuiXTvpid+3T2537gDXr8s+Tk4S1AcEAGXLSuBerZpUyyIyk/hvp2zZrHNNyNVVgvnjx2VmzYB2b0kAumULqv/9JaZjCapWtXw7UkWrBaZMkb9fA9NJfuI4B/NxHFevltXbbtFA/vFjuagAAEOGWOAERBmHUYF869atjT7ghg0bjN538ODB6NKlCypXrowqVapg5syZCA8PR7du3QAAnTt3Rr58+TB58mQAQPPmzTFjxgxUqFABVatWxdWrVzFmzBg0b948LqAfOnQomjdvDn9/f9y7dw/jxo2Do6MjOnToYHS7iIgyErU33tHRRjH0nDkyjrpgQaB3bxs0gKyiWDG59ekjP9+6JV2UBQtKVymrTpOFubnJqJ0nT6yTVq966y0J5I8dk+tZGDcO2LIF779cgcIYjSpVilivMcZ69gzo3BnYskV+7tBBalRERcnt77/heOAAlqArPgk+AsAZABARoSt+Z5FAfu5cufJcqZIM1SGiJBn1X9Xb2ztuXVEU/Pbbb/D29kblypUBACdOnMCLFy9MCvgBmcru8ePHGDt2LB48eIDy5ctj27ZtcQXwbt26pdcDP3r0aGg0GowePRp3796Fr68vmjdvjq+++ipunzt37qBDhw54+vQpfH198c477+Dw4cPw9fU1qW1ERBnF8+eyzJ7dBlNwh4ZKjw8gvfIcxpR5FCwoNyIryp/f+oF8lSpS1kGdMx5vvYVHbzVDrmNb8G3WSciRY6n1GmOM48eBDz+UC22urhI8J6wM37cvYkqUQsUXp9DiwmQoylhoNMC1a3K3t7cFhmpFRMiFXwAYPtwG/7CI0heNklROehI+//xzPHv2DPPnz4/rBY+NjcWnn36KrFmz4ttvv7VIQ60pLCwM3t7eCA0NRdasWW3dHCKiNNm7F6hdGyheHLh0yconHzNG5osPCgL+/Zfjn4nIopo3lzppzZsDmzZZ55znz0t5Bw8PuXbp6Ags6HEMn/xcBVqNAxwuXzL/WO+oKJlffcUKIGtWIHdu3a1YMaByZenVVjuyrl+Xehbr1ummiwwMlJ8rVDB4iujlq+DcuQOi4YTQnceR891y+P13qW9ZsaJuaj2zmTtXpiYNCACuXGEWD2VKpsShJv+FLFq0CPv3748L4gEZpz548GBUr149QwTyREQZic0K3T18qCta9OWXDOKJyOLUKeis2SNfooQE8eHhMtlC6dLAhttvIR+a4T1li3z+LTVjr/zLl8AHH8hsD4D0ZCcxdTMKFpSqf2fP6rZpNNIjv2BBshUBnf/XDn/2XosmERvg1qcrcP4oQkIkxd7safWxscCMGbI+eDCDeCIjmDwZRkxMDC4Z6NK5dOkStAYKZRARkW3ZLJD/6iv5ZvvWW0CrVlY+ORFlRtWry7JSJeud09FRd75jx6Ru3JEjwHiMl40rVsiUaubw4IGkWO3YIVcP1q+XrvGtW2V6x8mTZdrG4sUlYL91S4J4BwegXj3ghx+kZsnq1SmX9ddosKjSD3iCHPAMPg18/XVcobsi5h72v2GD5O3nyCFzxxNRiky+3NWtWzd8/PHHCAkJQZUqVQAAR44cwZQpU+KK1BERkf2wSSB/4wYwf76sT57MsY5EZBWdOwMNGgBJzGRsMVWqyDCmY8eAt9+WFPsL7pWhrfceHLb8AQwaBPz+e9oyk65cARo3ljR5X18pVKdOZG9IWBhw6pQE/3XrArlymXzKnKVyo+++uViN9sCXX0L7VksA5czbI68ogJrR27evXKAgohSZHMhPmzYNefLkwfTp03H/v7KVfn5+GDZsGIZwmggiIrtjk0B+/HggOhp49125ERFZiZ+f9c+pxtPHjgGHD8t65cqAw5eTgB1/SdA9YAAwe7ZxFzYPH5Ze99u35XbnDnD1qlR0DwwEtm9PuVs8a1bpvU+DIkWAoWiLwfnXouqd9eh8ehDmYxcKFzbjxdl//pEXzs1NxsgTkVFMDuQdHBwwfPhwDB8+HGFhYQDAgnBERHbM6oH8hQvA8uWy/vXXVjopEZHtqIH8mTMSlwLSM4/y5eXzsH17KeaWPz8wYoThg8TGAr/9JmPFDx0yvE+VKlLF778ZnixNavRpMMlnOjY//gPVXu9GY2xD4cJNzHeSb76RZdeuuuJ8RJSiVFWSiImJwZ49exASEoKOHTsCAO7du4esWbPC09PTrA0kIqK0sXogP3q0DBJt3Vq+dBIRZXCFCsnw7qdPgTVrZNvbb/93Z9u2Mvn6wIHAyJFA3rwyBkB19648aPZsSZsHABcXqS1SsqQE/+qtRAkZ724laqf//tv+CO3yGXx+/BbfaoYjX56GAMxQwHTRIuDPP+U5DR6c9uMRZSImB/I3b95E48aNcevWLURGRqJBgwbw8vLC1KlTERkZifnqmEgiIrILVg3kjxyRHiUHB6nUTESUCWg0ct3yzz+B169lW1wgD0ha/d27Mhb844+l9/3+fWDjxngT0EOuBvTpI2PFrT3Q34DAQHluoaHArrdGou6PC1FaOQcsXwp07562gx8/Dnz6qayPH2/+KfqIMjiTL+kNGDAAlStXxvPnz+Hu7h63vVWrVti1a5dZG0dERGlntUBeUaS3CZDepqAgC5+QiMh+xK87V6CAdLzrmTJFKsrHxEgQ/MUXEsRrNFJuf948qTI/aZJdBPGADFvPn1/W/ziQDV9itPwwZoxMe5daT57IFHqRkcD778trQUQmMblHft++fTh48CBcXFz0thcqVAh37941W8OIiMg8nj+XZbZsFj7Rb78Bu3cDrq7Su0JElInED+T1euNVDg6SSh4aCvz1lxQCbdUKaN7cbgJ3Q4oUkXp727cDT9EXX2SdjRz3bgAzZwKjRpl+wJgYqRlw65b0wi9bZtXhAkQZhcl/NVqtFrGxsYm237lzB15eXmZpFBERmY9VeuRfv9aNbxw+HPD3t+DJiIjsT/xAvmrVJHZycZFidRERMvd7z552HcQDunHy9+8DUXDFsZb/FTGdMgV4/Nj0A44eDezaJdPMbdgAeHubr7FEmYjJgXzDhg0xc+bMuJ81Gg1evXqFcePGoWnTpuZsGxERpdHz5zKVMJCqKYSN9+23wM2bkoP5+ecWPBERkX3KnRsoXlzWk531TaNJ23zyVpZwlrvYNu2ASpWAly/l8z4yMuWDPHgALFkCfPghMHWqbFu0CChd2uztJcosNIqiKKY84M6dO2jUqBEURUFwcDAqV66M4OBg5MyZE3v37kUui35TtI6wsDB4e3sjNDSUU+sRUbq2YwfQsCFQuLBMQWwRt25JJeXXr4FVq4B27Sx0IiIi+3bhAnDtGvDee7Zuifls2CDD2VUXLwIl7u8G6tWTDblyAb17y83PT7Y9fy5T6B04IDn5J07oH3TECGDyZOs8AaJ0xJQ41ORAHpDp51avXo0zZ87g1atXqFixIjp16qRX/C49YyBPRBnF5MkyhLFdO4mxLaJdO5k6qVYtYM8e6W0iIqIM4exZoFw5Wddo5JqtqyuABQukMJ9aI8vZWa4c37gBnD+f+ECVKwNNmwLNmnFqUqIkWDyQz+gYyBNRRtG6tdSgmzYNGDLEAifYsweoW1cKFZ04AZQvb4GTEBGRrYSHA56esl6ggCRhxYmOln8ys2YBBw/qP7BoUaBGDRln0KSJjD0gomSZEoeaXLXe0dERtWrVwvr165E9XuWkhw8fIm/evAYL4RERkW0cPy7L+EWYzCYmRuZGBoBevRjEExFlQB4ekjF//74M09Lj7Ay0bSu348eBnTulUED16gzciSzM5EBeURRERkaicuXK2Lx5M0qVKqV3HxER2YeHD2XKII0GqFDBAif4+WfJucyWTdIriYgoQypSJIlAPr7KleVGRFZhctV6jUaD9evXo3nz5qhWrRp+//13vfuIiMg+qL3xQUGA2WcHffUKGDdO1sePB3LmNPMJiIjIXpQtK0sWmSeyH6nqkXd0dMSsWbNQqlQptGvXDqNHj0aPHj0s0T4iIkqlY8dkaZEOkunTpcu/cGGpVExERBnWuHFAxYqclITInpgcyMfXq1cvFC1aFB9++CH27t1rrjYREZEZWGx8/IMHMm88IGXxXVzMfAIiIrInvr5A9+62bgURxWdyar2/vz8cHR3jfq5bty4OHz6M27dvm7VhRESUeopiwR758eOljHGVKkCbNmY+OBERERGlxGzTz7158wYPHz6Ev7+/OQ5nU5x+jojSu9u3gYIFAScnICwMcHc304EvXgTKlAFiY4F//pG544mIiIgozUyJQ03ukU+Km5tbhgjiiYgyArU3vnRpMwbxADBypATx77/PIJ6IiIjIRowaI589e3ZcuXIFOXPmRLZs2ZKtTv/s2TOzNY6IKLOKiADGjJEper/4wvSq8xYZH79vH/D774CDAzBlihkPTERERESmMCqQ/+677+D137fImTNnWrI9RESZ3t27QMuWumB81SqZsv3dd40/hkXGx48YIcsePWROOyIiIiKyCbONkc9IOEaeiGzl+HGgRQvg3j0gRw7pib9xQ+7r1UuKxaf0saQoQPbswIsXwMmTQIUKZmjYsWNS3M7FRRrk52eGgxIRERGRyuxj5MPCwoy+ERFR6qxdK8PO790DSpYEjh4F/v0X6NtX7v/xRxnzfvhw8scJCZEg3tVV9jeLuXNl2bYtg3giIiIiGzMqtd7HxyfZcfEAoCgKNBoNYmNjzdIwIqLMZMkSoFs3WW/SRNLp1Quxc+bILG8ffwxcuwbUqydBf7Nmho+lpuSXLy9j7NPsyRNpEKC7qkBERERENmNUIL97925Lt4OIKNN69AgYNEjW+/UDZs4EHB3196lTBzhzRjrE//xT0u8XLQI6d058PLOPj1+0CIiMBCpWBKpWNdNBiYiIiCi1jArka9eubel2EBFlWqNGSSp8hQqGg3iVp6cUjf/4Y2D5cqBLF+DhQ2DYMP39zFqxPjYWmDdP1vv2BVLIziIiIiIiyzMqkDckIiICt27dQlRUlN72smXLprlRRESZxdGjUpEekBT6pIJ4lbOzpOHnzg1MmwYMHy5j4kePBvLnl7j7xAnZ1yw98n/+KcXtsmUD2rc3wwGJiIiIKK1MDuQfP36Mbt264c8//zR4P8fIExEZR6uVVHpAUuSrVzfucQ4OUr0+d27pjV+wAFi4EGjVCmjcGAgPBzw8gBIlzNBItchd9+5AlixmOCARERERpZVRVevjGzhwIF68eIEjR47A3d0d27Ztw9KlS1G0aFFs2rTJEm0kIsqQFi+W8exeXsDUqaY/fuhQ6TCvU0d64tetkyneARnOnlLvfoquXgW2bZN0+j590ngwIiIiIjIXk3vk//77b/z++++oXLkyHBwc4O/vjwYNGiBr1qyYPHkymiVVRpmIiOI8fw6MGCHrEyYAefKk7jiNG8vt33+l83z5ciAiAnj3XTM0Uh0b36QJULiwGQ5IREREROZgco98eHg4cuXKBQDIli0bHj9+DAAoU6YMTp48ad7WERFlUGPHyqxuJUvq0uvTokwZYP584O5dYMcO3UWCVIuIkGr1AKecIyIiIrIzJgfyxYsXx+XLlwEA5cqVw4IFC3D37l3Mnz8ffn5+Zm8gEVFG8+AB8MMPsv7992aa6/0/Pj5A/fqAq2saD7RqlZTSDwyULn8iIiIishsmp9YPGDAA9+/fBwCMGzcOjRs3xi+//AIXFxcsWbLE3O0jIspw/vlHCt1VqGCmFHhLWLBAlp98ItX1iIiIiMhumBzI/+9//4tbr1SpEm7evIlLly6hYMGCyJkzp1kbR0SUEe3dK8tatWzbjiSdPi3z4jk7A1272ro1RERERJRAqueRV2XJkgUVK1Y0R1uIiDIFuw/kf/xRlq1bA//VRCEiIiIi+2FyIK8oCtatW4fdu3fj0aNH0Gq1evdv2LDBbI0jIsponj4Fzp2T9Zo1bdsWg8LDgRUrZL1XL9u2hYiIiIgMMjmQHzhwIBYsWIC6desid+7c0Gg0lmgXEVGGtH+/LIOCAF9f27bFoFWrgJf/b+++w6Oovj6AfzchpCcQSkggELogoRggUgQUkKL0DtIMSK8iRQgBUYJ0aaJSlSJF4FVA+EGUHopUQYz0ngDBEAikz/vHcXdZElJ3d3aT7+d58szs7OzMWSYDnLn3nvsEKFdOJqgnIiIiIouT5UT+hx9+wJYtW9CyZUtTxEOkuufPgchIwNdX7UgoNzp4UJYW363+o49Y5I6IiIjIQmX5f2nu7u4oU6aMKWIhUl1cHBAQIDNuff+92tFQbqQdH2+R3epfLHLXu7fa0RARERHRK2Q5kZ8yZQqmTp2K58+fmyIeIlV98QXw55+AogCBgcCePWpHRLnJkyfAqVOybpEt8ixyR0RERGQVsty1vnPnzli/fj2KFi0KX19f2NnZGbx/Svu/VCIrc+4cMGOGrL/xhiRcHTpIC2r16qqGRrlEWBiQnCzDNnx81I7mJSxyR0RERGQ1spzI9+7dGydPnsQHH3zAYneUayQnA/36AUlJQLt2wPr1QPPmwL59QMuWwNGjQMmSakdJ1s6ip51jkTsiIiIiq5HlRH7Hjh3YvXs36tevb4p4iFTx1VfAiROAuzuwaBFgbw9s3QrUrw9cuCBJ/eHDQMGCakdK1syiE3kWuSMiIiKyGln+35qPjw/c3NxMEQuRKq5eBSZNkvXZswFvb1kvUAD49VegeHHg4kWgTx+1IqTcIC5O6sgBFpjI37kjwWk0QK9eakdDRERERBnIciI/Z84cjB07FtevXzdBOETmpSjAgAEy5VyjRlLg7kU+PsCOHUC+fMDPPwOhoaqESbnAiRNAfDzg6Sm91y3K7t2yrF1bAiQiIiIii5blrvUffPABnj17hrJly8LJySlVsbtHjx4ZLTgiU/v1V2DvXsDBAfjuO2mQfFm1asCgQcDChcDHHwMnTwK2tuaPlazbi93qLa60yK5dsmzWTN04iIiIiChTspzIz58/3wRhEKlj715Z9u6dfivp5Mkyr/zZs1LYm1NsU1ZZ7Pj4pCT9PIvNm6sbCxERERFlSpYS+cTEROzfvx9BQUEoXbq0qWIiMpvDh2WZUXJVuDAwcSIwdqwsO3UCnJxMHx/lDklJmf9dM7sTJ4DoaKnkWKuW2tEQERERUSZkaYy8nZ0dfvrpJ1PFQmRWz57JXPEAUK9exvsPGwaUKiV1webONW1slLucPi3TtBcoAFSponY0L9F2q2/aVIpBEBEREZHFy3Kxu7Zt22Lbtm0mCIXIvI4fl5bSEiUyN0e8gwMwY4asz5gBRESYNj7KPQ4elOVbb1ngzG4cH09ERERkdbLc/FK+fHl89tlnOHz4MPz9/eHs7Gzw/vDhw40WHJEpHToky3r1Ml98rEsXYN48eQgQHAx8843p4qPcY/9+Wb71lrpxpPLwoXStB5jIExEREVkRjaIoSlY+kN7YeI1Gg6tXr+Y4KLXFxMTA3d0djx8/hpubm9rhkIm0aCGNkQsWSLf5zDp0SN+yeuEC8NprpouRrF9ystRYiI6WB0AWNQz9xx+Bbt0APz/g3Dm1oyEiIiLK07KSh2a5Rf7atWvZDozIUiQnA0eOyHr9+ln7bP36wPvvA9u3A0uWyIMAolc5d06SeFdXoEYNtaN5ibZbPavVExEREVmVHI3WVBQFWWzQJ7IIFy4AMTGAi4s0RmaVdgTJ6tXA06fGjY1yl337ZPnWWxZWSy4lhYk8ERERkZXKViL//fffw8/PD46OjnB0dETVqlXxww8/GDs2IpPRjo+vUyd7yVXjxjLvfEwMsH69cWOj3EWbyDdqpGYUaTh3DoiMlHkUMzNtAxERERFZjCwn8nPnzsWgQYPQsmVLbNy4ERs3bkTz5s0xcOBAzJs3zxQxEhmddk7v7OYvNjbAoEGyvmQJwI4plJbkZODAAVm3uER+925ZvvMOYG+vbixERERElCVZTuQXLlyIr7/+Gl9++SVat26N1q1bY+bMmViyZAkWZGOw8OLFi+Hr6wsHBwcEBATg+PHj6e4/f/58VKxYEY6OjvDx8cGoUaMQFxeXo2NS3qNtkc/q+PgX9ekjU9KdOQMcO2aMqCi34fh4IiIiIjKFLCfy9+7dQ926dVNtr1u3Lu7du5elY23YsAGjR49GcHAwTp06hWrVqqFZs2a4f/9+mvuvW7cO48ePR3BwMC5evIjly5djw4YN+PTTT7N9TMp7bt0Cbt4EbG2BgIDsH8fDQ6ajA6RVnuhlFjs+/skT/dMsJvJEREREVifLiXy5cuWwcePGVNs3bNiA8uXLZ+lYc+fORf/+/dG3b19UrlwZS5cuhZOTE1asWJHm/keOHEG9evXQvXt3+Pr64t1330W3bt0MWtyzekzKe7Td6qtXl2J3OTF4sCw3bgSionJ2LMp9LHZ8/O7dQFISULas/BARERGRVclyG9HUqVPRpUsXHDhwAPX+G2B8+PBhhIaGppngv0pCQgJOnjyJCRMm6LbZ2NigSZMmCAsLS/MzdevWxZo1a3D8+HHUrl0bV69exc6dO9GzZ89sHxMA4uPjER8fr3sdExOT6e9B1ien4+NfVKsW8MYbwKlTwMqVwJgxOT8mWRdFAZ49A5ydDbdb7Pj4GzeAoUNlvW1bVUMhIiIiouzJcot8hw4dcOzYMRQuXBjbtm3Dtm3bULhwYRw/fhzt2rXL9HEePnyI5ORkeHp6Gmz39PREREREmp/p3r07PvvsM9SvXx92dnYoW7YsGjVqpOtan51jAkBISAjc3d11Pz4+Ppn+HmR9jDE+Xkuj0bfKL10qM3pR3vLpp0CBAsCOHYbbLXJ8fEwM0KqVVKuvVg2YMkXtiIiIiIgoG7I1/Zy/vz/WrFmDkydP4uTJk1izZg1qmOF/qvv27cP06dOxZMkSnDp1Clu2bMGOHTswbdq0HB13woQJePz4se7n1q1bRoqYLE1MjCRYgPFm3OraFXB3B65cAfbsMc4xyTo8egR89ZX0Uh8yRFrmtSxufHxSkvyy/vkn4OUF/PJLzseWEBEREZEqspXIG0PhwoVha2uLyMhIg+2RkZEoVqxYmp8JCgpCz5490a9fP/j5+aFdu3aYPn06QkJCkJKSkq1jAoC9vT3c3NwMfih3OnpUWs1Llwa8vY1zTGdnqWAPAF9/bZxjknX47jvg+XNZv3ED+PJL/XsWNz5+9Gjg118BR0fg558B9jwiIiIislqZTuRtbGxga2ub7k++LDQ75c+fH/7+/ggNDdVtS0lJQWhoKOrUqZPmZ549ewYbG8OQbW1tAQCKomTrmJS3GHN8/Is++kiWO3aw6F1ekZQELF4s69pRRV9+KT0zLG58/MKF8gMAa9YANWuqGw8RERER5UimM++tW7e+8r2wsDAsWLAAKVkcIDx69Gj07t0bNWvWRO3atTF//nzExsaib9++AIBevXqhePHiCAkJAQC0atUKc+fORY0aNRAQEIDLly8jKCgIrVq10iX0GR2T8q4nT/TjmI2dyFeuLOOgT58GNm0CBg5MvU9iIhASIj0B+vaV6e/Iem3bJlMZFikCrFsnQ8/37gVGjQKmTrWQ8fHJyUBQkPziAbJs317FgIiIiIjIGDKdyLdp0ybVtvDwcIwfPx6//PILevTogc8++yxLJ+/SpQsePHiAyZMnIyIiAtWrV8euXbt0xepu3rxp0AI/adIkaDQaTJo0CXfu3EGRIkXQqlUrfPHFF5k+JmXOrVvSA7dwYbUjMY7t26Uo3a1bgJ0d0LSp8c/Rvbsk8mvXpp3If/89EBws60uWyM+bbxo/DjKeTZuA1auB+fOBcuUM3/vqK1kOGAA4OEiDt5+fDD1PSJD3VB0f//ix/FLu3Cmvx48Hxo1TKRgiIiIiMiaNoihKVj909+5dBAcHY/Xq1WjWrBlCQkJQpUoVU8SnipiYGLi7u+Px48d5crx8RARQoYK0HP/1F2CjWiWFnIuIAIYPl4QMkLHx334LNGli/HPduSPDjhUFuH4dKFVK/56iSJHwP/+UP09t55X+/aWRtFAh48dDOZOYKNfw3j2Zaj0sTFrfAZlu0N9fkvQbN/T1FsaOBWbN0h9j5kzgk0/MHzv+/hto0wb45x95yrBiBdCtmwqBEBEREVFmZSUPzVKK9vjxY4wbNw7lypXDhQsXEBoail9++SVXJfEE7Nol3dDDw4EzZ9SOJvsOHwYqVZIk3tZWEqo//zRNEg8AxYvrx0OvX2/43u+/y7mdnYGLF4HevWX7d98Br70m28iy7NghSTwg495btdJXpde2xnfubFg0MShICsJrqTI+fscOICBAkngfH7kRmMQTERER5SqZTuRnzpyJMmXKYPv27Vi/fj2OHDmCt956y5SxkUpenELt11/ViyMnrlyRBsnoaOCNN4ATJ6R11NnZtOft3l2Wa9cabtcmfr17S2+HVaukGFrlysDDh8CYMaaNi7Lu229l2bkz4OEBHDsm1/fuXeDHH+W94cMNP+PqCsyeLesFCph5fLyiSPeOVq1knsW33gL++ENuACIiIiLKVTLdtd7GxgaOjo5o0qSJrrBcWrZs2WK04NSSl7vWp6RIi+L9+/K6fn3g4EF1Y8qqf/8F6tSRHgX+/sD+/aZP4LWiowFPTxkjfe6cjJm+cgUoX17yrL//BipW1O9/6ZL0GkhOlj/n+vXNEyel78YNGYahKHKNIiOBxo2B+HjA11eGTgQEyHSGL1MUeVBTurQZW+RjY4HAQGDDBnk9aJAM7M+f30wBEBEREVFOmaRrfa9evdC5c2d4eHjA3d39lT9k3f78U5J47f//w8IkObUWCQlAhw6SxJcoIdNlmyuJB6QV9r33ZF3bKr9woSR3LVoYJvGAJPj9+sn6hAmyH6lv2TK5Fo0bS5G7evVk1jaNRpJ4ABgxIu3PajQyK4HZkvgbN+QJ0IYNUsnxm2+kkiKTeCIiIqJcK1vF7nK7vNwiP3u2jCVv2RK4elVakDdtAjp2VDuyjCmKFI9bvhxwcQEOHZICc+a2eTPQqZMMTz53DihZUmoO7N4NvPtu6v3v3JFkMS5Ohje3bGn+mEkvKUmu2b17kht37qx/b948YPRoeUh09arkzaq6e1e6nUREAEWLAj/9xG4dRERERFbKZMXuKPfTjo9v2hRo3lzWd+1SL56smDdPkngbGxnDrEYSDwDvvw+4uclUd/36SRJfqdKrp7wrXhwYNkzWP/1UX9Ge1KEtclekCNC2reF7o0bJPfLbbxaQxCcmAl26SBJfubKMh2cST0RERJQnMJEnnbg4KcAGSNLZooWs79pl+V2+FQX4/HNZnztX371dDQ4O0r0fkAZSQLphazSv/sy4cZL8nz2rH+ZM6tAWuevbN+3e6U2ayJAI1U2YIN1O3NyAbdukCwgRERER5QlM5Enn8GFJ5r29pYGvQQPA0VG6fp8/r3Z06Xv0SIrcAcCAAerGAuir1wNAwYJAz57p71+okMxBDsgUZomJpouNXu3mTf1MDdraBRZpyxZgzhxZX7nSQp4sEBEREZG5MJEnHW23+iZNpPXYwQF4+23ZZunT0F27JksvL4lbbW+/rZ9P/KOPACenjD8zYoQMc75yRYYIkPktXy69O955x4Jz40uXpLsAAHz8MdC+vbrxEBEREZHZMZEnnRfHx2tZyzh5bSJfurS6cWjZ2kq1+k6dMj9HvIsLMGmSrE+ZAjx+nPnzKYoMlabsS0rSP0D56CN1Y3mlZ8+k8mRMjIyHDwlROyIiIiIiUgETeQIAPHwInD4t602a6LdrE/lDh6Rom6WytEQekHHyGzcChQtn/jMDBgAVKsi85ZMnZ/5zQ4dKDwCOr8++I0dkGEmhQqmL3FmMiRNlKoSiRfXTzRERERFRnsNEngAAoaHSquvnBxQrpt9evjxQtqyM2f7tN/Xiy4glJvLZkT8/sGiRrC9aBJw5k/FnfvpJpg0HgGnTLL8woaXS1oGoWxewt1c3ljRduCDdPABg9WopZkFEREREeRITeQKQdrd6LWvoXp9bEnlArkHnzjIN3eDB6U9Hd/s20L+//vWFC/JQhrLur79kWamSunGkSVGkiEJysnQX0N6URERERJQnMZEnKEr6ibw1TEOXmxJ5QKbQc3EBwsKAVavS3iclBejdW6r1+/sDAwfK9nnzzBZmrnLxoiwrV1Y3jjRt2yZPaOzt9dXqiYiIiCjPYiJPuHRJpt3Kn1+mnHtZo0by3vXrQHi4uaPLWEqKxAbknkS+eHEpeAfItHRRUan3mTNHhjs4OQFr10oBc40G2LnTMq+TpbPYFvnnz4HRo2X9k0+AMmXUjYeIiIiIVMdEnnSt8fXqpT1NmrOzPsHfvt18cWXWvXtAQoJUii9RQu1ojGf4cOD11yWJ//RTw/dOnZK6ZwDw1VdAxYpAuXJAq1b6bZR5//6rr/pvcYn87NnypKpECWD8eLWjISIiIiILwESe8MsvskyrW72Wtoq3JVZF13arL1kSyJdP3ViMyc4O+PprWf/2W8DHR3oclC8v85wnJgLt2gGBgfrPjBwpy9WrgUePzB6y1dJ2qy9RAnB1VTcWA7du6aeYmz1bnqoRERERUZ7HRD6Pu30b+N//ZL1z51fv16mTtHj/8Yd0xc+szZuBrVtzFmNGctv4+Be99RbQr5+s374tDbOXL8sc8yVKAN99J93ptRo1AqpVk+nGv/tOjYitk7ZbvcWNj//kE+la36BB+jcoEREREeUpTOTzuO+/lwJ2DRrINHOvUrSofn759eszd+y7dyX36NwZiInJeayvcvWqLHNjIg8AS5dKNfqTJ4Fjx4BDh4B9+4DTp2XO8xdpNPpW+UWLpNWeMqZtkbeobvXHj0sXGBsbGSvx4hMbIiIiIsrTmMjnYYqir4jet2/G+3fvLst16zJXvV47N31SUtZa8bMqN7fIA9ITonJl4I03gNq1pZZBw4ZA4cJp79+1qzx4uX1b5pinjFlki3xQkCx79QKqV1c1FCIiIiKyLEzk87AjRyTBdnYGOnbMeP+2bQEHB6mIfuZMxvvv3atfN0ciz2LewsFB5p8HgPnzVQ3Falhci/yBAzLmxc4OCA5WOxoiIiIisjBM5POwlStl2amTzFmeETc34P33ZX3duvT3VRRpkdfK1S3yV69KP/ZOnYAxY6SkfGa6LJjQwIHSI/vYMZlakF7t6VPgxg1Zt4gWeUUBJk2S9X79AF9fVcMhIiIiIsvDRD6Pio3VV6DPTLd6LW33+h9/lPnbX+Wff4A7dwxfm0JCgnQhB8ycyF+6JBO3v/aaFBcYNkwq+82ZA/j7S9PutGnAlStmDErP0xN4801Z//VXVUKwGuHhsixSJHXNAVXs2QMcPAjY2+vnGCQiIiIiegET+Tzqp5+kJbJMGamMnlktWkjL/O3bUnTtVbSt8drp4EzVIn/zpjRgOjnJuHCzOHAAqFkTmDtXssB8+aRc/LRpUtlPO/5g8mSZK27QIFXmgmvZUpZM5NNnUePjX2yNHzwYKF5c3XiIiIiIyCIxkc+jtEXu+vTJWjFsBwegQwdZT697vTaRb9dOlqZK5LXd6n19zVTU+//+D3j3XSnDX6cOsGkT8PAh8PvvkoBt2ABERspE7k2bSmK2dClQoQKwbFn63RiMrEULWe7dC8THm+20Vseixsf/8gtw4oQ8mRo/Xu1oiIiIiMhC5VM7ADK/a9ck79RogN69s/757t1lfP2mTcCCBUD+/IbvJyfL8QFgwADZ79EjICrK+F2XzTo+fsUKoH9/ScZbt5bxBY6Oqfdzc5NK4716Afv3A0OGyPxx/ftLMt+1qxxD+5OQAERHy8+//8ok8eXKyZj7Ro2kbH02VK8OFCsGRERI74nGjXPw3XMxi2mRT0nRV6ofMcKMXUyIiIiIyNowkc+DVq+WZePGQMmSWf/822/LGOzISBnO+957hu+fOSP5qJubTJNWvLiMl790yYoT+S+/1LeQ9u0LfPutftxAeho2lAnfFy2S6uPHjslPRkJDgW++kWSuY0egSxcZA5GFbgc2NkDz5tL7YudOJvKvom2RVz2R37QJOHdObpwxY1QOhoiIiIgsGRP5PCYlJWtzx6fF1lbyygULgPXrUyfy2m71DRtKrlu+vD6R1xZgMxazJPLr1+uT+HHjgJCQrPXjt7MDRo2SP7TZs6WJ3MZG/2NnBxQoABQsKEsXFyl2tmULcP8+sGSJ/FSsKOPte/eW/TKhRQu53r/+KnX4yFB8PHD5sqyr2rVeUeR3AwBGjwY8PFQMhoiIiIgsHRP5POb8eZlqy8VF5oXPrm7dJJHfsgW4ft1whixtIq9tAS5fHti3zzSV602eyD96BIwcKesTJgDTp2f/WN7eUiAvM3r1kuQ9NFTG3W/eLAX0Ro6UOLp3l+7Xfn7pHqZpU3nwcvFi6utE8nApJQVwdwe8vFQM5Ngx4I8/pFL94MEqBkJERERE1oDF7vIYbevj669LPa3sCggAGjQAnj+XOcu106bHx0tjMqBP5CtUkKUpCt6ZPJEfN05axStXBqZMMdFJXsHOTvrGr1wJ3L0riX2VKvKHvnw5UK2adKvQzr+XhoIFpSYfwOr1adGOj69UyUzFEl9l4UJZdu0q8+AREREREaWDiXwec/WqLMuUydlxNBoZJm5vD+zeDaxdK9uPHpU809NTHhYA0iIPGD+Rf/oUePBA1k2SyB88KMXpABmv/nJVP3NydZVu9efOSVwdOsjTk1Wr5EnJxIlSST8NnIbu1SxifHxEhIyPB4Bhw1QMhIiIiIisBRP5PEabyBsj8a1YUaZKB6TH94MH+m7177yjb+F8MZHXttwbg7Y1vmBB6RptVAkJUnIfkGrz9esb+QTZpNFILJs3y1OT+vXlycn06UDZssCHH8q8gJGRuo9op6ELDQXi4lSK20K92CKvmm+/BRITpeuEv7+KgRARERGRtWAin8cYq0Ve65NPgKpVZWq5UaNSj48HJL/UaIAnTwzyyxwzabf6WbOkubZoUWDGDBOcwAgCAoADB4CtW6VV/uFD6Ybfo4fMO+fnB8yfj2pVFXh5Ac+e6Yc9kFC9RT4hAVi6VNaHDlUpCCIiIiKyNkzk8xht8musRN7OTnqf29hI9/qwMNn+YiJvbw+UKiXrxuxeb7JE/vJlYNo0WZ83z7IriGs0UrXw/Hlg1y55slKjhrx3/jwwahQ048ehRXPpCrFzp3qhWpqkJKkfCKjYIr9lC3Dvnjx46dhRpSCIiIiIyNowkc9DkpOlcjlgvEQeAGrV0hd2VxQ59svV0U0xTt5kifywYVK17913pTy/NbCzA5o1A2bOBE6dkgJ9ISHy3qxZGPtoHACF4+RfcO2aNIg7OuofNJmdtsjdgAHq1mAgIiIiIqvCRD4PuXtXEpd8+YASJYx77M8+0yfvL7bGa2kr1xtzCjqTJPJhYdKynS8fsHixyqXMc6BIEWD8eGDRIgBAxf+bhVmacQgPV3TDK/I67fj4116THiVmd+oUcOSI/K5p6zEQEREREWUCE/k8RJvAlSolc4sbk7Oz1F/r2FF6d7/MlC3yxuxdoOtS36sXUK6cEQ+skiFD5IEEgDHKLHyJcdj1qxErDlox1cfH//eQBR07qjyJPRERERFZGybyeYhJEt8X+PvLLFrapP1Fxk7kFcUELfJ//CFztNnaAp9+aqSDWoDBg3XJ/FjMgsvapSoHZBlUrVh//77MLgBwyjkiIiIiyjIm8nmIsSvWZ8WLiXxKSs6PFxUl88gDRhzfrG2N79FDSu3nJoMH48+eXwIA3j8RLFMI5HF//ilLVVrk58yROgy1asm0c0REREREWcBEPg9RM5H39ZWhwHFxwJ07OT+etjXe2xtwcMj58XDmDPDzzzImPje1xr/A6dNRuIRy8Eh6gOS589UOR1XPn+sT+Zo1zXzyqChdDwlMmmS9dRiIiIiISDVM5PMQbSJvknnXM2Bnpz9vTrrXR0cD+/cDq1bJa6N9l88/l2XXrkDFikY6qGUpXcEOn9v/9z1nz5Z55/Oo06dlFodixYxf+DFD8+cDsbFAtWpAq1ZmPjkRERER5QZM5PMQU4+Rz0hOxslPmSJd6AsWBBo1ApYske1GGd98/jzw00+yPnGiEQ5omWxsgMs1OuE0qsP2aQwwY4baIanm+HFZ1q5t5gbx6GhgwQJZDwpiazwRERERZQsT+Tzi2TMgIkLW1UrkszsF3bVrwNSpwM2b8rpUKaB1ayA4WD+sPUe++EKWHTsCr79uhANarqrVbTAB/80vv2gRcPu2ugGp5MQJWdaqZeYTL1wIxMTI71m7dmY+ORERERHlFvnUDoDMQ9saX6CAtGqrIbst8mvWyLJhQ2DbNvkORnPxIrBhg6xPmmTEA1umqlWBpWiGPz0awO/RAXlC8t13aodldi+2yJtNTAwwb56sT5yo0uT1RERERJQb8H+SeYSa4+O1spPIKwrw/feyHhho5CReUWTqL0UB2raVMcu5nHxFDSbZ/Ncqv2IFEB6uZkhm9+gRcPmyrJu10N2SJcC//0rXlM6dzXhiIiIiIsptmMjnEWqPjwf0XeuvXAGSkjL3mWPHJOlydjZBT+QffwRCQ6Xs/Zw5Rj64ZfLzk+XPD+sioVkrmQswD/REeJG2W3358oCHh5lOGhur/x2bOBGwtTXTiYmIiIgoN2Iin0eoOfWclo8PYG8PJCbqx7tnRNsa37494OJixGCio4HRo2V94kR1/2DMyNVV/1XPdPpCiq1t3ixDDPIIbbd6s46PX7pUZgkoUwbo3t2MJyYiIiKi3IiJfB5hCYm8jQ1QtqysZ6Z7fXy8fvh6r15GDmbSJKn+V7Ei8MknRj64ZataVZZhT/1kSAEAzJ2rWjzmpm2RN9v4+MePgZD/hjJ8+imQj6VJiIiIiChnmMjnEZYwRh7Qd6//+++M9925U8Yze3sDb79txCD++EM/f92SJdJNIA/RlgI4exbAmDHy4vvv9dMa5GKKokKhuy+/BKKigNdeA3r3NtNJiYiIiCg3YyKfByiKZYyRB/StwRMnAqtWSWyvou1W/8EHRhxSnJwMDBwoJ+7RA3jnHSMd2Hpor8G5cwDq1gXq1AESEoDFi1WNyxxu3QIiI6VRvHp1M5zwzh1g/nxZDwlhazwRERERGQUT+Tzg/n2ZR16jkTnY1TRypOTOsbFA376SS8fEpN4vKgrYsUPWe/Y0YgBLlwInTwLu7nmmwN3LtC3y58//V3RQ2yq/ZIlcmFxM2xrv5wc4OprhhFOmAM+fywOTNm3McEIiIiIiyguYyOcB2m71Pj5A/vzqxlKwIPC//wFffCGt7OvXAzVqAGFhhvtt2CBF8WrUAKpUMdLJL18Gxo+X9enTAU9PIx3YupQuLYUD4+P/q1XQpo0UL3j0SLpJ5GJm7Vb/118yvR8AzJolT9KIiIiIiIyAiXweYCnj47VsbaXm14ED0kPg6lVpsHzrLUns4+OBH36QfY1W5C4xUaqFP30KNGgADBhgpANbHxsb/TR0Z89CLoi2gv/cuTL8IJcya6G7CRNker+2beUXnIiIiIjISJjI5wGWULE+LXXrAmfOSLJuawscOiS5dokSwNGjsq1bNyOdbMoUyeIKFADWrMnz83hrx8mfPfvfhj59gEKF5Jdl2zaVojKt5GSpcwiYYeq5Q4eAn3+WpybTp5v4ZERERESU1zCRzwMspdAdbt0Cli0Dxo0DTp0CIHn16tXAjRuSa3t7y3TbAPDuu0bq/b5vn376r+++kzEGeZx2nPy5c/9tcHICBg+W9Vmz0q9CaKX+/ls6ZDg7A5Urm/BEigKMHSvrgYFApUomPBkRERER5UVM5PMAs7fIK4pUqzt5Eti8WSrcVa4MlCwJ9O8PzJwpfZuDg6VaOoDixeXl9evATz9JTvnVV0aI5dEjKXuvKJJUdexohINav1Qt8gAwZIhMxXfsGHD4sCpxmZJ2fLy/v4k7ZGzbJkUfHB3l6RQRERERkZFxLqQ8wOSJfEqKJH+bNwN798oJnz5NvZ+NDRAQIBXjd+0CPvtMuh+vXq3LLO3sgPbt5SfHFEUeHNy5A5Qvr58GjHRj5O/ckWcuhQpBuj/06iW9FqZNA3bvVjVGYzNLobukJBkbD0jdAW9vE56MiIiIiPIqtsjncvHxwO3bsm70YncnTwIjRkhLe926Uijt3Dl9El+smMxR3r8/sGmT9Jk/cgT49VcpS1+okAySr1kTmDHD+N25V64EtmyRpwPr10updgIAuLnpfx903esBSULt7GRqgX371AjNZLSJvEnHx69YAYSHy++2tns9EREREZGRMZHP5W7elPzYyQkoWtRIB01KAiZOlIxowQJp1nV1lUp1mzbJYORnz4B79yRx//Zb6dJesKD+GJ07y0TmbdpIRfkJEyTxMVYyf+2aPGQApHXZ3984x81FUo2TByS7799f1idOzDVj5ePi9N/TZC3ysbEyPgQAgoLkaQkRERERkQkwkc/lXuxWb5RprG/cABo2lErciiIJ+s8/A/fvA2vXyuuKFWV8cEaKFQO2btUPhp89W+Z5z2nymJwM9O4tPQPq1wfGjMnZ8XKpNMfJA8CkSXL9jhwBdu40e1ymsGyZPH8qUkSmPDSJefOAiAh5GDJwoIlOQkRERERkIYn84sWL4evrCwcHBwQEBOC4tg9sGho1agSNRpPq57333tPt06dPn1TvN2/e3BxfxeIYdXz8li1A9eqS4Lm5ARs3Sgt8q1aAg0P2jqnRAMOHA4sWyeuZM2WS+Zwk83PnAgcPSlf61avz/FRzr6JtkT99Wsoc6Hh5yTUBENlvIqpUTkFAgEw6YG0SEoBBg4Bhw+T1Bx8Y6YHWyx48kN9dAPjiCykaSERERERkIqoXu9uwYQNGjx6NpUuXIiAgAPPnz0ezZs0QHh6Oomn0Bd+yZQsS/qt0DgBRUVGoVq0aOnXqZLBf8+bNsXLlSt1r+zz6H2ttIp/j8fHz5wOjRsl6QICMOTfmoPshQyR5HzZMxsvb2ACff571rOvcOWlRBqSFVPU59yyXNpE/c0amAfT3l9ESJUoAew+NxQ/4Gp4RZ1ElYiM2oCvq1JH6d6+/rmbUmXf3LtChA3D0qPwaTZ0qowVMYto04MkT4I03gC5dTHQSIiIiIiKhURR1B8EGBASgVq1aWPRfi2xKSgp8fHwwbNgwjB8/PsPPz58/H5MnT8a9e/fg7OwMQFrko6OjsW3btkzFEB8fj/j4eN3rmJgY+Pj44PHjx3CzwnGuKSlSp2zlSpnK7flz6b3+XyNr1l28KC3xCQnAxx/LnOx2dkaM+AULFujHtjdrJlPXvfuuJPYZiY+XAdDnzkkvgf/7PxM1v+YOiiIjEDZvlt+Rl03C55iGIDwuUg5vFfoLf/5thwIFZCTFW2+ZPdwsOX4caN0aiIyUhxRr1wItW5roZFeuyFzxiYnAnj1AkyYmOhERERER5WYxMTFwd3fPVB6qatf6hIQEnDx5Ek1e+I+vjY0NmjRpgrCwsEwdY/ny5ejatasuidfat28fihYtiooVK2LQoEGIiop65TFCQkLg7u6u+/Hx8cneF1KZogBffgmULQs0bgysWSMJWpUqQNu22TxocjLw4YeSxLdsCcyaZbokHpCnDV99JQn47t1AixYyB/3ixWlPaad1+7aMSz53DihcWKZQYxKfLo0G+P57ICZGxskvXy5/hE2bSgmEjy6MAIoUgfuDywgbuBp16wLR0fL+li1qR5++AQMkiffzA06cMGESD0hhu8REeeDEJJ6IiIiIzEDVFvm7d++iePHiOHLkCOrUqaPbPnbsWOzfvx/Hjh1L9/PHjx9HQEAAjh07htovlKL+8ccf4eTkhNKlS+PKlSv49NNP4eLigrCwMNimMV46t7TI798PNGok625uQLduQN++0kid7Zx23jyZD9vNDbhwQfpdm8Ply5K8r1ghmSYg447r1gXeeUd+qlWTqeyWL5fp0rQDvbdsAdq1M0+cuZ12SEXx4nh++m906++i6+iwcydgiaUnoqP1EyTcuyc1FU3m7FnprQIAp04BNWqY8GRERERElJtlpUVe9THyObF8+XL4+fkZJPEA0LVrV926n58fqlatirJly2Lfvn1o3LhxquPY29vnijH0v/0my/fflzp0mSkcn67Ll/WDimfPNl8SDwDlyslDhM8+k4J1CxcC//wD/P67/AQFpf5MgwbSLZ9JvPEMHCjJ/I0bcJw6Hps3L0K3btIdf9Mmy0zktbUyy5QxcRIP6O+PLl2YxBMRERGR2ajatb5w4cKwtbVFZGSkwfbIyEgUy+B/4LGxsfjxxx8RGBiY4XnKlCmDwoUL4/LlyzmK19Lt3y/L1q2NkMSnpMh84s+fSz/9fv1yHF+2uLoCQ4fK3PQXL0orfYcOgIeHvO/tLVXu//lH/gDat1cnztzKwUHmbgOAxYuR79A+NG0qLx88UC+s9GhH5bzQycc0Dh8GduyQWRE++8zEJyMiIiIi0lM1kc+fPz/8/f0RGhqq25aSkoLQ0FCDrvZp2bRpE+Lj4/HBBx9keJ7bt28jKioKXl5eOY7ZoiQm6gYrx8VJdW5A370+R779VirmOTlZxnhzjQZ47TVg8GBpDn7wQOa0v3FDpvsqX17d+HKzJk2Ajz6S9Q8/RDHXWADqJfLXr+t7n6TFLIm8osgDJEDGr1SoYMKTEREREREZUn0e+dGjR+O7777D6tWrcfHiRQwaNAixsbHo27cvAKBXr16YMGFCqs8tX74cbdu2RaFChQy2P336FJ988gmOHj2K69evIzQ0FG3atEG5cuXQrFkzs3wns0hKkqmuOnQAdu/G0aNStN3bW3ql58itW8Ann8j6jBnGnWbOWGxsgJIlgXxWPTrEesyaBfj4ANeuoeZPcj8+fGj+MBITgbfflk4iaZXQSEnRb3/zTRMG8r//AQcOSN2G4GATnoiIiIiIKDXVE/kuXbpg9uzZmDx5MqpXr44zZ85g165d8PT0BADcvHkT9+7dM/hMeHg4Dh06lGa3eltbW5w7dw6tW7dGhQoVEBgYCH9/fxw8eDBXjIPXyZdPqmQDwNix2P9bMgBpjc9R47miyJzuT59KYbkhQ3IcKuUCbm66LvbePy3EWzigSov8+vXSIg8AW7emfj88XIrdOToCVauaKIiUFH1r/JAh5q0dQUREREQEC5hH3hJlpVqgqh49krnmoqMxo+JKTAjvg2++0feCzpaffgI6dpQp5k6fBl5/3WjhUi7Qvz+wbBkuoyyq4hweJziZdDbCF6WkSHJ+4YK8fv114Px5w31WrAACA6XuobZmhNFt2gR07gy4uABXrwJFipjoRERERESUl1jNPPKUQx4euqrZH4RPgiOe5Wx8fHQ0MGyYrI8fzySeUps9G0qJEiiHK5iPkWbtXr9jhyTxrq5SX+7CBX3rvJbJx8cnJelnTPj4YybxRERERKQKJvLWbuhQxHmWQgncwSTXr3JW823CBJl4u0IFfddhohe5u0OzYgVSoMFH+A7JX39rtlN/+aUsBw+WUR+AJPcv0hZ8NNn4+K1bpf9+oULA6NEmOgkRERERUfqYyFs7BwfsrPcFAGDk8xBoHmZz4PKhQ8DSpbL+7bcy7RhRWpo2xVdF5XfOO2SovhnchA4flp/8+YERI4D335ft27fr93n8WN/t3mQt8gsXynLQIKkbQERERESkAibyucDiR91wEm/AKekJMG1a1g8QH68fWB8YCDRsaNwAKdfZVnE8NqMDbJISZeaElwpSGpu2Nb5XL8DLC3jvPXn9++9ArMyGh+PHpVZj6dLAf7UyjevsWeDgQSk0OXCgCU5ARERERJQ5TOStXFwccOSoDT7BLNnw9dfApUtZO0hwMHDxIlC0KDBzpvGDpFynSFEN+mAVorxelyS+Y0cgIcEk57pwAfjlF5mNQTsrYuXKgK+vPIMKDZVtJh8fr22N79ABKF7cRCchIiIiIsoYE3krd/y4JPMXi70DpWVLKcY1aJC+mTIjixbpmzsXLpQCekQZKFIEiIUL1nbYCri7A0eOSJ93E5j13zOqdu2kfAMgSb22e712nLxJx8dHRQFr18q6tiAkEREREZFKmMhbuX37ZNmoEaCZOROwt5cmynr1gBs30v/whg3A8OGyPnWqTKlFlAmFC8syPKU8sG6dZNZLlwLnzhn1PLdu6fPnceMM39N2r9++Xaam0ybyJmmRX7ZMnpjVqKGvtEdEREREpBIm8lZOm8g3bAiZLu6332SA8NmzQK1aUsQuLXv2AD17yqDiIUP0U2oRZYJ21rWHDwG0bAm0by8bli836nl+/FE6mTRoANSubfheo0aAkxNw9y6wcSPw77+AoyNQrZpRQ5AAliyR9eHD5aEFEREREZGKmMhbsfh4/bhg3fzxdesCJ05Iy+GDB8A77wCLFwN//SUt9A8fSjfodu2AxERphf/qKyYnlCXaRP6BdpKEfv1kuWaNtFwbyd69smzXLvV7Dg5A06ayHhwsy5o1ATs7o51e/PILcPOmdEPo2tXIByciIiIiyjom8lZMOz7e0xOoWPGFN3x8pLp2p06SrA8dKq31vr6SgdWrJ2PomzQBvv8esLVV6yuQldJ2rdcl8k2byu/do0fAtm1GOUdcnPwaA/KrmhZt9/p//pGlScbHL1ggy/79OS0jEREREVkEJvJW7MVu9aka1J2dZQz8jBkyH1ehQoZJyDvvAFu2yJh6oiwy6FoPyMOgDz+U9WXLjHKOsDDg+XOgWDF5DpWWli0NXxt9fPyff8qNZmsrRSSJiIiIiCwAE3kr9mKhuzRpNFIh7OpVybieP5fxvk+eSEE8V1czRUq5jbZF/uFDKbMAAOjbV37nQkPldy6H9uyRZZMmrx75Uby4jCLRMnoiv3ixLNu1kx4HREREREQWgIm8FWvUSBKXVybyabG1BVxcTBQR5RXaFvmkJCA6+r+NpUrpB62vWJHjc2jHx7+qW72Wdho6X19pvTeap0/1JfOHDDHigYmIiIiIcoaJvBULCpK6dZUqqR0J5TX29voOHbru9YC+6N3KlZLlZ9O//wJ//CHrGSXygYFA5cr6mRSNZtMmSebLlftvWggiIiIiIsvARJ6IsiVVwTsAaN1a3rh7F9i1K9vH/u036bJfqZJ0n09PqVLAhQvAqFHZPl3atGP9AwM5qwMRERERWRQm8kSULammoAOkqb5XL1nPQdG7zHarN5mLF6W7i60t0Lu3SkEQEREREaWNiTwRZUuqyvVagYGy3L4diIjI1rG1ibx2yL3ZLV8uy/feA7y8VAqCiIiIiChtTOSJKFvS7FoPyID1OnWA5GRg9eosH/f6deDyZWkMV2VoekIC8P33sq4d809EREREZEGYyBNRtryyRR4A+vSR5datWT6utjU+IABwc8tWaDnzyy/ydMLLC2jRQoUAiIiIiIjSx0SeiLLllS3yANCypSyPH39Fpv9qFtOtvndvIF8+lYIgIiIiIno1JvJElC1pFrvTKlEC8POT0vN79mT6mCkpQGiorKtS6O7WLX21/Q8/VCEAIiIiIqKMMZEnomxJt2s9ADRvLstff830Mc+dk+O5uEjXerNbtUoePjRsCJQvr0IAREREREQZYyJPRNmSbtd6QD++fNcuaWrPBG3jfaNGgJ1djsLLupQUYMUKWWeROyIiIiKyYEzkiShb0u1aDwD16knT+oMHwKlTmTrm//4nS1W61e/YISXz3d2BDh1UCICIiIiIKHOYyBNRtmgT+dhY4PnzNHbIn1+fkWeie/0vv+gL3Wl75ZtNSgowebKsDxwIODqaOQAiIiIiosxjIk9E2eLmpu/+/spx8i92r0/HnTtA376yPno0ULGicWLMtG3bgDNnAFdX4JNPzHxyIiIiIqKsYSJPRNmi0WRinLy2af3oUeDRozR3SU4GevYEoqKAN94Apk83fqzpSkkBgoNlfeRIoFAhMwdARERERJQ1TOSJKNsyrFxfsiRQubIky6+Yhm7GDOD33wFnZ2D9esDe3jSxvtLGjcD58zI2ftQoM5+ciIiIiCjrmMgTUbZl2CIP6LvXpzFO/sgRfWP44sVAhQrGjS9DSUnAlCmy/vHHQMGCZg6AiIiIiCjrmMgTUbZl2CIPvHIauuhooHt36VrfvTvQq5fJwny1deuA8HDAwwMYMUKFAIiIiIiIso6JPBFlW6Za5OvXl37zkZFSUO4/s2cDN24AZcoAX38tY+7NKjERmDpV1seOlep9RERERERWgIk8EWVbhnPJAzLovXFjWf+vev2zZ5K8A8DMmSrl0KtXA1evAkWLAkOHqhAAEREREVH2MJEnomzLVNd6INU4+e+/lyL2pUsDbduaLLxXO3tW5rkDgPHjpccAEREREZGVYCJPRNmWqa71gH4aurAwpNx/iHnz5OXIkYCtramie4Vbt4CWLYEnT4CGDYHBg80cABERERFRzjCRJ6Jsy1TXegDw9QX8/YHkZFwatRj//COzvfXta+oIXxIdLb0D7t6VafG2blVhvjsiIiIiopxhIk9E2ZbprvWAFJQD4LXxKzjjKT76CHB1NV1sqcTHA+3aARcuAF5e0s2f080RERERkRViIk9E2abtWh8VJdPIpatDB8SVLA+3pH8xUPMthg0zeXh6iYnAhx8C+/YBLi7Azp1AyZJmDICIiIiIyHiYyBNRthUqJEtFkeJ16bK1xRrvcQCATx3mwKdovGmD0zpyRLr1r1sH5MsH/PQTUL26ec5NRERERGQCTOSJKNvs7PS90zPqXn/nDjD8RE/cRnF4PL8rpetNKSoK6NcPqFcP+PNPeeqwYQPw7rumPS8RERERkYkxkSeiHMls5frFi4HnyfmxtczHsmHmzEz0x88GRQFWrgQqVgSWL5dtgYFAeDjQvr3xz0dEREREZGZM5IkoRzJT8C4lBVi2TNZLTesvreOXLwObNxs3mPPngQYNZDx8VBRQpQpw6JCcXDsOgIiIiIjIyjGRJ6IcyUyL/D//yPuOjkCLTi7A8OHyRkiItKDnVGwsMG4cUKOGJO5OTsCsWcCpU9K1noiIiIgoF2EiT0Q5kpm55MPCZFmrloyrx9ChUj3+7FmpIJ8Tv/4qc8LPnAkkJQFt2wIXLwJjxvx3MiIiIiKi3IWJPBHlSGa61h85Iss6df7b4OEBDBwo6x9+CPz1V9ZP/PAh0LMn0LIlcPMmUKoU8PPPwNatnFqOiIiIiHI1JvJElCOZ6VqvTeTr1n1h48SJ0hX+/n3g7bczn8wrilSfr1wZWLMGsLEBRo8GLlwAWrXK1ncgIiIiIrImTOSJKEcy6lofHa3P0XUt8gBQoACwd2/WkvlHj4AOHYCuXeWEr78uTwnmzAGcnXP4TYiIiIiIrAMTeSLKkYy61h89Ksvy5fX76nh4ZD6ZP3gQqFZNus7b2QFTpkgxu4AAY3wNIiIiIiKrwUSeiHIko671qcbHv+zlZL5OHRn7vnEj8PixzDU/dSrQqBFw+7Y8ETh6FAgOBvLnN/bXISIiIiKyePnUDoCIrNuLXesVBdBoDN/XVqw3GB//Mm0y37w5cOKEjH1fswbIlw/w8QGuXZP9evcGFi4EXF2N/j2IiIiIiKwFW+SJKEe0iXx8PPD0qeF7ycn6rvXpJvKAJPNhYcCBAzJ1XMWKMp3ctWsyVd0PPwCrVjGJJyIiIqI8T6MoiqJ2EJYmJiYG7u7uePz4Mdzc3NQOh8iiKQpQrJj0it+6VaZx1zp7FqheXXLvf/8FbG2zePBLl6SFvl49mV6OiIiIiCiXykoeyhZ5IsoRjQYIDJT1r74yfE/brf7NN7ORxAMyHr57dybxREREREQvYCJPRDk2aJAk6vv2AefO6benOX88ERERERHlCBN5IsoxHx+gfXtZX7hQvz3DivVERERERJRlTOSJyCiGD5flmjUyp/z9+8CVK9L1nlO9ExEREREZDxN5IjKKevVkKvi4OGDZMv34+NdfBwoUUDU0IiIiIqJchYk8ERmFRgOMGCHrixfLLHIAu9UTERERERkbE3kiMpouXWRe+du3gaVLZRsL3RERERERGRcTeSIyGgcHYMAAWX/2TJZM5ImIiIiIjMsiEvnFixfD19cXDg4OCAgIwPHjx1+5b6NGjaDRaFL9vPfee7p9FEXB5MmT4eXlBUdHRzRp0gSXLl0yx1chyvMGDQLy5ZP1QoVkKngiIiIiIjIe1RP5DRs2YPTo0QgODsapU6dQrVo1NGvWDPfv309z/y1btuDevXu6n/Pnz8PW1hadOnXS7TNz5kwsWLAAS5cuxbFjx+Ds7IxmzZohLi7OXF+LKM/y9ga0t2OdOjJ2noiIiIiIjEejKIqiZgABAQGoVasWFi1aBABISUmBj48Phg0bhvHjx2f4+fnz52Py5Mm4d+8enJ2doSgKvL298fHHH2PMmDEAgMePH8PT0xOrVq1C165dMzxmTEwM3N3d8fjxY7i5ueXsCxLlQTduAOPHA6NHA7VqqR0NEREREZHly0oeqmqLfEJCAk6ePIkmTZrottnY2KBJkyYI085dlYHly5eja9eucHZ2BgBcu3YNERERBsd0d3dHQEDAK48ZHx+PmJgYgx8iyr5SpYD165nEExERERGZgqqJ/MOHD5GcnAxPT0+D7Z6enoiIiMjw88ePH8f58+fRr18/3Tbt57JyzJCQELi7u+t+fHx8svpViIiIiIiIiMxC9THyObF8+XL4+fmhdu3aOTrOhAkT8PjxY93PrVu3jBQhERERERERkXGpmsgXLlwYtra2iIyMNNgeGRmJYsWKpfvZ2NhY/PjjjwgMDDTYrv1cVo5pb28PNzc3gx8iIiIiIiIiS6RqIp8/f374+/sjNDRUty0lJQWhoaGoU6dOup/dtGkT4uPj8cEHHxhsL126NIoVK2ZwzJiYGBw7dizDYxIRERERERFZunxqBzB69Gj07t0bNWvWRO3atTF//nzExsaib9++AIBevXqhePHiCAkJMfjc8uXL0bZtWxQqVMhgu0ajwciRI/H555+jfPnyKF26NIKCguDt7Y22bdua62sRERERERERmYTqiXyXLl3w4MEDTJ48GREREahevTp27dqlK1Z38+ZN2NgYdhwIDw/HoUOH8L///S/NY44dOxaxsbH46KOPEB0djfr162PXrl1wcHAw+fchIiIiIiIiMiXV55G3RJxHnoiIiIiIiMzJauaRJyIiIiIiIqKsYSJPREREREREZEWYyBMRERERERFZESbyRERERERERFaEiTwRERERERGRFWEiT0RERERERGRFmMgTERERERERWREm8kRERERERERWhIk8ERERERERkRVhIk9ERERERERkRZjIExEREREREVmRfGoHYIkURQEAxMTEqBwJERERERER5QXa/FObj6aHiXwanjx5AgDw8fFRORIiIiIiIiLKS548eQJ3d/d099EomUn385iUlBTcvXsXrq6u0Gg0aofzSjExMfDx8cGtW7fg5uamdjiUDbyG1o/X0PrxGlo/XkPrx2to/XgNcwdeR3UpioInT57A29sbNjbpj4Jni3wabGxsUKJECbXDyDQ3NzfeaFaO19D68RpaP15D68draP14Da0fr2HuwOuonoxa4rVY7I6IiIiIiIjIijCRJyIiIiIiIrIiTOStmL29PYKDg2Fvb692KJRNvIbWj9fQ+vEaWj9eQ+vHa2j9eA1zB15H68Fid0RERERERERWhC3yRERERERERFaEiTwRERERERGRFWEiT0RERERERGRFmMgTERERERERWREm8lZs8eLF8PX1hYODAwICAnD8+HG1Q6JXCAkJQa1ateDq6oqiRYuibdu2CA8PN9inUaNG0Gg0Bj8DBw5UKWJ62ZQpU1Jdn9dee033flxcHIYMGYJChQrBxcUFHTp0QGRkpIoR08t8fX1TXUONRoMhQ4YA4D1oiQ4cOIBWrVrB29sbGo0G27ZtM3hfURRMnjwZXl5ecHR0RJMmTXDp0iWDfR49eoQePXrAzc0NBQoUQGBgIJ4+fWrGb5G3pXcNExMTMW7cOPj5+cHZ2Rne3t7o1asX7t69a3CMtO7dGTNmmPmb5F0Z3Yd9+vRJdX2aN29usA/vQ3VldA3T+rdRo9Fg1qxZun14H1oeJvJWasOGDRg9ejSCg4Nx6tQpVKtWDc2aNcP9+/fVDo3SsH//fgwZMgRHjx7Fnj17kJiYiHfffRexsbEG+/Xv3x/37t3T/cycOVOliCktr7/+usH1OXTokO69UaNG4ZdffsGmTZuwf/9+3L17F+3bt1cxWnrZiRMnDK7fnj17AACdOnXS7cN70LLExsaiWrVqWLx4cZrvz5w5EwsWLMDSpUtx7NgxODs7o1mzZoiLi9Pt06NHD1y4cAF79uzB9u3bceDAAXz00Ufm+gp5XnrX8NmzZzh16hSCgoJw6tQpbNmyBeHh4WjdunWqfT/77DODe3PYsGHmCJ+Q8X0IAM2bNze4PuvXrzd4n/ehujK6hi9eu3v37mHFihXQaDTo0KGDwX68Dy2MQlapdu3aypAhQ3Svk5OTFW9vbyUkJETFqCiz7t+/rwBQ9u/fr9vWsGFDZcSIEeoFRekKDg5WqlWrluZ70dHRip2dnbJp0ybdtosXLyoAlLCwMDNFSFk1YsQIpWzZskpKSoqiKLwHLR0AZevWrbrXKSkpSrFixZRZs2bptkVHRyv29vbK+vXrFUVRlL/++ksBoJw4cUK3z6+//qpoNBrlzp07ZoudxMvXMC3Hjx9XACg3btzQbStVqpQyb9480wZHmZLWNezdu7fSpk2bV36G96Flycx92KZNG+Wdd94x2Mb70PKwRd4KJSQk4OTJk2jSpIlum42NDZo0aYKwsDAVI6PMevz4MQDAw8PDYPvatWtRuHBhVKlSBRMmTMCzZ8/UCI9e4dKlS/D29kaZMmXQo0cP3Lx5EwBw8uRJJCYmGtyTr732GkqWLMl70kIlJCRgzZo1+PDDD6HRaHTbeQ9aj2vXriEiIsLgvnN3d0dAQIDuvgsLC0OBAgVQs2ZN3T5NmjSBjY0Njh07ZvaYKWOPHz+GRqNBgQIFDLbPmDEDhQoVQo0aNTBr1iwkJSWpEyClad++fShatCgqVqyIQYMGISoqSvce70PrEhkZiR07diAwMDDVe7wPLUs+tQOgrHv48CGSk5Ph6elpsN3T0xN///23SlFRZqWkpGDkyJGoV68eqlSpotvevXt3lCpVCt7e3jh37hzGjRuH8PBwbNmyRcVoSSsgIACrVq1CxYoVce/ePUydOhVvvfUWzp8/j4iICOTPnz/Vfzw9PT0RERGhTsCUrm3btiE6Ohp9+vTRbeM9aF2091Za/xZq34uIiEDRokUN3s+XLx88PDx4b1qguLg4jBs3Dt26dYObm5tu+/Dhw/HGG2/Aw8MDR44cwYQJE3Dv3j3MnTtXxWhJq3nz5mjfvj1Kly6NK1eu4NNPP0WLFi0QFhYGW1tb3odWZvXq1XB1dU01PJD3oeVhIk9kZkOGDMH58+cNxlcDMBgr5ufnBy8vLzRu3BhXrlxB2bJlzR0mvaRFixa69apVqyIgIAClSpXCxo0b4ejoqGJklB3Lly9HixYt4O3trdvGe5BIPYmJiejcuTMURcHXX39t8N7o0aN161WrVkX+/PkxYMAAhISEwN7e3tyh0ku6du2qW/fz80PVqlVRtmxZ7Nu3D40bN1YxMsqOFStWoEePHnBwcDDYzvvQ8rBrvRUqXLgwbG1tU1XEjoyMRLFixVSKijJj6NCh2L59O37//XeUKFEi3X0DAgIAAJcvXzZHaJRFBQoUQIUKFXD58mUUK1YMCQkJiI6ONtiH96RlunHjBvbu3Yt+/fqlux/vQcumvbfS+7ewWLFiqYrAJiUl4dGjR7w3LYg2ib9x4wb27Nlj0BqfloCAACQlJeH69evmCZCypEyZMihcuLDu707eh9bj4MGDCA8Pz/DfR4D3oSVgIm+F8ufPD39/f4SGhuq2paSkIDQ0FHXq1FExMnoVRVEwdOhQbN26Fb/99htKly6d4WfOnDkDAPDy8jJxdJQdT58+xZUrV+Dl5QV/f3/Y2dkZ3JPh4eG4efMm70kLtHLlShQtWhTvvfdeuvvxHrRspUuXRrFixQzuu5iYGBw7dkx339WpUwfR0dE4efKkbp/ffvsNKSkpugc1pC5tEn/p0iXs3bsXhQoVyvAzZ86cgY2NTaru2mQZbt++jaioKN3fnbwPrcfy5cvh7++PatWqZbgv70P1sWu9lRo9ejR69+6NmjVronbt2pg/fz5iY2PRt29ftUOjNAwZMgTr1q3D//3f/8HV1VU3Jszd3R2Ojo64cuUK1q1bh5YtW6JQoUI4d+4cRo0ahQYNGqBq1aoqR08AMGbMGLRq1QqlSpXC3bt3ERwcDFtbW3Tr1g3u7u4IDAzE6NGj4eHhATc3NwwbNgx16tTBm2++qXbo9IKUlBSsXLkSvXv3Rr58+n8CeQ9apqdPnxr0iLh27RrOnDkDDw8PlCxZEiNHjsTnn3+O8uXLo3Tp0ggKCoK3tzfatm0LAKhUqRKaN2+O/v37Y+nSpUhMTMTQoUPRtWtXg2EVZDrpXUMvLy907NgRp06dwvbt25GcnKz799HDwwP58+dHWFgYjh07hrfffhuurq4ICwvDqFGj8MEHH6BgwYJqfa08Jb1r6OHhgalTp6JDhw4oVqwYrly5grFjx6JcuXJo1qwZAN6HliCjv0sBeRC6adMmzJkzJ9XneR9aKLXL5lP2LVy4UClZsqSSP39+pXbt2srRo0fVDoleAUCaPytXrlQURVFu3rypNGjQQPHw8FDs7e2VcuXKKZ988ony+PFjdQMnnS5duiheXl5K/vz5leLFiytdunRRLl++rHv/+fPnyuDBg5WCBQsqTk5OSrt27ZR79+6pGDGlZffu3QoAJTw83GA770HL9Pvvv6f5d2fv3r0VRZEp6IKCghRPT0/F3t5eady4caprGxUVpXTr1k1xcXFR3NzclL59+ypPnjxR4dvkTeldw2vXrr3y38fff/9dURRFOXnypBIQEKC4u7srDg4OSqVKlZTp06crcXFx6n6xPCS9a/js2TPl3XffVYoUKaLY2dkppUqVUvr3769EREQYHIP3oboy+rtUURTlm2++URwdHZXo6OhUn+d9aJk0iqIoJn9aQERERERERERGwTHyRERERERERFaEiTwRERERERGRFWEiT0RERERERGRFmMgTERERERERWREm8kRERERERERWhIk8ERERERERkRVhIk9ERERERERkRZjIExEREREREVkRJvJERESULRqNBtu2bVM7DEyZMgXVq1dXOwwiIiKzYSJPRERkoR48eIBBgwahZMmSsLe3R7FixdCsWTMcPnxY7dCM4vr169BoNDhz5ozaoRAREVmVfGoHQERERGnr0KEDEhISsHr1apQpUwaRkZEIDQ1FVFSU2qERERGRitgiT0REZIGio6Nx8OBBfPnll3j77bdRqlQp1K5dGxMmTEDr1q11+82dOxd+fn5wdnaGj48PBg8ejKdPn+reX7VqFQoUKIDt27ejYsWKcHJyQseOHfHs2TOsXr0avr6+KFiwIIYPH47k5GTd53x9fTFt2jR069YNzs7OKF68OBYvXpxuzLdu3ULnzp1RoEABeHh4oE2bNrh+/Xqmv/O+ffug0WgQGhqKmjVrwsnJCXXr1kV4eLjBfjNmzICnpydcXV0RGBiIuLi4VMdatmwZKlWqBAcHB7z22mtYsmSJ7r0PP/wQVatWRXx8PAAgISEBNWrUQK9evTIdKxERkZqYyBMREVkgFxcXuLi4YNu2bbqEMy02NjZYsGABLly4gNWrV+O3337D2LFjDfZ59uwZFixYgB9//BG7du3Cvn370K5dO+zcuRM7d+7EDz/8gG+++QabN282+NysWbNQrVo1nD59GuPHj8eIESOwZ8+eNONITExEs2bN4OrqioMHD+Lw4cNwcXFB8+bNkZCQkKXvPnHiRMyZMwd//PEH8uXLhw8//FD33saNGzFlyhRMnz4df/zxB7y8vAySdABYu3YtJk+ejC+++AIXL17E9OnTERQUhNWrVwMAFixYgNjYWIwfP153vujoaCxatChLcRIREalGISIiIou0efNmpWDBgoqDg4NSt25dZcKECcrZs2fT/cymTZuUQoUK6V6vXLlSAaBcvnxZt23AgAGKk5OT8uTJE922Zs2aKQMGDNC9LlWqlNK8eXODY3fp0kVp0aKF7jUAZevWrYqiKMoPP/ygVKxYUUlJSdG9Hx8frzg6Oiq7d+9OM9Zr164pAJTTp08riqIov//+uwJA2bt3r26fHTt2KACU58+fK4qiKHXq1FEGDx5scJyAgAClWrVqutdly5ZV1q1bZ7DPtGnTlDp16uheHzlyRLGzs1OCgoKUfPnyKQcPHkwzRiIiIkvEFnkiIiIL1aFDB9y9exc///wzmjdvjn379uGNN97AqlWrdPvs3bsXjRs3RvHixeHq6oqePXsiKioKz5490+3j5OSEsmXL6l57enrC19cXLi4uBtvu379vcP46deqken3x4sU0Yz179iwuX74MV1dXXW8CDw8PxMXF4cqVK1n63lWrVtWte3l5AYAutosXLyIgIOCVccbGxuLKlSsIDAzUxeHi4oLPP//cII46depgzJgxmDZtGj7++GPUr18/SzESERGpicXuiIiILJiDgwOaNm2Kpk2bIigoCP369UNwcDD69OmD69ev4/3338egQYPwxRdfwMPDA4cOHUJgYCASEhLg5OQEALCzszM4pkajSXNbSkpKtuN8+vQp/P39sXbt2lTvFSlSJEvHejE2jUYDAJmOTVsf4LvvvkuV8Nva2urWU1JScPjwYdja2uLy5ctZio+IiEhtbJEnIiKyIpUrV0ZsbCwA4OTJk0hJScGcOXPw5ptvokKFCrh7967RznX06NFUrytVqpTmvm+88QYuXbqEokWLoly5cgY/7u7uRoupUqVKOHbs2Cvj9PT0hLe3N65evZoqjtKlS+v2mzVrFv7++2/s378fu3btwsqVK40WIxERkakxkSciIrJAUVFReOedd7BmzRqcO3cO165dw6ZNmzBz5ky0adMGAFCuXDkkJiZi4cKFuHr1Kn744QcsXbrUaDEcPnwYM2fOxD///IPFixdj06ZNGDFiRJr79ujRA4ULF0abNm1w8OBBXLt2Dfv27cPw4cNx+/Zto8U0YsQIrFixAitXrsQ///yD4OBgXLhwwWCfqVOnIiQkBAsWLMA///yDP//8EytXrsTcuXMBAKdPn8bkyZOxbNky1KtXD3PnzsWIESNw9epVo8VJRERkSkzkiYiILJCLiwsCAgIwb948NGjQAFWqVEFQUBD69++vq65erVo1zJ07F19++SWqVKmCtWvXIiQkxGgxfPzxx/jjjz9Qo0YNfP7555g7dy6aNWuW5r5OTk44cOAASpYsifbt26NSpUq6qeHc3NyMFlOXLl0QFBSEsWPHwt/fHzdu3MCgQYMM9unXrx+WLVuGlStXws/PDw0bNsSqVatQunRpxMXF4YMPPkCfPn3QqlUrAMBHH32Et99+Gz179jSYgo+IiMhSaRRFUdQOgoiIiCyLr68vRo4ciZEjR6odChEREb2ELfJEREREREREVoSJPBEREREREZEVYdd6IiIiIiIiIivCFnkiIiIiIiIiK8JEnoiIiIiIiMiKMJEnIiIiIiIisiJM5ImIiIiIiIisCBN5IiIiIiIiIivCRJ6IiIiIiIjIijCRJyIiIiIiIrIiTOSJiIiIiIiIrMj/A791Sl9yDTWvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High - MSE: 0.0024, MAE: 0.0452, R²: 0.4148\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low - MSE: 0.0022, MAE: 0.0425, R²: 0.4953\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close - MSE: 0.0614, MAE: 0.2453, R²: -23.8826\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume - MSE: 0.0016, MAE: 0.0296, R²: -1.1215\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/oAAAIjCAYAAACzoGDyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXwTZf4H8E/Si5a23JSbcl8CIiiLuiAIgjfigYLLKa4HXvWCn6t44wGIy7LiunKsJx6ICoorLOABeHCoICCW+wYFChR6ZX5/PD6dSTpJZpKZzCT9vF+vvpImafK0TWae73y/z3c8iqIoICIiIiIiIqKE4HV6AERERERERERkHQb6RERERERERAmEgT4RERERERFRAmGgT0RERERERJRAGOgTERERERERJRAG+kREREREREQJhIE+ERERERERUQJhoE9ERERERESUQBjoExERERERESUQBvpEREQ2yc3NxYgRI8q/X7ZsGTweD5YtW+bYmAIFjpFiw43vBSIiShwM9ImIKCHNnj0bHo+n/KtKlSpo3bo1xo4diwMHDjg9PFM++eQTPProo04PwxYXXHCB3/8p2JeTv3+nTp3QpEkTKIoS9DHnnXcecnJyUFpaGsORERER6Ut2egBERER2evzxx9GsWTOcPn0aX331FV566SV88sknWL9+PTIyMmI6lp49e+LUqVNITU019XOffPIJpk+fnpDB/kMPPYSbbrqp/PvvvvsOf//73/F///d/aNeuXfntnTp1cmJ4AIChQ4di3Lhx+PLLL9GzZ88K92/fvh0rV67E2LFjkZzMqRURETmPeyMiIkpoF198Mbp16wYAuOmmm1CrVi1MmTIFH374IW644Qbdnzl58iSqVq1q+Vi8Xi+qVKli+fPGs379+vl9X6VKFfz9739Hv379cMEFFwT9Obv+R3qGDBmC8ePH480339QN9N966y0oioKhQ4fGZDxEREThsHSfiIgqlT59+gAAtm3bBgAYMWIEMjMzkZ+fj0suuQRZWVnlAZvP58PUqVPRoUMHVKlSBTk5OfjrX/+KI0eO+D2noih48skn0ahRI2RkZKB3797YsGFDhdcOti77m2++wSWXXIIaNWqgatWq6NSpE1588cXy8U2fPh0A/ErZJavHGKikpAQ1a9bEyJEjK9xXUFCAKlWq4L777iu/bdq0aejQoQMyMjJQo0YNdOvWDW+++WbY1wnl0Ucfhcfjwc8//4whQ4agRo0aOP/88wGI0n+9AwIjRoxAbm6u321G/1aBGjdujJ49e+K9995DSUlJhfvffPNNtGjRAt27dwcArF27FhdffDGys7ORmZmJCy+8EKtWrQr7ewbrlxD4O8r30TvvvIPHHnsMDRs2RFZWFq655hocO3YMRUVFuPvuu1G3bl1kZmZi5MiRKCoqqvC8r7/+Orp27Yr09HTUrFkT119/PXbt2hV2nERE5H7M6BMRUaWSn58PAKhVq1b5baWlpejfvz/OP/98TJo0qbyk/69//Stmz56NkSNH4s4778S2bdvwj3/8A2vXrsXXX3+NlJQUAMAjjzyCJ598EpdccgkuueQSrFmzBhdddBGKi4vDjufzzz/HZZddhvr16+Ouu+5CvXr1sHHjRixYsAB33XUX/vrXv2Lv3r34/PPP8dprr1X4ebvHmJKSgquuugrz5s3Dyy+/7LfsYP78+SgqKsL1118PAHjllVdw55134pprrsFdd92F06dP48cff8Q333yDIUOGhP1bhHPttdeiVatWePrpp0Oulw/G6N9Kz9ChQ3HzzTfjs88+w2WXXVZ++08//YT169fjkUceAQBs2LABf/7zn5GdnY0HHngAKSkpePnll3HBBRdg+fLl5QcDrDBx4kSkp6dj3Lhx+PXXXzFt2jSkpKTA6/XiyJEjePTRR7Fq1SrMnj0bzZo1Kx8jADz11FN4+OGHcd111+Gmm27CoUOHMG3aNPTs2RNr165F9erVLRsnERE5QCEiIkpAs2bNUgAoixcvVg4dOqTs2rVLefvtt5VatWop6enpyu7duxVFUZThw4crAJRx48b5/fyXX36pAFDeeOMNv9sXLVrkd/vBgweV1NRU5dJLL1V8Pl/54/7v//5PAaAMHz68/LalS5cqAJSlS5cqiqIopaWlSrNmzZSmTZsqR44c8Xsd7XPdfvvtit4u244x6vnss88UAMrHH3/sd/sll1yiNG/evPz7K6+8UunQoUPI5wrn3Xff9fsbKYqiTJgwQQGg3HDDDRUe36tXL6VXr14Vbh8+fLjStGnT8u+N/q2C+f3335W0tLQKYxg3bpwCQNm8ebOiKIoycOBAJTU1VcnPzy9/zN69e5WsrCylZ8+e5bcFvhcURVGaNm2q+78I/B3lz55xxhlKcXFx+e033HCD4vF4lIsvvtjv53v06OH3t9i+fbuSlJSkPPXUU36P++mnn5Tk5OQKtxMRUfxh6T4RESW0vn37ok6dOmjcuDGuv/56ZGZm4oMPPkDDhg39Hnfrrbf6ff/uu++iWrVq6NevHw4fPlz+1bVrV2RmZmLp0qUAgMWLF6O4uBh33HGHX0n93XffHXZsa9euxbZt23D33XdXyKBqnyuYWIwREMsdateujblz55bfduTIEXz++ecYPHhw+W3Vq1fH7t278d133xl6XrNuueWWiH/W6N8qmBo1auCSSy7BRx99hJMnTwIQyyHefvttdOvWDa1bt0ZZWRn++9//YuDAgWjevHn5z9avXx9DhgzBV199hYKCgoh/h0DDhg3zq0Lo3r07FEXBqFGj/B7XvXt37Nq1q/yMAPPmzYPP58N1113n97eoV68eWrVqFfZvQURE7sfSfSIiSmjTp09H69atkZycjJycHLRp0wZer/9x7uTkZDRq1Mjvti1btuDYsWOoW7eu7vMePHgQALBjxw4AQKtWrfzur1OnDmrUqBFybHIZwRlnnGH8F4rxGAHx97n66qvx5ptvoqioCGlpaZg3bx5KSkr8Av0HH3wQixcvxjnnnIOWLVvioosuwpAhQ3DeeedF9PsFatasWcQ/a/RvFcrQoUPxwQcf4MMPP8SQIUOwYsUKbN++HXfddRcA4NChQygsLESbNm0q/Gy7du3g8/mwa9cudOjQIeLfQ6tJkyZ+31erVg2A6CkQeLvP58OxY8dQq1YtbNmyBYqiVHg/SKGWMBARUXxgoE9ERAntnHPOKe+6H0xaWlqF4N/n86Fu3bp44403dH+mTp06lo0xUrEc4/XXX4+XX34Zn376KQYOHIh33nkHbdu2RefOncsf065dO2zevBkLFizAokWL8P777+Of//wnHnnkETz22GNRjyE9Pb3CbR6PR3e9fllZmd/3VvytLrvsMlSrVg1vvvkmhgwZgjfffBNJSUnlPQqiFayKo6ysDElJSRVu17st1O3y7+Tz+eDxePDpp5/qPjYzM9PokImIyKUY6BMREelo0aIFFi9ejPPOO083wJSaNm0KQGSMteXahw4dCtvNvUWLFgCA9evXo2/fvkEfFywAjMUYpZ49e6J+/fqYO3cuzj//fPzvf//DQw89VOFxVatWxeDBgzF48GAUFxdj0KBBeOqppzB+/HhbTi1Yo0YNbN26tcLtsopBMvq3CiUtLQ3XXHMN/vOf/+DAgQN499130adPH9SrVw+AOFiQkZGBzZs3V/jZTZs2wev1Vsi2B/4uR48e1f1dtP+3aLVo0QKKoqBZs2Zo3bq1Zc9LRETuwTX6REREOq677jqUlZXhiSeeqHBfaWlpeUDWt29fpKSkYNq0aX6Z5alTp4Z9jbPOOgvNmjXD1KlTKwR42ueS54sPfEwsxih5vV5cc801+Pjjj/Haa6+htLTUr2wfAH777Te/71NTU9G+fXsoiqJ7WjortGjRAps2bcKhQ4fKb/vhhx/w9ddf+z3O6N8qnKFDh6KkpAR//etfcejQofJTMQIik37RRRfhww8/xPbt28tvP3DgAN58802cf/75yM7ODvm7rFq1yu9MCAsWLLD8lHeDBg1CUlISHnvssQrVEIqiVPg/EhFR/GFGn4iISEevXr3w17/+FRMnTsS6detw0UUXISUlBVu2bMG7776LF198Eddccw3q1KmD++67DxMnTsRll12GSy65BGvXrsWnn36K2rVrh3wNr9eLl156CZdffjnOPPNMjBw5EvXr18emTZuwYcMGfPbZZwCArl27AgDuvPNO9O/fv7xcPBZj1Bo8eDCmTZuGCRMmoGPHjmjXrp3f/RdddBHq1auH8847Dzk5Odi4cSP+8Y9/4NJLL0VWVpbJ/4Axo0aNwpQpU9C/f3+MHj0aBw8exIwZM9ChQwe/xndG/1bh9OrVC40aNcKHH36I9PR0DBo0yO/+J598Ep9//jnOP/983HbbbUhOTsbLL7+MoqIiPPfccyGf+6abbsJ7772HAQMG4LrrrkN+fj5ef/318soPq7Ro0QJPPvkkxo8fj+3bt2PgwIHIysrCtm3b8MEHH+Dmm2/GfffdZ+lrEhFRjDnT7J+IiMhe8vR63333XcjHDR8+XKlatWrQ+//1r38pXbt2VdLT05WsrCylY8eOygMPPKDs3bu3/DFlZWXKY489ptSvX19JT09XLrjgAmX9+vUVTpemd0o1RVGUr776SunXr5+SlZWlVK1aVenUqZMybdq08vtLS0uVO+64Q6lTp47i8XgqnGrPyjGG4vP5lMaNGysAlCeffLLC/S+//LLSs2dPpVatWkpaWprSokUL5f7771eOHTtm6PkVJfTp9Q4dOqT7M6+//rrSvHlzJTU1VTnzzDOVzz77rMLp9SQjf6tw7r//fgWAct111+nev2bNGqV///5KZmamkpGRofTu3VtZsWKF32OCvRcmT56sNGzYUElLS1POO+885fvvvw96er13333X72eDveeD/f3ef/995fzzz1eqVq2qVK1aVWnbtq1y++23l58qkIiI4pdHUXQ62BARERERERFRXOIafSIiIiIiIqIEwkCfiIiIiIiIKIEw0CciIiIiIiJKIAz0iYiIiIiIiBIIA30iIiIiIiKiBMJAn4iIiIiIiCiBJDs9gHjl8/mwd+9eZGVlwePxOD0cIiIiIiIiSnCKouD48eNo0KABvN7geXsG+hHau3cvGjdu7PQwiIiIiIiIqJLZtWsXGjVqFPR+BvoRysrKAiD+wNnZ2Q6PhoiIiIiIiBJdQUEBGjduXB6PBsNAP0KyXD87O5uBPhEREREREcVMuOXjbMZHRERERERElEAY6BMRERERERElEAb6RERERERERAmEa/SJiIiIiKjSKCsrQ0lJidPDINKVlJSE5OTkqE/hzkCfiIiIiIgqhRMnTmD37t1QFMXpoRAFlZGRgfr16yM1NTXi52CgT0RERERECa+srAy7d+9GRkYG6tSpE3XGlMhqiqKguLgYhw4dwrZt29CqVSt4vZGttmegT0RERERECa+kpASKoqBOnTpIT093ejhEutLT05GSkoIdO3aguLgYVapUieh52IyPiIiIiIgqDWbyye0izeL7PYcF4yAiIiIiIiIil2CgT0RERERERJRAGOgTERERERGR7TweD+bPn+/0MCoFBvpEREREREQu5PF4Qn49+uijMRlHx44dccstt+je99prryEtLQ2HDx+OyVjIGAb6RERERERELrRv377yr6lTpyI7O9vvtvvuu6/8sYqioLS01JZxjB49Gm+//TZOnTpV4b5Zs2bhiiuuQO3atW15bYoMA30iIiIiIqp0FAU4edKZL0UxNsZ69eqVf1WrVg0ej6f8+02bNiErKwuffvopunbtirS0NHz11VcYMWIEBg4c6Pc8d999Ny644ILy730+HyZOnIhmzZohPT0dnTt3xnvvvRd0HDfeeCNOnTqF999/3+/2bdu2YdmyZRg9ejQA4KWXXkKLFi2QmpqKNm3a4LXXXgv6nMuWLYPH48HRo0fLb1u3bh08Hg+2b98OAJg9ezaqV6+OBQsWoE2bNsjIyMA111yDwsJCzJkzB7m5uahRowbuvPNOlJWVlT9PUVER7rvvPjRs2BBVq1ZF9+7dsWzZstB/7AST7PQAiIiIiIiIYq2wEMjMdOa1T5wAqla15rnGjRuHSZMmoXnz5qhRo4ahn5k4cSJef/11zJgxA61atcIXX3yBG2+8EXXq1EGvXr0qPL527dq48sorMXPmTNx4443lt8+ePRuNGjXCRRddhA8++AB33XUXpk6dir59+2LBggUYOXIkGjVqhN69e0f8+xUWFuLvf/873n77bRw/fhyDBg3CVVddherVq+OTTz7B1q1bcfXVV+O8887D4MGDAQBjx47Fzz//jLfffhsNGjTABx98gAEDBuCnn35Cq1atIh5LPGGgT0REREREFKcef/xx9OvXz/Dji4qK8PTTT2Px4sXo0aMHAKB58+b46quv8PLLL+sG+oAo37/44ouxbds2NGvWDIqiYM6cORg+fDi8Xi8mTZqEESNG4LbbbgMA5OXlYdWqVZg0aVJUgX5JSUl5pQAAXHPNNXjttddw4MABZGZmon379ujduzeWLl2KwYMHY+fOnZg1axZ27tyJBg0aAADuu+8+LFq0CLNmzcLTTz8d8VjiCQN9IiIiIiKTCguB9euBs88GPB6nR0ORyMgQmXWnXtsq3bp1M/X4X3/9FYWFhRUODhQXF6NLly5Bf65fv35o1KgRZs2ahccffxxLlizBzp07MXLkSADAxo0bcfPNN/v9zHnnnYcXX3zR1PgCZWRklAf5AJCTk4Pc3FxkasoxcnJycPDgQQDATz/9hLKyMrRu3drveYqKilCrVq2oxhJPGOgTEREREZn0wAPA9OnARx8Bl1/u9GgoEh6PdeXzTqoa8Et4vV4oAU0ASkpKyq+f+OPoxsKFC9GwYUO/x6WlpQV9Ha/XixEjRmDOnDl49NFHMWvWLPTu3RvNmzePaNxer2gXpx2rdpxSSkqK3/cej0f3Np/PB0D8fklJSVi9ejWSkpL8Hpfp1FoNB7AZHxERERGRSTt2+F8SuUWdOnWwb98+v9vWrVtXfr19+/ZIS0vDzp070bJlS7+vxo0bh3zukSNHYteuXZg3bx4++OCD8iZ8ANCuXTt8/fXXfo//+uuv0b59+6DjBOA3Vu04I9WlSxeUlZXh4MGDFX6/evXqRf388YIZfSIiIiIik2TiUScBSeSoPn364Pnnn8d//vMf9OjRA6+//jrWr19fXpaflZWF++67D/fccw98Ph/OP/98HDt2DF9//TWys7MxfPjwoM/drFkz9OnTBzfffDPS0tIwaNCg8vvuv/9+XHfddejSpQv69u2Ljz/+GPPmzcPixYt1n0seWHj00Ufx1FNP4ZdffsHkyZOj/v1bt26NoUOHYtiwYZg8eTK6dOmCQ4cOYcmSJejUqRMuvfTSqF8jHjCjT0RERERkUnGxuGSgT27Tv39/PPzww3jggQdw9tln4/jx4xg2bJjfY5544gk8/PDDmDhxItq1a4cBAwZg4cKFaNasWdjnHz16NI4cOYIhQ4agSpUq5bcPHDgQL774IiZNmoQOHTrg5ZdfxqxZs/xO66eVkpKCt956C5s2bUKnTp3w7LPP4sknn4zqd5dmzZqFYcOG4d5770WbNm0wcOBAfPfdd2jSpIklzx8PPErgAg4ypKCgANWqVcOxY8eQnZ3t9HCIiIiIKIb+/Gfgq6+AJ58EHnrI6dGQEadPny7vGK8NUIncJtR71Wgcyow+EREREZFJzOgTkZsx0CciIiIiMolr9InIzRjoExERERGZxECfiNyMgT4RERERkUks3SciN2OgT0RERERkEjP6RORmDPSJiIiIiEySAX5pqbPjICLSw0CfiIiIiMgklu4TkZsx0CciIiIiMoml+0TkZgz0iYiIiIhMYqBPRG7GQJ+IiIiIyCSW7lMiGjFiBAYOHFj+/QUXXIC777475uNYtmwZPB4Pjh49attrbN++HR6PB+vWrbPtNZzEQJ+IiIiIyCRm9ClWRowYAY/HA4/Hg9TUVLRs2RKPP/44SmPQCXLevHl44oknDD02FsE5ABQXF6N27dp45plndO9/4oknkJOTg5JK/uFkoE9EREREZEJZGaAo4noljyUoRgYMGIB9+/Zhy5YtuPfee/Hoo4/i+eef131ssSw3sUDNmjWRlZVl2fNZITU1FTfeeCNmzZpV4T5FUTB79mwMGzYMKSkpDozOPRjoExERERGZoI2jGOjHMUUBTp505kseKTIoLS0N9erVQ9OmTXHrrbeib9+++OijjwCo5fZPPfUUGjRogDZt2gAAdu3aheuuuw7Vq1dHzZo1ceWVV2L79u3lz1lWVoa8vDxUr14dtWrVwgMPPAAlYFyBpftFRUV48MEH0bhxY6SlpaFly5Z49dVXsX37dvTu3RsAUKNGDXg8HowYMQIA4PP5MHHiRDRr1gzp6eno3Lkz3nvvPb/X+eSTT9C6dWukp6ejd+/efuPUM3r0aPzyyy/46quv/G5fvnw5tm7ditGjR8Pn8+Hxxx9Ho0aNkJaWhjPPPBOLFi0K+pyzZ89G9erV/W6bP38+PB5P+fePPvoozjzzTMycORNNmjRBZmYmbrvtNpSVleG5555DvXr1ULduXTz11FN+z3P06FHcdNNNqFOnDrKzs9GnTx/88MMPIX/HaCXb+uxERERERAlGG9wz0I9jhYVAZqYzr33iBFC1asQ/np6ejt9++638+yVLliA7Oxuff/45AKCkpAT9+/dHjx498OWXXyI5ORlPPvkkBgwYgB9//BGpqamYPHkyZs+ejZkzZ6Jdu3aYPHkyPvjgA/Tp0yfo6w4bNgwrV67E3//+d3Tu3Bnbtm3D4cOH0bhxY7z//vu4+uqrsXnzZmRnZyM9PR0AMHHiRLz++uuYMWMGWrVqhS+++AI33ngj6tSpg169emHXrl0YNGgQbr/9dtx88834/vvvce+994b8/Tt27Iizzz4bM2fOxPnnn19++6xZs3Duueeibdu2eOGFFzB58mS8/PLL6NKlC2bOnIkrrrgCGzZsQKtWrSL+2+fn5+PTTz/FokWLkJ+fj2uuuQZbt25F69atsXz5cqxYsQKjRo1C37590b17dwDAtddei/T0dHz66aeoVq0aXn75ZVx44YX45ZdfULNmzYjHEpJCETl27JgCQDl27JjTQyEiIiKiGDp0SFFESlZRzj3X6dGQUadOnVJ+/vln5dSpU+KGEyfUf2Ssv06cMDzu4cOHK1deeaWiKIri8/mUzz//XElLS1Puu+++8vtzcnKUoqKi8p957bXXlDZt2ig+n6/8tqKiIiU9PV357LPPFEVRlPr16yvPPfdc+f0lJSVKo0aNyl9LURSlV69eyl133aUoiqJs3rxZAaB8/vnnuuNcunSpAkA5cuRI+W2nT59WMjIylBUrVvg9dvTo0coNN9ygKIqijB8/Xmnfvr3f/Q8++GCF5wo0Y8YMJTMzUzl+/LiiKIpSUFCgZGRkKP/+978VRVGUBg0aKE899ZTfz5x99tnKbbfdpiiKomzbtk0BoKxdu1ZRFEWZNWuWUq1aNb/Hf/DBB4o2ZJ4wYYKSkZGhFBQUlN/Wv39/JTc3VykrKyu/rU2bNsrEiRMVRVGUL7/8UsnOzlZOnz7t99wtWrRQXn75Zd3frcJ7VcNoHMqMPhERERGRCczoJ4iMDJFZd+q1TViwYAEyMzNRUlICn8+HIUOG4NFHHy2/v2PHjkhNTS3//ocffsCvv/5aYX396dOnkZ+fj2PHjmHfvn3lGWcASE5ORrdu3SqU70vr1q1DUlISevXqZXjcv/76KwoLC9GvXz+/24uLi9GlSxcAwMaNG/3GAQA9evQI+9w33HAD7rnnHrzzzjsYNWoU5s6dC6/Xi8GDB6OgoAB79+7Feeed5/cz5513XtQl87m5uX5/15ycHCQlJcHr9frddvDgQQDif3HixAnUqlXL73lOnTqF/Pz8qMYSCgN9IiIiIiITGOgnCI8nqvL5WOrduzdeeuklpKamokGDBkhO9g/jqgb8HidOnEDXrl3xxhtvVHiuOnXqRDQGWYpvxok/DqQsXLgQDRs29LsvLS0tonFI2dnZuOaaazBr1iyMGjUKs2bNwnXXXYfMzEwUFBSYfj6v11vhIIde5/7AJn8ej0f3Np/PB0D8DerXr49ly5ZVeK7AngBWYqBPRERERGQCm/FRrFWtWhUtW7Y0/PizzjoLc+fORd26dZGdna37mPr16+Obb75Bz549AQClpaVYvXo1zjrrLN3Hd+zYET6fD8uXL0ffvn0r3C8rCsrKyspva9++PdLS0rBz586glQDt2rUrbyworVq1KvwvCdGU74ILLsCCBQuwYsWK8jMRZGdno0GDBvj666/9Xvfrr7/GOeeco/tcderUwfHjx3Hy5MnyAyfr1q0zNI5QzjrrLOzfvx/JycnIzc2N+vmMYtd9IiIiIiITmNEntxs6dChq166NK6+8El9++SW2bduGZcuW4c4778Tu3bsBAHfddReeeeYZzJ8/H5s2bcJtt92Go0ePBn3O3NxcDB8+HKNGjcL8+fPLn/Odd94BADRt2hQejwcLFizAoUOHcOLECWRlZeG+++7DPffcgzlz5iA/Px9r1qzBtGnTMGfOHADALbfcgi1btuD+++/H5s2b8eabb2L27NmGfs+ePXuiZcuWGDZsGNq2bYtzzz23/L77778fzz77LObOnYvNmzdj3LhxWLduHe666y7d5+revTsyMjLwf//3f8jPzzc1jlD69u2LHj16YODAgfjvf/+L7du3Y8WKFXjooYfw/fffR/38wTDQJyIiIiIygYE+uV1GRga++OILNGnSBIMGDUK7du0wevRonD59ujzDf++99+Ivf/kLhg8fjh49eiArKwtXXXVVyOd96aWXcM011+C2225D27ZtMWbMGJw8eRIA0LBhQzz22GMYN24ccnJyMHbsWADAE088gYcffhgTJ05Eu3btMGDAACxcuBDNmjUDADRp0gTvv/8+5s+fj86dO2PGjBl4+umnDf2eHo8Ho0aNwpEjRzBq1Ci/++68807k5eXh3nvvRceOHbFo0SJ89NFHQTvu16xZE6+//jo++eQTdOzYEW+99ZZfH4RIeTwefPLJJ+jZsydGjhyJ1q1b4/rrr8eOHTuQk5MT9fMHfV0lWLcFCqmgoADVqlXDsWPHgpbDEBEREVHi+f574OyzxfVGjYBdu5wdDxlz+vRpbNu2Dc2aNUOVKlWcHg5RUKHeq0bjUGb0iYiIiIhMYEafiNyOgT4RERERkQkM9InI7RjoExERERGZwK77ROR2DPSJKCaWLgV27HB6FERERNFjRp+I3I6BPhHZbvNmoE8f4IYbnB4JERFR9Bjoxzf2Iie3s+I9ykCfiGy3b5//JRERUTzTlu6XlQGMG+NDUlISAKBY+w8kcqHCwkIAQEpKSsTPkWzVYIiIgpHZjqIiZ8dBRERkhcAsfmkpEMV8nGIkOTkZGRkZOHToEFJSUuD1MudJ7qIoCgoLC3Hw4EFUr169/OBUJBjoE5Ht5ISIB9CJiCgRBO7PSkoY6McDj8eD+vXrY9u2bdjBxkHkYtWrV0e9evWieg7HA/3p06fj+eefx/79+9G5c2dMmzYN55xzju5jN2zYgEceeQSrV6/Gjh078MILL+Duu+/2e0xubq7uB/e2227D9OnTAQAXXHABli9f7nf/X//6V8yYMcOaX4qI/DDQJyKiRBKY0ec6/fiRmpqKVq1asXyfXCslJSWqTL7kaKA/d+5c5OXlYcaMGejevTumTp2K/v37Y/Pmzahbt26FxxcWFqJ58+a49tprcc899+g+53fffYeysrLy79evX49+/frh2muv9XvcmDFj8Pjjj5d/n5GRYdFvRUSB5L6U+1QiIkoEDPTjm9frRZUqVZweBpGtHF2YMmXKFIwZMwYjR45E+/btMWPGDGRkZGDmzJm6jz/77LPx/PPP4/rrr0daWpruY+rUqYN69eqVfy1YsAAtWrRAr169/B6XkZHh97js7GzLfz8iErRr9NmwiIiI4p1e6T4RkZs4FugXFxdj9erV6Nu3rzoYrxd9+/bFypUrLXuN119/HaNGjYLH4/G774033kDt2rVxxhlnYPz48eWdDYMpKipCQUGB3xcRGaOdAJWWOjcOIiIiKzCjT0Ru51jp/uHDh1FWVoacnBy/23NycrBp0yZLXmP+/Pk4evQoRowY4Xf7kCFD0LRpUzRo0AA//vgjHnzwQWzevBnz5s0L+lwTJ07EY489Zsm4iCob7QSouJgNi4iIKL4x0Ccit3O8GZ+dXn31VVx88cVo0KCB3+0333xz+fWOHTuifv36uPDCC5Gfn48WLVroPtf48eORl5dX/n1BQQEaN25sz8CJEox2AlRUBFSt6txYiIiIosXSfSJyO8cC/dq1ayMpKQkHDhzwu/3AgQNRn0oAAHbs2IHFixeHzNJL3bt3BwD8+uuvQQP9tLS0oH0BiCi0wIw+ERFRPGNGn4jczrE1+qmpqejatSuWLFlSfpvP58OSJUvQo0ePqJ9/1qxZqFu3Li699NKwj123bh0AoH79+lG/LhFVxECfiIgSCQN9InI7R0v38/LyMHz4cHTr1g3nnHMOpk6dipMnT2LkyJEAgGHDhqFhw4aYOHEiANFc7+effy6/vmfPHqxbtw6ZmZlo2bJl+fP6fD7MmjULw4cPR3Ky/6+Yn5+PN998E5dccglq1aqFH3/8Effccw969uyJTp06xeg3J6pcAkv3iYiI4hlL94nI7RwN9AcPHoxDhw7hkUcewf79+3HmmWdi0aJF5Q36du7cCa9XLTrYu3cvunTpUv79pEmTMGnSJPTq1QvLli0rv33x4sXYuXMnRo0aVeE1U1NTsXjx4vKDCo0bN8bVV1+Nv/3tb/b9okSVHDP6RESUSJjRJyK3c7wZ39ixYzF27Fjd+7TBOwDk5uZCMXAS7osuuijo4xo3bozly5ebHicRRY6BPhERJRIG+kTkdo6t0SeiyoOBPhERJRKW7hOR2zHQJyLbcY0+ERElEmb0icjtGOgTke2Y0SciIjMUBVizBigsdHok+pjRJyK3Y6BPRLZjoE9ERGb8739A167AnXc6PRJ9zOgTkdsx0Cci27F0n4iIzNi6VVxu3+7oMIJioE9EbsdAn4hsx4w+ERGZIQ8Ku3WfwdJ9InI7BvpEZDsG+kREZMbp0+LSrfsMZvSJyO0Y6BOR7Vi6T0REZrg9o89An4jcjoE+EdmOGX0iIjLD7Rl9Oa70dHFZWurcWIiI9DDQJyLbMdAnIiIzZEbfrVVgcr9Wtar/90REbsFAn4hsx0CfiIjMcHtGX+7XMjL8vycicgsG+kRkO67RJyIiM9we6MtxMdAnIrdioE9EtmNGn4iIzIiXZnws3Scit2KgT0S2Y6BPRERmuD2jz9J9InI7BvpEZDuW7hMRkRlub8YnD0Awo09EbsVAn4hsx4w+ERGZITP6JSWAojg7Fj3M6BOR2zHQJyLbMdAnIiIztJl8NwbRbMZHRG7HQJ+IbMfSfSIiMkNm9AF3HiBmMz4icjsG+kRkO2b0iYjIDO1BYbcdIFYUlu4Tkfsx0Cci2zHQJyIiM9yc0S8tVa8z0Ccit2KgT0S2Y6BPRERmaLP4bttvaPdpLN0nIrdioE9EtuMafSIiMsPNGX3tPo0ZfSJyKwb6RGQ7ZvSJiMgMN2f0teNhoE9EbsVAn4hsx0CfiIjM0Gb03VYJJvdpSUlAaqr/bUREbsFAn4hspe1ODLhvwkZERO4TD6X7KSniS3sbEZFbMNAnIltpuxMD7puwERGRu5SWAmVl6vdu22/I8aSmAsnJ4joDfSJyGwb6RGSrwMmP2yZsRETkLoGVX27bbzCjT0TxgIE+EdkqcPLD0n0iIgolXgL91FQG+kTkXgz0ichWzOgTEZEZ2vX5gPsOEMv9GDP6RORmDPSJyFYM9ImIyIx4yehrA/3AfjRERE5joE9EtmKgT0REZgRm9N2239A242NGn4jcioE+EdmKa/SJiMiMeMzoM9AnIrdhoE9Etgqc/JSWAj6fM2MhIiL3c/safQb6RBQPGOgTka3k5CctreJtREREgdye0WfpPhHFAwb6RGQrOfnJzFRvc1t2hoiI3MPta/SZ0SeieMBAn4hsJSc/Vauqt7lt0kZERO7h9ow+A30iigcM9InIVnLyk5oKJCeL626btBERkXu4PaPP0n0iigcM9InIVtrMR2qquM7SfSIiCobN+IiIosdAn4hspZ0QyYZ8bsvOEBGRe8Rj6b7PxzPKEJG7MNAnIlvpZfTdNmkjIiL3iMfSfYBZfSJyFwb6RGQrBvpERGRGPGb0tbcTEbkBA30ishXX6BMRkRnxskafGX0icjMG+kRkK67RJyIiM9ye0ZfjYUafiNyMgT4R2Yql+0REZIbM6Gdmiku37TO0+zWPB0hK8r+diMgNGOgTka1Yuk9ERGbIfUR2trh0W6CvbcYH8BR7RORODPSJyFYs3Y9fiuL0CIioMpIZfbcG+tr9mvaSgT4RuQkDfSKyFUv349MzzwB16wIbNzo9EiKqbGRGPyvL/3u3YKBPRPGAgT4R2Yql+/HpnXeAw4eBVaucHgkRVTZuz+izdJ+I4gEDfSKyFUv344+iAFu2iOuFhc6OhYgqH7ev0Q/M6Ccn+99OROQGDPSJyFYs3Y8/Bw4AJ06I6wz0iSjW3J7RZ+k+EcUDBvpEZCsG+vFHZvMBBvpEFHsy0Jdr9N22zwhWul9a6sx4iIj0MNAnIltxjX78YaBPRE4KLN132z6DGX0iigeOB/rTp09Hbm4uqlSpgu7du+Pbb78N+tgNGzbg6quvRm5uLjweD6ZOnVrhMY8++ig8Ho/fV9u2bf0ec/r0adx+++2oVasWMjMzcfXVV+PAgQNW/2pEBK7Rj0cM9InISSzdJyKKnqOB/ty5c5GXl4cJEyZgzZo16Ny5M/r374+DBw/qPr6wsBDNmzfHM888g3r16gV93g4dOmDfvn3lX1999ZXf/ffccw8+/vhjvPvuu1i+fDn27t2LQYMGWfq7EZHA0v348+uv6nUG+kQUa25vxseu+0QUD5KdfPEpU6ZgzJgxGDlyJABgxowZWLhwIWbOnIlx48ZVePzZZ5+Ns88+GwB075eSk5ODHgg4duwYXn31Vbz55pvo06cPAGDWrFlo164dVq1ahT/96U/R/lpEpCEnPqmp6vpFt5Vhkj9m9InISczoExFFz7GMfnFxMVavXo2+ffuqg/F60bdvX6xcuTKq596yZQsaNGiA5s2bY+jQodi5c2f5fatXr0ZJSYnf67Zt2xZNmjQJ+bpFRUUoKCjw+yKi8Fi6H18UhRl9InKWPBgsm/G57eCw9gA2wECfiNzJsUD/8OHDKCsrQ05Ojt/tOTk52L9/f8TP2717d8yePRuLFi3CSy+9hG3btuHPf/4zjh8/DgDYv38/UlNTUb16dVOvO3HiRFSrVq38q3HjxhGPkagyYel+fNm3Dzh5Uv2egT4RxZpeRl9RnBtPILkPY0afiNzM8WZ8Vrv44otx7bXXolOnTujfvz8++eQTHD16FO+8805Uzzt+/HgcO3as/GvXrl0WjZgosbHrfnzRlu0DDPSJKPYC1+gD7jp1HUv3iSgeOLZGv3bt2khKSqrQ7f7AgQMhG+2ZVb16dbRu3Rq//lGLWq9ePRQXF+Po0aN+Wf1wr5uWloY0WXdMRIYFZj60t5H7yEA/JUVMWhnoE1GsBWb0AbHf0O5HnMRmfEQUDxzL6KempqJr165YsmRJ+W0+nw9LlixBjx49LHudEydOID8/H/Xr1wcAdO3aFSkpKX6vu3nzZuzcudPS1yUigWv044tcn9++vbhkoE9EsVRaCpSVietyjT7grv0GM/pEFA8c7bqfl5eH4cOHo1u3bjjnnHMwdepUnDx5srwL/7Bhw9CwYUNMnDgRgGjg9/PPP5df37NnD9atW4fMzEy0bNkSAHDffffh8ssvR9OmTbF3715MmDABSUlJuOGGGwAA1apVw+jRo5GXl4eaNWsiOzsbd9xxB3r06MGO+0Q20E6IkpLEdTdN2MifzOh37gz88AMDfSKKLe3SrqpVAY9HrM9305IvBvpEFA8cDfQHDx6MQ4cO4ZFHHsH+/ftx5plnYtGiReUN+nbu3AmvVy062Lt3L7p06VL+/aRJkzBp0iT06tULy5YtAwDs3r0bN9xwA3777TfUqVMH559/PlatWoU6deqU/9wLL7wAr9eLq6++GkVFRejfvz/++c9/xuaXJqpktBMi2UzJTRM28qcN9AH/xnxERHbT7h+qVBHl8UVF7jpAzNJ9IooHjgb6ADB27FiMHTtW9z4ZvEu5ublQwrRdffvtt8O+ZpUqVTB9+nRMnz7d8DiJKDLaQN/jEdfdNGEjlc+nlu7LQJ8ZfSKKJbk+PykJSE4WS77cFugzo09E8cDxQJ+IEpt2QiQLdNw0YSPV3r3AqVNigi3X6BcVifWyctkFEZGdZKAve7q48bSsDPSJKB4k3On1iMhdeHq9+CGz+bm5QLVq6u2nTjkyHCKqhOT+oUoVcenGQN9s6f6JE/aPiYgoEAN9IrIVu+7HD7k+v1UrdZINsHyfiGInWEbfTQeIzWT0p0wRB04XL47N2IiIJAb6RGQrvYw+A3130gb6Xi+Qni6+Z6BPRLHi9oy+oohTAALGAv1Vq0T/k++/j834iIgkBvpEZCuW7scPbaAPABkZ4pKBPhHFiszoy0DfbZVg2mDeSOm+XPrEJVBEFGsM9InIVszoxw8G+kTkNHkg2K3N+LTBvJGMPgN9InIKA30ishXX6McHnw/IzxfXW7YUlwz0iSjWAjP6bqsEM5vRl9tPBvpEFGsM9InIVszox4c9e8QEOzlZdN0HGOgTUey5PaOvHUfyHyepZkafiNyIgT4R2Ypr9OODLNtv1kydvDLQJ6JYC5bRd0ugL/dpycmAx6NeB9QmfVrM6BORUxjoE5GtWLofHwLX5wNA1arikoE+EcVKYEbfbfsNOQ55AAJgRp+I3ImBPhHZSi+j7/MBZWXOjYkq0gv0mdEnoliLl4y+DO611xnoE5GbMNAnIlvpBfoAy/fdRgb6shEfwECfiGIv2Bp9t+wzzAb6LN0nIqcw0Cci2yiKumYxMNB3S3aGhF9/FZfM6BORk9ye0TdTuq8ozOgTkXMY6BORbbSNiVJS/DMgbpm0kf+p9RjoE5GTZKDv1jX6ZjL6xcUi2AcY6BNR7DHQJyLbaCc9KSmiQ7HbyjAJ2LVL/D9SUoAmTdTbGegTUazJfYNbM/pmAn3ttpOBPhHFGgN9IrJNYKAPuG/SRsDOneKySRP1NFEAA30iir1gpftuOThspnRfG9wz0CeiWIso0M/Pz8ff/vY33HDDDTh48CAA4NNPP8WGDRssHRwRxTe9QN9tZZikTqzl6fQkBvpEFGvBmvG5ZZ9hJqPPQJ+InGQ60F++fDk6duyIb775BvPmzcOJEycAAD/88AMmTJhg+QCJKH7JSY/HAyQlietum7SR/sQVYKBPRLHn9mZ8LN0nonhhOtAfN24cnnzySXz++edI1dQt9enTB6tWrbJ0cEQU3/QmRG4rwyT9UlSAgT4RxV5gRt9tVWDRlO7LxnxERLFgOtD/6aefcNVVV1W4vW7dujh8+LAlgyKixBAq0HfLpI3CB/onT8Z2PERUeSVqRh/gAW4iii3TgX716tWxb9++CrevXbsWDRs2tGRQRJQY9CZEbsvOEEv3icg9gq3Rd0uQLLeXZjP6et8TEdnJdKB//fXX48EHH8T+/fvh8Xjg8/nw9ddf47777sOwYcPsGCMRxSmW7scHlu4TkVu4PaMvx2G2GZ/e90REdjId6D/99NNo27YtGjdujBMnTqB9+/bo2bMnzj33XPztb3+zY4xEFKf0Mh9um7QRA30icg+3r9GPpnSfgT4RxVJy+If4S01NxSuvvIKHH34Y69evx4kTJ9ClSxe0atXKjvERURxj6X580DsgAzDQJ6LYi5eMPkv3icjtTAf6UpMmTdCkSRMrx0JECYal+/FBrxQVYKBPRLEXbI2+WwJ9Mxl9BvpE5CTTgf6oUaNC3j9z5syIB0NEiYVd9+ODkdJ9RQE8ntiOi4gqn2AZfbccHGbpPhHFC9OB/pEjR/y+Lykpwfr163H06FH06dPHsoERUfxj6X58CFe67/OJ/5f83xER2UUG+m7N6Icr3dceFGVGn4icZDrQ/+CDDyrc5vP5cOutt6JFixaWDIqInPHJJ8Dy5cDTTwNJSdE/HzP68SFc6T4gMlMM9InIbjJzLzP6bjs4HCqjDwBlZUDyH7NrBvpE5CTTXfd1n8TrRV5eHl544QUrno6IHDJuHPDcc8CqVdY8H9fox4dgpfspKeqElev0iSgW3N6ML1ygry3fZ+k+ETnJkkAfAPLz81FaWmrV0xGRAwoK/C+jxYx+fAgW6ANsyEdEsRWsGZ9bDg6HKt0HAO1UmBl9InKS6dL9vLw8v+8VRcG+ffuwcOFCDB8+3LKBEVHsyUyKVZMRvZJwt5Vhkv4BGSkjQxz4YaBPRHYrLRWl7wAz+kRE0TId6K9du9bve6/Xizp16mDy5MlhO/ITkbvJQF9eRoul+/GBGX0icgPtfsGtzfj09mvanjbaQJ8ZfSJykulAf+nSpXaMg4hcwOqMPkv34wMDfSJyA+1BZhnou60KTG976fGIfialpfqBfnq6uM5An4hiybI1+kQU3xRFzabYGei7bdJGoUv3q1YVlwz0ichuch+UlKQ2AnXbweFg20vtKfYkud2sVUtcMtAnolgylNHv0qULPPKkoGGsWbMmqgERkTO0JZMs3a9cmNEnIjcI7LgP+O8ztOeod4rcr+mdpeTUKf2Mfs2awO7dDPSJKLYMBfoDBw60eRhE5DRtcM/S/cqFgT4RuUFgx31A3S4piv856p2i12RW+32wQF/7PRFRLBjaXE6YMMHucRCRwxjoV17huu4DDPSJyH56GX1t0F9c7Hygz9J9IooXXKNPRABiF+hzjb77MKNPRG4QKqMPuGO/EWx7yYw+EbmN6eOiZWVleOGFF/DOO+9g586dKA7Y6v7++++WDY6IYkc7AeEa/cqFgT4RuYFeRl+bwXdDoG8mox8Y6HM7SkSxZDqj/9hjj2HKlCkYPHgwjh07hry8PAwaNAherxePPvqoDUMkolhg6X7lxdJ9InIDuR/SZvQ9HncdIGbpPhHFC9OB/htvvIFXXnkF9957L5KTk3HDDTfg3//+Nx555BGsWrXKjjESUQywdL/yMpLRP3kyduMhospJBvLajD7grgPERkv3S0qA0lJxnaX7ROQE04H+/v370bFjRwBAZmYmjh07BgC47LLLsHDhQmtHR0Qxow30WbpfubB0n4jcQK90H3DXAWKjGX1tUM+MPhE5wXSg36hRI+zbtw8A0KJFC/z3v/8FAHz33XdI09ZaEVFcYel+5cXSfSJyA71mfIC79huRBPrVq1e8jYjIbqYD/auuugpLliwBANxxxx14+OGH0apVKwwbNgyjRo2yfIBEFBss3a+8mNEnIjcIltF3UyWY0dJ9uR9NT1e3owz0idzB5wMGDgQGD3Z6JPYy3HX/H//4B2688UY888wz5bcNHjwYTZo0wcqVK9GqVStcfvnltgySiOzH0v3Ki4E+EblBImX05TYzPV18AQz0idxi2zbgww/F9ZkzgapVnR2PXQxn9B966CE0aNAAQ4cOxf/+97/y23v06IG8vDwG+URxjqX7lRdL94nIDcJl9N2w3zBbus9An8h9Nm5Uryfy/MZwoL9//37MmDEDe/fuRb9+/dCsWTM88cQT2LVrl53jI6IYYaBfeTGjT0RuECyj76YlX2ZL9zMyGOgTuY020E/kswoZDvTT09MxbNgwLF26FFu2bMFf/vIXvPrqq2jWrBkGDBiAd999FyXak4cSUVyJVem+myZsJDDQJyI3SKSMvl7pflmZej8ROWfTJvV6Is9vTDfjA4DmzZvj8ccfx7Zt2/Dpp5+iVq1aGDFiBBo2bGj1+IgoRmKd0ecaffdg6T4RuUG4Nfpu2G/I7WUkGX3t7UTkHGb0DfB4PEhOTobH44GiKMzoE8Uxlu5XTooSfOIKMNAnotiJh4y+HIOZNfra34eBPpGzFIVr9EPatWsXHn/8cTRv3hz9+vXD3r178corr2Dfvn1Wj4+IYiSwdF9Ron/OcKX7VrwGRUd7fJaBPhE5KR7W6EdSuu/xqME+A30iZx04ABw9qn6fyBl9w6fXKy4uxrx58zBz5kz873//Q/369TF8+HCMGjUKzZs3t3OMRBQDgevyi4oqZlXMCpXRl/frBZcUO0YD/aIisb40KSk24yKiysftGX2fT2wHgeCl+6Wl4lJbui8vT59moE/kNG02H0jsRIbhjH69evUwYsQIZGdn4+OPP8aOHTvw5JNPRh3kT58+Hbm5uahSpQq6d++Ob7/9NuhjN2zYgKuvvhq5ubnweDyYOnVqhcdMnDgRZ599NrKyslC3bl0MHDgQmzdv9nvMBRdcAI/H4/d1yy23RPV7EMW7wMmHFZMRvZJw7XWnJ23k/z8ItUYf4ASViOwlA323rtHXHhg1k9HXXnI7SuQsbSM+ILEz+oYD/b/97W/YtWsX3nvvPVx88cXweqNa3g8AmDt3LvLy8jBhwgSsWbMGnTt3Rv/+/XHw4EHdxxcWFqJ58+Z45plnUK9ePd3HLF++HLfffjtWrVqFzz//HCUlJbjoootwMuC/OGbMGOzbt6/867nnnov69yGKZ4EZfSs674fL6DPQd572f5CsU+Olzawl8lFvInKeDOTdmtE3E+hr1+hrLxnoEzmrMmX0DZfu5+XlWf7iU6ZMwZgxYzBy5EgAwIwZM7Bw4ULMnDkT48aNq/D4s88+G2effTYA6N4PAIsWLfL7fvbs2ahbty5Wr16Nnj17lt+ekZER9GABUWUUGNhbmdHXToiSkwGvV5RAOp2dIf+qC4+n4v1er5ignjqV2DtDInKe20v3ta8fWLovD5Tqdd0HGOgTuYUM9JOSxFIcZvRtUFxcjNWrV6Nv377qYLxe9O3bFytXrrTsdY4dOwYAqFmzpt/tb7zxBmrXro0zzjgD48ePR2GYGWxRUREKCgr8vogSSawCfcA9kzYK3kFaiw35iCgW3N6MT5vRD+xXwtJ9ovggA/0zzhCXiRzoG87oW+3w4cMoKytDTk6O3+05OTnYFLh4IkI+nw933303zjvvPJwh/5sAhgwZgqZNm6JBgwb48ccf8eCDD2Lz5s2YN29e0OeaOHEiHnvsMUvGReRGsQ70T592ftJG6v8gVFPEqlWB335joE9E9nJ7Rl+7TwusgApWus+MPpF7FBQAe/aI6127Aj/8kNhzG8cC/Vi4/fbbsX79enz11Vd+t998883l1zt27Ij69evjwgsvRH5+Plq0aKH7XOPHj/dbvlBQUIDGjRvbM3AiB8RqjT7gnuwMGQv0mdEnolgIltF3SzO+UNtLrtEncj+ZS65XD2jQQFxP5Ix+xKX7xcXF2Lx5M0rleURMql27NpKSknDgwAG/2w8cOGDJ2vmxY8diwYIFWLp0KRo1ahTysd27dwcA/Prrr0Efk5aWhuzsbL8vokTiROm+05M2Cv4/0mKgT0SxEE8Z/UAs3SdyPxnot2snqhWBxJ7bmA70CwsLMXr0aGRkZKBDhw7YuXMnAOCOO+7AM888Y/h5UlNT0bVrVyxZsqT8Np/PhyVLlqBHjx5mh1VOURSMHTsWH3zwAf73v/+hWbNmYX9m3bp1AID69etH/LpE8Y5r9CsnZvSJyC3CZfSd3meYCfRZuk/kPnJ9frt26meTGX2N8ePH44cffsCyZctQRXPItW/fvpg7d66p58rLy8Mrr7yCOXPmYOPGjbj11ltx8uTJ8i78w4YNw/jx48sfX1xcjHXr1mHdunUoLi7Gnj17sG7dOr9M/O23347XX38db775JrKysrB//37s378fp/7Ysubn5+OJJ57A6tWrsX37dnz00UcYNmwYevbsiU6dOpn9cxAlDBnoy87BLN2vHBjoE5FbBMvou2WfwdJ9ovgmA/22bStHRt/0Gv358+dj7ty5+NOf/gSPphNJhw4dkJ+fb+q5Bg8ejEOHDuGRRx7B/v37ceaZZ2LRokXlDfp27twJr1c9FrF371506dKl/PtJkyZh0qRJ6NWrF5YtWwYAeOmllwAAF1xwgd9rzZo1CyNGjEBqaioWL16MqVOn4uTJk2jcuDGuvvpq/O1vfzM1dqJEIydY1asDhw+zdL+yMFO6n8hHvYnIeYmU0WfpPpH7aDP6hw6J64k8tzEd6B86dAh169atcPvJkyf9An+jxo4di7Fjx+reJ4N3KTc3F4qihHy+cPc3btwYy5cvNzVGospABvo1asQu0Hd60kbM6BORe4Rbo+/0wWG5TzOT0WfpPpE7FBcDMifdrp06p0nkuY3p0v1u3bph4cKF5d/L4P7f//53VGvrichZ2kBf+32kFAWQvToZ6LsXA30icgu3Z/Tl6zOjTxR/fv0VKCsDsrJEx31Zus+MvsbTTz+Niy++GD///DNKS0vx4osv4ueff8aKFSuYKSeKY9rSfSD6yYic7ADB1+g7nZ0hdt0nIncoLRWTcMC9a/QjacbHQJ/IHbTr8z2eyrEs0XRG//zzz8e6detQWlqKjh074r///S/q1q2LlStXomvXrnaMkYhsVlamTk5kRt/OQN8t2RliRp+I3EFbReb2jD5L94nij3Z9PsBmfEG1aNECr7zyitVjISKHaDPrVpXuM9CPDwz0icgNtPuhYIG+01VgbMan2rMHGDECGDsWuPJKp0dDFF5goF8ZMvoRBfoAcPDgQRw8eBA+n8/vdp6ijij+aCcesSzdZ6DvPJbuE5EbaE/xmhwwO3XLwWGjgb7Ppx6USNSM/oIFwOLFYn/OQJ/iQaiMvqKIcv5EYzrQX716NYYPH46NGzdW6HDv8XhQJhdYEVHc0E6wMjPFdasCfa9XfGm5JTtDzOgTkTsEa8QHuCfQN1q6r62IS9SM/uHD4jJRfh9KbD4fsGmTuB6Y0ZcH5gJ7gyQC04H+qFGj0Lp1a7z66qvIycmJ6JR6ROQu2lMaycmIVaX7epkPt0zaiIE+EblDsFPrAe6pAjOa0dduKxM10P/9d3HJA/YUD3btEp+9lBSgeXNxm5zbAOIzy0AfwNatW/H++++jZcuWdoyHiBygnWDJDZ1VGX0G+u7G0n0icoN4yOgbDfTl/jM1FUhKEtcZ6BPFzrp1wI4dQKdOQG6uWrbfqpW6NCglRXyVlIh1+jVrOjVa+5gO9C+88EL88MMPDPSJEoheRt/OQJ+n13MPZvSJyA1CZfTdstzLaOl+4Kn1tNcTJdD/7Tdx6fT/hCjQ8ePAueeqn7WsLLXRtCzbl6pWBY4eTdz5jelA/9///jeGDx+O9evX44wzzkBKwCz+iiuusGxwRBQbsQ703ZKdIQb6ROQOiZLRLy2t2HFfez1RAn2Z0Y92mR+R1X77zb+q5vhx8QUAZ57p/1gZ6Cdq533Tgf7KlSvx9ddf49NPP61wH5vxEcUnuaNOT+ca/cqGpftE5AaJtEZfBhnaNcCJGugzo09uI7clNWsC+/cDv/wC/PCDaCA5YoT/YxP9FHumA/077rgDN954Ix5++GHk5OTYMSYiirFYr9Fn6b57MKNPRG4QDxl9o6X7lSGjz9J9civtnDYlBejQQXzp0Z5iLxF5wz/E32+//YZ77rmHQT5RAmHpfuXFQJ+I3MDIGn2n9xlWZPSLisTpvOKZorB0n9wr1LYkUKJn9E0H+oMGDcLSpUvtGAsROYSn16u8zJbuK4r9YyKiysdIRr+sTHw5RW4vo2nGB8R/cHzihOhFADCjT+4TalsSKNEz+qZL91u3bo3x48fjq6++QseOHSs047vzzjstGxwRxYZTpfsM9J1nJqPv84nHG9l5EhGZYSSjD4htkDZojiW5vdTbr8lTdoUr3QfE/lWb7Y83smwfEEGVogAej3PjIdJiRl8VUdf9zMxMLF++HMuXL/e7z+PxMNAnikNOle4zE+A8M4E+ICawDPSJyGpGmvEBzgb6Rrvu65XuJyWp5+yO93X6smwfEEF+SUnofQhRLJkJ9JnRD7Bt2zY7xkFEDmLpfuUVqhRVSklRJ6iFher5aImIrBKq3Fa7H3Fyv2GkGR8AFBSIy8ADEunpiRfoA+J/x0Cf3IIZfZXpNfpElHj0SvdLS9U1eJFgoB8fQpWiarEhHxHZKdTk3ONRt1FOVoIZyegDoQN9IP63o9rSfYDVeeQuXKOvMp3RHzVqVMj7Z86cGfFgiMgZehl9QGQdsrIie06eXi8+GCndB0Sgf+xY4u4MichZ4Sbnqaliv+LkAWKzgX7gOvxEOcVeYEY/3psLUmKJpHQ/UTP6pgP9I0eO+H1fUlKC9evX4+jRo+jTp49lAyOi2JGTDm1GHxAbSzsCfWb03cNI6T6Q+OVtROSscJPz1FSx/YmH0v1jx8RlsIx+vAf6zOiTm7F0X2U60P/ggw8q3Obz+XDrrbeiRYsWlgyKiGJLu1H0esUkprg4uslIqACSgb57sHSfiNwgXEbfDWdrCXUAOylJLDFQlMqX0WegT27CZnwqS9boe71e5OXl4YUXXrDi6YgoxgI3ilZMRli6Hx/MlO4DibszJCJnGcnoA+4N9LW3J3pGn6X75GZm1ugnekbfsmZ8+fn5KI2mcxcROSZYoB/Nzpul+/GBgT4RuYGRNfraxzkh3PZS7u/CNeOL90CfpfvkZszoq0yX7ufl5fl9rygK9u3bh4ULF2L48OGWDYyIYidwoygv7croM9B3j3AZKomBPhHZKZEy+izdJ3IO1+irTAf6a9eu9fve6/WiTp06mDx5ctiO/ETkTrEu3XfDhI0EZvSJyA3ifY2+9naW7hM5hxl9lelAf+nSpXaMg4gcxDX6lRcDfSJyg3jI6LN0X5Cl+1Wrikwo9+XkJlyjr7JsjT4RxS85wZKTEDnR4hr9xMfSfSJyg3hYo280oy/3nYlYuq8oaka/QQNxyUCf3IQZfZWhjH6XLl3g8XgMPeGaNWuiGhARxR5L9ysvZvSJyA3iIaMf6rSxQMX9XSJm9I8fB8rKxPX69YEtW1i6T+4SSaCfqBl9Q4H+wIEDbR4GETnJqdL90lLA5wO8rC1yDAN9InKDeAj05WuHy+hLiZjRl2X76elA9eriOjP65CZyW8LSfYOB/oQJE+weBxE5yKnT6wFi4mTkqCvZg6X7ROQGidSMT0rEjL4s269Zk/12yJ3k+9FMRr+0VHy+w82F4o3pZnzS6tWrsXHjRgBAhw4d0KVLF8sGRUSx5dTp9QAG+k5jRp+I3CCeMvqVuXRfBvq1aqmBPkv3yU0iOb0eILL6skolUZgO9A8ePIjrr78ey5YtQ/U//hpHjx5F79698fbbb6NOnTpWj5GIbObUGn2AmQAnKUr4NacSA30islO4ctt4asYnJXLpfs2a6pyB+3FyEzOBfmoqkJQk+k4UFiZeoG96Zewdd9yB48ePY8OGDfj999/x+++/Y/369SgoKMCdd95pxxiJyGaxLt33eoHkPw4zsiGfc0pL1ess3SciJ8ltiyylDeSGjD5L91m6T+5nZo2+x5PY6/RNZ/QXLVqExYsXo127duW3tW/fHtOnT8dFF11k6eCIKDZiXboPiElbaSkDfSdp//bM6BORk+S2JTALLrkh0Gfpvn7pPgN9chMza/QBcXDx+PHEnN+Yzuj7fD6k6MzcU1JS4PP5LBkUEcVOSYl6qpxYle4D7pi0VXYM9InIDYqL1QqjYBn9eGvGl5QUPPCP50Bfr3Sfa/TJTcyU7gOJndE3Hej36dMHd911F/bu3Vt+2549e3DPPffgwgsvtHRwRGQ/7Q7aytL9cKchYibAeXLSCqhLKYJhoE9EdtFuV9yc0TcT6Keni7JgrUQI9Fm6T25nNtCXBxcTcX5jOtD/xz/+gYKCAuTm5qJFixZo0aIFmjVrhoKCAkybNs2OMRKRjbTBvNxpx6p0H2BG30nagzGBE9JAckd44oS9YyKiykdm0pKTg1cXOd2Mr6wMkIWrRkr39Q5YJFKgz9J9cisza/QBdX6TiBl9w2v077vvPtx0001o27Yt1qxZg8WLF2PTpk0AgHbt2qFv3762DZKI7CM3iKmpokkewNL9ysLoqfUAIDNTXDLQJyKrhVufDzi/z9BWQAXbr2krowLX52tvi+dAX1u6L/cHLN0nNzG7Rj+RS/cNB/offvghXnjhBXTv3h033XQTBg8ejH79+tk5NiKKAb0SJ7u77gPMBLhBuP+RVlaWuDxxQpyWL1wFABGRUUYCfafX6BsJ9ANL9wMlQqCvLd0/cEBc536c3MLnU7cRLN03Ubq/ZcsWLF26FK1bt8Zdd92FevXqYfTo0VixYoWd4yMim+kF+izdrxwiyegrSmLuDInIOTKTFqwRH+D8PsNI81KW7hM5S/teZEbf5Br9nj17Yvbs2di/fz9efPFF/PLLLzj//PPRrl07TJo0CQfkoT0iihuhMvoM9BObmUA/I0PN4rN8n4isZKZ036mgUu7TPB7RUV+PmYy+olg7vlhQFP+MPrvuk9vo9Z0Khxn9AFWrVsWoUaPw5Zdf4pdffsGgQYMwceJENGnSxOrxEZHNnCrdd3rSRuZK971edWd4/Lh9YyKiykdm0uJhjX6oA6NGA31Fic+D3AUF6ul42XWf3Ei+F73e8GcTkpjRD+LkyZP48ssvsXz5chw5cgTNmze3alxEFCMymNdOSmJRuu/0eksyl9EH/NfpExFZRWbS4qF0P9SB0XCl+9rb4rF8X2bzMzLEPIGBPrmNNnlltJcQM/oBvvrqK4waNQr169fHnXfeidatW+PLL7/Exo0brR4fEdnMqdJ9+XqJuGGNF2YDfblOnxl9IrJSPDXjMxro62X0U1LUs9vEY6Cv7bgPqP8Tlu6TW+jNacNJ5Iy+4a77+/btw5w5czB79mz88ssv+NOf/oQpU6bg+uuvR6ac/RFR3HEq0K9bV1yytYdzjJSiajGjT0R2iKdmfEZL9/UOWng8Yv968mR8Bvra9fmAOm9gRp/cQs5pja7PBxI7o2840G/cuDFq1aqFv/zlLxg9ejTatWtn57iIKEacWqNfv7643Lcv8teg6BgpRdViRp+I7BBPzfiiyejL2+M90K9VS1yydJ/cRr4XzWT0ZaBfqTP677zzDq644gokG+1sQERxIdTp9U6fjvyc6Qz03Y9r9InIDeKhGZ8MzEMFEEYDfe3zxROW7pPbsXTfn+E1+oMGDWKQT5SAQmX0tfebxUDf/cyW7jOjT0R2MNKMz+k1+jIwDxbAA+FL97U/H4+BPkv3ye0iCfQTuXQ/qq77RBT/nAr0GzQQl3v3Rvb8FD2zpfvM6BORHcyU7jsd6IcaY6Jn9Fm6T24XyRp9ZvSJKGHplSMmJ0ffGdhMRl9RInsNig677hORG8RDMz6zGf1EDPRDle5zP05uEM0afWb0iSjh6GX0ZWdgwL5Av149cVlcDBw5EtlrUHS4Rp+I3CAemvGxdD946T6g7vOJnMQ1+v4Y6BNVcsE2itF03lcUoKxMXA8WRFapAtSoIa5znb4zjHSR1mJGn4jsEA/N+OTBiMqc0Q9Wug+wfJ/cgWv0/RkK9AcNGmT4y6zp06cjNzcXVapUQffu3fHtt98GfeyGDRtw9dVXIzc3Fx6PB1OnTo3oOU+fPo3bb78dtWrVQmZmJq6++moc4Mm8qZIKtlGU30cyGdEe2Q8VRLIhn7OY0SciN4inZnxG1+gnYkY/WOk+wM775A5co+/PUKBfrVq18q/s7GwsWbIE33//ffn9q1evxpIlS1CtWjVTLz537lzk5eVhwoQJWLNmDTp37oz+/fvj4MGDuo8vLCxE8+bN8cwzz6CerPuN4DnvuecefPzxx3j33XexfPly7N27N6KDFESJIFxGn4F+4uIafSJyg3hqxseMvhroe73q78yMPrlBNGv0i4rUatREYSjQnzVrVvlXTk4OrrvuOmzbtg3z5s3DvHnzsHXrVlx//fWoXbu2qRefMmUKxowZg5EjR6J9+/aYMWMGMjIyMHPmTN3Hn3322Xj++edx/fXXIy3IoZpwz3ns2DG8+uqrmDJlCvr06YOuXbti1qxZWLFiBVatWmVq/ESJwI7SfbOBPjvvO8Ns6T4z+kRkBzPN+EpLAZ/P/jEFquyBvs9XsXQfYOd9cpdoSveBxCvfN71Gf+bMmbjvvvuQlJRUfltSUhLy8vKCBuh6iouLsXr1avTt21cdjNeLvn37YuXKlWaHZfg5V69ejZKSEr/HtG3bFk2aNAn5ukVFRSgoKPD7IkoETpbuy1PsMaPvDGb0icgNzGT0AWey+mbX6Cda6X5BgXqARfbXAfw77xM5LZJAv0oV0YQaSLzyfdOBfmlpKTZt2lTh9k2bNsFn4hDr4cOHUVZWhpycHL/bc3JysH//frPDMvyc+/fvR2pqKqpXr27qdSdOnOi3hKFx48YRjZHIbews3U9KUjeeeli67yyu0SciNzDTjA9wJtA3u0Y/0TL6MpufkeE/X5DXmdEnN4hkjb7Ho36uEy2jn2z2B0aOHInRo0cjPz8f55xzDgDgm2++wTPPPIORI0daPkC3GD9+PPLy8sq/LygoYLBPCcHO0v1wJeEM9J3FrvtE5AZGmvG5JdCvrKX7emX7AEv3yV0iWaMPiED/5MnEy+ibDvQnTZqEevXqYfLkydj3x+y8fv36uP/++3Hvvfcafp7atWsjKSmpQrf7AwcOBG20Z8Vz1qtXD8XFxTh69KhfVj/c66alpQXtC0AUz2QgHzgpsaJ0n4G+uzGjT0ROUxRjpfteL5CcLNbox0Ogn2il+4Ed9yUG+uQmkZTuA+Ig46FDiZfRN1267/V68cADD2DPnj04evQojh49ij179uCBBx7wW7cfTmpqKrp27YolS5aU3+bz+bBkyRL06NHD7LAMP2fXrl2RkpLi95jNmzdj586dEb8uUTyzs3TfTKCvKOZfh6IT6Rr9oiL/PgxERJHS7mNCZfQBdVvlRFBpdo1+uIx+vAUUgR33JTl34Bp9coNIA/1EPcWe6Yw+INbpL1u2DPn5+RgyZAgAYO/evcjOzkamnAkakJeXh+HDh6Nbt24455xzMHXqVJw8ebJ8CcCwYcPQsGFDTJw4EYBotvfzzz+XX9+zZw/WrVuHzMxMtGzZ0tBzVqtWDaNHj0ZeXh5q1qyJ7Oxs3HHHHejRowf+9Kc/RfLnIIprbgj0T54U5eDZ2eZfiyIXaek+ILL62oZMRESR0Aa8oYJoQAT6hYXxsUY/0TL6LN2neBDJGn1APcgYbwfgwjEd6O/YsQMDBgzAzp07UVRUhH79+iErKwvPPvssioqKMGPGDMPPNXjwYBw6dAiPPPII9u/fjzPPPBOLFi0qb6a3c+dOeL1q0cHevXvRpUuX8u8nTZqESZMmoVevXli2bJmh5wSAF154AV6vF1dffTWKiorQv39//POf/zT7pyBKCE6u0c/MFOXgx4+LrD4D/dgym9FPTRVfxcXif8ZAn4iiJTNoaWmigWsocvLu1tL95D9m1R5P8EAjXgP9RC3d/+wz4NlngVdeAVq0cHo0FK1o1ugDzOjjrrvuQrdu3fDDDz+gluaw3lVXXYUxY8aYHsDYsWMxduxY3ftk8C7l5uZCMVDfG+o5AaBKlSqYPn06pk+fbmqsRInIztPrGckU16+vBvpt2ph/LYqc2UAfEAdmfvuN6/SJyBpGGvFJclvl1kBf7vO0p+sKFK+BfqKW7v/738DSpcBHHwH33OP0aCha0azRBxIvo296jf6XX36Jv/3tb0gNmBnm5uZiz549lg2MiGLDydJ9gA35nGS2dB9g530ispaRRnySnHo+8gjw7bf2jUmPkTX6tWuLAF/u1/TEe6CfaKX7x46Jy0QL8CqraAP9RMvomw70fT4fysrKKty+e/duZMmWzEQUN+Rkw4nSfYCBvpMizegDzOgTkTXkxNpIRv/668XlJ58A3bsDffqI0utYNHM1ktFv0AD49FPggw+CPyZeA/1ELd0vKBCXDPQTQ6Rr9BO1dN90oH/RRRdh6tSp5d97PB6cOHECEyZMwCWXXGLl2IjIZorijtJ9gIG+EyIJ9JnRJyIrmcnoP/kksGEDMHy4WA+/dCkwYABg4uzOETPSjA8A+vcHOnUKfn+8BvqJWrovA/14+3+QvkjX6LN0/w+TJ0/G119/jfbt2+P06dMYMmRIedn+s88+a8cYicgm2nWOTpfu791r/nUoOpGU7jOjT0RWkhk0I4E+ALRvD8yeDWzdCgwbJm4LaOlkCyMZfSPiPdBPtNJ9ZvQTC0+v5890M75GjRrhhx9+wNy5c/HDDz/gxIkTGD16NIYOHYr0aLd+RBRT2iPwTpXuN2ggLpnRjz1m9InIaWaa8Wk1bgyMHQv85z/AoUPWj0tLUYyt0Tci3gP9wLOtJEqgH2//D9LHZnz+TAf6AJCcnIyhQ4di6NChVo+HiGJIG8QHBnss3U98XKNPRE4zU7ofqG5dcXnwoAjGg3W6j1ZxsdoHINpAX/6ehYX2jtlKiqI2ratWzf++eC7d9/nUg9aJFuBVVlyj78906X5SUhJ69+6N3+WhvT8cOHAASeFOgEpErqI98hk42WDX/cTHrvtE5DQzzfgC1akjLouL7d0mafeDkRyQ0JIHS8vK4icLfvq0ur8IDPTjOaOvPWDNjH5i4Bp9f6YDfUVRUFRUhG7dumHDhg0V7iOi+BGqxCma0n2ZKTYT6B87xh1trDGjT0ROiyajn5GhTtAPHrRuTIHkvsnrNXdgVI/2gEa8HDCV5e0ej3qwV4rnQF/+XkDiBXiVFdfo+zMd6Hs8Hrz//vu4/PLL0aNHD3z44Yd+9xFR/Ai1QYxV6X61auprMasfW1yjT0ROM9uML5DM6tu5Tl/biC/aqW5Skvq7xssBU1m2n50tDnZoxXPpvjbQZ6Ih/vl86ryGGX0hoox+UlISXnzxRUyaNAmDBw/Gk08+yWw+URwyktG3O9D3eNh53yny/8SMPhE5JdJmfJJ2nb5drGrEJ8XbAVNtoB+IGX1yC+170Owafbn9SbSMfkTN+KSbb74ZrVq1wrXXXosvvvjCqjERUYzYVbpvdu13gwbAtm3M6MeamSUWUrxNUInI3aIp3Qdim9GPdn2+lJUlDkzEywHTYI34gMQJ9JnRj3/a9yBL9wXTGf2mTZv6Nd3r3bs3Vq1ahV27dlk6MCKynwzi9bIUsSrdB9iQzynRrNFnoE9EVoimGR8Q+9J9K8TbAVMZEOsF+izdJ7eQ70GvF0g2mcpO1NJ90xn9bdu2VbitZcuWWLt2LQ4cOGDJoIgoNtxQug8w0HdKJKX7coIaL5koInK3aDP6sSjdtzrQj7cDppUho59oAV5lpD21ntleGszoh1GlShU0bdrUqqcjohgwEuiXlakBoVEM9N1PUSIr3Y+3CSoRuVs8NOOza41+vBwwrQxr9JnRj3+RdtwHKnlGv2bNmvjll19Qu3Zt1KhRI2R3/d9//92ywRGRvYwE+vJxZoJBBvruV1qqXmdGn4icEg/N+JjRF5eJXrqvKNGfVYGcIw82RRLoywONhYWie3/g2SXilaFA/4UXXkDWH1ulqVOn2jkeIoqhUIG+tmPpqVPqxMSISAN9dt2PHZnNB7hGn4icU1mb8QHxc8A01Br9RMnoA2JOZNXBHIo9KzL68nms+qw7zVCgP3z4cN3rRBTf5ORFb6Po9YodeFGR+ZK2SLruA8zox5J2OUYkXfdPnkyso95E5Ixom/HFY0Y/3prxVYY1+oA46MRAP35p1+ibpf2/nzxZyQL9gsBPQgjZegt4iMiVwh39TE8XO2+zJXmRZvR/+01kms1kmCky2ox+JGv0FUVMiuSElYgoElZm9O0qvbZ6jX68ZfRDrdFPlNJ9gOv04100Gf2kJPFzp08n1jp9Q4F+9erVQ67LBwBFUeDxeFBWVmbJwIjIfuE2ipGeYs9soF+rlnhsSQmwfz/QpIm51yPztI34zEyMMzLE4xVFTFIZ6BNRNKxqxldSIgLS6tUtGZYfZvTFZWXI6FP8imaNPiCqik6fTqzO+4YC/aVLl9o9DiJygJGMPhB5oG80M+/xAPXqAbt2ifJ9Bvr2M3swRvJ4xCT1+HHxVa+e9WMjosoj2mZ86elim3TihMjq2xnoW71GP14C/cqyRp8Z/fgWTUYfEJ/v336rhIF+r1697B4HETnAaKBvd+k+IMr3ZaBP9pMZ/UiWSchAP17KTonInUpL1W1RNEF03bpie3TwINCqlTVj07Irox8v21Bm9CkeRLNGH0jMU+wZCvT1FBYWYufOnSjWLvQE0KlTp6gHRUSx4ZbSfYCd92MtmkA/K0sckImXbBQRuZN2Qh1pRh8Q5ftbt9rXed+uNfrxsg01ukY/3k5Px4x+YrEiow9Uwoy+1qFDhzBy5Eh8+umnuvdzjT5R/LC7dD+SQJ8Z/diItHQfiL9sFBG5kwygPZ7Is3CA/Z33rc7ox2szvlAZfUDsV+Kpma4M9OXSj0TK5FZGVqzRBxLrfWD6xEh33303jh49im+++Qbp6elYtGgR5syZg1atWuGjjz6yY4xEZBM3le7zFHuxFW1GH4ifbBQRuZO2EV80mWBt5307WL1G343N+BRF//bSUjXwCRfox1P5vqKogX5OjrhkRj++MaNfkemM/v/+9z98+OGH6NatG7xeL5o2bYp+/fohOzsbEydOxKWXXmrHOInIBm4s3WegHxvRrtEH4icbRUTuFG0jPklm9O0O9BM1o3/ddcDPPwOrV1esrNCWt+uV7msff/q0+ru53alTgCxCzskB8vMZ6Mc7rtGvyHRG/+TJk6j7xxa1Ro0aOPTHVrVjx45Ys2aNtaMjIluxdL/yiqZ0nxl9IrKCnFBHmymXGX27SvetXqPvtoz+xx8DGzYAv/xS8T5Ztp+err+/8HrV2+Mpoy8PYHg86vsnkQK8yogZ/YpMB/pt2rTB5s2bAQCdO3fGyy+/jD179mDGjBmoL2fqRBQX3FS637ChuNyxI3gJIVmHGX0icpqcUEeb0Y9V6b7VGf3Tp0VpvJMURQ3QDx+ueH+o9flSPHbel4F+Vpb6/mNGP75xjX5Fpkv377rrLuz7I+U2YcIEDBgwAG+88QZSU1Mxe/Zsq8dHRDaSAXywyUukpfuRZGnatBGZgd9/F533ZeBP9uAafSJymlUZ/Vg147N6jT4gDphWr27N80aitFQ9uK4X6MuAOFSgX6WK+D3MJgWcJH+v7Gz1/5pIAV5lFG1GXwb6iZTRNx3o33jjjeXXu3btih07dmDTpk1o0qQJateubengiMhedpXuy0yvdjITTno60LatWCf4ww8M9O3GrvtE5DRtM75oxFtGPy1NbHtLSsQBUycDfW0WPp4z+sePA088AZx7LjBwYPjHawP9SOc65C7RrtGvXx9o3RqoUcO6MTnNdOl+oIyMDJx11lkM8imhyexnorEr0I+0HLNzZ3G5bp25nyPzmNEnIqfZ0YzPyNKvFSuAhx4ynoG2OtAH3NOQz2igr9eIT3I60D98GLjwQuD554G77zb2M9pKBWb0E0O0Gf377gM2bwbGjbNuTE4zndFXFAXvvfceli5dioMHD8Ln8/ndP2/ePMsGR+QG//gHcM89olnNgAFOj8ZacvJi9Rr9SDL6AHDmmcBbb4mMPtmLa/SJyGlWN+MrLQWOHg2fkbv9dnFA+eyzjWV/rW7GB4jt6O+/O3/A1IqMvpxDOFG6v3MncNFFIkADgN27AZ9PLAUMhRn9xBPtGv1EZDqjf/fdd+Mvf/kLtm3bhszMTFSrVs3viyjRvPKKmDysXOn0SKxn1+n1ZADIjL57ses+ETnNqmZ8aWlqxjncOv1jx9SDyUbP8pLIGX1tcB7pGn2nMvobNwLnnSeC/MaNRQf9sjJjSzi4Rj/xRJvRT0SmM/qvvfYa5s2bh0suucSO8RC5yp49wI8/iuuJGNTYUbpfUqJmiyPJ6APAli1iAhjt5I+CY0afiJxmVUYfEFn9ggIR5LVpE/xxK1eq5f1GAkJFUfeVVjXjA9xzir14XaO/Zo3I5P/2G9CuHfDZZ8A55wD794uGvjk5oX+eGf3EE+0a/URkOqNfrVo1NG/e3I6xELnOp5+q153eGdvBjtPrabuVmg30c3LEl6IA69eb+1kyh2v0ichpVjXjA4x33v/qK/W6kUBfu/+zI6Pv9HbUijX6TpTujxsngvxzzgG+/FJk9Bs0EPft3Rv+5/UCfWb04xsz+hWZDvQfffRRPPbYYzjFw15UCXzyiXrd6Z2x1Xw+NdizsnRfTtySkyMLImVWn+X79mLXfSJymlXN+ADjnfe//lq9biTQ1wZ/Vq/RB5zfjsZrRl9WW06fDtSqJa5HGujLA00MbeIb1+hXZLp0/7rrrsNbb72FunXrIjc3FykBs8Q1a9ZYNjgiJxUXA4sXq98nWqCv3SGHy+ibOcodaSM+qXNnUYLHhnz2YkafiJxmZem+tvN+MMXFwDffqN8bCfRl8JecLL6s4pbtaLhA341r9I8cAQ4cENfbtlVvjzajz0A/vjGjX5HpTdbw4cOxevVq3HjjjcjJyYHH47FjXESO+/pr/x2w0ztjq2lL7IJtFOW5fY8eNf680Qb6zOjHBtfoE5HTrGrGB6gZ/VCl+2vX+gdzZgJ9K9fnA+5pxqcNzgsLxZf2d3Vj1/2NG8Vlo0b+c41oM/os3Y9vXKNfkelAf+HChfjss89w/vnn2zEeIteQZfv164vOvIka6Hu9wbMUshzu99+NP2+0EzcZ6P/4o7FT5FBkZOl+NBn94mLxFclzEJG7/PwzMGGC+DrjjNi8Zqwz+nJ9fpMm4rRsehnsQHZ03Afc2YwPEH+TJk3U742s0Y91Rn/TJnHZrp3/7czoV27M6FdkegrduHFjZIf6tBMlCNmI79prxaXTO2OraTeIwQpzatYUl7/9pnYpDifajH6rVmJMJ08C+fmRPQeFJzP60azRB5zPRlH8UhTgyiuBnj3FQT1y1uzZwHvvAf/8Z+xe0+qu+0DojL4M9AcOFJeHD4fft8kxWh3ouyWjH5iFDzz44cY1+jKjry3bB0RiBmBGv7LiGv2KTAf6kydPxgMPPIDt27fbMBwid9i5E9iwQWSTBw0StyVyoB+MzOiXlPh30w9FTloizegnJwMdO4rrXKdvn2hK91NS1Ildon0uKHZOnwY++kh0zDZ6PnOyjwzoZLY0Fuwo3Q+W0VcUtRGfDPRLStTfO5jKmNHXMrJGP9al+8zokx5m9CsyHejfeOONWLp0KVq0aIGsrCzUrFnT74soEchs/rnnqiVscqeQKIxsEDMy1EDwt9+MPa+cuEWa0QdEQz6A6/TtFE3pPsB1+hQ9bYDldLBD6rY7loG+HaX7wTL6W7aIgwBpaWLfLrdh4dbp271G3+n3fqhAX1Hc2YxPZvSDBfoHDgClpaGfgxn9xMM1+hWZXqM/depUG4ZB5C5yff7FF6s749OnxY7Dyq67TjIS6Hs8Iqu/b58I9Js2Df+80ZbuA+o6fWb07RNN6T4gPhe//eb8JJXil7bJJ99HzpPb7n37RBAUi1WadmT0Dx/W7+8iy/bPOUcEAnXqiN/50CGxZCwYuzP6Th8sDRXonzihLqtxyxr906eBbdvE9cDS/Tp1gKQkoKxMBPsNGwZ/Hm2gL8d/6pQ4uME+4/HHyCmjKyNTIUtJSQmWL1+Ohx9+GM2aNbNrTFTJHD8udnhu2bAWFQFLlojrl1yiBvqAGGuNGs6My2oy0A83eZGBvtGGfFZM3JjRt180pfuAeyapFL+Y0XcX7Wd582bg7LPtf0071uiXlYnTr8mlZ5IM9GUv6Tp1RMAYLqNv9xp9p9/7oQJ9+RlNTg79+8eydH/LFhHUVa8O5OT435eUBNSrB+zZI8r3gwX6RUXq752d7X9Q6PRp6//XZD85pwEY6GuZKt1PSUnB+++/b9dYqBL65Rexsx0zxumRqL78UgSr9euLgDMtTc16Or1DtpLRtUzahnxGWJHR79RJXO7ebfx1yZxoS/fdMkml+MVA310CA/1YsDLQT01Vy8v1gne9QB8I33m/Mmf0tWX7oZIxsczoaxvx6Y3JyDp97fYmK8v/f8t1+vHJyCmjKyPTa/QHDhyI+fPn2zAUqozWrBE7ho8+Mt7V3W6ybP+SS9SdSCIGNUYDfbOn2Iu2GR8gjrA3by6us3zfHtGW7rtlkkrxi6X77qL9LMdinb6iWFu6DwRfp3/ggMgEA0CPHuIyXPM+KdHX6Ifqum+k4z7gTKAfuD5fMhLoywMYVauKKoCUFHVZJtfpxyf5PvZ4EmeJrRVM/ylatWqFxx9/HF9//TW6du2KqgFb5zvvvNOywVHiO3JEXB46FLrMKpa06/OlrCwR6Dq9Q7aSnLyEa1piNqNvRTM+QKzT37pVBPp9+kT3XFRRtKX7bpmkUvxiRt9dYp3RLy5W139bFUTXqaM23dOS3fbPOENdfmc20E/00v06dcTfQi/QD9evQSYMYhHoB+u4L5kJ9LW/V0aGuJ0Z/fhk5JTRlZHpQP/VV19F9erVsXr1aqxevdrvPo/Hw0CfTNFmdNaudT7Q37NHTHCSkoC+fdXb3bJDtpL8XbQ9CPREmtGPNtDv3BmYN4/r9O3CNfrkNGb03SXWGX3tKVutCvRlRj9YoC/L9gGgdm39xwaya42+3IaePKnfPDBWZHDesGHwQN9oRj8Wa/S1pft6Ig3009MZ6LvRiRMiPjjvvNCfEfk+Ztm+P9OB/jbZ6pLIAjKjD4gP8mWXOTcWQGSQASA313/HloiBvtEdeKQZ/WhLMdl5315yjX40XfeBxPpMUGwxo+8u2kB/yxbR1C4pyb7XkwF0Skrk26FAMksfWLofuD5f+1inM/qKIv4W0R4cj5Q20F+3Lvga/VBiVbrv86nVJnZk9AGW7rvNAw8AL70EvPMOcO21wR9ndDlqZRPV8UNFUaC4ZWE1xaXAQN9pu3eLy0aN/G+XO4NEmowaDfRlRj+WzfgAtfP+zz/7d1MlazCjT05joO8eJSX+QVpREbBjh72vaWUjPkkvo3/ypOgHBIisoOR0oJ+RoZYYO7kdlf93Oe85fFjtmWR0nhCr0v0dO0RAl5oqEjJ6osnoA8zou80334jLn38O/TgZ6IdbjlrZRBTo/+c//0HHjh2Rnp6O9PR0dOrUCa+99prVY6NKwG2B/q5d4rJxY//bEzF7aTajH8tmfADQpIk4fU5JiVqqR9bhGn1yGkv33UNbRt+mjbi0e52+1Y34AP2M/sKFQGmpyFg3bVrxsU414/N41AOmTr7/AwP9khJ1PG4r3ZdzgdatgzdcY0Y/cSiKODsXIBpqhsKMvj7Tgf6UKVNw66234pJLLsE777yDd955BwMGDMAtt9yCF154wY4xUgLTTvS2b/cP/KP19tviPMBmVpsw0K/IbEbfqmZ8Ho9avs91+taLtnSfGX2KFjP67iG32ykpQMeO4rrd6/RjkdEvKADy8sT1ESP8m3QZPb2eXWv0AXdsR2WAVK2aetBF/k2MNuOLVem+fE8GW58PqIH+4cPBx8OMfnzYu1f9bIQL9LlGX5/pQH/atGl46aWX8Oyzz+KKK67AFVdcgeeeew7//Oc/8fe//92OMVICCwzsrQzoZs4Evv9eNHQzqjIG+uF24E414wPUNXi//hr9c5E/ZvTJaczou4e2EksGUXYH+rHI6D/0kGiy26KFuK732MLC0Flcu0r3AXdsR2WAlJZWsUGh0TX6sSrdD3dqPUDMWeQB7P379R/DjH580FYVBftfSszo6zMd6O/btw/nnntuhdvPPfdc7Nu3L6JBTJ8+Hbm5uahSpQq6d++Ob7/9NuTj3333XbRt2xZVqlRBx44d8Yk8H9ofPB6P7tfzzz9f/pjc3NwK9z/zzDMRjZ8iJwP9evXEpZWBvsxAy7IfI2SgH7hGX+6M5c4hEURSui9PhRSKlZO35s3FpWySSNbhGn1yGjP67qE9QBur0n27M/rffANMny6+f/nlioF6Zqa6/QtVvl8ZA/3AjL5bSvfDnVoPEFUb4cr3mdGPD9ptkNHSfa7R92c60G/ZsiXeeeedCrfPnTsXrVq1Mj2AuXPnIi8vDxMmTMCaNWvQuXNn9O/fHwcDW6b+YcWKFbjhhhswevRorF27FgMHDsTAgQOxfv368sfs27fP72vmzJnweDy4+uqr/Z7r8ccf93vcHXfcYXr8FB0Z6MvzpFu5Tj+SQF8246tMGX2jgb7PZ+xAh5UZfQb69mHXfXKaNtBPpIOo8Ui73Y5VRt+OQF9bjj9mjFjjO2wYcOGFFR/r8Rhbp2/XGn3AHQdMrQz0Y5XRD1W6D0QX6DOj7x7M6EfP9On1HnvsMQwePBhffPEFzvujfenXX3+NJUuW6B4ACGfKlCkYM2YMRo4cCQCYMWMGFi5ciJkzZ2LcuHEVHv/iiy9iwIABuP/++wEATzzxBD7//HP84x//wIwZMwAA9WR6+A8ffvghevfujeYyavhDVlZWhcdS7Ph86k6kd2/gzTedDfSLitRyPwb6qipVxASnsFD8TatXD/7Y0lJ1R29loJ+fH/1zkT9m9Mmo338HPvsMGDjQ2qwmS/fdQxvot24trh84IP5Hobb50bCjdF8Gqj4f8NNPoox78uTgj69TR5T2M6Mv9vXBAv1wS/xiUbp/6JA6r5NVJ8FEEujLAznM6LuHNtA/eVJsp4LNLblGX5/pjP7VV1+Nb775BrVr18b8+fMxf/581K5dG99++y2uuuoqU89VXFyM1atXo2/fvuqAvF707dsXK1eu1P2ZlStX+j0eAPr37x/08QcOHMDChQsxevToCvc988wzqFWrFrp06YLnn38epaWlQcdaVFSEgoICvy+KTkGBegqX3r3F5caN1mxki4rUicvevcZ2ojKbn56uZrElN+yMrWZ07R1gvCGftnOzlaX7hw4l1t/eDbhGn4x66ilgyBDR98QqgRVCfB85SxvoZ2ergZKd5ft2ZPRTUoAaNdTvX3hBDV71GMnoJ3ozvlAZfaPzhFiU7ssKk6ZNw79nmNFPDIHbn1Dl+yzd12c6ow8AXbt2xeuvvx71ix8+fBhlZWXIycnxuz0nJwebgtSM7d+/X/fx+4PUdMyZMwdZWVkYNGiQ3+133nknzjrrLNSsWRMrVqzA+PHjsW/fPkyZMkX3eSZOnIjHHnvM6K9GBsiy/YwMEdDVqiUCyfXrRbf8aAQGpFu2AGedFfpntI34tJ15gcQLahTFeEYfEAc+du0K35BPTlaSkyMPILWys8XE4/BhcfaETp2if04S2HWfjJJnLjFzBpNwjh9XD/TK78k5gUuu2rQRQdLmzUD37va8pjwwbHVJfJ06Yn7Rty9w443hHwuE7ryf6Bl9bYBkRem+olScQ1nBSCM+iRn9+Hf6tDgbFyA+J8ePi0C/RYvgjweY0Q9kOqMfb2bOnImhQ4eiSsB/Pi8vDxdccAE6deqEW265BZMnT8a0adNQFKTuaPz48Th27Fj51y4ZFVLEZKBfvbrYKXTpIr63onw/MNA3Ur4frBEf4I6dsZUKC4GyMnHdyoy+tnOzVTt6rtO3h1UZ/RMnjDVppPglP/fhTkNmhnZ9PiDej/I9SbEXGOjHYp2+zJxaWboPACNHilOzvvxy+P0Q1+hbs0ZfO8WWB5GtZqQRn8SMfvz79Vdx0Cg7G+jQQdxmJKPPQN+f4UDf6/UiKSkp5FdysrkCgdq1ayMpKQkHAv5zBw4cCLp2vl69eoYf/+WXX2Lz5s246aabwo6le/fuKC0txXZ5+ChAWloasrOz/b4oOnJ9piyzczrQD9aID0i8QF/uvJOSjE2yjJ5iT2ZorFifL3GdvvUUxbo1+gAnRolOfu7tCPS1y6QSZfsaj/Qy+kD8le4DwLhxYh4R0JZJl5lAP1Ez+sEC/dOn1f1EuCmvtlzarvJ9o434AGb0E4Hc9rRpo56ZK1RDPq7R12c4Mv/ggw+C3rdy5Ur8/e9/h89kWic1NRVdu3bFkiVLMHDgQACAz+fDkiVLMHbsWN2f6dGjB5YsWYK77767/LbPP/8cPXr0qPDYV199FV27dkXnzp3DjmXdunXwer2oK8/NQraTGf3AQN+KU+xFk9GvTIF+draxzLucjBvN6NsR6DOjbx1ZzQFEXrqfkSHeO4oiPhdW/s/JXezI6MsDvbVqiYDv9GnxPpIHFSm2Ag/SxiKjb0czPrMCzxuvx841+m6YWwQL9GUw7PGo4wxGe8DYroZ8dpfu8/R67qIN9OV2iWv0zTMc6F955ZUVbtu8eTPGjRuHjz/+GEOHDsXjjz9uegB5eXkYPnw4unXrhnPOOQdTp07FyZMny7vwDxs2DA0bNsTEiRMBAHfddRd69eqFyZMn49JLL8Xbb7+N77//Hv/617/8nregoADvvvsuJuu0W125ciW++eYb9O7dG1lZWVi5ciXuuece3Hjjjaih7eJSSfz0k5h0/fnPsX3dYIH+jz+KQCQpKfjPfvMN8N57wJNP6n+o5cQ0JUWUkUUb6MudgVxXasf6s1gysz4fMJ/Rt3LixkDfetoS6Ugz+h6P2PkeP851+olMUewt3a9eXex/ZKBPztAuuwLUjP6vv4qzqZgs2DTEroy+GeEy+mVlail6ZWvGJz+jWVmAN0z9r9erzrfsCPQLC4EdO8R1Mxn9o0dF4K7935WVqXMVvYw+K9TcQRvoy17poTL6LN3XF9Ea/b1792LMmDHo2LEjSktLsW7dOsyZMwdNmzY1/VyDBw/GpEmT8Mgjj+DMM8/EunXrsGjRovKGezt37sS+ffvKH3/uuefizTffxL/+9S907twZ7733HubPn48zzjjD73nffvttKIqCG264ocJrpqWl4e2330avXr3QoUMHPPXUU7jnnnsqHCyoDIqKRMf7Pn2CH/m0i3aNPgC0aqWexi1cYD5mDDBpEhCs0EROTGUDvs2b/Rs/6TGS0S8rs7erbKyYDfSdzOjLxisM9K1jRaAPuCMbRfYqLFTfL3Zk9KtV4/vIDQK33U2aiAlzcbHaEMtqdjXjMyNcoK/N7toxTje89/VOr/f77+oczeg8QQZYdsyRZNBXq5b6PwulWjU1uNeEEAD8/9baSgVm9N1FG+jLHuxco2+eqWO0x44dw9NPP41p06bhzDPPxJIlS/BnC9LAY8eODVqqv2zZsgq3XXvttbj22mtDPufNN9+Mm2++Wfe+s846C6tWrTI9zkS0ZIkavK1frx4FjYXANfpJSUDnzsDKlWJ9XbDyrN27RRUCIM5/q0dOSM85B/j2W1GmdfCgurHQE6oZnzZwPX7cniP7sRRpRt9MMz6ryIz+9u3hKz3IGG2zpEhL9wF3ZKPIXtrP/LFj4r0TzXtG+1wAA323CAz0vV6gdWtRYbd5M9CypfWvaVczPjPCdd3XBn12BBBOb0MVxT+jLw/q+3zqAR6jLanS0sRn2I6M/q+/isvWrY093uMR89n8fJHE0vZrkGX7aWn+FaFsxuceiuIf6MuKIq7RN89wRv+5555D8+bNsWDBArz11ltYsWKFJUE+OWv+fPW63JDGSmDpPmCsId9nn6nXgx3dk5PTBg2A3FxxPVSVQGGhWpaul9H3etXJSCJMRiPN6DvRjK9hQxFYFBcHP7BD5sgMbXJydMtQIgnQysqAiy4Cbrkl8tel2An8zIc72GeUtnSfgb7z9Kqx7F6n76bS/aNH9bvFyzGmpYUvX4+E0+99bXVXWprY18p5gayiMzpP0J5iz2qyGW+wU6vpCbZOXwb6gb8Xm/G5x6FD4jPp8YhqXzMZfa7R92c4oz9u3Dikp6ejZcuWmDNnDubMmaP7uHnz5lk2OLJXWRnw4Yfq9/ES6C9apF4PF+jXqiWOAG/bJgL9YMemZMf9zMzgO7WsLBHIJsJkVNuMzwizGX0rA/2kJHGwZssWMfFo0sS6566sou24L0WSjcrPBz7/XEya//lPeybPZJ3Az/zhw2oH5GiwdN9d9Lbddnfed0Mzvho1xDbI5xPv7fr1/e+3s+M+4HxGXxuUywCpdm0xR5DBtRtK9+VBByNnUpCCBfrB5j/M6LuH3OY0bSr+L3Kfc+BA8D5ZLN3XZzjQHzZsGDzx3oGM/KxaJcrZpS1bYvv6gWv0AXHuW0AE+nof5tJSESRIRgP9zz4LndHXrs8P9jbPyhJlQ/JocDyzO6Nv9cSteXM10L/gAmufuzKSmatoS7BlgGbmMyE/9z6fCOyMvgfJGXqBvhW02yBts1NyRmXN6Hu9Yp5w6JD4inWg7/RBrmCBfn6++UDfzoy+DPStzOgHBvrM6LuHtmwfUDP6hYViW6V3FggG+voMB/qzZ8+2cRjkBFm237ChKImOdUY/cI0+AJxxhsjg/v67CL4Ds7erVqkTRMB4oA+EzkqEasQnOb1DtlKka/SPHg3dgdmOjD7AhnxWsyqjL98XZoI/GegD4v3EQN/dAg/uWRXoy+0/S/fdIVRG/+efRV+c9u2t7ZHihmZ8gCjfl4F+IBn02TVG+fd26ow+MihPTlarq2RDPhnom1mjr31OK8mxWJHRDxbouzmjP22a6Jnw3HOVo09RYKBftar4OnlSzPv1An2u0dfHoslKSlHUjvV33y0ut271P7+23fRK96tUATp0ENcXL674M7JsX2YagjXmkIF+7dpqoG8ko6/XiE9KpMlosDVqwciMPqBO0PXYFejLnbvc2VN0rAr0jaybC6QNHLVBP7lTYEbf6jX62tL9RKiWilfBAn2vV/zPO3USgdGf/wzcf3/oplhGuaEZHxC6874co90Z/dJS//XysaIXHMlAX86LzJbumw30d+8G+vYFXnlF//6SEmDnTnHdzkDfzRn9Bx8EpkwBPv3U6ZHERmCgD6jl+8G2PVyjr4+BfiW1YYMImtLSxKnqZLMzuVY9FvQCfQAYMkRcTpkiynu15EZu+HBxeehQxceUlanPXauW//mAgx3IkL83M/r6kpPVnWKoib6dpfsAM/pWkaX7TgT6gRl9cje7SveZ0XcXvUaqmZnAv/4llktlZoqg96uvxKltn302+td0Q+k+EDrQj9UafcCZ97+2474kA315SmKzpftm1ugrimjMumSJyFbr2blTzPOqVKm4tCKUaDL64U7HHEulper7MNjBkESjF+iHm2+wdF8fA/1KSpbt9+0rNuIykIrVOn1F0V+jDwB//auY+G3YAHzyiXr7gQPAmjXi+o03isuysooT0aNH1eC/Zk0RvKelieBmxw798bB0PzwjDfnszugz0LeGzBxFu0Y/2kCfGX33kxUYcrmOHWv0E2nbGo8UJfipUUePBpYuFfvVDRvE/hkIvi81yudTgxe3ZPT13tt2B/rJyWpg4kRDPr0sqAz0JTvX6L/zDrBwobi+dav+QQJt2b6ZpQ2RZvQBe5YfREoehAOABQsS/+xDJSXqXE8vo89A3xwG+pWUDPSvukpctmolLmO1Tr+wUBylBCpm9KtXV0+9pT3CK0+rd9ZZosReBp6BH3oZiGZliYyl16v+fsHK9xnoh2ekIZ/dGf3Dh1neawW3lO4zo+9+cnsq+2Qw0E88p0+rB8eDHaRNShJr9Pv1E9+b+czr0ZZHx0NG384xOvn+D5XRl4yu0Tdbuv/778Cdd6rf+3z6c7RIOu4Davb/+HH/v224jD7grvJ97QEgnw+YOdO5scTC1q0iPqhaVfQQk+R8I1jpPtfo62OgXwnt3AmsXi2OjF5+ubitZUtxGatAX2byUlL0d6B33y3u+/JLYOVKcZtcnz9ggLgMFmRoG/FJ4dbpV7Y1+vGW0c/KUidj27ZZ+9yVkVtK95nRdz95YEZuQ1m6n3i0gUS4gDaSz7webZbSrmy5UTKwdWKNPuDsKfaMBPp2le7ff78481O7dkC3buK2n3+u+LhIOu4DYrsity379qm3Bwv0U1LURnduasin/awAwKuvxrafVqzJsv3Wrf0rOIyW7nONvj8G+pXQhx+Ky/POA+rWFdedCvRr1NAvxWrQAPjLX8T1Z58VG7X//ld8f/HF4jKSQF+v8/7x42rgy4x+cEYy+nYF+gAb8lnJ6tL9335TDx6EwzX68UVuT2UJpRWBfnGxmjFjRt95crudkRG+o3e4hlhGaQNor8MzUSfX6APuz+jbUbq/dKmamX7lFfXUynqBfiQd9yW98v1ggT7gzoZ8MtCvVUvMmXfs8D/NdKLRW58PGG/Gx4y+Pwb6CS4/v+IEXJbtDxyo3iZL22O1Rj/Y+nyt++8XBwE+/BB4/XUx4axWDfjTn8T9VmX0ZSM+7YRTT6Kc61lR7Mvo21W6D3CdvpWsPL2enKTrTZL1sOt+fJGfdysz+tpTpGZnM9B3mpkDtHK/e/JkxUyjVFwMvPVW6GVWbmnEBzgf6GtPsRdrobruS1Z33T91Crj5ZnH91ltF0ql9e/F9qIx+NIG+du4XKtB34yn25OesZk1g2DBx/V//cm48dgsW6LMZX2QY6CcwRQHOPVdspHv2FKfnePttYPlycb820JcZ/fz8il3s9eTni4D77bcjG5vM5AWuz9dq2xa48kpx/fbbxWW/fmpTqHCBvnZnFSrQN7I+H0icyejp0+rBn0gCfacz+gz0o2dVoJ+UpE6SjZbyMqMfP3w+9fNuZUZfBvqZmWJ7nijb1nhlZrudmakGQ8E+83PmiLPnyMZ9euw8KGyWW9bou7V03+gafaOl+08/LapHGzQAJk4UtwUL9BUl8tJ9QJwxAhCVoXJc8ZrRr1pVnCULAD7+2H85QiKJJKOvKOq8hoG+Pwb6CezQIRHQnTol1ro/9xxwww2iDL5jR/+NZpMmYsJVVGSso+ekScA33wAvvRTZ2IKdWi/QAw+IS7mhk+vzgcgy+jt3VtyAV7ZAX06yPR5zAbks3TeyRp8ZfXeTB3qiLd0HzK/Z5Rr9+FFQoB74ldvQEyfMnT5LT2BFUaJsW+OVmUDf4wlfQiuDtXnzgh8YdmNG/7ffKiY6Er10X29dc+CSSqtL9994Q1xOnqw+twz0t2xRAzZA/E9kYJ6ba2wcWnl5oinf1q3A1KnitnjL6GvnVR06iAReaSkwe7ajw7KNkYx+4OkPte85rtH3x0A/gdWtK7IvGzeKtVBjxoiNRFqaf6dTQAT5zZqJ6+HK94uKgLlzxfVI10sbKd0HgB49gD//Wf0+0kC/dm31oEJgHwIjjfiAxJmMykl2dra5tZHhSvdLS9WNrR0ZfXlgimv0o2dVRh8wH+izdD9+yM96Rob4P8v126EO9hmhbcQH+Gc03XT+6srCbCVWuM+8TBYUF4vTp+mRB+/dEOjLDLbPV3GbVBmb8SUlqQf2AWtL90+fBrZvF9d791Zvb9RI/B1KS/3naPLAfoMGkf0PMjNFNh8AnnpKZMHjOaMPqMseXnnFWAVuPDlyRK2skQeXJbndOX264jxce/CZGX1/DPQTnNcrSuBHjhRretavFxuwm26q+Fijp9hbuFDdGe7ZE9kG0WhGHwD+7//E5Tnn6J9qI3CyIUtLtYG+xxO8fL+yZvSNluNJ4Zrxaddr2lm6v317YnecjQWnAv2iIv/tBUv33U1+1mvVEttQGRBFW74fLKPv87krk1ZZyG23VYG+tvHZnDn6j5H/ZzeU7qekqO/FwPL9RM/o6wX6gFrlkJ5uvPLLSOn+r7+Kg3nVqqnNoAGxfdEr34+mbF8aOlTMH0+cEPPJeMvoB34+r71W/P22bQP+9z/nxmUHeValevUqbo8yMtTPSmA1kXzPeTzWVComEgb6lZBel3vAeOf9117z/14enTXDyBp9acAA4KuvRBmglpmMPhC8875sxmc00I/387hH0ogPCJ/RlzujpCRrAshADRqI5y0tVf9nFBmnSvcDs2XM6Ltb4LbUqkA/MKNftaq6X4r3A6nxyOySq3Cl+9rlf6tW6ffGcVPpPhB8nX4s1ui7LaMPqJ91MwkBI6X72rLswLmoXqAfTcd9yesFXnxRXJ89O/4z+hkZwI03iuuyujZRyH2DtqJEK9h8Q9tUMliMU1kx0KdyRgL9w4dFRh9QP4iRlFKbyegDoiurNpsPqB/4gwf9yz3DBfqVPaMvd3JmA/1wGX1t+acdG9qkJHWNHtfpR8epjH7ge4cZfXeT/y/52bcro+/xJM72NR5ZWbqvKGpGv0MHcfmf/1R83Lp14tJsZZldwgX6lS2jLz/rZuYJRkr35fwrsCwbCJ3RjybQB0TzaBkcS/GW0dceiOvaVVwa6amlNX8+8NBD7i35D5eICnaQUa/XBAkM9KmckVPszZ0rsoFnnaWur4ok6DK6Rj8UWfZVUuKfGTQT6CuK+UC/sDC+S8ejzeifOOHfLEeysxGfxIZ81nAq0JefU/leOnXK2DmXyRl2ZfT1tkEM9J1jZaD/22/q9kU2033tNf/A4qefgGnTxPW//MX8eO0QLNCP5Rp9t5xeD4gs0DdSuh+s0RpgX+m+9MwzasY+OVl/LXc8ZPSByLfFt90mznrw7bfWjM1q8uB/sPddsG0PT60XHAN9KmfkFHuybP8vf1GDrlhk9PWkpakHCuSHXlH0T68HqNmFb78FFi8W148dUyc5RpvxAc6U2Fkl0kC/enU1U6+X1Te7zjMSbMhnDadL93Nz1fcSs/ruJbelMqMvA36rS/cBBvpOMhvohyrdl9n82rWB664T+5mdO9XT+vp8oplYaSkwaBBw+eXRjd0qMtAPfG/HMqPvxLwiWCY0mkA/2oz+5s3i/QFYU7ovNWyo9nyqVk2/8tCNGX29JIr8/5hpjFpQoJ6Sz63JEjk/DZYElPONYBl9BvoVMdCnck2bivLoU6f0z8+5ebM4pV5SkjhNnwy6ItlgmFmjH0pgkFFYqO5kAjP6HTqIAxRlZcA11wCbNqnZ/Jo1w6/Bq1JF7Todz5PRSAN9r1f9f+ntXMxOFiPBjL41nC7dr1VLLZvkOn330v6/gNhk9OO9B0o8sjKjL0uJGzQQ+8zBg8X3snx/xgyxbj8rC/j73yMfs9VYuu9/u/x7mKm6NFK6Hyqj37Sp+DsXF4t9fFGR2o/HikAfAO69VzSjfvxx/fvl/9ntGf1IDrpqq3V37Ih+XHYwWrofao0++WOgT+VSUtQ10Hrr9F9/XVz27y929E5n9IGKEw4ZgKam6peQv/KKWO9/7Bhw6aXqOsFwZftA4qwjjTTQB0I35NPbGVmNgb417Aj0Dx8Ov6RFfu5r1lQ/+8zou1ew0n2rTq/H0n13sCPQlz11hg0Tl++9JwKN8ePF908/XbHvjpPke5vN+IRrrgEuuwy49VbjzxWudP/wYfXgoVwqquX1Au3aies//yyCUUURcwpth/5oVKki5oG33aZ/v5tL97WfT/l+LShQK/TC0S5bjddAP1zpPtfoV8RAn/wEW6fv86ll+3LHrc3om23sYcUafaDih157aj29sqy0NOCDD4BmzcS45U7MSKAPJMZkNJpAP1RDvlhm9OUpeigyVpbu16kjPms+X8VJciDtAT752WdG370CS/etzujHa+m+orirtDdakZbunzxZMTiVpfsyiD/3XDFXOHFC9PUpKAC6dzcXQMaCk2v0rXzvf/890KWL8dOuBQv0mzQBPv4Y6NPH+GuHK92XgWbjxsEPnGjX6Wsb8cWqk7obS/f1kijVq4sDI4DxA6/aeX0kZ8uKhXBr9MM142NGvyIG+uQnWOf9r74SRwCzs4ErrhC3NW4sStmLivRL/YPRnkvbrox+YNm+Vp06wIIF4neRG9Bw6/MlWW5s12T066/FQYj58+15fsC+jH4sAv3WrcXO7cgRc+85o0I1EUokVmb0k5PVADBc+b48QFSjBjP68cCJ0v14CPTHjBF/k1CNa+OJ2W13ZqYaqAV+5rWl+4AI0GRyYM8eMWd4+WV1GZxbyED/4EH/22NRum9lRv/VV0Wl4oMPGnt8sEA/EuFK90OV7Usy0N+40dr1+Ua5OaOvDfS9XvUArNHtcTxl9MOt0WczPuMY6JOfYIG+XF937bXqDi8lRaypAsyV78uJvccT/al1Ign0AbEzefdddbIRq4x+uEDyzTfFkdb334/s+Y2wK6Mfi9L9KlXUJj4//WTtc7/5pphwvfWWtc/rRlYG+oDxdfra0n1m9N3Prq778d6Mb+FCsS3/4gunR2KNSA7SBvvMB2b0ATXQB4C8PKBzZ/NjtJsMJn/5RW0EB8TfGv3168Xl99+rSxNDsXJtc7jSfTOBfmBGP1bcmNEPdkYjs0upAgN9N1ZFGi3d37/ff/xcox8cA33yo1e6v3q1f7d9rUga8mnL9r1RvgODBfqBHff1XHQRMGeOKC289lpjrxfNDvmdd8REas6c4I/58UdxGe0a2FDiOaMPAB07ikurA/0FC8Qa86VLrX1eN7KydB8wH+gzox8f5AE9u0r34zGj//vvatmoduIczyI5SBushDYwow+I3j//93+iy/6ECREP01atWonEw6lT6undFCW2a/RPnfI/yGCWoqiBPiCy++FYmdE3Wrqv13Ff0mb0ZcLJilPrGRUvGX3AXEM+RfGf1586Ff123A5GT69XXKzuRwCu0Q+FgT750Wb0FUV86K69VnyorrwS6NnT//GRNOSzan0+EHlGXxo6VJTL6zWG0RPNZPS//xWB5Acf6N+vKO4P9J3O6ANqoC//VlbZsEFc2rEkwG2cyujrle4zo+9OpaXqpCswo3/qVOQZL7lfAeIz0Nee47uylu4D5jL6APDUU6JSze79Q6S8XqBrV3H9u+/EZUmJ2mA0Fhl9QN2P6vH5xNmCgmVi9+3zP3D6+uvhA1YrAyQrSvebNRNjOXVKrZip7Bn9YHMrMwdeDx9W3xtyHufG8v1w89P0dLUSWLvtYel+cAz0yU9urtjhFRaKncaoUcC2beL2WbMqNkSJ5LzmVnXcB6IP9M2KZjIqqx7WrNG/f8cO9dRSbg303ZDR79RJXFqZ0S8tVSchDPTNi6Z0nxl9d9IegJHb6sxM9T0TaTaosFANnuKxdJ+BvqD3mS8pUde4u6mjvlHduolLGehrg2Q7A/20NNHrBAj9/p8+XXSlf/ll/ftlNr9VK9FM7+hRYN680K9tR0Zfr3S/rEzN0IcK9JOT1fvlvoFr9MVl4Ocz1HwskNxWNWmiVlS4OdAPlQjUqyZioB8cA33yk5qqrru/+26RfU5JEWXneoF5JKc7kxtvqwN9RYmPQH/XLv3u5NoMdSwC/Uj6I7gh0JcZ/Z9/jq7MUWvbNnXCE1iKmojcVLrPjL47yeqLatXUIMTjib58X25/kpL8M1SxCPSff16cNkwe6IqErPwBROBi9owzbhTJtltvsr1vn9gPp6QYWz7nNmefLS6//15cymDP47G3JNjjMdaQb9Eicblggf798r3ZqZNI0gDhy/djVbq/Y4f43KWlhe+JJMv3AfG3kad9joVEzehrl03Iv6fbOu8rirFElN58g2v0g2OgTxXIMvZ33xWXU6aoO8BAbsnoFxWJDYT29Hp2kJNRmXk3qqREBPjS2rUVH6MN9I8etS6I1SoqUjeI8Vq6n5srXqO42Lo1strJ+4EDiTF5D8WJjL6i+JfuM6PvbsEOmkYb6GvL9rUVYnaf0eTgQbFO/P33gRUrIn8ebUb/9Glg9+7ox+ak0lI1GxZtRl+W7devH33/HSfIjP6PP/qfHSg93f7Tuxk50PXDD+Lyu+/0y/dlRv+MM4CRI8WYly6t2FxZy66u+4HjkxVzrVqFP+OCNtBv1Ci2665loO+WjH5xsXpgPppmfDKj36qVmsxzW0b/9Gl1bmIk0NfL6HONfkVxuCkmu8l1+oBYn3/77cEfKzP6hw8bD36tXKOfnq7uIA8ccG9Gf+dO/+BRr3w/cM25XjAdLe3/KF4z+l6vmMgA1pXvayfvpaXubFJjJScC/cJCdcJSsyYz+m4nP+Py4J5kVUY/cCJnd0b/rbfUg6c7d0b+PHJbIQPZeC/f164JjzbQ12vEF09yc8U+rqRE7I9lVtfOsn0pXEb/t9/Uv+/Bg/6JA0kG+h06iBLt/v3F9zNnBn9dO7ruA+q2XjKyPl/SBvqxLNsH1NJ9t2T0tZ/PaJrxaTP6bg305b7B4/HvWxFIVhNxjb4xDPSpAhlEtWgBvPJK6CPZ2dnqxM9o+b6VGX3Af8Lh1kA/8G+jl9GXR+slO8r35YY0MzOy8xiHyugHOwWMHaxep68N9IHEL9+X7wOr/ldGAn35uU9JEZMpZvTdTX7G7czoa9kd6GvPdhJpoH/0qJq1Pv98cRnvnffldjs52dyBP73JdrBGfPHC4/Ffpx+LU+tJ4d7/gfMD2UdA8vnU/Zicw40ZIy5nzQpeIWhH6T5QcZ2+kY77kjbQj2XHfcB9GX0Z6Ot9PiMp3XdzRl+7rDRURVCojD4D/YoY6FMFw4cDL7wALFlirLzb7Cn2rFyjD+gH+natD4w20JdZ9MCMfmGhmhmSf3M7ssrRNOID1En/6dMVj3gHaxhjB6tPsRcY6CdyQz5FUZfaWJUtkZ/BQ4eCL3vQlu17PMzou51dpfvBmi1FG+grSvBu3z/95H9wNdJAX24nGjVSA8J4z+hrK7HMlKfrTbbjPaMP+K/Tj2WgL/ebkQb6O3eK/2VqqlqVedllQN264n/0ySf6z2tlybP2OQI/i2Yy+i1bqn1BnMrouy3Q1zsob7QZn8+nLt+Ih4x+uPlp4EHGH38EVq0S1xnoV8RAnyrIyBCN+OTGIByzp9izK6O/Z49amu7WjP7ll4vLX3/1Pwfohg1iolqnDtC2rbjNzox+pIF+Vpa6Aw7M6seqdB+w9hR7ZWXinL2A+l5O5ED/8GHx/vV4xKmMrFC3rrgsKwv+vtV23AfUQO/YscTviRCP5Oc7Xkr3L7lElF7rTV7/8x9xKSeB0Qb67durvWwSJaNvdrst97uFhepzxHtGH1ADfW1GXwZ/dpLv/2Cl+zLQb9JEXAYG+rJsv00btclqaqpI3ADAv/+t/7xWZvQ9HjXrHCzQN5LRT0lRHxfrQF/bjC/YaQxjKVQCxei2eO9e8fskJYltpJzbHz3qPw91WrBqr0By27N+PTBgANC5M7B6tbhNVnuSioE+Rc1sQz4r1+gD6odeBmsej3XPHSjaQP/ss9WN7Lp16v1yJ965s7kGK2ZFG+h7POrEP3B8sWrGB6iB/vbt0Zf6bt8ushppacC554rbEjnQl5/TRo2sO/qdkqK+L4KV7wce4JOXPp/7T6lWGQXL6JtZF6pHTuaCZfRPnTLfiLSoCPjvf0Xm8u67/e8rLRXnEwfUUuZIM1myaWeHDmogEu8Z/Ui325mZ6s/Iz7zM6MdzoC8rNX7+WX2PuyGjL+cLspv+99/7HyCV701Zti+NHi0uFy7U76NkZaCvfR5t6f6JE+p7w0hGHwAee0z0iLrsMmvGZZQ8qKMo0Z2dwyqhPp9yrnjsWMWeCFpyG9W8udhXZ2aq+2s3ZfWNnFoPUOf8O3YAn30myvyvu04c/Ir1+yUeMNCnqJk9xZ5dGX2ZbalRI7L150ZE2hl62zZx2awZcNZZ4rq2fF9mpjt1MnduVLOiDfSB4OOLZUa/Vi21PFRmMiRFAR56CJg40dgRefm+adtWBL9AYq/Rl4G+1Wsfw63T15buA+Igg5wUcp2++zjVjA8wv33dvl0NeubP9y9TXrxYfJ5r1QJuuUXctnNnZNk6vYz+1q3GDkwoijiDzRdfmH9dO0Wz3Q4s35cZ/Xgu3W/QQHz5fOrZGWIR6MuqKDlX0CouVt97Q4aIbWdBgf9BJm3Hfa02bUSQ6PPpn9bX6kBf23lfkuOsXbvi9iSYa64Rp3UO1ZTNDtr/tRsa8oUK9KtXV5fbhGrerF2fL8lT7Lkx0A83P23dWmyv0tOBsWPF+2vuXPUgHfljoE9RM5vRt2uNvjyibVfZPhB9Rr95c+OBvhvX6ANqtkZ7DtayMvUIfiwy+kDw8v3ly4Gnnxan0nryyfDPIydQHTqoa78SOaMv1+rFOtAPLN0HuE7fzWLdjC81VS37Nbt9DTx92J13qtsjWbZ/ww3qQenCwsjOaqIN9Bs2FEFNaamx81F/9RVw773AzTebf107WRHoJ1JGH1ADBnlQJhaBfs+e4nLJkor3bdokMrbZ2WL9epcu4nZt+b622iRQsHmLz6dmgu3M6JtpxOe0lBQ1UeSGdfqhmhwnJan701DbY3mgRfv3d+M6faPz0+rVxZx63z5g2rTYL++INwz0KWoyYNixw1hmw66MvnxetwX6R46oY9PL6CtKfGX0ZQ+BTZvU2yI9RVM0gjXkmzVLvf7II/7f65ETpPbtxfmfgcQO9J3K6Ot97tl5P7Z8PuCee8J/JoDwzfgi3T6FKs+M9ECqDPQvukhkY/PzgeefF1nPDz4Q9w0bJgJz+T41u07/2DFg925xvX17US4qM2RGyvdl6fXWre7qSRFNoK9tinX8uPp/i+eMPqCu05dZ8lgE+hdcIN5Tmzer7zNJLu3r1ElkcLV9BABxoD2w475WsPX/2tJ0q5ZxyffE9OnqbWYa8TnN4/Ffp++0cEtrjMwX9TL6bgz0ja7RB0Q/q2jmsZUJA32KWv364ihuWVn4yVNZmbpOzKp19HLHIsUi0C8pCd7hOZAsxcvJERtrGehv2iQ24rt3iyAoKUlMIN28Rh8A2rUTl7InAqBOIJKSrMsMhKN3ir3jx4H33hPXr7hCXI4ZI9ZxBaPN0slAn6X75pkt3ddeZ0Y/NtauBaZOBR54IPxjjZTuR1L+HmobFG2g36ULMHmyuP7008Bzz4nMYrt2apZWTnDNBvpye9eggbrvMhPoy+1USYk4D7pbWFW6L8v2s7JiX25tNfleke/vWDTjq15dfd3ArL4M9M88U1xqzwwAiG16UZEIUPUarAb7XGmz7lbtt597ThywmDULePVVcVs8BfqAuzrvhzubkZEKK72KCjcG+kbX6JM5DPQpal6v8c772syd1c34JLtOrQf4b2yNTka1ZfuAODBRv77I6vz4o5rNb9tW7GzdntHXC/S1R53NnKIpGtrSfTkhe+cdcRS+TRuRybvxRnFw6ZprKp7SEBD/A/l7MKMfnUhK95nRjy150PHw4fDVV+FK94uLg3cIDyVU1ibaQL9lS2DwYKB3bxHEPPWUuH3YMHW7JLuWmw30tQcEJTlxNtJ5X9tLJNKu/3awqnQ/Ucr2gYprfWOR0QeAvn3F5eLF/rdrm/UCaqC/dq34HGur0vTOPx7sc6VNVgSeoz1SvXurS+Zuv11UssRT6T4QXxn9cIF+aak6B42XQJ+Zemsx0CdLGG3IJyd5mZnqKWCiFRjo25nRT05WdwJGJ6PaRnyStnxfW7YPuH+Nvizd37ZNzQjEshGf1K6dqCA4elSdZM6cKS5HjhQTnldfBS68UIzv0ksrTrB37hQ789RUEfjK6pCTJxOzE/yJE2og7obSfWb0Y0s7qQt1ILGoSJ1gBm5PMzLUbWAk2yg7S/dbthQB/T/+oZ4G1OMRB/ykSAN9vTXQRjP6iuIf6O/aZe617WRV6X4iNOKTatdWm5UBzgT68uC1olQM9Fu1Euv1T50S78tgjfikcIF+aqq1B+gffFB0Py8qAq6+Wl3mFy8Zffn/dlNGP9LS/R07RBVRlSpqs2FADfSN9BeJFTOl+2QcA32yhNGGfFavzwfEBlC7EbQz0AfMT0YDM/qAf6AfuBOPRUZfnj0gEvXqiQ2xz6dOcJ0I9NPS1CPUP/0kygNXrBAB/l/+Im5PTQXef19k//fvBx591P855OS9TRsRGGRmqr9DImb15eezVi3ry+MiKd1nRj+2tIG+XgduSf6vvF79bUU0DfmszuiXlKiT1ZYtxWX79kBenrjer5//BFcG+mYzWXoZfRnoh8vo79rl/zslSqCvLd1PpIw+oGbNgdgF+j16iNfav199v+3fLz6rXq8ayHu9atXBd9+FbsQHBD91n9Ud9yWvF5gzRxws2bpVvMe8XusPLttFlu67IaMfqhkfEH5bLOdoLVv6V3vIQP/gQXcc0ACY0bcLA32yhNGMvgz07QoygNgF+nrnpNUTLtAPzOjLDffvv1vftEmOOZoNqcdTsXw/0nMxR0u7Tn/2bHH94ov9s0rVqgEvvSSuv/WWf7dtvcl7Iq/Tt6tsH2DX/XhgNNDXrs/XKwXWm1wuXiyCD20ncD1WZ/R37hTlqVWq+H/un3xSbBMCGw/aUbq/c2foni2BpwBNxNL9RMroA/7l+7FYow+I9/Cf/yyuy/J9mQho3dr/gIO2IV+0GX07+urUrAm8+666JCA3N3b9e6IVjxn9YIG+XiM+QPx/5GfeLdsjrtG3BwN9soSTGX3AmUDfioz++vXqhjiwdL+sTN3wWcWqI6aBgb4TGX1AXae/dq16Gq2RIys+7txzxd/39Gn1gAAQOtBP5Iy+HYG+LOM9eFC/SRtL952nndAZDfT1BAb6RUXATTcBq1eLTF4wZWXqdlNvGySrB8wE+trTRWoPSqSkAMOHVww8Iwn0jx9XH6/dVtStK/YHPl/og9yBgb6bMvrRHKTVlu4zo2+NwHX68mwNsuJPkuNbsUJtdhcsox8u0Leq436gbt3E6c8A9QBGPHBjM75wGf1gFaB6p9YDRMLGbev0mdG3BwN9soQMHLZuDd2JWZZtVpZAv6xM3YhqA/3GjcU4S0vFY2rVUiekaWnqRt3q8n2rNqSBp9hzKqMvA/1580RGqVYt4PLLKz7O4xGNgQCR3ZeVEjLQ106Q5OSVgb45deuKy5KSioG7z8fT67mB2dL9YNvSwEB/xgz1uUOtV9dWQVlVuq9dn2+EDPT37TN+5hR5QLNePf+DHx6PsfJ9Geh37Souow30X3hBbPOsYEVGv7BQDTYTJdCXB+MBZwL9ZcvEtjSw474kKw7WrxfziKwsMa/QE+z0enZm9KWbbxafDVlVFw/c2Iwv0q77wTL6gPsCfa7RtwcDfbKEbFxTUBA6OK1sGf09e8TOOiXFP7Pk8fhPJOT5cSW71uknWkZfVkHI8wEPHRq8e/CQISJj+OuvwOefiwNSLN23TlqaGrgHlu8fP64eXGFG3xnHj/v/nY1k9I0E+sePq122gdCBvtz+VKmiH1zEItCvXVudyMssdDh62wlJZspC/d4y0L/4YnEZTansDz+I/gOjRgU/qO7zAVddpR7cDCWabbe2P4729IOJoFo1tXlcLAP9zp3F5+7ECeDbbyv28JGaNBHnEpfOOCN4Q71wp9ezu6S+VavY/g2jFU8Z/XBzxWAZfcD+QP/HH8XpTrWncQxGUaw/9TYJDPTJEunpaqZk0qTgE5BYrNG38/R6gLnJqCznzM0VHeK1AgN9rXDlWJEoKVGPUFsV6G/eLCoSnAr0mzb1P2fzqFHBH5uZCYwYIa7/858iq3bihDgIow0SWLofuWDr9OXnPj3dv0yUGf3YCZzMhWqkZ6Z0f8oUcSkzuTt2BM+Uh8vYxCLQ93jMl++HanYWLqNfVqYeKLjkEnG5f796cNKsr74Sl8eOBf87/forMH++2M6Fe51ot92yAqqsTFwmSkYfEMvA6tYVTfJixesVZ4oBgI8/VislAgN9j8d/eUGwsn3AmTX68cyNGf1ImvEVFamNSkNl9CPpvL9kCXDvvaG3L3fcAdx3nzgLQzgnT6rbEGb0rcVAnyzzyCPi8tln/TM8Woma0f/tN1FOGdigT299vhQq0LfjFHvasUXTdR8QpwpMTRVHanfudK503+NRGxB16VJxMhTo1lvF5YIFwKefiuutW/uf6jFcoB9qaYqbFRerwZ7RoMgsbRduLb2O+9rvmdG3X2Cgb0Xp/saN4sAuIAL+cOvVwzVbikWgD5gP9KPJ6Ofniwl3ejpwzjkiqFIUtXmdWStWqNeDPYe2UiHcPiTaQF+77/V41MA/ETz4oNiWyQPbsSLL9195RXyeatdW90ta2kA/WCM+gIG+WW7K6Bvtun/0qFjCoZWfL7Y1WVkVT0MNRJfRz8sT2/yPP9a/X1HU/hLTpqkHKIOR+4akpNg1v6wsGOiTZUaPFh98QAT9zz1X8TF2r9GvWtX+nZZew6jRo8WGb/x4/8caDfQDA1Q7SvflhjQjwz+wjURSkjrB3bjRuYw+IE6fBQB33hn+sW3bimyJz6cemAqcvIdao//ZZ+K9+/bbkY/XKTt2iN87I8O+yXi4jH5ghpgZ/diRkznZsM6KZnxffik++127AtdcE/688lZn9MvK1G1sJIG+0QluqEA/3O8sy/Y7dBDbTXmqv0jL97WBfrClB9rbDx4M/XxWBvp160a/b3EbK88vb5QM9OUBt86d9cdhNNCP9en14l08ZfRr1FDfG9ozCgHqNqlVK/33T6SBflmZ2p9JLi0JtHu3mlxSFFFtGervqd03OPGZS2QM9MlS99wDPP20uP7gg8Df/+5/v10ZfVkuqHfU0mqBk9HVq4EPPxTX33jD/yhwqEC/eXPRUKdNm4o7aTsDfavKorTr9J3K6APA3/4mdjqyLD+c224Tl3ICHDh5D7VGf+5c8XcMdhTbzWTZfvPm9u1IwwX6wTL6p05VLPf+/XfrzzpRmcnJnGykGU1GP/D2iRPFAYRwQW+4bZDZU5fu3i0qVVJSgjci02Mmo3/ihFraGqp0f88edTuoFXjqM/nakTTk27vXv8zWSEY/2OkuJatK94HEWZ/vtGbN/OcMwSrVmNG3RzydXi8pSd2PBlbvyL4ZstdEIBnoy15SRm3frpbs//ST/mPkcqfcXDE/37JFTa7o4an17MNAnyw3frz6gb7rLtEZvWlT8QH+/HNxu9Uf5nPOEQcWZEWBnQJ3mhMmqPcdOwa8/776/bZt4rJZs4rP4/UC33wjskWBO1o71ujbGeg7mdFPSQm+I9NzxRX+60iDBfqHD1dcf7Z6tbh00+mxjLJ7fT4QPNAPVrqfna0edNBm9QsLRUB65pnxu1TCbWSgL7t1W9GMDxAVMrKqRlb5BFuvbnXpvizbb968Yg+UUMwE+jJzVbeu/t+jZk31djkeLTkRloGYPCARyTZk5Ur/74MF+trbQ2X0FcXajH4irc93mszqAxU77kt16wL/+pfoaB8qyeHU6fXilSwdd1NGP9TnM9hSTxlsBzsIVK+eWILp8xlvTAqo20QgeKAvD3CefTbw8svi+pQpFbdhEk+tZx8G+mSLRx8FHnhAXF+/Xkyo5Ae5dm11smkVrxd45hngyiutfV492p3mN98ACxeK1x82TNz+6qvqY0Nl9AHxc16dT2G0a/S/+EIcYNGOxa5Af9MmZwN9s5KTgb/+Vf0+MEtXs6ZafqoNWE+dUnecu3fbO0Y7OBnoByvd93rV96N2nf7334tAdPt2lvVbJTDQP3xYPRNCoHCl+9os7sSJ6vVYl+5Hsj4fMBfoy3WmoTKmoX7vwIy+DPQjKd3Xlu0Dxkr3Q2X0T59W3wMM9N1FG+iH6j0zZgxwyy2hnyvY6fVi1XU/3rglo68oxqolgyWGtMuG9Hi96rbQTEM+baC/dWv4SqZLLxXzY1nCr9eFn4G+fRjoky08HhF4f/cd8N//ioB40yax7nnv3vhu2KOdjMps/rBhogGhxyPOf/vrr2KnKrMpwQL9YKIp3f/2W7FhXb9edDyVZbBWb0hlCbA2o+9E6X4kbrpJjLVOnYrdaL1e/aZyP/6odoXdvTt4kBTOL7+IipcePYB33gn/WCOnpjHCDYG+3pIdvXX6336rXg+3xpiMkYG+PJd7WVnwgyjhSvdzcoB//EMcSNSWD4cL9OUYgmUfYxXoy5LVnTvDV4ysWiUuu3cP/phglQynT6t/CytK92WgL8dipHQ/1OdHO0GPtAEWS/ft0aePOPhSp466r42U9nOlfb+zdF+fWzL6xcVqgz0jgb42MVRWppbuhzpIGck6fW2gryhqAkQr8EwlL7wgthWbNgGPP17x8eEOAlPkXBHoT58+Hbm5uahSpQq6d++Ob7WzPB3vvvsu2rZtiypVqqBjx4745JNP/O4fMWIEPB6P39eAAQP8HvP7779j6NChyM7ORvXq1TF69GicCDzcSVHxeET2qF8/UVrfpo34oMd7sx6501y9WjRnS0oCHn5YZGr69xf3zZyplu3XrGl+4xVpoP/jj8CAAWrgffSomJAD1gf6bdqI//Hvv6u/azxk9AFRnr9mjSgjS03Vvx/wb8gny/YBsZ4tVOlzoCNHxP+he3fxd3viCRFAjBql/u0CzZghHnvXXcZfJ5RIgyIzzHbd196mzeh/84163czfmfQVFanv5Vat1Iaien9bRQlfug+Ic7QHns5SBvq7d+tPkr//XlxqG5FqBQtIgon0PS0b4hUWVmxgFUgG+n/6U/DHBDvAIU8/Wr26GgRHWrp/+rS6DbrmGnEZbaAv9xPp6eaWPmgxo2+PWrXEdvDrr/X3UWbIz5XP55+lZqCvzy0Zfe2BuFCBvt58UXu2D72lo1Ikgb485aNcdhdYvu/zqQ1M5UGGmjWBF18U119/veJzco2+fRwP9OfOnYu8vDxMmDABa9asQefOndG/f38cDLJ3WrFiBW644QaMHj0aa9euxcCBAzFw4ECsl3UifxgwYAD27dtX/vXWW2/53T906FBs2LABn3/+ORYsWIAvvvgCN998s22/JyWOwIZRI0eqGfvRo8Xl7NnqpM9sNh+IbI3+L7+IgypHjohJ6UsvidunTBETOjleqwL99HTRaAWIv0AfEFm4YNntcIE+YG6ifsEF4pyy334rJtSXXCIyqydPitLLwKBm/XrR2BIAli41/jrBaE95ZmdGv1UrURGxe7f/xCFY6T7AjH4syPdqerrYttSpI77XWxp08qTamyJY6X4wtWqpB24C16sXFvqv29Qjt61lZcYqWSIN9NPS1Ex0qBL6Y8fUCWuojL4M9Nes8f8sa8tX5aQ40tL91avFAcacHOD888VteqX7Pp//ditU6b4VS660gT4z+tZq317//OdmZWSo7z9ttQwDfX1uyejLQD8lJXSCTC+jry3b11seKkWT0e/VS1z++KP//du3i79dWpr/fKNnT3Gp1/yPpfv2cTzQnzJlCsaMGYORI0eiffv2mDFjBjIyMjBz5kzdx7/44osYMGAA7r//frRr1w5PPPEEzjrrLPxDpi3/kJaWhnr16pV/1dCkkjZu3IhFixbh3//+N7p3747zzz8f06ZNw9tvv429kZ7clioNORkFxMb3oYfU76+4Qmx09+0D/vlPcVuoo6nBaNfoG8ls7dgh1vQdPCjW833yiShPb9FCHCyYMUPdkMpsnhUCzy8cL6X74VgZ6J88qe4IJ08WO7mFC8Up+tLTgSVLgH//W338qVPADTeogU5+fujMwu7d4YOiffvEY5KS1NJhO9SsqQYh2jMThCrdD8zo79/vHwQxox89OYlr2lRM+GWgr/e3lQcXU1Mj+zwHO6/8Dz+IAD4nR82oB9IGnOHK9xVFXY4SSZWKkVPsffedeJ1mzUI3O+vZU3yWf/wReO899fbA9fna1z1yRH9tazCybP/cc9XM+b59FZcQHTrkfz5tIxl9qwJ9ZvTdyetVP8sM9MNzW0Y/3HZYr6dTuPX5kkxErVxpbK7522/qfkNWFgVm9OVrt20reiJJdesGb/7H0n37OBroFxcXY/Xq1eir6Tri9XrRt29frAzSmnHlypV+jweA/v37V3j8smXLULduXbRp0wa33norftOkRleuXInq1aujm6YjXN++feH1evGNtmZUo6ioCAUFBX5fVDlpA/3Ro9WsNiA2YrIp35Il4jKSjL7ccBcVhT+qvH27WM+3a5co9f7vf0XwlJwM/N//icdMmqSWU1u5IQ1cOxhPGf1QZLZP/s1On1bXnJ1zjrg02pBPZtJr1ADy8tSJccuWoq8DANx7r3rg4IEHxI6ybl3xv/L5/NfEaX3/vQjebr899BhkQNS0qf1LZy6/XFx+9JF6W6jS/cCMfuDKLWb09SmKf0AXijbQB0IH+vJ93aBBZKdhDFbG/t134rJbt+DP6/UGP+d3oH37xEQ8KUn9vcww0pDPSNk+IA4MPviguH7ffWqAoBfoZ2erB1vNVAVpA325fSopqVj1FTiBtjvQr1pVBBO1atlbLUTR0et/wa77+mRG3y2BfrjPp14FaLiO+9Jll4n3xsaNIkEUjizbb9xY3S7+9FPwSiYtbfO/wO0uM/r2cTTQP3z4MMrKypATcKg8JycH+/VOYg1g//79YR8/YMAA/Oc//8GSJUvw7LPPYvny5bj44otR9kcnrf3796Nu3bp+z5GcnIyaNWsGfd2JEyeiWrVq5V+NzZy0lxJK3briCHhamhpIa8nyfSmSQD8zUw3IQpXvb94sMqhbt4qs0+LFYnzSX/6/vfMOb6ps//g3STdtaUuhg9VCZUkpUKQUFFFQhiIgynAwRFQEAXEgKsOJwg/0RXGgMl4ERXwRFRRetoyy9yq0tKwuaGlLWzpzfn/c79NzkiZN0iZNmt6f6zpXkpOT5MkZz3m+z72epUFwerqc+M2aHWldseifPEmiKjCQkugB5g/SlfXr9ZkyhW6Wt29T5uQ//5RzKqxYIWdbNpTsBgA2baKJgD//rHw2viYS8Qkee4wed+6Ub96Vue7rW/T1hT5b9A3z5pvUTwjX8srQF/piYGho34oBWFXEMyALff3EdELoG3PbF5ibkE+47YeFVW3yyppCHwDeeIMGv1eu0MQqIA94IyMt/20lkqQr9F1d5X5eX9iL12IyJyPDeN9grWopBw/S8XCW/t8ZMXRdcdZ9wwiLvqO47pu6ripz3Tcl9P385KoNn3xiuk3C6NCmDYWWqNX0u8oQIf1EfEqMeVJxjL7tsLvrvi0YMWIEHnvsMURGRmLw4MHYsGEDDh06hJ07d1b5O2fMmIGcnJzy5WptLKTNWIX69clqvmePHG+ppF073YFhVYS+SmW481Zy8iS5jF6/Tp3u7t0VXWJdXYG33qLnYvbelkLfWSz6+kJfuO1HR8vH3FKLviGRrdFQ4kZ3d5pNHzaM1k+dSkkVxY1SLwVJOceO0eONG5XXwRWiqCaEfqtW5FlSUkLJKgHzXPf1LfrCW4Qt+hURSTaLioAtW0xvb4lFX2xb1RAPYxZ9kYjP2kK/qsklTYltSbJM6Ht5AfPn0/O5c8lCJkpW6Q94LU3Id+kSXQdubnIiQ+Emrx9tKPqBTp3osbhYHkTrYy2h7+XFA3RHx1CJPXbdN4yjuO6bW81I33W/qEieaDXlug/QeMPNjca0e/dWvq1S6Ht6yv2v0n2/skkGZcUTJWzRtx12FfqBgYHQaDRI18sWk56ejmAj9deCg4Mt2h4AWrRogcDAQCT8b2QQHBxcIdlfaWkpsrKyjH6Pu7s7fH19dRam7tKzp1yP2hBKq35VhD5Qeeb9AwcoEUpGBtCxI/DPP8bjI8eO1X2PXfdNI4S+cPAxJPQttegbE9lt2wJz5tDzwkKy4ouZdXGjNGbRF0IfoERgVW2DtRFW/T/+oLhscROvzHX/1i3yThBC/9FH6ZEt+hVZs0Y3h4MpLBH61bXoG4rRz82VXT4r6zeBmhP6xgacgsRE6nvd3amPNYdhw8jD6s4dedIuJKRi9QJL+xBhzY+Olt2sReI7faEvXrdoIYcIGJsss5bQZxyfylz3WejrIoR1bq55ceu2wlKLvhgrXrhAHoi+vsbzoSgJDZVDTj/9tPJtlUIfkL2VhNAvLZW3scSizzH6tsOuQt/NzQ3R0dHYJoKZAWi1Wmzbtg2xwj9Wj9jYWJ3tAWDLli1GtweAa9euITMzEyH/G73HxsYiOzsbRxTZtbZv3w6tVouYylLrMoyZDB9O4josrOqWMWNC/+xZSryXnU1u5Dt2yAN3Q7i7k5uvwJodaYMG8m+r1c4zYFDG6EuSLKKjo+Ubp7WEPkBxvffdR67tP/0k78fKLPrZ2bql+cwR+rYsradECP2NG3U9UkxZ9C9epEkBT0/KOwGwRd8Qy5bJz/Wz2xvCHhb99HS50ofIRt+smW5okSEcxaIvrPmdO5tf3kylohJSKlXlVi1LXfeVbvsCIfSNue43bizva2OZ91no1x1Y6JtPkybkbVdUVLnnXkKCZdnqLcXSZHy3bpHQVsbnm5tn5Y03aNs//zTuQQiYFvoJCeRF5OWlm79KYMqiz55B1sfurvvTpk3Dd999hxUrVuDcuXOYMGEC8vPzMXbsWADAqFGjMGPGjPLtp0yZgk2bNmHBggU4f/485syZg8OHD2PSpEkAgLy8PLzxxhvYv38/kpOTsW3bNgwaNAgRERHo+78i523btkW/fv0wfvx4HDx4EHv37sWkSZMwYsQIhHJ9GMYK+PhQx3f8uG7WUUswJvRXrqQBWmwshRCY0zGOHy8n1zLU+VYH4b7v7V215F2OiEgDUlJCFjJx4+vcWbbGXb9eMeO1IcwR+i4uNGGTkqIbDiGEfnKyrsslQOeWEv2qAJa2wZrExtL5m50tZ9/38TF8LSgt+sKa37mzLGTYoq/LuXPk0SMwZdEvK5MnpfSFvqGwIDEAq6rQ9/WVBaaw6psbnw/UvNBPTZUFjxIh9C2d++/cWdejy5DQr6pFXyn0Tbnuh4bK/Zgpiz7H1js/LPTNx81N7leMJcLNySHvpB49zE+KainmCn1l7ptbt8zPuK+kVStg6FB6Pm+e4W2KiuRQRGNCXxmfb6isn6kYfbboWx+7C/3hw4fj//7v/zBr1ix07NgRx48fx6ZNm8oT7l25cgWpihpX3bt3x+rVq7FkyRJERUXh119/xfr169H+f3dTjUaDkydP4rHHHkOrVq0wbtw4REdHY/fu3XBX9GarVq1CmzZt0Lt3bwwYMAD33nsvlixZUrN/nnFq/P2r12kZi9EXltvRo823xHh6UuzVzp1VDyUwhhCmzjRYdHOT9/+WLST4AwJIKIWE0A2stLTyGtUAbSPidE2JbI2m4oArMFAerOsnXRNu+0IQG7Po37olx8hb+9gbQ6ORXe+XL6dHQ9Z85frsbFnAdu2qK0bNmVCpK4j9KWKwk5JIzBsjNZXOQ41GPleMWfQlqaL1vyrox+krM+6bwhyhL0nVF/oNGsixuIasduJcNCc+X58PP5Td5qsr9HNz5UG00nHRmOu+IYu+MaFvblZvpvZjqJoFZ903jhjXnDtn+P0TJ0icXr9eMfGotTD3+nRxke+jN2+an4hPH1E5ZPVqw54KiYl0r/HxkcMbhdA/c4beMzXJoLToi7AIrVY+L1noWx+7C30AmDRpEi5fvoyioiIcOHBAx31+586dWC5GNv/jySefRHx8PIqKinD69GkMGDCg/D1PT09s3rwZGRkZKC4uRnJyMpYsWVIhU39AQABWr16N27dvIycnB0uXLoU33+0YB8KQRV/pRi6SMplLWBjlFrA2Sou+MyHc9zdsoMfoaPJYcHGRb3KmEvJdu0Yiy81NHphbirhh6sfpC6H/7LPUrpQUOaeAEmHxDQ6u2ckYUWZPJPcxlHEfMGzR79pVnmgpK5MnKuo6paXAv/9Nz995hyaGSkoqF4xiwCbcUQFdoa+MQc3JkQdc1Sksox+nb24iPkAW+pVVsL1xg9qpUlG1kaqgUhl3ob9zR/aYqYrQDwqiEJwxY+RYfSXK3zUVA3zgAG0THi73OwC77jOWwVn3LcOU0Fe6t+t711kLcy36gG5CPnNL6+nTpQuFhZaVAQsWVHxfeDe0bi17b7ZoQROmhYU0+WpqkkGEPhYUyGNbZS4EFvrWxyGEPsMwFTEk9K9epY7cxaViySZ7ISyLykGoMyD+z3//S4/R0fJ75lrkhMgOD5dFlqWIG6Z+3JyY8Ln3XtmNzpBVX7ggt2tXtd+vKg8/rBvbbI5FXwyYYmLos2ISgOP0if/+lyZzAgNpIkWI3Mri9A1Z6MUkSmGhPJgEZMEbGFi9SSGlRf/mTTmXhPIaMoY5Fn3xf5s1q55IMSb0jx6lSZXg4KqHMAwYQLkUDIloMdi9cwfIyqr8ewy57QOGXffv3JEnxRo3Nt91n4W+88Ou+5Yh7qn2FPqWhNaIPv3qVXncYanQB2Sr/vffV/Qm1Y/PB2hcI37n1KnKS+sB5D0ijCji3iTc9t3d2bvEFrDQZxgHxZDQF0Lu7rsdp0O87z7g55+B776zd0usixD6YmCkFCnmJuSzRmy8IYv+nTvyTbdTJ9m7w5DQ/+sveuzXr+ptqAo+PnJCPcC0RV+SyDodGCjnkRAWSWeO0791C+jbV3bJrwyRhO/pp3XjSCuL0zck9OvVk/sP5b6tbiI+gRD6Fy7IuSPuusu8fCLComOsrChQfbd9gTGhryyrZ4u8I+7u8rltqg8RXi76ngXCop+RQdcNIIt+T0/a12zRZwRcXs8yhEXfWIy+o1r0d++me2lgoOnEp4bo3ZvGE3fu6CZ9BeTKKfrVloTR6cgROYyhskkG/YR8HJ9vW1joM4yDYihGX5n93VFQqajKgHDXdRb0PRQMWfRNue5bQ+gbsuifOkXudQ0b0oBftE0/IV9BASX5A8jCWNOI7PuAcYu+h4fupFXXrrK4Ei7mzmzR//13stQbS4AkyMykcoUAlcwE5PPKUqGvUhmO069uaT2B0qJvSSI+AOjQgR6FwDWEOM+ViSurgrEM0EqhbyvMzbwvRIR+qFZgIODqSoN6EbKjTMSnUpmO0WehX3dgi75lCDGbnl4xdEySKgr96pTh27wZWLeu4npLhL4YL+7aRY9VseYD1G+8/DI9//Zb3fw4hiz6gCz0f/2VxiW+vsbLPQMVE/Kx0LctLPQZxkExZNEXA1xL4/MZyxHuZQCJVGW1gpq06AuX++vX5VqzIj6/Uye6MRuz6O/YQe7ZzZrVvOs+IMfpA8aFPqBr6VVmOa8LFn0h5C5dqjzp4E8/Udmijh2BqChaJ84rS133AcNC31oWfWFpz8qiQSxgXiI+QHZRP3fOuFv77t30eO+9VW8jICenXLdOvqaAmhH65oT/3LghW+n1Q7XUankyUmyjjM8H2HWfkWGhbxk+PvJ9Xt99PzWVxL9aTcuNG7SuKhQXA0OGUC4P/f6uKkJftLWqQh8ARowgsZ6YCGzfTuskybTQF/chU2X99CdYxbiGhb5tYKHPMA5KZa77LPRtj9Ki37mz7o3LXIu+KEVTHaHv5ycPOETmfaXQVz5euaLrASLc9h95xD6lD5s0kc/VyoS+8r2uXeXndcGif+IEPRYVVUyspkS4UQprPlB1132gcot+dYV+vXqy2Nyzhx7NtegHBlKyJ0COT1eSmyvvs+oK/SFD6HzLyqIwk4MH6Zq+do0G8OZOTlQFc4S++J8tW8pCTYl+5n3xKPY9u+4zAhb6lmMsTl9Y8++6S95GXKuWcu0aucmXlVXMdG9JVQwxXhRYUlpPn3r1KMkvQFZ9gLyGcnOpX9QPmdKfhDQ1yWDMom9OaBdjOSz0GcZBER337ds065uaSp2tWi1b9BjboRT6+qES5gzSJUkWYNUtaydu2mKAoS/0fX1ld2kxGSRJstC3h9u+4L33aP898YTxbZQ3eKUgNOV6XNuRJN34TmOW+bNn6bi6ugJPPSWvV7ruG3IdraxcnrJ8ocAapfUE4nwEqM8S56o59OhBj6Jig5K4OPJ8CA+v3D3UHLy8qHxmjx5kVerTB/jsM3qvQwfbVqkwx3VfiIeOHQ2/ry/09S364vrJyZFFnRIW+nUHLq9nOcbi9JWZ5cW1WdU4faW41zccVCUZn6A6Fn0AePFFely/nsadYh+0aFFxYqhRI918AKYmGThGv2Zhoc8wDoqfHw2QAbLqK+NSvbzs1qw6Q2VCX1jYU1KM1zDPzJRLhFW1BJhA3LTPnKFs4CdP0muleBKWc3GenDsHJCfTTfmBB6r3+9Xh0UepvJpS+OkjLPotW+paJozVe3cWrlyR3RYB40JflKfr3l13QBcWRn1Efr5hq21mJuVpACpa6W1p0Qd0j3e7dpaJ5sqEvnDbv+++qrdNia8vsGkT0KsXiaCFC2m9Ld32AfMmC4V4MDaxKwS9EPj6Qt/fnyq0AIavIUuEBFO74fJ6lmOsxJ41hX5ysvxcX+hXJRmfoDoWfYCs9LGxNN5YutS4275ye0FVLfos9G0DC32GcVA0GlkAZWay235NU5nQDwmh41NaatwtVljzGzemLNjVQWnRj4+nAZq3t64LnWijOE+ENb9XL8cfyAuLvjI+H3B+i77+4NCY0BcDTf08C25u8qDJ0GfFQCooqKLVTkwYCAEovIYA61j0lck5zXXbFwihf+gQtUuJCAWortu+Em9vYONGKgkpsLXQF8fNHNd9Sy36Yr0yIZ+hfsoS12CmdsOu+5ZjjtAXk3C2sOhXJUYfoDFHZaFy5vLSS/T43Xdy1R9zhL65Fv0bNyhsgWP0bQsLfYZxYJRx+o6Ycd+Z8fYG3nkHmDatouu9RiNPBBgbqFsjEZ9AadEXbvtRUbLHB1AxIZ8yPt/REef0o4/qrnd2i74YHGo09GhM6FdmTaksTr8yV3z9fXvtGrn6e3jI71UHpUXfUqHfqhUNXAsLdRNMFhUBBw7Qc2tZ9AVeXlQBYeRIumb797fu9+ujzPNhyCuoqEgWGMYs+qZc9wHjk2VlZTTIBljo1wWU5fUkiY6/OO9Y6BtGCP2kJPla0Wpl0RsZKV+bFy/qli40F2tZ9JVCv7rWfMGTT9KEQXIysGoVrTMl9M0p6+fnJ/c5V65wjL6tYaHPMA6MEPo3bzppxv2bN0mRzplDI+ugILpLvfEGpYzXN+fVMB9+CCxYYDiRnamEfNZIxCcQA470dIopBiqeB8KN/9IlEnjCxdnWgsUavPoqWZNHjtRd7+wWfWGxffBBejRl0TdUTq6yEnuWCH2l2741Ejcqhb6lSe1UKjn7vtJ9/+hREv/KhH3WxMMDWL2ajkNValBbQnAwudWXlcnl8ZScPUseQ/7+cl+jj9J1X5IqJuMDjGfeF4NrgIV+XUAIfUmicB5lzgYW+oZp1IjEpySRkAdI9BYU0D5r2ZKur5AQ2ubUKct/w1oWfaXrfnXj8wWensCoUfRcWN2NCf1+/ajfeeYZ0/cPlUo3Tp9d920LC32GcWDELO3583QTUKmMu3HWOt5/n9TGI49QxrZNm2g0evYs8H//R+onMBAYOhT44Qd5FOsgmIqxtVYiPoAG4iLOX9Tb1U9uFhAgbzNvHomEVq0qZsh1RFQq3XKGAiFGMzON50JwdC5ckOPk9REW/aFD6TEhoWJSvZIS+VwyNMiqrMSeEO/mCH1rldZTtqtpU/q+Dh0s/7yhOH1lWT17VJGwJhqNLMgN9SFiEigqyvh/VVr0MzPleVGxHjDuui+skk2bcjK2uoCXl+wBdvs2C31zUKkquu8Lt/22beX8F9WJ0zdm0Zcky0JrAgLk59YS+oCclE9gTOiHhlL7RTJTUyjj9Nl137aw0GcYB0bM0gorbqtWhsss1Tpu3QI+/ZSet2pF08ZffkkptdesodcNG9KIZN064PnnaVTcuTPw7rvArl3G1VMNIRLyGbPoW9N1H5Dd8YR7oKEs5sLK/8MP9GjPbPvWQEx0SZJumcnawo4dZHkeP77ie9nZ5BIKAIMG0SC8oKCidTchgSZtvL3lc05JZa77wgplqUXfGri7kwX+yJGqCQml0BeTHyI+39pu+/ZCTBaK80CJqUR8gCzos7PliZ6GDSl3g8CYV4w53884DyqVbuZ9IfRVKqrmwRjGmNBXiumqCv3SUt3xgwifAuj4iMltcyz6rq7yeNGaQr9tW6BnT3oeGFgx6V9VEfeky5fZdd/WsNBnGAdGdKqinrTTuO0vWUKqpkMHcldYsQKYOJEyYA0bRq/T0qiw9Zw5VOxapaIA9Y8+ogxzfn60/euvUw2YGg7kNteiby2hr7x5u7pWTMwGyOeHGMTVhvj8ynBxkS0VtTFOf+VKevzPfyrGb4rKCc2akTeDGPjoW+aV8fmGLLvGLPqFhTTRAMiiWYkQ+mLQb83SeoLAwIpln8wlOpoEa0YG/Tet1jaJ+OyJuF7/+9+K75lKxAdQxQAhAg4dokelNR8w7rpvzvczzoVS6Csz7td27xhbol9iz5pCPyWFxL7wDCgokK3bwpoPmJ9Md8EC4M03LQ+VMsWkSfRoze9l1/2aw8XeDWAYxjhC6JeU0KNTCP2SEuCLL+j5tGnGRxlqNWXxuuceYPZsGqlu2gT8/TdZ9FNTKTPXgQN0hwPIO+Dee2lp2pRGM0VFtNy5Q54EysXVlVSWWPz9aYLh8mXyqbtyhe4+gwYBAwfqTGcL66ohoX/njhxpYG2LPkCDDKXVTqBM1FivnnNYPhs1ArKy6PBbK8lQTVBaCvzxBz0vKgI2b5Zd9IGKQisigiy7CQm6x01Ykoy5TIrzKyuLTmmRbXn7dho4NmliWMz5+dEAs7SUUmVY26JfXTw8aGC5bx9Z9YuK6P95eRn2ZqmNDB0KLFpESQBLSmTLqiTpuu4bQ6UiYX/xIs2JArrx+YBx130hSljo1x2UmfeFeGS3/cqxxKJ/6hRZ4UVyVVMow6Vyc6kfvnaN+nAh9N3c5IkAU4webd52lvLkkzTsUmbWry5K130W+raFhT7DODD61jCnyLi/di1ljwoKAkaMMP9zjRqRS/+oUTQSTk4mE59Yzp6lgOgLF6jwqzVZv57u3r16AY8/DnTpgjD/1gDqG3TdF6649evrxs5VB+XAwpjQUU4E9enjHIO4hg3JmlLbLPr79umGG/z+u67Q13edjoigEB1jFn1DifgAGrAHB9P8VGKibHURkwwDBxqeS1OpqH9JS6N9awuLfnXp0UMW+sIC2a2b87ga9+hB3VpGBnlfiPJ+V6/SpIaLi2HPHSVC6B8+TK+NCX2lRb+0VBYs7Lpfd1AKfTEh6Az3CFsiJljj42myUfTHyvtxy5bUD+fn07VobFJWH9HnhoXRRK0Q+pGRliXiqwn69bPu9ykt+hyjb1tY6DOMA6MfD1XrLVmSJFvfJ02q+ihDpaLMc+HhwLPP0rqsLFIFe/aQMsjOJrOguzs9eniQGdPfX15KSkjppKWRh0BWluxH3bw5TTsnJVGegBMngG3baAHQBUAKgnHhamtop8dCPW1quZ+s0m3fWm6RbdqQk4NWa/w8aNiQHBmuXq39bvsCa2feP3sWmDwZePttOdu9LVi/nh5bt6ZB4saNum6a+hZVY7H2piz64rNKoS9JwJ9/0nuPPWb8c0LoZ2Q4nkUfIMec+fPpchYpOZzBS0Wg0QBDhgDffkvhHULoC2t+27amu0gh7OPjdV8LhOu+0qIvRIu3t3WShTK1A2WJPRHexUK/csLCaB8VFVGITUkJXTfKflKjIXG+fz/16+YKfZGIr3lz8lQ6flyO2Xc0oW9txP67epXuiwDH6NsKFvoM48AohX7Llk7QEe7eTRm6PDyAl16y7ncHBFAhdv1i7NZg1iwytf72G4UPnDsHpKYiBGkIQRowbxfw5SKavHjjDSQmkiuGNQfRHh4k8I8cqTxGee5cEpX6pepqK/pJ46rL5Mk0V5OWRq6WtohPlSSy4APABx8AEyaQdX/PHnIKKSmRLar6Ql9p0Zck0xZ9gPqGPXvkSYKjRyl0pF49+j1jiH177hxZzFUqwwn/7IUosXfunHz8nUnoA+Tl8e231LV89RWJBkvc6kVMvkjiZcyif+MGTRKq1breJGrO1FRnUFr0Weibh0ZDk7UnTwK//krr2reveN/o2FEW+uY6Kiot+uI4CKEvcro4a+nL0FDat0LkA5RzhLE+3MUzjCVotVSofONGMg3aGKXQd4r4/IUL6XH06Kpn6bIXERHAG2+QSkxJAXJyMDDoIMZgGfLadSWT47x5QHg42qx6F42QbrX4fMHateTiW5kAePppqgXuLAMEa1r0d+8ud8jAmTMUx24LTp+mbsLDgyofiLknIf7Pn6dSaL6+NMgDdJPqCdF2/ToN+DSaynM96CfkE277fftWXjpNCH3h9h0c7FgD/8BAGmQD5Naq0QAxMfZtk7Xp1YvmKG/ckMsHmhOfL9BPvqf/Whzj0lLZRdaS72ecB0NCn0srmkZMsor+21BW+6ok5FNa9PWr+Di7RV+j0Z1U9vJynpAsR4Mt+kzVuXWLTEhJSdRjJSVRFrLwcBJFLVvSY3XqcRQWkkt1aiplJQkIoO/z9aUp1eJiMpVlZlJ7IiKAkBDj35ebS3c4f3/TGU4kiQKuduwgl/DTp8m0dOeOvM3YsWRCFf6RVkaphe0m9AsKaF97elbvexISZAUydWq1m2V3fH2R1fIebEi/B4/MHo0nvTaS5f/YMfQ7/BGu4xOkbHwYiHqWkvl5eVX7J0W0gl3Izyc/6uvXacQolqZNKW+Bje7S1rTov/cePXp50Wm9aBHQu3f1v1cf4bb/0EM0UBs0iApJ/P47zXUJodWhg2xRFd4fOTnUnQUGym77ERGGky8K9N3+zXHbB+R9e+QIPTqS276gRw/ZLb1zZ+eZwBK4utL5sWwZWQx79bJMiOtb8PVfu7uTJ1h2NrnvBwRwIr66ilLoK7PuM5UjXPFF0jhrCX1DeVHqitAH6H+LfcDx+baDhT5jHK2WzEk5OSSQk5PJJ1QsIqjTFCEhlEUuOppGapGRZKbz8pL9n0pKqIeMi6Pl1Cmymt66Zfg7NRqailbWIAFo1NynDyVsGzyYesnMTPKL/OUXMuGJ4qR+fjRpoL8EBJDA375dTp2uxN2d1Nb58zQ6+89/KCv8pEmVj8argDKRm10S8e3aRVlYCgtpX4p6WeHh5Hr/4IPm+z7/6180eTJggPlBbA6OKLF37boKePVRCoxfvx7Hn5qHjoX70ez038BTf9MIa8AAUnbt2lH6+BYtzE/Pa28SEiiYWPib69OvH6kUG4xKrGXR37OHrPkuLpRyoV8/EsSJidarjCAQlp/Bg+nx4Yepu0pKol1oSGh5epKF49o12t2Bgea57QO6Fv2rV6kKpUpFp1xlCKEvfseREvEJevSQc2s6S1k9fYYOpVvJunVUPVR4ZlTFoq8v9AG6hrKz6Rpq04aFfl1FWV6PXffNR7//NST0IyNp+JmeTmFhwcGVf6dWq+u6L4aldUnoKyeWa31YqgPDQp/RJS+PTE5ffUWjAuFDaozgYNnMGB5Oo9VLl2ikkphI1r/UVGDDBlqUeHjQaLZ+fdpWTDHr4+FBv1NaSsnSCgqoVxQ9oVpNitjHh0bS//0vLd7eNFLav1/uRZVkZ9Oin/1KiZsbEBtLZpaOHUmktWhBamH/fuCVV8jv9bXXgO++o8fhw+Wp82ri5kY3lWvXqJR8jZKRQYHe4rjk59Ny+TKZAH/9lWYfpk8ni25lovXYMXm0Pm2a7dteQ1QosadSoeyxIYjRDkFzXMDByT/C74+VNEm2Zg0tAjc32TtFLMHBFIjfuTOdbyI1sj3ZuJHiAXJyqH0vvUReLbdv0wTgunWUt6B3b9q2Oh48BqjMor9vHw2YzBGAwpr/3HPk0t63L5W8W7xYjiixBlev0uWhVlPGe4AGa336UBf4++/GhVZEhCz0u3UzLxGf+BxA85K//ELPu3eX950xxPuim3dUi77A2eLzBX360OWfmkq3EYAEvKnjJ7YTuLsbvvwaNaJiJBkZcpUFtdqwYGGcF47RrxrmCH0vL6rue/489e+mstSnp5NDqlpNk3PieNQloa+cWGaLvu1goc8QxcXAkiWUOUrfdObqSlehUoR07kwi2tTVmZdHWUyOHJGXCxfo9woLqVcTPVtAAI1uu3en1NFNm5I3gJ+frtW4sFAW/AEB9L7wf01MBH78Efj3v2nCYe9eWt+xIzBsGBUEFbVMhMu/oSUoCHjgAWqLMZf1bt2ohvvy5cBbb1EPP348MGUK/da4cTRKrWa2r7g42l012hFqteQVkZpKkxvbttH+vnGDls2bgR9+oOM5bBgpjalTKQO+MqNKSQmFNnzwAU3U3HOPbVOd1zDlFn1Fib3r1+l4Jbu2gs/C94HP5tB5uHcvBYafPSuHgIiwFCWrVsnPw8MpKLlHD1oiI80vqltdtFo6bnPm0Ovu3SlJgL4JceJE8mQ4cICU2ObN8o6xAsYs+tnZJJAkiXZhZRaBvXuBrVtp182YQeumTJFP4/fft55LuLDm6wvtQYNkoS/KLxoS+jt3yhZdcy36ohvMzga++ILWiUmGytAXko5o0W/Vihxg0tKA+++3d2tsg7s7Ha9Vq4BPP6V15lrblZdjaKjh2424htLT5Umm1q2rH43F1C5Y6FeNVq3kijeBgfL1pE/HjuYLfWHNb9KEhtjCEyc3lxYh9J0tVEmJcmKZhb7tYKFf10lLo5HnvHkkjAHyA/3wQxK69evTnaCqYtXbm0a8In0yQCPz/HzKrnTzJgnrsDDqTc35HQ+PimJD0LIludHPmkWj+7Nn6X/cdZfudo0aGe+tLUGtJhPh44/TRMnSpRRQunw5LW3bAm++CTz1VJXd+u3S0c+bRyrI05NMhMIPTQQSP/oo7eMvv6QlIYFCF6ZPB555htKMu7hQ0j0RADx0KPD117ZJc24nhJ4tt+hDdhAJCxNODmoSwEpzpFYrF8vOzdUNjzl2jEJjkpLk5eef6XPe3kDPnsDLLwP9+9s2ZfYLL5AKBuj3PvvM8DncrRtlEevblyYwuncnjxpT6tRMhBjNytItT7dvn5wu48SJykWgsOaPHSsnv+vbl7qcCxcofn7iRMvbVlZW0ZFF321fIOrZi8R3Gg0JWCX6mffNteiLzx4+LA8gTcXnAxXzYTqiRV+lorCL4mLdUCZnY+hQEvo3b9JrcxPleXjQfsnKMn5bFClkMjLkbN7stl/34PJ6VcPDg+bcExMNZ9wXiH5aWTnFGMpEfADd2sVkrUjCCrBFn6k+nHW/riFJNCr+8EPyBQ8JIVfcS5doNLB4MY0uR4yg1x4e1hdmKhX1amFhZLnv25fMC9b8HZWK/HlfeKGiyLcFfn4k6M+do1Hpc89RD33uHKmLli3JP/j2bdu3pbrs3Qu8+y49/+KLimpE0LAhKajLl2m7tm1pAufbb2kUGRVFIt/fn9LAr11rni9qLUKZKTc7mwbqQlRWGvetVtNdrmNHEu4DB5J7/DvvUEjEpUs0AbZlC5mb+/YlT4m8POCvv2iipV074Jtv5ALj1uTf/yaRr1bT5NXixZVPVLVrR+dNmza0M+67jyYsrECDBnLXIEQQQJeZoLKf2rePdqOLC/D22/J6tZoibwA6fbVay9r1zz/UjXXrRt8vSTRvs3MnvT9okO72QUG0raBNm4oZr5VCPzub5mHFtqZQnm8REeZ9pjZY9AHqXq0xL+vI9O2rm6/TEiEuBL6h+HxA1ytGWVqPqVuwRb/qiP60snAXkShXeGxVhjI+X6AcT9Q1132O0bcdLPTrAklJwPffU7x1cDCNIGbOBA4dovfvuYcsuAkJZLnjGhdVR6UiF+sffqCA2XnzaDLl2jWK32/alPyNX3oJWLCAzH9iatcRyMyk86SsjLwQnnvO9Ge8vcmaf+YMVSgYNoxUVVkZZQM7fZq+04ks+QKl636jRuTMsGsXrevTp5pfHhBAXzJzJsXAZ2XRKP3110n0x8eT50TTpuQ5sXgxXdNiBFdV4uOpHwDIO2bsWPM+16wZWfa7dKHz6MEH5T6mGmg0suVZGacvSpEBlQv999+nxzFjdAdVAO02sSu3bDG/TZJE83qFhRSx8PDD5Dg0dy55HbRvL4t2JUrxb0jIKYW+cNsPDTWvvrBS6AvvAVPoC31HtOjXFby8KAJGYIkQFwLflNBXuu6zRb/uYSjrPpfXM48nn6R+eMgQ49sIoW/OkE7fog/UPaGvjPBji77tYKHvzKSmkqt1ixYUO/7zzzSl7+VFfp3ffUdi9OBBqg/uzMFA9sDXl/ZrUhLt61atyEV72zayer/+Ovn3hoeT1fytt8hMaShxYE1w7hyNNK9eJcXxzTeWiXOVipIWrllD37FnDwUlG/MndQKCguTBU0kJGbbffZccGV57zco/ptHQ6H/+fBoJ/OtfdG1nZZEFftIk8tLx9SVvlqVLLbf2FxbSRE1+PinXd96x7POBgRQMHxtLJunevcmkXk2EIBVx+oWF1G0JjAn9zEyKQAF0rfkCHx95Lutf/zK/Pf/9Lwl8T0+aE3Fzowme+fPpfX1rvsCU0BdiPTOTcnMA5kdAKCcWzHHbB3QTtwnXUcZ+DB1Kj56ehieKjCGsjca8OITrflIShaoALPTrImzRrzqjR9MtrbIUQ0LoX7liehhnqLReXRP6opATwELflrDQd2aCgqi3cHEhK/OsWTQavXWLLMnPP195zXnGOri7074+e5ZG78uXkxocMYKSGmo09N6nn5LLc2AgmR6bNaOePzSUstvPnSvnUbAmBQUk6KKiSL14e1NcfnUqBwQHWyURoaOjVlPlxoULaZ7kzBnKX9e5s41/2McHmDyZRu2bN5PlvX9/Um7FxeRGP24cmfimTpULkZvitdcoeWbDhhSHUJXyf/XrU5vuv59GlA8/LLs5VBH9hHyHD9PfFK7OZ88aLtqxfz89tm4tD8L0mTiRTtO//9ZNqmgMSZLzE06YQI4UCQk0l6rR0DJsmOHPtm4tR8LExlZ839tbFmWiSIm5Qr91a3r099fNVF8ZLi5y3Hvz5k5/uTo8gwaRV9DHH1t26c2ZQ/3Q6NGG3xfXz8mTdP4GBcnnGVN34PJ61cNU/xgSQg6xpaWm7yXCol+XXfcB2YuMJ5ltByfjc2bUahpwt2xptXJvTDXQaChIVxmoC9DEy6ZNVNT777/lsn9KUlMpQdvbb1OoxbBh5CHg40MWXB8fUj1qtbwA9D03b5LP882blL3M25u29/Gh354xQw4qe/RRSq7nqMG6Dkjv3rTYBY2GhPTDD9NrSaLJoP/8hzwykpLIVP2vf9FETo8eZO3v0aOin/Z//kNlNQHyEKjOJKCPD+USGDyYfOL796fv79+/Sl+nX2JPuO33708x8ZmZFCHSpYvu54QzgTIXqD4REVRM5OhR2t6YSBds2UITCB4e5LADkAvikiU0f5eTQ8URDKFSAevX08SEMTEeEUEu1v/8Q6/NibUHaOLg00/JUmtJ9FXDhuQUwm779sfDA1i50vLP+flVTP6oRAh9UUaRrfl1E7bo2xaNhoZOCQl06zU2jJIk0xb94mJ67uyOtt260b3XWCoopvqw0Hd2+I7u+Pj7Uwz7yJHk/336ND0Kwa5SUU/488/A9u0U92yF2GcdmjQBFi2i0SKb9WovKhVN7L35JoWGbN5MlQ42bqQknCdOyGLe359GJmVllIlOpPl9803TtYHMwcsL+OMP4Ikn6PcHDqRcIWPGWPxV+hZ9IfTvu4+E9dat5L5fFaEPyION/fsrF/r61nxRjEJgjliOiKjcLTsighwySkvptbkWfZWKDp2lNGxIDh88t+e86FvveVhgZ06fpoTIPj40W9iqVY38rDLrvvCAYqFvXcLDZaHfq5fhbW7elKPqlPcMpdAXlnxnt+h//jk5EoqCToz1YaHPMI6EqyuZF/Xp1IlcsdPTKSv7X3/R3eL2bVpyc8lar9XSIkw3Pj40kg8MpMXTk3zCxOcKC0mAzZ7NXh/OhlpNJu/+/em82b2b8ibs3Uuq+Natip956CEagFoLDw9g3ToKXVm5khL7paSQF4kFE0pKi35ZGf0FgIT+9esk9EWSMUFJiRzHb47Q/+or2dXfGFu3UvSNh0fVRLU56E8CmGvRrypi37JF33mpX59uLSUl9Joz7tuYsjK6B7voDbGvXaN77fLlcpmPpUtpkv+dd6xWktQYylt8VhY9stC3LuZk3hfW/JAQ3f2vFPriubMLfVdXFvm2hoU+w9QmgoIoqNhU0W9JosWWddaZ2kNQEFnWn3iCXufl0UhErSarvlpNd9ywMOt7dLi5UaH6xo2BTz6hAe316+RBYmYgstKif/o0zWv5+AAdOsjpB/QT8p08SVYTPz/TYllE0xw9Si6ThioJKq35L71U0ZpvLZRC39fX9mlUJkygub8RI2z7O4z9UKnoGrp+nV6zRd+GpKdTkpabNylxRrt2tNy+TWFxwpQ+dCh1Nn/+SflQVq8Ghg8H/u//jJdPqCaentTVa7VyqVKrZ91fu5Y60smT62QOKEuEvn4VGCHus7Lk4+LsQp+xPSz0GcYZUanYBZ8xjre38UByW6BSUTLJxo1pAPjVV5Sgr317Gu2Eh5P7as+eBsW/0qIv3PZjY8lgJkTLiRNkSBMfF277sbGm57siIigpXVYWfc8991TcZts2+k5bWvNFWwRt2tj+Mn7oIVoY5yYoiIS+p2eNeYrXTebOJa8lADh1ihYl991HZXeVs4sffEDJO37+mUrU/vor5VKxMioVTZDm5MhC32oWfa2WkpTMnUuvv/gCmD6d/LJF1tQ6gDlC31BpPYAmdr29aR5enEIs9JnqwuY+hmEYpmaYNIkqOri7U4mCNWsog9xLL1HdovvvBy5erPAxpUVfGZ8PkGjx8iLrvfKj5sbnAzQAFuNuY+77IqLhhRdsa6gSJfYAm3vyMnUIcQ1FRlatmAZjBteuURJUAPjxR8pNMn8+5SUZNIhyluzapZuQt3NnKplw7BgdnPR0Km361VdyCJ4VEe77VhX6hYXAU0/JIr91a3ITmjWLOuh//1sOVahJioqo1t3FizbZl4YQQl+IeUMYs+irVLJVX8BCn6kuLPQZhmGYmuOJJyhb0bp1wIIFwCuvULUHb28Kvo+KIrd+xcBQWPQzMijNACALfY2GXPgBXfd9S4Q+ULnQv3aNxucqlZxp31b4+8v17VnoM9ZCCP1aH59fWEhVaByRjz8mcXnffSR8BwygpKjLlpHFfuBA4y46HTtSApDhwykT58SJlJfHUN3QaiCyuFtN6N+8SWVn1qyh8K/ly6nW7M8/k8n6+nWq+9ipE+0DWwnu69dpcmTAAJpo8PMj96vmzWmyoXFj4LnnKLRAv6qRFRFCPyVFrmygjzGLPlBR6Dt71n3G9rDQZxiGYWqWJk2AIUOAadNI1P/5JwXf9+5NSSWnTCELf0ICAFmk5OTQAMrVFejaVf46kb9SCP1r18iQo1brblcZlQn933+nx+7dKw7EbIGIquBYasZaDBkChIbW8lwMt29TLE5oKFm916yR65DZm+RkqioCkCt+VWJu6tUDfvqJXPvVapog6N6d3PuthLDoi6zv1RL6wjth3z4S1ps3k6hXqWjC4vx58tjy9aWkKUOGANHRwIYNpgW/JBlXygD5t8fFUd6XmBjqmCdOpBLFFy7QzQKghCseHjQ5tGwZlVUJDKSU+J9/LpvXlRQU0M1EZCy0gMBA8jBTltDTx1BpPQFb9BlrwzH6DMMwjP1p3pyK1H/zDZnNd+0iS0yvXvAf+TQC1EORpfUDQGX0PD3ljwqhLzLvx8XRY1SU+RaRrl1pfHrpEnkOiMkFgDxrgcprlVuTJUvoPzz8cM38HuP8DB5cc+evTdBqgWeflS/ynTtpadSILLVPPUU5P+yVm+aDD6isQe/eFIJUVYTbUMeONCtz7BglDZkyBXj//WqbePWL61RJ6J8/T/H3f/xBr8PDKUxB3wVJJDR5/nlg4ULgX/+i/zNwIB2rzp2pj2/VilKvX7kCHD4sL1lZpJybNyc/96ZNaab3+HHD7vixsXSSd+1K2VKDgmgCoriYYr7+/psqFp0/T/eXXbuAV1+lG8j995MCP3UKSEyk7/b2pnY//7zZ55VKRbvjzBmK0zeUD0NY9PVd9wEW+owNkJgqkZOTIwGQcnJy7N0UhmEY5yIxUZL69RO1IyQJkO7AXfoFT0jtcVJ6803dzQ8dos0CAyVJq5WkqVPp9cSJlv1su3b0uT/+kNdlZkqSRkPrExKq/9cYhqkC77xDF6G7uyStXy9Js2dLUmioTh8hNWkiSePHS9K6dZKUm1tzbbt4Ue4k9u2z3vempEjS8OG6/++33ySprKzKXzlokO4u27Chko1zciQpOVmSzp+XpOPH6b9NmCD/V42GXt+4Yd6P37ghSdOnS5KXl24jqrqEhEjSo49K0jff0L4yl0uXJOmzzySpZ09JUqsNf3e9evLzAQMk6fp1s7/+0UfpY19/XfG9W7fkr83Lq/j+N9/I77u7m/+XGCui1dq7BWZhrg5liz7DMAzjWLRoQdaXy5fJlfXHH+Fx5gyexK8YhN9x6dq7QMkM8uEHGYc0GgoXvX7d8vh8QbduwNmz5L4/cCCt27iRsvlHRuomymNshFZLMb7NmlU0PzJ1kzVrgI8+oufffUeJ7QYNoizvGzYAP/xAZTGuXaP3v/uO/KfffZeyvhuql2lN3nuPOokBA8iqbC1CQijWfcwY4OWXyUQ8ZAiZeSMjyWUpKor6y3r16D/Xq0fuToWF5IJeUECJ8XJygMxMPJ18Ez2RCU/cwWo8BXf3+yr+bkkJ1RL99FP6X4YYNIjc5k3VLlUSGEifee018sa4eJHc7C9cIFeq4GBy1xJLWBh16Jcvkxn86lX6jk6d6H8HBVm8SwGQyX3qVFpu3KDQsWPHqIOPjKQbSmAgufa/8w55AbRvTzkAzIh9qSzzvrDmN2xo2FqvtOizNb+GkSTyUpkzh459dTxzHIkamnhwOtiizzAMU0NotdLz9xyX1uMx2dwRFSVJR4+Wb9K+Pa1es0aSXFzoeVKSZT+zZAl97sEH5XVDhtC6mTOt8k+cl5ISMldV1dqo1UrS339LUocOtMNdXSWpd29JWrhQkuLjrWtlKSuTpIwMSTp2TJI2bZKkM2ckqbTUet/PWI/DhyXJw4POiTfeML5dQQGdP5MnS1JEhNxPtGkjSdu32659Z89KkkpFv3X4sO1+Jz9fkt56y3rW8P8tKQPHS1JWlvw7ycmS1L27vI2npyT5+5P1PDycOsedO233Px2NM2ckKTpa3h8vvCBJxcWVfmThQtr0yScrvrd+Pb3XpYvhzx4/Lv9U06ZWaD9jGq2WDkzHjvLOf+QRe7fKJObqUJUk1VDNCScjNzcX9evXR05ODnx9fe3dHIZhGKdmxAhgzRoJbzT5GfPuvAJkZpIZf/JkYMIEjPrgLqxcSTXht2whY9j165aF7J46RRn8vb0pMXNRERl27tyhfFgiF0Cd5+xZqphw8iTF0WZmysmvXFxo54eEUNK01q0pcdq99xo3UR06RDG/O3bI31FaqrtNy5bAI4+Q1fT++yn+1xCSRJa/I0eAEyco4UJWFnDrFj3euEFxviUlup+rV48OcHS0vLRuzbXo7Mnp00C/fnQhDxhA1jZzjockUXm711+n4w8AzzxDNTINZUCrKjk5QN++wIEDFBsuknnYktJSsoCfOCEvqamy5T4/nzosDw9dK7+PDxAYiEOXGmD7qUCEIBWjsJK+MyiI6t5rNJTpPzubEuh9/z3w5JO2/0+OTkkJeZS8/z6dWw8+SNn7AwIMbr5+PTle3HMPcPCg7nuLFlG6hSeeoK/QJzOT7jkApTw4e9a6f4VRIEmUafe99+TcH97eNKaYNk0uf+OgmKtDWehXERb6DMMwNce0acBnnwETJgBfzcmgsny//FL+/vXwHpiVNBa/YBjy4IPHHwf+8x/LfqOsjHI35eWRhr10icbvzZuTG6a98nw5DMeO0YDX0h0LkHiPiQF69CCxkplJS3o6CX2AXKxfeQV4+22Kw/jrL4qd2LVLV5h7edFgW9RdFKSkkMAXtcNM0agRfUdSkpyGXEm9epQULToauPtuICICuOsuKtWlVpOgSk6mz1++TGIqPJxcqYODne+EKS4m8S3EZUYGHb+MDBKWMTHkut61K1C/ftV/Jz+fRNXChXSutG1L2Skt/c5bt8h9/+uv5cRtMTGksoYOpWNVWkoTQ4mJdAxbt6Zz1NSxu3WLRP6hQ1QTMy6OPuvgfPABlbcHgPvwD/4b9gI8kuN1N+ralUIGhA86Q/z5JyV9zMujfmDDBoPZ9k6coG4jMJDmFZWMH0/zJ9OnUxSDPpJE3VthIUUviK6RsSK1XOALWOjbGBb6DMMwNcelSxQ299prCqPcX38BixcDmzZRbDeAfHjhVzwBz5fGYNji+0mQWUDv3sD27RTmu2cPsGIFWWA+/9yqf8cxSE0FVq8ms1N4OMWhtm8vx90mJZEASkwkN4mNG+XPDh1KVtJGjWhg1KABDZZu3iTBnZJCltjDh8lSb6zWFECiatQoGngZsrjevk0x2Bs30jFPSan8f7m4kDDv3JkydQcEkBgLCKB2Nm5MQlzEbpeVAfHxNElw+DA9HjtmWPwDlKrcz49ErjE8PMgLoXNnmijo0oVG/7Up8FaSKFfGhg20X06cMK+cnUpFotfTk7YXS716dFzEeda+PU20eHuX59vAhg3ApEny+TJkCPDll+QdUlWEx8jOnbqZ2ps0AdLSKnqPtGpFmfxHj6bzRJ/MTHIdOnaMzqetW2tNLczPP6dE84LzJ4rQet1c4OOPaTLt9ddpMs/WeQ1qKydPUgKXK1eoD1i2jF4rPE1ycugtgLouUShBkqibvXyZurH+/Q3/xF13UWXZ+++nU5axEk4i8AUs9G0MC32GYRgHISUFd5asxOX3lqENFNap8HAarI8YQYN3Myys77xDY97Ro8mAk5VFgy2Hz8uj1VLZqOJiErV+fmRhFhMdkkSCJj+fRpn//jeJ9/9NkOigVstRvPrrR4wgi/vdd1vWvqQkEvxHjpDgE5MDDRpQAqyICPO+R5JosL1zJ5m9lNSvT8K6Qwfjrv3mohT/R4+Su3RCAs04KYWhjw9Z8Js3p1H9pUtkITa2Xz096T2xeHhQm7t1I2t4TIxhcVkdJIkS1SUm0qSDOUkOL18mwb1hg+56f39qb7Nm5PLdqBEtt26RVTsuznAWMlO4uZEpMzubXjdrRgJfZMW0Bmlp5F6/di15iYhj5OZGfUWTJpSJMz+f1ms0ZLXv3p3COjp1okmkPn3oHGzYkCagIiOt10Yb88MPVC1OcOnS/wz3ycmkUKOi7NW02kN6Ok1AiTqujRoBjz8ODBsG9OwJaDQICKBL4uRJ+fS4eJFuQ25udF8xNuf3wAPUvQ0YoDu3ylSDoiKaTBZegLVY4AtY6NsYFvoMwzCORYtwCUHJ+/G8ehmeq/czVLdvy28GBpKY6taNxFTjxiSG/f11ROGffwKPPUZG26IiGgOkpdH43qEoLqakAqIe9O7dNLJUolaTeCopoe0N3e67d6fY9+vXyS379GkahQIkCFu2pKV1a8r+fdddNv9rDk1pKVnzbt2irOABARUnkEpKSOyfO0cTBcJTwJQngiAsTD5Xu3Ujy3deHnlL3LxJ/sDXrpE4ExnJMzNJqLZoIS83b5JwjYuTf9vNjYTqkCEkovUzl5eWUr3zWbPIo8HVFXjhBRIwXbqQKjQ1YZaeTtZ/SaLfc3WV1c2ZM3SOnTpF+0ffa0KjIbedWbNs6/2QkUHKq1kzORQDoMmaNWtIEe/fX/Fzbm50LQUHk8hv1852bbQBv/wCDB8uv05JoXQajIUUFtKE54oVcn8JkOh/7jn03zARm043we+/0/0EIOezSZOAXr3kdCSGePZZSjHx5JM60Wm24fx5SiogSdSXCa+nhg3p2qhOCI6jkJNDMXg7d1Jf9Prr1MfUUoEvYKFvY1joMwzDOBZDhwLr1pF23bulgKx3y5cD//xTucuxuzsN0MLCcCckHJ/+Eo5LaIFduB+9xzbH0qU19AcKC2ngdeYMjcBdXalt7u70/PJlWYzHx1d0ORZJt7KzK1q7lbRoQaPJZ56paEmXJBJqGg1NjjhbnLk9ycgga7FKRcJSraZjdfAgicr9++nY2mJYptGQqFdONqhUdPx9fWnx8SET7+nT9P599wHffksx8raiuJj2SV4eLQEBVS+bZm3OnCHvl+PHyU0/Pp68AEJDKb6nFsTk6/P332QpFmRmGs0px5hDSQmdC2vX0v3mf6K/TKXBr9JQqKZMwbDPYgGVCoMHk+f4Rx/RHIExZsyg+P0xYygywOpkZlIOhhUrTCcB8PMjbyX9JSyMhHJeHpCbSxNkt2/TvaVjR9snMdVqqZ809TspKRQjcfIk9W+//UbxeU4AC30bw0KfYRjGsfj2W+Cll4C5c4G33lK8UVREg/W4OBJTR4+StTM726Soym7ZGX5jHyfXzOoIntJSEuoXLtCjyFaflUVtiY8n12pDLt/G8POjbPY9e1JsQadOcqxzYSH9v7w8skK6ucmTBp6eLOAdldxcGnwL4b9/P50fKhUpssBAWkJCaLAdFkYD78BA2T3/0iVavL0pHKBbN7LGe3qSFf2332g5csRwG/z9gfnzgbFjLc5x4dQUFND+Cw+vtep4zx6avxHk5dWutBEOTUkJhbosWqQbXN+tG8o+nIuAx3uVX95duhj/miNHKEXEp59S0QmTxMcDq1YBP/1E7mfR0ZRQMSaGwmzS0siD5uRJeoyLk5OburhQeEqjRnQvEvel9HR6rAp+fuS28MAD1A6Nhu5/ZWW0+PjIIT+W5oJISaH9++23lAy1VSvyqmnXjp77+VG/5+NDJ/dTT5EHVlAQzXI5UekcFvo2hoU+wzCMY6HVksdwhw5mGhS0WrJC3LpFg6GkJCA5Gdt/SIJb4lnEIg4aKIR3o0Y0gPDyItEkko3duUMi4M4dGsjUqycvHh7kFp+YWLGkmyH8/Sn+PSyMBkdFRfQbRUVkSVQmMmvShAW7syNJcrkza1vJrl2jCQFhjcvNpWvi8cfpXGecDpERXlBS4oBhSU7AmrdPIG/uIjyrXgU3bREAYCMGYK7vJ9iVFVn9SzkvD1i6FFi5ksKCLKVTJ0pEM3Kk8Ws9L48mpcUiQoXEkpUlewP5+tL98PRp6kfMxd+fJiqfeoomFkVtQX1On6aSrqtWmXcfVXLXXcDmzU5XRYKFvo1hoc8wDOOciIRVLwy5gW8f+YPiAbZuNS/jeGV4eNCgIzycBjQiHjIggFwe777bOcuyMQzjECQmytE6ajXNSzLWR4RI9Gqbjh0PvI+yb5ZAoy2FFiqoR48iv/xu3SxPGlpURNbsDz+Ua/dpNMDDD1MoVvv2JPwPHKCQoFOnyJodGUlLhw7APffIlVWsTWkpecxt306JCM6epfZpNDSjpFZTzHxGRsWTz92dEhpOmEATAPv2ycu5c/J2991Hcfbt29P6c+fodxITacIyL09+7NGDJkP0S7E6ASz0bQwLfYZhGOdEq6VYygcekMskITeXsq7fuaNrwRfZwj096VGtpphjsRQUkJt1q1ZkgWdXaIZh7ERGhpwCwdPTeAVJpnqcP0+RXj4+pGtHdrmIx4++g2FYK2/k4UEJZR58kCZ6s7NpuXWLRGpICK0PD6dlyxZKUilKT0ZEUOb44cONW+W1Wse852i15BGQnk6hBF99RXkwjKFWk6fR669TSALDQt/WsNBnGIZhGIZhagt37tB8JEBGU2XCeMZ6KPdzUhJp8rIy4PpvBxH66yKyeKemVu3LQ0OB2bPJ1V3kZKntSBJ5IHz9NVW9UKkovj82liZDYmONu/XXUczVoRyZwzAMwzAMwzBOjocHeVGXlZGnNGMbPD0pCistjTLnl5WR2A8d3BUY/CMJ2/h42cX9xg2aeRFLvXqU2+XSJZopuHqVSt299RbV6BOzCM6CSkWW+pgYCk1Qq51nEsPOsNBnGIZhGIZhGCdHpZIrcLLQty3h4ST0f/iBXj/0kOJNlYri5Nu0AV5+2fSXFRfLse7ODp+YVsUhAjcWL16MsLAweHh4ICYmBgcPHqx0+7Vr16JNmzbw8PBAZGQk/vrrr/L3SkpKMH36dERGRqJevXoIDQ3FqFGjkKKsHQsgLCwMKpVKZ/nkk09s8v8YhmEYhmEYxt74+NAj6ynbIpK8X79OjzpC31Lc3OqGyGesjt2F/po1azBt2jTMnj0bR48eRVRUFPr27YuMjAyD2+/btw8jR47EuHHjcOzYMQwePBiDBw/G6dOnAQAFBQU4evQoZs6ciaNHj2LdunWIj4/HY489VuG73n//faSmppYvr7zyik3/K8MwDMMwDMPYCxb6NYOymptGQ8ldGaamsXsyvpiYGNxzzz348ssvAQBarRZNmzbFK6+8grfeeqvC9sOHD0d+fj42bNhQvq5bt27o2LEjvvnmG4O/cejQIXTt2hWXL19Gs2bNAJBFf+rUqZg6dWqV2s3J+BiGYRiGYZjaREwM5T3r0gU4dMjerXFeRJlWgHLJ7dtn3/YwzoW5OtSuFv3i4mIcOXIEffr0KV+nVqvRp08fxMXFGfxMXFyczvYA0LdvX6PbA0BOTg5UKhX8yuskEZ988gkaNGiATp06Yf78+SgtLTX6HUVFRcjNzdVZGIZhGIZhGKa2ICz6lpZwZyxDadGvlts+w1QDuybju3nzJsrKyhAkinr+j6CgIJw/f97gZ9LS0gxun5aWZnD7wsJCTJ8+HSNHjtSZ8Zg8eTI6d+6MgIAA7Nu3DzNmzEBqaioWLlxo8Hvmzp2L9957z5K/xzAMwzAMwzAOA7vu1wxhYfJzFvqMvXDqrPslJSUYNmwYJEnC119/rfPetGnTyp936NABbm5uePHFFzF37ly4G+j9ZsyYofOZ3NxcNG3a1HaNZxiGYRiGYRgrwkK/ZmjWDGjfXq4cxzD2wK5CPzAwEBqNBunp6Trr09PTERwcbPAzwcHBZm0vRP7ly5exfft2k3H0MTExKC0tRXJyMlq3bl3hfXd3d4MTAAzDMAzDMAxTG2ChXzO4uAAnTwJlZfScYeyBXWP03dzcEB0djW3btpWv02q12LZtG2JjYw1+JjY2Vmd7ANiyZYvO9kLkX7x4EVu3bkWDBg1MtuX48eNQq9Vo1KhRFf8NwzAMwzAMwzguLPRrDpWKRT5jX+x++k2bNg2jR49Gly5d0LVrV3z++efIz8/H2LFjAQCjRo1C48aNMXfuXADAlClTcP/992PBggV45JFH8PPPP+Pw4cNYsmQJABL5TzzxBI4ePYoNGzagrKysPH4/ICAAbm5uiIuLw4EDB/DAAw/Ax8cHcXFxePXVV/HMM8/A39/fPjuCYRiGYRiGYWyIyEvt5WXXZjAMUwPYXegPHz4cN27cwKxZs5CWloaOHTti06ZN5Qn3rly5ArVadjzo3r07Vq9ejXfffRdvv/027rrrLqxfvx7t27cHAFy/fh1//PEHAKBjx446v7Vjxw706tUL7u7u+PnnnzFnzhwUFRUhPDwcr776qk4MPsMwDMMwDMM4EyNGAEePAi++aO+WMAxja1SSJEn2bkRtxNz6hQzDMAzDMAzDMAxjDczVoXaN0WcYhmEYhmEYhmEYxrqw0GcYhmEYhmEYhmEYJ4KFPsMwDMMwDMMwDMM4ESz0GYZhGIZhGIZhGMaJYKHPMAzDMAzDMAzDME4EC32GYRiGYRiGYRiGcSJY6DMMwzAMwzAMwzCME8FCn2EYhmEYhmEYhmGcCBb6DMMwDMMwDMMwDONEsNBnGIZhGIZhGIZhGCeChT7DMAzDMAzDMAzDOBEs9BmGYRiGYRiGYRjGiWChzzAMwzAMwzAMwzBOBAt9hmEYhmEYhmEYhnEiWOgzDMMwDMMwDMMwjBPBQp9hGIZhGIZhGIZhnAgW+gzDMAzDMAzDMAzjRLDQZxiGYRiGYRiGYRgnwsXeDaitSJIEAMjNzbVzSxiGYRiGYRiGYZi6gNCfQo8ag4V+Fbl9+zYAoGnTpnZuCcMwDMMwDMMwDFOXuH37NurXr2/0fZVkaiqAMYhWq0VKSgp8fHygUqns3Ryj5ObmomnTprh69Sp8fX3t3RymCvAxrP3wMaz98DGs/fAxrP3wMaz98DGs/fAxtD+SJOH27dsIDQ2FWm08Ep8t+lVErVajSZMm9m6G2fj6+vLFWMvhY1j74WNY++FjWPvhY1j74WNY++FjWPvhY2hfKrPkCzgZH8MwDMMwDMMwDMM4ESz0GYZhGIZhGIZhGMaJYKHv5Li7u2P27Nlwd3e3d1OYKsLHsPbDx7D2w8ew9sPHsPbDx7D2w8ew9sPHsPbAyfgYhmEYhmEYhmEYxolgiz7DMAzDMAzDMAzDOBEs9BmGYRiGYRiGYRjGiWChzzAMwzAMwzAMwzBOBAt9hmEYhmEYhmEYhnEiWOg7OYsXL0ZYWBg8PDwQExODgwcP2rtJjAHmzp2Le+65Bz4+PmjUqBEGDx6M+Ph4nW169eoFlUqls7z00kt2ajGjz5w5cyocnzZt2pS/X1hYiIkTJ6JBgwbw9vbG0KFDkZ6ebscWM4YICwurcBxVKhUmTpwIgK9DR+Sff/7BwIEDERoaCpVKhfXr1+u8L0kSZs2ahZCQEHh6eqJPnz64ePGizjZZWVl4+umn4evrCz8/P4wbNw55eXk1+C/qNpUdw5KSEkyfPh2RkZGoV68eQkNDMWrUKKSkpOh8h6Fr95NPPqnhf1J3MXUdjhkzpsLx6devn842fB3aF1PH0NC9UaVSYf78+eXb8HXoWLDQd2LWrFmDadOmYfbs2Th69CiioqLQt29fZGRk2LtpjB67du3CxIkTsX//fmzZsgUlJSV4+OGHkZ+fr7Pd+PHjkZqaWr7MmzfPTi1mDHH33XfrHJ89e/aUv/fqq6/izz//xNq1a7Fr1y6kpKTg8ccft2NrGUMcOnRI5xhu2bIFAPDkk0+Wb8PXoWORn5+PqKgoLF682OD78+bNw6JFi/DNN9/gwIEDqFevHvr27YvCwsLybZ5++mmcOXMGW7ZswYYNG/DPP//ghRdeqKm/UOep7BgWFBTg6NGjmDlzJo4ePYp169YhPj4ejz32WIVt33//fZ1r85VXXqmJ5jMwfR0CQL9+/XSOz08//aTzPl+H9sXUMVQeu9TUVCxduhQqlQpDhw7V2Y6vQwdCYpyWrl27ShMnTix/XVZWJoWGhkpz5861Y6sYc8jIyJAASLt27Spfd//990tTpkyxX6OYSpk9e7YUFRVl8L3s7GzJ1dVVWrt2bfm6c+fOSQCkuLi4GmohUxWmTJkitWzZUtJqtZIk8XXo6ACQfvvtt/LXWq1WCg4OlubPn1++Ljs7W3J3d5d++uknSZIk6ezZsxIA6dChQ+Xb/P3335JKpZKuX79eY21nCP1jaIiDBw9KAKTLly+Xr2vevLn02Wef2bZxjFkYOoajR4+WBg0aZPQzfB06FuZch4MGDZIefPBBnXV8HToWbNF3UoqLi3HkyBH06dOnfJ1arUafPn0QFxdnx5Yx5pCTkwMACAgI0Fm/atUqBAYGon379pgxYwYKCgrs0TzGCBcvXkRoaChatGiBp59+GleuXAEAHDlyBCUlJTrXY5s2bdCsWTO+Hh2Y4uJi/Pjjj3juueegUqnK1/N1WHtISkpCWlqazrVXv359xMTElF97cXFx8PPzQ5cuXcq36dOnD9RqNQ4cOFDjbWZMk5OTA5VKBT8/P531n3zyCRo0aIBOnTph/vz5KC0ttU8DGYPs3LkTjRo1QuvWrTFhwgRkZmaWv8fXYe0iPT0dGzduxLhx4yq8x9eh4+Bi7wYwtuHmzZsoKytDUFCQzvqgoCCcP3/eTq1izEGr1WLq1KnoEoe+AgAADftJREFU0aMH2rdvX77+qaeeQvPmzREaGoqTJ09i+vTpiI+Px7p16+zYWkYQExOD5cuXo3Xr1khNTcV7772H++67D6dPn0ZaWhrc3NwqDEqDgoKQlpZmnwYzJlm/fj2ys7MxZsyY8nV8HdYuxPVl6F4o3ktLS0OjRo103ndxcUFAQABfnw5IYWEhpk+fjpEjR8LX17d8/eTJk9G5c2cEBARg3759mDFjBlJTU7Fw4UI7tpYR9OvXD48//jjCw8ORmJiIt99+G/3790dcXBw0Gg1fh7WMFStWwMfHp0IIIl+HjgULfYZxMCZOnIjTp0/rxHcD0IlTi4yMREhICHr37o3ExES0bNmyppvJ6NG/f//y5x06dEBMTAyaN2+OX375BZ6ennZsGVNVfvjhB/Tv3x+hoaHl6/g6ZBj7UVJSgmHDhkGSJHz99dc6702bNq38eYcOHeDm5oYXX3wRc+fOhbu7e003ldFjxIgR5c8jIyPRoUMHtGzZEjt37kTv3r3t2DKmKixduhRPP/00PDw8dNbzdehYsOu+kxIYGAiNRlMhq3d6ejqCg4Pt1CrGFJMmTcKGDRuwY8cONGnSpNJtY2JiAAAJCQk10TTGQvz8/NCqVSskJCQgODgYxcXFyM7O1tmGr0fH5fLly9i6dSuef/75Srfj69CxEddXZffC4ODgCklqS0tLkZWVxdenAyFE/uXLl7FlyxYda74hYmJiUFpaiuTk5JppIGMRLVq0QGBgYHnfyddh7WH37t2Ij483eX8E+Dq0Nyz0nRQ3NzdER0dj27Zt5eu0Wi22bduG2NhYO7aMMYQkSZg0aRJ+++03bN++HeHh4SY/c/z4cQBASEiIjVvHVIW8vDwkJiYiJCQE0dHRcHV11bke4+PjceXKFb4eHZRly5ahUaNGeOSRRyrdjq9DxyY8PBzBwcE6115ubi4OHDhQfu3FxsYiOzsbR44cKd9m+/bt0Gq15RM5jH0RIv/ixYvYunUrGjRoYPIzx48fh1qtruAOzjgG165dQ2ZmZnnfyddh7eGHH35AdHQ0oqKiTG7L16F9Ydd9J2batGkYPXo0unTpgq5du+Lzzz9Hfn4+xo4da++mMXpMnDgRq1evxu+//w4fH5/yeLT69evD09MTiYmJWL16NQYMGIAGDRrg5MmTePXVV9GzZ0906NDBzq1nAOD111/HwIED0bx5c6SkpGD27NnQaDQYOXIk6tevj3HjxmHatGkICAiAr68vXnnlFcTGxqJbt272bjqjh1arxbJlyzB69Gi4uMi3Sb4OHZO8vDwdj4qkpCQcP34cAQEBaNasGaZOnYoPP/wQd911F8LDwzFz5kyEhoZi8ODBAIC2bduiX79+GD9+PL755huUlJRg0qRJGDFihE7YBmM7KjuGISEheOKJJ3D06FFs2LABZWVl5ffIgIAAuLm5IS4uDgcOHMADDzwAHx8fxMXF4dVXX8UzzzwDf39/e/2tOkVlxzAgIADvvfcehg4diuDgYCQmJuLNN99EREQE+vbtC4CvQ0fAVF8K0ETp2rVrsWDBggqf5+vQAbF32n/GtnzxxRdSs2bNJDc3N6lr167S/v377d0kxgAADC7Lli2TJEmSrly5IvXs2VMKCAiQ3N3dpYiICOmNN96QcnJy7Ntwppzhw4dLISEhkpubm9S4cWNp+PDhUkJCQvn7d+7ckV5++WXJ399f8vLykoYMGSKlpqbascWMMTZv3iwBkOLj43XW83XomOzYscNg/zl69GhJkqjE3syZM6WgoCDJ3d1d6t27d4Vjm5mZKY0cOVLy9vaWfH19pbFjx0q3b9+2w7+pm1R2DJOSkozeI3fs2CFJkiQdOXJEiomJkerXry95eHhIbdu2lT7++GOpsLDQvn+sDlHZMSwoKJAefvhhqWHDhpKrq6vUvHlzafz48VJaWprOd/B1aF9M9aWSJEnffvut5OnpKWVnZ1f4PF+HjodKkiTJ5rMJDMMwDMMwDMMwDMPUCByjzzAMwzAMwzAMwzBOBAt9hmEYhmEYhmEYhnEiWOgzDMMwDMMwDMMwjBPBQp9hGIZhGIZhGIZhnAgW+gzDMAzDMAzDMAzjRLDQZxiGYRiGYRiGYRgngoU+wzAMwzAMwzAMwzgRLPQZhmEYhmEYhmEYxolgoc8wDMMwjE1QqVRYv369vZuBOXPmoGPHjvZuBsMwDMPUGCz0GYZhGKaWcuPGDUyYMAHNmjWDu7s7goOD0bdvX+zdu9feTbMKycnJUKlUOH78uL2bwjAMwzC1Chd7N4BhGIZhmKoxdOhQFBcXY8WKFWjRogXS09Oxbds2ZGZm2rtpDMMwDMPYEbboMwzDMEwtJDs7G7t378ann36KBx54AM2bN0fXrl0xY8YMPPbYY+XbLVy4EJGRkahXrx6aNm2Kl19+GXl5eeXvL1++HH5+ftiwYQNat24NLy8vPPHEEygoKMCKFSsQFhYGf39/TJ48GWVlZeWfCwsLwwcffICRI0eiXr16aNy4MRYvXlxpm69evYphw4bBz88PAQEBGDRoEJKTk83+zzt37oRKpcK2bdvQpUsXeHl5oXv37oiPj9fZ7pNPPkFQUBB8fHwwbtw4FBYWVviu77//Hm3btoWHhwfatGmDr776qvy95557Dh06dEBRUREAoLi4GJ06dcKoUaPMbivDMAzD2BMW+gzDMAxTC/H29oa3tzfWr19fLkgNoVarsWjRIpw5cwYrVqzA9u3b8eabb+psU1BQgEWLFuHnn3/Gpk2bsHPnTgwZMgR//fUX/vrrL6xcuRLffvstfv31V53PzZ8/H1FRUTh27BjeeustTJkyBVu2bDHYjpKSEvTt2xc+Pj7YvXs39u7dC29vb/Tr1w/FxcUW/fd33nkHCxYswOHDh+Hi4oLnnnuu/L1ffvkFc+bMwccff4zDhw8jJCRER8QDwKpVqzBr1ix89NFHOHfuHD7++GPMnDkTK1asAAAsWrQI+fn5eOutt8p/Lzs7G19++aVF7WQYhmEYuyExDMMwDFMr+fXXXyV/f3/Jw8ND6t69uzRjxgzpxIkTlX5m7dq1UoMGDcpfL1u2TAIgJSQklK978cUXJS8vL+n27dvl6/r27Su9+OKL5a+bN28u9evXT+e7hw8fLvXv37/8NQDpt99+kyRJklauXCm1bt1a0mq15e8XFRVJnp6e0ubNmw22NSkpSQIgHTt2TJIkSdqxY4cEQNq6dWv5Nhs3bpQASHfu3JEkSZJiY2Oll19+Wed7YmJipKioqPLXLVu2lFavXq2zzQcffCDFxsaWv963b5/k6uoqzZw5U3JxcZF2795tsI0MwzAM44iwRZ9hGIZhailDhw5FSkoK/vjjD/Tr1w87d+5E586dsXz58vJttm7dit69e6Nx48bw8fHBs88+i8zMTBQUFJRv4+XlhZYtW5a/DgoKQlhYGLy9vXXWZWRk6Px+bGxshdfnzp0z2NYTJ04gISEBPj4+5d4IAQEBKCwsRGJiokX/u0OHDuXPQ0JCAKC8befOnUNMTIzRdubn5yMxMRHjxo0rb4e3tzc+/PBDnXbExsbi9ddfxwcffIDXXnsN9957r0VtZBiGYRh7wsn4GIZhGKYW4+HhgYceeggPPfQQZs6cieeffx6zZ8/GmDFjkJycjEcffRQTJkzARx99hICAAOzZswfjxo1DcXExvLy8AACurq4636lSqQyu02q1VW5nXl4eoqOjsWrVqgrvNWzY0KLvUrZNpVIBgNltE/kJvvvuuwoTAhqNpvy5VqvF3r17odFokJCQYFH7GIZhGMbesEWfYRiGYZyIdu3aIT8/HwBw5MgRaLVaLFiwAN26dUOrVq2QkpJitd/av39/hddt27Y1uG3nzp1x8eJFNGrUCBERETpL/fr1rdamtm3b4sCBA0bbGRQUhNDQUFy6dKlCO8LDw8u3mz9/Ps6fP49du3Zh06ZNWLZsmdXayDAMwzC2hoU+wzAMw9RCMjMz8eCDD+LHH3/EyZMnkZSUhLVr12LevHkYNGgQACAiIgIlJSX44osvcOnSJaxcuRLffPON1dqwd+9ezJs3DxcuXMDixYuxdu1aTJkyxeC2Tz/9NAIDAzFo0CDs3r0bSUlJ2LlzJyZPnoxr165ZrU1TpkzB0qVLsWzZMly4cAGzZ8/GmTNndLZ57733MHfuXCxatAgXLlzAqVOnsGzZMixcuBAAcOzYMcyaNQvff/89evTogYULF2LKlCm4dOmS1drJMAzDMLaEhT7DMAzD1EK8vb0RExODzz77DD179kT79u0xc+ZMjB8/vjw7fFRUFBYuXIhPP/0U7du3x6pVqzB37lyrteG1117D4cOH0alTJ3z44YdYuHAh+vbta3BbLy8v/PPPP2jWrBkef/xxtG3btrz0na+vr9XaNHz4cMycORNvvvkmoqOjcfnyZUyYMEFnm+effx7ff/89li1bhsjISNx///1Yvnw5wsPDUVhYiGeeeQZjxozBwIEDAQAvvPACHnjgATz77LM6JQYZhmEYxlFRSZIk2bsRDMMwDMPULsLCwjB16lRMnTrV3k1hGIZhGEYPtugzDMMwDMMwDMMwjBPBQp9hGIZhGIZhGIZhnAh23WcYhmEYhmEYhmEYJ4It+gzDMAzDMAzDMAzjRLDQZxiGYRiGYRiGYRgngoU+wzAMwzAMwzAMwzgRLPQZhmEYhmEYhmEYxolgoc8wDMMwDMMwDMMwTgQLfYZhGIZhGIZhGIZxIljoMwzDMAzDMAzDMIwTwUKfYRiGYRiGYRiGYZyI/wfTnb6gjUBeJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Metrics (All Features):\n",
      "Mean Squared Error (MSE): 0.0138\n",
      "Mean Absolute Error (MAE): 0.0789\n",
      "R² Score: -4.6788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_lr, best_optimizer_name, best_hidden_size, best_num_layers, best_dropout = best_params\n",
    "model = MyLSTM(\n",
    "    input_size=5,\n",
    "    hidden_size=best_hidden_size,\n",
    "    num_layers=best_num_layers,\n",
    "    output_size=5,\n",
    "    dropout=best_dropout\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "# Test\n",
    "model.eval()\n",
    "\n",
    "# Transform to PyTorch Tensor\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "\n",
    "# Transform prediction and true to NumPy\n",
    "predictions = predictions.cpu().numpy()\n",
    "y_test = y_test.cpu().numpy()\n",
    "\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "# Calculate metrics\n",
    "for i, feature in enumerate(features):\n",
    "    mse = mean_squared_error(y_test[:, i], predictions[:, i])\n",
    "    mae = mean_absolute_error(y_test[:, i], predictions[:, i])\n",
    "    r2 = r2_score(y_test[:, i], predictions[:, i])\n",
    "    print(f\"{feature} - MSE: {mse:.4f}, MAE: {mae:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "    # Plot Charts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(y_test[:, i], label=f\"True {feature}\", color=\"blue\")\n",
    "    plt.plot(predictions[:, i], label=f\"Predicted {feature}\", color=\"red\")\n",
    "    plt.title(f\"Predicted vs True {feature}\")\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(f\"Normalized {feature} Value\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Total Metrics\n",
    "mse_total = mean_squared_error(y_test, predictions)\n",
    "mae_total = mean_absolute_error(y_test, predictions)\n",
    "r2_total = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"\\nOverall Metrics (All Features):\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_total:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_total:.4f}\")\n",
    "print(f\"R² Score: {r2_total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These tables indicates that the model have a good performance on predicitng close, high, and open, but did bad in volume and close. Howeverm, I design the LSTM for the next 1 day prediction base on previous 30 days, which means that this model works for those people that want to make a decision to sell or keep the stock. By predicting close, high and open is enough to make such a decision.\n",
    "\n",
    "Next I will also compare to other model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mobile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
